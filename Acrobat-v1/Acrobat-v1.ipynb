{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from gym import wrappers\n",
    "    \n",
    "\n",
    "%matplotlib inline\n",
    "# base code from udacity-deep-learning/reinforcement/Q-learning-cart.ipynb\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# $ CUDA_VISIBLE_DEVICES=0 python my_script.py  # Uses GPU 0.\n",
    "# $ CUDA_VISIBLE_DEVICES=1 python my_script.py  # Uses GPU 1.\n",
    "# $ CUDA_VISIBLE_DEVICES=2,3 python my_script.py  # Uses GPUs 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 15:04:24,273] Making new env: Acrobot-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.99859193 -0.05304872  0.99540208  0.09578462 -0.06649392 -0.08276705]\n"
     ]
    }
   ],
   "source": [
    "# Create new cart pole environment\n",
    "env = gym.make('Acrobot-v1')\n",
    "state = env.reset()\n",
    "print(state)\n",
    "action = 2\n",
    "done = 0\n",
    "# while not done:\n",
    "#     env.render()\n",
    "#     next_state, reward, done, _ = env.step(action)\n",
    "#     print(next_state)\n",
    "#     print(reward)\n",
    "#     print(done)\n",
    "\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create class QNetwork\n",
    "class QNetwork:\n",
    "    def __init__(self, \\\n",
    "                 learning_rate=0.01, \\\n",
    "                 state_size=6, \n",
    "                 action_size=3, \\\n",
    "                 hidden_size=10, \\\n",
    "                 hidden_layers=2, \\\n",
    "                 alpha=0., \\\n",
    "                 name='QNetwork'):\n",
    "        \n",
    "        # create Q Network\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, \\\n",
    "                                          [None, state_size], \\\n",
    "                                          name='inputs')\n",
    "            \n",
    "            # placeholder for actions, to be one-hot encoded next\n",
    "            self.actions_ = tf.placeholder(tf.int32, \\\n",
    "                                           [None], \\\n",
    "                                           name='actions')\n",
    "            \n",
    "            # one hot encode actions\n",
    "            one_hot_actions = tf.one_hot(self.actions_, \\\n",
    "                                         action_size)\n",
    "            \n",
    "            # placeholder for target Qs\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, \\\n",
    "                                            [None], \\\n",
    "                                            name='target')\n",
    "            \n",
    "                \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.layers.dense(self.inputs_, \\\n",
    "                                        hidden_size,\\\n",
    "                                        activation=None,\\\n",
    "                                        kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.fc1 = tf.maximum(alpha*self.fc1,self.fc1)\n",
    "            \n",
    "            if hidden_layers == 1:\n",
    "                out_layer = self.fc1\n",
    "            else:\n",
    "                \n",
    "                self.fc2 = tf.layers.dense(self.fc1, hidden_size,\\\n",
    "                                            activation=None,\\\n",
    "                                            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                self.fc2 = tf.maximum(alpha*self.fc2,self.fc2)\n",
    "                \n",
    "                if hidden_layers == 2:\n",
    "                    out_layer = self.fc2\n",
    "                else:\n",
    "                    self.fc3 = tf.layers.dense(self.fc2, hidden_size,\\\n",
    "                                            activation=None,\\\n",
    "                                            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                    self.fc3 = tf.maximum(alpha*self.fc3,self.fc3)\n",
    "                    out_layer = self.fc3\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.layers.dense(out_layer, action_size, \\\n",
    "                                          activation=None,\\\n",
    "                                          kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            ### Train with loss (targetQ - Q)^2\n",
    "            # output has length 2, for two actions. This next line chooses\n",
    "            # one value from output (per row) according to the one-hot encoded actions.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create memory class for storing previous experiences\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_memory_rand_states(memory_size=1000,pretrain_length=20):\n",
    "    # Initialize the simulation\n",
    "    # Make a random action\n",
    "    env.reset()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    memory = Memory(max_size=memory_size)\n",
    "\n",
    "    # Make a bunch of random actions and store the experiences\n",
    "    ii = 0\n",
    "    while ii < pretrain_length or not done:\n",
    "        \n",
    "        # Make a random action\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            # The simulation fails so no next state\n",
    "            next_state = np.zeros(state.shape)\n",
    "            \n",
    "            # Add experience to memory\n",
    "            memory.add((state, action, reward, next_state))\n",
    "\n",
    "            # Start new episode\n",
    "            state = env.reset()\n",
    "\n",
    "        else:\n",
    "            # Add experience to memory\n",
    "            memory.add((state, action, reward, next_state))\n",
    "            state = next_state\n",
    "        \n",
    "        ii = ii + 1\n",
    "            \n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_q_network(train_episodes=500,\\\n",
    "                   gamma=0.99,\\\n",
    "                   explore_start=1.0,\\\n",
    "                   explore_stop=0.01,\\\n",
    "                   decay_rate=0.0001,\\\n",
    "                   hidden_size=64,\\\n",
    "                   hidden_layers=2,\\\n",
    "                   learning_rate=0.0001,\\\n",
    "                   memory_size=10000,\\\n",
    "                   batch_size=20,\\\n",
    "                   max_steps=500,\\\n",
    "                   alpha=0.,\\\n",
    "                   verbose=True):\n",
    "    \n",
    "    \n",
    "    mainQN = QNetwork(name='main', hidden_size=hidden_size, hidden_layers=hidden_layers, learning_rate=learning_rate, alpha=alpha)\n",
    "    \n",
    "    memory = initialize_memory_rand_states(memory_size=memory_size,pretrain_length=batch_size)\n",
    "\n",
    "    state = env.reset()\n",
    "    \n",
    "    # Now train with experiences\n",
    "    saver = tf.train.Saver()\n",
    "    rewards_list = []\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        steps_list = []\n",
    "        \n",
    "        for ep in range(train_episodes):\n",
    "            total_reward = 0\n",
    "            t = 0\n",
    "            \n",
    "            while t < max_steps:\n",
    "                step += 1\n",
    "                # Uncomment this next line to watch the training\n",
    "                # env.render() \n",
    "\n",
    "                # Explore or Exploit\n",
    "                explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "                if explore_p > np.random.rand():\n",
    "                    # Make a random action\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    # Get action from Q-network\n",
    "                    feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                    Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                    action = np.argmax(Qs)\n",
    "\n",
    "                # Take action, get new state and reward\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "                total_reward += reward\n",
    "\n",
    "                if done:\n",
    "                    t = t+1\n",
    "                    # the episode ends so no next state\n",
    "                    next_state = np.zeros(state.shape)\n",
    "                    steps_list.append(total_reward)\n",
    "                    t = max_steps\n",
    "\n",
    "                    # Add experience to memory\n",
    "                    memory.add((state, action, reward, next_state))\n",
    "                    state = env.reset()\n",
    "                else:\n",
    "                    # Add experience to memory\n",
    "                    memory.add((state, action, reward, next_state))\n",
    "                    state = next_state\n",
    "                    t += 1\n",
    "\n",
    "                # Sample mini-batch from memory\n",
    "                batch = memory.sample(batch_size)\n",
    "                states = np.array([each[0] for each in batch])\n",
    "                actions = np.array([each[1] for each in batch])\n",
    "                rewards = np.array([each[2] for each in batch])\n",
    "                next_states = np.array([each[3] for each in batch])\n",
    "\n",
    "                # Train network\n",
    "                target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "\n",
    "                # Set target_Qs to 0 for states where episode ends\n",
    "                episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "                target_Qs[episode_ends] = (0, 0, 0)\n",
    "\n",
    "                targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "                loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                    feed_dict={mainQN.inputs_: states,\n",
    "                                               mainQN.targetQs_: targets,\n",
    "                                               mainQN.actions_: actions})\n",
    "            \n",
    "            rewards_list.append((ep, total_reward))   \n",
    "            runningMean = np.mean(steps_list[-100:])\n",
    "            if verbose:\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p),\n",
    "                      'RunMean : {:.4f}'.format(runningMean))\n",
    "               \n",
    "            \n",
    "            \n",
    "            if runningMean > -60.:\n",
    "                saver.save(sess, \"checkpoints/cartpole.ckpt\")\n",
    "                return rewards_list, mainQN, saver, runningMean\n",
    "            \n",
    "        saver.save(sess, \"checkpoints/cartpole.ckpt\")\n",
    "        return rewards_list, mainQN, saver, runningMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rewards(rewards_list):\n",
    "    eps, rews = np.array(rewards_list).T\n",
    "    smoothed_rews = running_mean(rews, 10)\n",
    "    plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "    plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_q_network(mainQN, saver, test_episodes=100, test_max_steps=500, render=True):\n",
    "\n",
    "\n",
    "    tot_rewards = 0.\n",
    "    rewards_list = []\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "   \n",
    "        state = env.reset()\n",
    "        for ep in range(test_episodes):\n",
    "            t = 0\n",
    "            while t < test_max_steps:\n",
    "                if render:\n",
    "                    env.render() \n",
    "\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "\n",
    "                # Take action, get new state and reward\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                \n",
    "                tot_rewards = tot_rewards + reward\n",
    "                \n",
    "                if done:\n",
    "                    t = test_max_steps\n",
    "                    state = env.reset()\n",
    "                    # Take one random step to get the pole and cart moving\n",
    "                    #state, reward, done, _ = env.step(env.action_space.sample())\n",
    "                    rewards_list.append(tot_rewards)\n",
    "                    tot_rewards = 0.\n",
    "                else:\n",
    "                    state = next_state\n",
    "                    t += 1\n",
    "    mean_rewards = np.mean(rewards_list)         \n",
    "    return mean_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_and_train_qnetwork(train_episodes=1000,\\\n",
    "                   gamma=0.99,\\\n",
    "                   explore_start=1.0,\\\n",
    "                   explore_stop=0.0,\\\n",
    "                   decay_rate=0.0001,\\\n",
    "                   hidden_size=64,\\\n",
    "                   hidden_layers=2,\\\n",
    "                   learning_rate=0.001,\\\n",
    "                   memory_size=10000,\\\n",
    "                   batch_size=20,\\\n",
    "                   test_episodes=10,\\\n",
    "                   render=False,\\\n",
    "                   alpha=0.,\\\n",
    "                   verbose=True):\n",
    "    \n",
    "    # reset graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # train q-network\n",
    "    rewards_list, mainQN, saver, runMean = train_q_network(train_episodes = train_episodes, \\\n",
    "                                                  gamma=gamma,\\\n",
    "                                                  explore_start=explore_start,\\\n",
    "                                                  explore_stop=explore_stop,\\\n",
    "                                                  decay_rate=decay_rate,\\\n",
    "                                                  hidden_size=hidden_size,\\\n",
    "                                                  hidden_layers=hidden_layers,\\\n",
    "                                                  learning_rate=learning_rate,\\\n",
    "                                                  memory_size=memory_size,\\\n",
    "                                                  batch_size=batch_size,\\\n",
    "                                                  alpha=alpha,\\\n",
    "                                                  verbose=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        # plot training\n",
    "        plot_rewards(rewards_list)\n",
    "    \n",
    "\n",
    "    avg_train_rewards = np.sum([each[1] for each in rewards_list]) / len(rewards_list)\n",
    "#     max_train_rewards = np.max([each[1] for each in rewards_list])\n",
    "    if verbose:\n",
    "        print('average training reward = ',avg_train_rewards)\n",
    "\n",
    "    # test q-network\n",
    "    avg_test_rewards = test_q_network(mainQN, saver, test_episodes=test_episodes, render=verbose)\n",
    "    \n",
    "    if verbose:\n",
    "        print('average test reward = ', avg_test_rewards)\n",
    "    \n",
    "    return avg_test_rewards, runMean, mainQN, saver, len(rewards_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:13:39,212] Making new env: Acrobot-v1\n",
      "[2017-05-27 14:13:39,214] Clearing 24 monitor files from previous run (because force=True was provided)\n",
      "[2017-05-27 14:13:40,431] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000000.mp4\n",
      "[2017-05-27 14:13:50,600] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Total reward: -500.0 Training loss: 14.3324 Explore P: 0.9048 RunMean : -500.0000\n",
      "Episode: 1 Total reward: -486.0 Training loss: 12.4525 Explore P: 0.8209 RunMean : -493.0000\n",
      "Episode: 2 Total reward: -336.0 Training loss: 8.5973 Explore P: 0.7674 RunMean : -440.6667\n",
      "Episode: 3 Total reward: -380.0 Training loss: 13.7218 Explore P: 0.7111 RunMean : -425.5000\n",
      "Episode: 4 Total reward: -454.0 Training loss: 8.3095 Explore P: 0.6492 RunMean : -431.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:14:06,993] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5 Total reward: -444.0 Training loss: 10.2077 Explore P: 0.5939 RunMean : -433.3333\n",
      "Episode: 6 Total reward: -500.0 Training loss: 5.9303 Explore P: 0.5374 RunMean : -442.8571\n",
      "Episode: 7 Total reward: -448.0 Training loss: 29.1629 Explore P: 0.4913 RunMean : -443.5000\n",
      "Episode: 8 Total reward: -500.0 Training loss: 45.9373 Explore P: 0.4445 RunMean : -449.7778\n",
      "Episode: 9 Total reward: -500.0 Training loss: 10.8766 Explore P: 0.4022 RunMean : -454.8000\n",
      "Episode: 10 Total reward: -500.0 Training loss: 52.2865 Explore P: 0.3639 RunMean : -458.9091\n",
      "Episode: 11 Total reward: -365.0 Training loss: 18.1040 Explore P: 0.3382 RunMean : -451.0833\n",
      "Episode: 12 Total reward: -500.0 Training loss: 10.8892 Explore P: 0.3061 RunMean : -454.8462\n",
      "Episode: 13 Total reward: -384.0 Training loss: 219.0972 Explore P: 0.2834 RunMean : -449.7857\n",
      "Episode: 14 Total reward: -500.0 Training loss: 9.3904 Explore P: 0.2564 RunMean : -453.1333\n",
      "Episode: 15 Total reward: -500.0 Training loss: 16.7970 Explore P: 0.2320 RunMean : -456.0625\n",
      "Episode: 16 Total reward: -500.0 Training loss: 23.4112 Explore P: 0.2099 RunMean : -458.6471\n",
      "Episode: 17 Total reward: -500.0 Training loss: 11.0019 Explore P: 0.1899 RunMean : -460.9444\n",
      "Episode: 18 Total reward: -494.0 Training loss: 9.6028 Explore P: 0.1720 RunMean : -462.6842\n",
      "Episode: 19 Total reward: -333.0 Training loss: 30.1952 Explore P: 0.1609 RunMean : -456.2000\n",
      "Episode: 20 Total reward: -333.0 Training loss: 11.4165 Explore P: 0.1505 RunMean : -450.3333\n",
      "Episode: 21 Total reward: -397.0 Training loss: 8.7739 Explore P: 0.1390 RunMean : -447.9091\n",
      "Episode: 22 Total reward: -304.0 Training loss: 26.2275 Explore P: 0.1308 RunMean : -441.6522\n",
      "Episode: 23 Total reward: -256.0 Training loss: 19.0044 Explore P: 0.1242 RunMean : -433.9167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:14:46,057] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000027.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 24 Total reward: -202.0 Training loss: 5.5231 Explore P: 0.1193 RunMean : -424.6400\n",
      "Episode: 25 Total reward: -183.0 Training loss: 6.7272 Explore P: 0.1150 RunMean : -415.3462\n",
      "Episode: 26 Total reward: -231.0 Training loss: 12.0029 Explore P: 0.1098 RunMean : -408.5185\n",
      "Episode: 27 Total reward: -211.0 Training loss: 25.8273 Explore P: 0.1052 RunMean : -401.4643\n",
      "Episode: 28 Total reward: -227.0 Training loss: 11.9298 Explore P: 0.1005 RunMean : -395.4483\n",
      "Episode: 29 Total reward: -150.0 Training loss: 21.8064 Explore P: 0.0975 RunMean : -387.2667\n",
      "Episode: 30 Total reward: -128.0 Training loss: 9.9732 Explore P: 0.0950 RunMean : -378.9032\n",
      "Episode: 31 Total reward: -316.0 Training loss: 14.0398 Explore P: 0.0892 RunMean : -376.9375\n",
      "Episode: 32 Total reward: -121.0 Training loss: 14.4431 Explore P: 0.0871 RunMean : -369.1818\n",
      "Episode: 33 Total reward: -165.0 Training loss: 13.5520 Explore P: 0.0842 RunMean : -363.1765\n",
      "Episode: 34 Total reward: -135.0 Training loss: 6.4009 Explore P: 0.0820 RunMean : -356.6571\n",
      "Episode: 35 Total reward: -155.0 Training loss: 6.3441 Explore P: 0.0794 RunMean : -351.0556\n",
      "Episode: 36 Total reward: -190.0 Training loss: 13.3363 Explore P: 0.0765 RunMean : -346.7027\n",
      "Episode: 37 Total reward: -128.0 Training loss: 11.5373 Explore P: 0.0745 RunMean : -340.9474\n",
      "Episode: 38 Total reward: -170.0 Training loss: 8.1949 Explore P: 0.0720 RunMean : -336.5641\n",
      "Episode: 39 Total reward: -475.0 Training loss: 6.9305 Explore P: 0.0655 RunMean : -340.0250\n",
      "Episode: 40 Total reward: -90.0 Training loss: 6.2485 Explore P: 0.0643 RunMean : -333.9268\n",
      "Episode: 41 Total reward: -97.0 Training loss: 5.9217 Explore P: 0.0630 RunMean : -328.2857\n",
      "Episode: 42 Total reward: -91.0 Training loss: 5.9717 Explore P: 0.0619 RunMean : -322.7674\n",
      "Episode: 43 Total reward: -143.0 Training loss: 4.7600 Explore P: 0.0601 RunMean : -318.6818\n",
      "Episode: 44 Total reward: -98.0 Training loss: 6.6355 Explore P: 0.0590 RunMean : -313.7778\n",
      "Episode: 45 Total reward: -96.0 Training loss: 12.8107 Explore P: 0.0578 RunMean : -309.0435\n",
      "Episode: 46 Total reward: -500.0 Training loss: 8.7815 Explore P: 0.0523 RunMean : -313.1064\n",
      "Episode: 47 Total reward: -77.0 Training loss: 4.1892 Explore P: 0.0515 RunMean : -308.1875\n",
      "Episode: 48 Total reward: -87.0 Training loss: 4.1777 Explore P: 0.0506 RunMean : -303.6735\n",
      "Episode: 49 Total reward: -74.0 Training loss: 4.2803 Explore P: 0.0499 RunMean : -299.0800\n",
      "Episode: 50 Total reward: -76.0 Training loss: 6.0672 Explore P: 0.0491 RunMean : -294.7059\n",
      "Episode: 51 Total reward: -146.0 Training loss: 4.2838 Explore P: 0.0477 RunMean : -291.8462\n",
      "Episode: 52 Total reward: -97.0 Training loss: 2.5999 Explore P: 0.0467 RunMean : -288.1698\n",
      "Episode: 53 Total reward: -89.0 Training loss: 3.1960 Explore P: 0.0459 RunMean : -284.4815\n",
      "Episode: 54 Total reward: -110.0 Training loss: 5.5426 Explore P: 0.0449 RunMean : -281.3091\n",
      "Episode: 55 Total reward: -99.0 Training loss: 1.8740 Explore P: 0.0440 RunMean : -278.0536\n",
      "Episode: 56 Total reward: -65.0 Training loss: 4.2820 Explore P: 0.0434 RunMean : -274.3158\n",
      "Episode: 57 Total reward: -76.0 Training loss: 2.3559 Explore P: 0.0428 RunMean : -270.8966\n",
      "Episode: 58 Total reward: -70.0 Training loss: 3.9560 Explore P: 0.0422 RunMean : -267.4915\n",
      "Episode: 59 Total reward: -95.0 Training loss: 2.7742 Explore P: 0.0414 RunMean : -264.6167\n",
      "Episode: 60 Total reward: -136.0 Training loss: 11.2364 Explore P: 0.0403 RunMean : -262.5082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:15:26,842] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000064.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 61 Total reward: -115.0 Training loss: 3.2965 Explore P: 0.0393 RunMean : -260.1290\n",
      "Episode: 62 Total reward: -117.0 Training loss: 4.4724 Explore P: 0.0384 RunMean : -257.8571\n",
      "Episode: 63 Total reward: -135.0 Training loss: 8.9516 Explore P: 0.0374 RunMean : -255.9375\n",
      "Episode: 64 Total reward: -95.0 Training loss: 3.2227 Explore P: 0.0367 RunMean : -253.4615\n",
      "Episode: 65 Total reward: -96.0 Training loss: 4.2473 Explore P: 0.0360 RunMean : -251.0758\n",
      "Episode: 66 Total reward: -83.0 Training loss: 5.7654 Explore P: 0.0354 RunMean : -248.5672\n",
      "Episode: 67 Total reward: -85.0 Training loss: 4.3838 Explore P: 0.0348 RunMean : -246.1618\n",
      "Episode: 68 Total reward: -92.0 Training loss: 3.0446 Explore P: 0.0341 RunMean : -243.9275\n",
      "Episode: 69 Total reward: -338.0 Training loss: 7.0566 Explore P: 0.0319 RunMean : -245.2714\n",
      "Episode: 70 Total reward: -96.0 Training loss: 5.4665 Explore P: 0.0313 RunMean : -243.1690\n",
      "Episode: 71 Total reward: -104.0 Training loss: 4.2883 Explore P: 0.0306 RunMean : -241.2361\n",
      "Episode: 72 Total reward: -145.0 Training loss: 6.5185 Explore P: 0.0297 RunMean : -239.9178\n",
      "Episode: 73 Total reward: -106.0 Training loss: 6.7487 Explore P: 0.0291 RunMean : -238.1081\n",
      "Episode: 74 Total reward: -85.0 Training loss: 4.5300 Explore P: 0.0286 RunMean : -236.0667\n",
      "Episode: 75 Total reward: -80.0 Training loss: 4.5191 Explore P: 0.0282 RunMean : -234.0132\n",
      "Episode: 76 Total reward: -125.0 Training loss: 2.8270 Explore P: 0.0275 RunMean : -232.5974\n",
      "Episode: 77 Total reward: -86.0 Training loss: 8.1384 Explore P: 0.0270 RunMean : -230.7179\n",
      "Episode: 78 Total reward: -118.0 Training loss: 26.8426 Explore P: 0.0263 RunMean : -229.2911\n",
      "Episode: 79 Total reward: -85.0 Training loss: 2.8964 Explore P: 0.0259 RunMean : -227.4875\n",
      "Episode: 80 Total reward: -214.0 Training loss: 2.6004 Explore P: 0.0248 RunMean : -227.3210\n",
      "Episode: 81 Total reward: -84.0 Training loss: 11.1839 Explore P: 0.0244 RunMean : -225.5732\n",
      "Episode: 82 Total reward: -84.0 Training loss: 3.1664 Explore P: 0.0240 RunMean : -223.8675\n",
      "Episode: 83 Total reward: -69.0 Training loss: 3.8882 Explore P: 0.0236 RunMean : -222.0238\n",
      "Episode: 84 Total reward: -95.0 Training loss: 12.9605 Explore P: 0.0232 RunMean : -220.5294\n",
      "Episode: 85 Total reward: -98.0 Training loss: 3.8148 Explore P: 0.0227 RunMean : -219.1047\n",
      "Episode: 86 Total reward: -108.0 Training loss: 1.7786 Explore P: 0.0223 RunMean : -217.8276\n",
      "Episode: 87 Total reward: -100.0 Training loss: 7.4874 Explore P: 0.0218 RunMean : -216.4886\n",
      "Episode: 88 Total reward: -84.0 Training loss: 3.8497 Explore P: 0.0214 RunMean : -215.0000\n",
      "Episode: 89 Total reward: -94.0 Training loss: 13.1327 Explore P: 0.0210 RunMean : -213.6556\n",
      "Episode: 90 Total reward: -110.0 Training loss: 4.8032 Explore P: 0.0206 RunMean : -212.5165\n",
      "Episode: 91 Total reward: -103.0 Training loss: 5.9667 Explore P: 0.0201 RunMean : -211.3261\n",
      "Episode: 92 Total reward: -78.0 Training loss: 5.8238 Explore P: 0.0198 RunMean : -209.8925\n",
      "Episode: 93 Total reward: -136.0 Training loss: 3.4654 Explore P: 0.0193 RunMean : -209.1064\n",
      "Episode: 94 Total reward: -80.0 Training loss: 3.1604 Explore P: 0.0190 RunMean : -207.7474\n",
      "Episode: 95 Total reward: -101.0 Training loss: 2.2747 Explore P: 0.0186 RunMean : -206.6354\n",
      "Episode: 96 Total reward: -86.0 Training loss: 6.7664 Explore P: 0.0183 RunMean : -205.3918\n",
      "Episode: 97 Total reward: -87.0 Training loss: 2.8518 Explore P: 0.0180 RunMean : -204.1837\n",
      "Episode: 98 Total reward: -128.0 Training loss: 6.4055 Explore P: 0.0175 RunMean : -203.4141\n",
      "Episode: 99 Total reward: -208.0 Training loss: 12.0423 Explore P: 0.0168 RunMean : -203.4600\n",
      "Episode: 100 Total reward: -72.0 Training loss: 4.7421 Explore P: 0.0165 RunMean : -199.1800\n",
      "Episode: 101 Total reward: -91.0 Training loss: 3.0956 Explore P: 0.0162 RunMean : -195.2300\n",
      "Episode: 102 Total reward: -154.0 Training loss: 7.6543 Explore P: 0.0157 RunMean : -193.4100\n",
      "Episode: 103 Total reward: -98.0 Training loss: 6.1039 Explore P: 0.0154 RunMean : -190.5900\n",
      "Episode: 104 Total reward: -224.0 Training loss: 3.1977 Explore P: 0.0148 RunMean : -188.2900\n",
      "Episode: 105 Total reward: -123.0 Training loss: 10.1311 Explore P: 0.0144 RunMean : -185.0800\n",
      "Episode: 106 Total reward: -127.0 Training loss: 5.9578 Explore P: 0.0140 RunMean : -181.3500\n",
      "Episode: 107 Total reward: -133.0 Training loss: 3.3588 Explore P: 0.0137 RunMean : -178.2000\n",
      "Episode: 108 Total reward: -111.0 Training loss: 1.9203 Explore P: 0.0134 RunMean : -174.3100\n",
      "Episode: 109 Total reward: -97.0 Training loss: 3.4108 Explore P: 0.0131 RunMean : -170.2800\n",
      "Episode: 110 Total reward: -124.0 Training loss: 1.5522 Explore P: 0.0128 RunMean : -166.5200\n",
      "Episode: 111 Total reward: -119.0 Training loss: 12.3438 Explore P: 0.0125 RunMean : -164.0600\n",
      "Episode: 112 Total reward: -127.0 Training loss: 3.4254 Explore P: 0.0122 RunMean : -160.3300\n",
      "Episode: 113 Total reward: -131.0 Training loss: 5.7882 Explore P: 0.0118 RunMean : -157.8000\n",
      "Episode: 114 Total reward: -118.0 Training loss: 8.6928 Explore P: 0.0116 RunMean : -153.9800\n",
      "Episode: 115 Total reward: -118.0 Training loss: 7.9282 Explore P: 0.0113 RunMean : -150.1600\n",
      "Episode: 116 Total reward: -126.0 Training loss: 6.0401 Explore P: 0.0110 RunMean : -146.4200\n",
      "Episode: 117 Total reward: -80.0 Training loss: 10.3255 Explore P: 0.0108 RunMean : -142.2200\n",
      "Episode: 118 Total reward: -135.0 Training loss: 7.2779 Explore P: 0.0105 RunMean : -138.6300\n",
      "Episode: 119 Total reward: -131.0 Training loss: 4.2273 Explore P: 0.0103 RunMean : -136.6100\n",
      "Episode: 120 Total reward: -124.0 Training loss: 3.4786 Explore P: 0.0100 RunMean : -134.5200\n",
      "Episode: 121 Total reward: -134.0 Training loss: 7.1402 Explore P: 0.0097 RunMean : -131.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:16:24,386] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 122 Total reward: -110.0 Training loss: 5.8172 Explore P: 0.0095 RunMean : -129.9500\n",
      "Episode: 123 Total reward: -124.0 Training loss: 7.1110 Explore P: 0.0093 RunMean : -128.6300\n",
      "Episode: 124 Total reward: -113.0 Training loss: 8.8850 Explore P: 0.0091 RunMean : -127.7400\n",
      "Episode: 125 Total reward: -131.0 Training loss: 4.3446 Explore P: 0.0089 RunMean : -127.2200\n",
      "Episode: 126 Total reward: -93.0 Training loss: 4.1852 Explore P: 0.0087 RunMean : -125.8400\n",
      "Episode: 127 Total reward: -79.0 Training loss: 2.6654 Explore P: 0.0085 RunMean : -124.5200\n",
      "Episode: 128 Total reward: -112.0 Training loss: 2.4275 Explore P: 0.0084 RunMean : -123.3700\n",
      "Episode: 129 Total reward: -98.0 Training loss: 3.8092 Explore P: 0.0082 RunMean : -122.8500\n",
      "Episode: 130 Total reward: -81.0 Training loss: 3.9755 Explore P: 0.0081 RunMean : -122.3800\n",
      "Episode: 131 Total reward: -103.0 Training loss: 3.2483 Explore P: 0.0079 RunMean : -120.2500\n",
      "Episode: 132 Total reward: -149.0 Training loss: 8.5638 Explore P: 0.0077 RunMean : -120.5300\n",
      "Episode: 133 Total reward: -123.0 Training loss: 4.5795 Explore P: 0.0075 RunMean : -120.1100\n",
      "Episode: 134 Total reward: -116.0 Training loss: 3.6974 Explore P: 0.0073 RunMean : -119.9200\n",
      "Episode: 135 Total reward: -120.0 Training loss: 5.6882 Explore P: 0.0071 RunMean : -119.5700\n",
      "Episode: 136 Total reward: -153.0 Training loss: 5.4455 Explore P: 0.0069 RunMean : -119.2000\n",
      "Episode: 137 Total reward: -93.0 Training loss: 5.6256 Explore P: 0.0068 RunMean : -118.8500\n",
      "Episode: 138 Total reward: -183.0 Training loss: 9.8028 Explore P: 0.0065 RunMean : -118.9800\n",
      "Episode: 139 Total reward: -141.0 Training loss: 5.2597 Explore P: 0.0064 RunMean : -115.6400\n",
      "Episode: 140 Total reward: -202.0 Training loss: 3.9648 Explore P: 0.0061 RunMean : -116.7600\n",
      "Episode: 141 Total reward: -125.0 Training loss: 2.7742 Explore P: 0.0059 RunMean : -117.0400\n",
      "Episode: 142 Total reward: -500.0 Training loss: 3.5006 Explore P: 0.0054 RunMean : -121.1300\n",
      "Episode: 143 Total reward: -117.0 Training loss: 17.5520 Explore P: 0.0053 RunMean : -120.8700\n",
      "Episode: 144 Total reward: -74.0 Training loss: 5.9689 Explore P: 0.0052 RunMean : -120.6300\n",
      "Episode: 145 Total reward: -98.0 Training loss: 13.0888 Explore P: 0.0051 RunMean : -120.6500\n",
      "Episode: 146 Total reward: -239.0 Training loss: 4.4006 Explore P: 0.0048 RunMean : -118.0400\n",
      "Episode: 147 Total reward: -94.0 Training loss: 3.7572 Explore P: 0.0047 RunMean : -118.2100\n",
      "Episode: 148 Total reward: -138.0 Training loss: 6.2662 Explore P: 0.0046 RunMean : -118.7200\n",
      "Episode: 149 Total reward: -107.0 Training loss: 8.9345 Explore P: 0.0045 RunMean : -119.0500\n",
      "Episode: 150 Total reward: -106.0 Training loss: 3.0820 Explore P: 0.0044 RunMean : -119.3500\n",
      "Episode: 151 Total reward: -88.0 Training loss: 4.1450 Explore P: 0.0043 RunMean : -118.7700\n",
      "Episode: 152 Total reward: -106.0 Training loss: 11.9627 Explore P: 0.0043 RunMean : -118.8600\n",
      "Episode: 153 Total reward: -114.0 Training loss: 3.3407 Explore P: 0.0042 RunMean : -119.1100\n",
      "Episode: 154 Total reward: -86.0 Training loss: 2.5932 Explore P: 0.0041 RunMean : -118.8700\n",
      "Episode: 155 Total reward: -121.0 Training loss: 8.2268 Explore P: 0.0040 RunMean : -119.0900\n",
      "Episode: 156 Total reward: -143.0 Training loss: 3.1048 Explore P: 0.0039 RunMean : -119.8700\n",
      "Episode: 157 Total reward: -173.0 Training loss: 6.7284 Explore P: 0.0037 RunMean : -120.8400\n",
      "Episode: 158 Total reward: -170.0 Training loss: 5.7441 Explore P: 0.0036 RunMean : -121.8400\n",
      "Episode: 159 Total reward: -134.0 Training loss: 7.3832 Explore P: 0.0035 RunMean : -122.2300\n",
      "Episode: 160 Total reward: -145.0 Training loss: 2.9363 Explore P: 0.0034 RunMean : -122.3200\n",
      "Episode: 161 Total reward: -75.0 Training loss: 3.4938 Explore P: 0.0034 RunMean : -121.9200\n",
      "Episode: 162 Total reward: -111.0 Training loss: 10.1424 Explore P: 0.0033 RunMean : -121.8600\n",
      "Episode: 163 Total reward: -122.0 Training loss: 4.6213 Explore P: 0.0032 RunMean : -121.7300\n",
      "Episode: 164 Total reward: -104.0 Training loss: 3.0419 Explore P: 0.0031 RunMean : -121.8200\n",
      "Episode: 165 Total reward: -155.0 Training loss: 33.2399 Explore P: 0.0030 RunMean : -122.4100\n",
      "Episode: 166 Total reward: -92.0 Training loss: 4.1672 Explore P: 0.0030 RunMean : -122.5000\n",
      "Episode: 167 Total reward: -100.0 Training loss: 4.5753 Explore P: 0.0029 RunMean : -122.6500\n",
      "Episode: 168 Total reward: -246.0 Training loss: 5.3480 Explore P: 0.0028 RunMean : -124.1900\n",
      "Episode: 169 Total reward: -118.0 Training loss: 2.5544 Explore P: 0.0027 RunMean : -121.9900\n",
      "Episode: 170 Total reward: -90.0 Training loss: 5.7729 Explore P: 0.0027 RunMean : -121.9300\n",
      "Episode: 171 Total reward: -106.0 Training loss: 5.2444 Explore P: 0.0026 RunMean : -121.9500\n",
      "Episode: 172 Total reward: -77.0 Training loss: 4.3538 Explore P: 0.0026 RunMean : -121.2700\n",
      "Episode: 173 Total reward: -76.0 Training loss: 4.9021 Explore P: 0.0025 RunMean : -120.9700\n",
      "Episode: 174 Total reward: -86.0 Training loss: 2.3408 Explore P: 0.0025 RunMean : -120.9800\n",
      "Episode: 175 Total reward: -104.0 Training loss: 3.1145 Explore P: 0.0024 RunMean : -121.2200\n",
      "Episode: 176 Total reward: -89.0 Training loss: 5.5025 Explore P: 0.0024 RunMean : -120.8600\n",
      "Episode: 177 Total reward: -100.0 Training loss: 3.4589 Explore P: 0.0024 RunMean : -121.0000\n",
      "Episode: 178 Total reward: -166.0 Training loss: 3.6038 Explore P: 0.0023 RunMean : -121.4800\n",
      "Episode: 179 Total reward: -126.0 Training loss: 5.5862 Explore P: 0.0022 RunMean : -121.8900\n",
      "Episode: 180 Total reward: -101.0 Training loss: 6.5195 Explore P: 0.0022 RunMean : -120.7600\n",
      "Episode: 181 Total reward: -72.0 Training loss: 5.2832 Explore P: 0.0021 RunMean : -120.6400\n",
      "Episode: 182 Total reward: -90.0 Training loss: 2.5523 Explore P: 0.0021 RunMean : -120.7000\n",
      "Episode: 183 Total reward: -76.0 Training loss: 5.1637 Explore P: 0.0021 RunMean : -120.7700\n",
      "Episode: 184 Total reward: -90.0 Training loss: 3.8672 Explore P: 0.0020 RunMean : -120.7200\n",
      "Episode: 185 Total reward: -119.0 Training loss: 2.5718 Explore P: 0.0020 RunMean : -120.9300\n",
      "Episode: 186 Total reward: -93.0 Training loss: 3.3594 Explore P: 0.0019 RunMean : -120.7800\n",
      "Episode: 187 Total reward: -113.0 Training loss: 3.4492 Explore P: 0.0019 RunMean : -120.9100\n",
      "Episode: 188 Total reward: -77.0 Training loss: 4.5038 Explore P: 0.0019 RunMean : -120.8400\n",
      "Episode: 189 Total reward: -79.0 Training loss: 3.5118 Explore P: 0.0018 RunMean : -120.6900\n",
      "Episode: 190 Total reward: -108.0 Training loss: 5.5390 Explore P: 0.0018 RunMean : -120.6700\n",
      "Episode: 191 Total reward: -84.0 Training loss: 3.3000 Explore P: 0.0018 RunMean : -120.4800\n",
      "Episode: 192 Total reward: -112.0 Training loss: 4.4257 Explore P: 0.0017 RunMean : -120.8200\n",
      "Episode: 193 Total reward: -84.0 Training loss: 6.3296 Explore P: 0.0017 RunMean : -120.3000\n",
      "Episode: 194 Total reward: -106.0 Training loss: 3.7969 Explore P: 0.0017 RunMean : -120.5600\n",
      "Episode: 195 Total reward: -100.0 Training loss: 5.1768 Explore P: 0.0016 RunMean : -120.5500\n",
      "Episode: 196 Total reward: -103.0 Training loss: 6.4966 Explore P: 0.0016 RunMean : -120.7200\n",
      "Episode: 197 Total reward: -83.0 Training loss: 4.3666 Explore P: 0.0016 RunMean : -120.6800\n",
      "Episode: 198 Total reward: -77.0 Training loss: 7.3812 Explore P: 0.0016 RunMean : -120.1700\n",
      "Episode: 199 Total reward: -80.0 Training loss: 2.2937 Explore P: 0.0015 RunMean : -118.8900\n",
      "Episode: 200 Total reward: -107.0 Training loss: 4.8588 Explore P: 0.0015 RunMean : -119.2400\n",
      "Episode: 201 Total reward: -93.0 Training loss: 3.5147 Explore P: 0.0015 RunMean : -119.2600\n",
      "Episode: 202 Total reward: -81.0 Training loss: 7.2619 Explore P: 0.0014 RunMean : -118.5300\n",
      "Episode: 203 Total reward: -72.0 Training loss: 12.7324 Explore P: 0.0014 RunMean : -118.2700\n",
      "Episode: 204 Total reward: -93.0 Training loss: 5.4389 Explore P: 0.0014 RunMean : -116.9600\n",
      "Episode: 205 Total reward: -119.0 Training loss: 4.6503 Explore P: 0.0014 RunMean : -116.9200\n",
      "Episode: 206 Total reward: -76.0 Training loss: 3.8131 Explore P: 0.0013 RunMean : -116.4100\n",
      "Episode: 207 Total reward: -94.0 Training loss: 2.2733 Explore P: 0.0013 RunMean : -116.0200\n",
      "Episode: 208 Total reward: -81.0 Training loss: 8.1450 Explore P: 0.0013 RunMean : -115.7200\n",
      "Episode: 209 Total reward: -83.0 Training loss: 21.9977 Explore P: 0.0013 RunMean : -115.5800\n",
      "Episode: 210 Total reward: -103.0 Training loss: 7.6875 Explore P: 0.0012 RunMean : -115.3700\n",
      "Episode: 211 Total reward: -82.0 Training loss: 6.2268 Explore P: 0.0012 RunMean : -115.0000\n",
      "Episode: 212 Total reward: -83.0 Training loss: 2.6752 Explore P: 0.0012 RunMean : -114.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:17:43,775] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000216.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 213 Total reward: -128.0 Training loss: 3.9442 Explore P: 0.0012 RunMean : -114.5300\n",
      "Episode: 214 Total reward: -500.0 Training loss: 3.5306 Explore P: 0.0011 RunMean : -118.3500\n",
      "Episode: 215 Total reward: -105.0 Training loss: 4.5613 Explore P: 0.0010 RunMean : -118.2200\n",
      "Episode: 216 Total reward: -76.0 Training loss: 4.0832 Explore P: 0.0010 RunMean : -117.7200\n",
      "Episode: 217 Total reward: -71.0 Training loss: 2.9461 Explore P: 0.0010 RunMean : -117.6300\n",
      "Episode: 218 Total reward: -98.0 Training loss: 7.8747 Explore P: 0.0010 RunMean : -117.2600\n",
      "Episode: 219 Total reward: -148.0 Training loss: 5.5481 Explore P: 0.0010 RunMean : -117.4300\n",
      "Episode: 220 Total reward: -71.0 Training loss: 10.8208 Explore P: 0.0009 RunMean : -116.9000\n",
      "Episode: 221 Total reward: -79.0 Training loss: 5.7130 Explore P: 0.0009 RunMean : -116.3500\n",
      "Episode: 222 Total reward: -113.0 Training loss: 2.8961 Explore P: 0.0009 RunMean : -116.3800\n",
      "Episode: 223 Total reward: -105.0 Training loss: 3.2483 Explore P: 0.0009 RunMean : -116.1900\n",
      "Episode: 224 Total reward: -89.0 Training loss: 6.5403 Explore P: 0.0009 RunMean : -115.9500\n",
      "Episode: 225 Total reward: -189.0 Training loss: 6.6575 Explore P: 0.0008 RunMean : -116.5300\n",
      "Episode: 226 Total reward: -72.0 Training loss: 6.1495 Explore P: 0.0008 RunMean : -116.3200\n",
      "Episode: 227 Total reward: -94.0 Training loss: 2.5031 Explore P: 0.0008 RunMean : -116.4700\n",
      "Episode: 228 Total reward: -71.0 Training loss: 5.5065 Explore P: 0.0008 RunMean : -116.0600\n",
      "Episode: 229 Total reward: -138.0 Training loss: 4.4880 Explore P: 0.0008 RunMean : -116.4600\n",
      "Episode: 230 Total reward: -237.0 Training loss: 5.6676 Explore P: 0.0007 RunMean : -118.0200\n",
      "Episode: 231 Total reward: -83.0 Training loss: 3.1001 Explore P: 0.0007 RunMean : -117.8200\n",
      "Episode: 232 Total reward: -120.0 Training loss: 3.7452 Explore P: 0.0007 RunMean : -117.5300\n",
      "Episode: 233 Total reward: -119.0 Training loss: 5.6075 Explore P: 0.0007 RunMean : -117.4900\n",
      "Episode: 234 Total reward: -99.0 Training loss: 4.2379 Explore P: 0.0007 RunMean : -117.3200\n",
      "Episode: 235 Total reward: -135.0 Training loss: 4.5020 Explore P: 0.0007 RunMean : -117.4700\n",
      "Episode: 236 Total reward: -89.0 Training loss: 3.7980 Explore P: 0.0007 RunMean : -116.8300\n",
      "Episode: 237 Total reward: -93.0 Training loss: 9.5165 Explore P: 0.0006 RunMean : -116.8300\n",
      "Episode: 238 Total reward: -106.0 Training loss: 12.4372 Explore P: 0.0006 RunMean : -116.0600\n",
      "Episode: 239 Total reward: -96.0 Training loss: 8.3996 Explore P: 0.0006 RunMean : -115.6100\n",
      "Episode: 240 Total reward: -114.0 Training loss: 4.8366 Explore P: 0.0006 RunMean : -114.7300\n",
      "Episode: 241 Total reward: -95.0 Training loss: 3.5943 Explore P: 0.0006 RunMean : -114.4300\n",
      "Episode: 242 Total reward: -92.0 Training loss: 3.6065 Explore P: 0.0006 RunMean : -110.3500\n",
      "Episode: 243 Total reward: -136.0 Training loss: 3.3541 Explore P: 0.0006 RunMean : -110.5400\n",
      "Episode: 244 Total reward: -168.0 Training loss: 2.0424 Explore P: 0.0005 RunMean : -111.4800\n",
      "Episode: 245 Total reward: -103.0 Training loss: 3.5944 Explore P: 0.0005 RunMean : -111.5300\n",
      "Episode: 246 Total reward: -128.0 Training loss: 4.1380 Explore P: 0.0005 RunMean : -110.4200\n",
      "Episode: 247 Total reward: -100.0 Training loss: 3.8145 Explore P: 0.0005 RunMean : -110.4800\n",
      "Episode: 248 Total reward: -120.0 Training loss: 4.6535 Explore P: 0.0005 RunMean : -110.3000\n",
      "Episode: 249 Total reward: -85.0 Training loss: 2.7064 Explore P: 0.0005 RunMean : -110.0800\n",
      "Episode: 250 Total reward: -109.0 Training loss: 3.6059 Explore P: 0.0005 RunMean : -110.1100\n",
      "Episode: 251 Total reward: -87.0 Training loss: 4.2298 Explore P: 0.0005 RunMean : -110.1000\n",
      "Episode: 252 Total reward: -87.0 Training loss: 3.3166 Explore P: 0.0005 RunMean : -109.9100\n",
      "Episode: 253 Total reward: -172.0 Training loss: 3.2201 Explore P: 0.0004 RunMean : -110.4900\n",
      "Episode: 254 Total reward: -108.0 Training loss: 6.9748 Explore P: 0.0004 RunMean : -110.7100\n",
      "Episode: 255 Total reward: -135.0 Training loss: 2.1210 Explore P: 0.0004 RunMean : -110.8500\n",
      "Episode: 256 Total reward: -95.0 Training loss: 7.6524 Explore P: 0.0004 RunMean : -110.3700\n",
      "Episode: 257 Total reward: -123.0 Training loss: 5.2077 Explore P: 0.0004 RunMean : -109.8700\n",
      "Episode: 258 Total reward: -97.0 Training loss: 5.9694 Explore P: 0.0004 RunMean : -109.1400\n",
      "Episode: 259 Total reward: -101.0 Training loss: 3.4724 Explore P: 0.0004 RunMean : -108.8100\n",
      "Episode: 260 Total reward: -82.0 Training loss: 6.3286 Explore P: 0.0004 RunMean : -108.1800\n",
      "Episode: 261 Total reward: -152.0 Training loss: 2.9151 Explore P: 0.0004 RunMean : -108.9500\n",
      "Episode: 262 Total reward: -85.0 Training loss: 6.3722 Explore P: 0.0004 RunMean : -108.6900\n",
      "Episode: 263 Total reward: -141.0 Training loss: 1.8365 Explore P: 0.0004 RunMean : -108.8800\n",
      "Episode: 264 Total reward: -86.0 Training loss: 1.8812 Explore P: 0.0004 RunMean : -108.7000\n",
      "Episode: 265 Total reward: -71.0 Training loss: 1.9257 Explore P: 0.0003 RunMean : -107.8600\n",
      "Episode: 266 Total reward: -111.0 Training loss: 3.6781 Explore P: 0.0003 RunMean : -108.0500\n",
      "Episode: 267 Total reward: -113.0 Training loss: 3.5625 Explore P: 0.0003 RunMean : -108.1800\n",
      "Episode: 268 Total reward: -107.0 Training loss: 2.8242 Explore P: 0.0003 RunMean : -106.7900\n",
      "Episode: 269 Total reward: -109.0 Training loss: 2.8423 Explore P: 0.0003 RunMean : -106.7000\n",
      "Episode: 270 Total reward: -104.0 Training loss: 4.9462 Explore P: 0.0003 RunMean : -106.8400\n",
      "Episode: 271 Total reward: -108.0 Training loss: 1.8990 Explore P: 0.0003 RunMean : -106.8600\n",
      "Episode: 272 Total reward: -148.0 Training loss: 4.1631 Explore P: 0.0003 RunMean : -107.5700\n",
      "Episode: 273 Total reward: -92.0 Training loss: 4.1567 Explore P: 0.0003 RunMean : -107.7300\n",
      "Episode: 274 Total reward: -78.0 Training loss: 12.6678 Explore P: 0.0003 RunMean : -107.6500\n",
      "Episode: 275 Total reward: -107.0 Training loss: 3.8609 Explore P: 0.0003 RunMean : -107.6800\n",
      "Episode: 276 Total reward: -97.0 Training loss: 2.9735 Explore P: 0.0003 RunMean : -107.7600\n",
      "Episode: 277 Total reward: -131.0 Training loss: 3.4324 Explore P: 0.0003 RunMean : -108.0700\n",
      "Episode: 278 Total reward: -106.0 Training loss: 4.0177 Explore P: 0.0003 RunMean : -107.4700\n",
      "Episode: 279 Total reward: -108.0 Training loss: 3.6199 Explore P: 0.0003 RunMean : -107.2900\n",
      "Episode: 280 Total reward: -112.0 Training loss: 3.2598 Explore P: 0.0002 RunMean : -107.4000\n",
      "Episode: 281 Total reward: -122.0 Training loss: 2.8568 Explore P: 0.0002 RunMean : -107.9000\n",
      "Episode: 282 Total reward: -114.0 Training loss: 2.4017 Explore P: 0.0002 RunMean : -108.1400\n",
      "Episode: 283 Total reward: -105.0 Training loss: 4.7900 Explore P: 0.0002 RunMean : -108.4300\n",
      "Episode: 284 Total reward: -112.0 Training loss: 3.3593 Explore P: 0.0002 RunMean : -108.6500\n",
      "Episode: 285 Total reward: -168.0 Training loss: 3.3889 Explore P: 0.0002 RunMean : -109.1400\n",
      "Episode: 286 Total reward: -127.0 Training loss: 3.7444 Explore P: 0.0002 RunMean : -109.4800\n",
      "Episode: 287 Total reward: -83.0 Training loss: 3.9574 Explore P: 0.0002 RunMean : -109.1800\n",
      "Episode: 288 Total reward: -75.0 Training loss: 6.9818 Explore P: 0.0002 RunMean : -109.1600\n",
      "Episode: 289 Total reward: -141.0 Training loss: 4.3749 Explore P: 0.0002 RunMean : -109.7800\n",
      "Episode: 290 Total reward: -98.0 Training loss: 2.6061 Explore P: 0.0002 RunMean : -109.6800\n",
      "Episode: 291 Total reward: -190.0 Training loss: 3.1677 Explore P: 0.0002 RunMean : -110.7400\n",
      "Episode: 292 Total reward: -132.0 Training loss: 2.2531 Explore P: 0.0002 RunMean : -110.9400\n",
      "Episode: 293 Total reward: -122.0 Training loss: 10.6028 Explore P: 0.0002 RunMean : -111.3200\n",
      "Episode: 294 Total reward: -71.0 Training loss: 5.5580 Explore P: 0.0002 RunMean : -110.9700\n",
      "Episode: 295 Total reward: -122.0 Training loss: 3.8979 Explore P: 0.0002 RunMean : -111.1900\n",
      "Episode: 296 Total reward: -126.0 Training loss: 3.9619 Explore P: 0.0002 RunMean : -111.4200\n",
      "Episode: 297 Total reward: -87.0 Training loss: 6.8051 Explore P: 0.0002 RunMean : -111.4600\n",
      "Episode: 298 Total reward: -92.0 Training loss: 4.1911 Explore P: 0.0002 RunMean : -111.6100\n",
      "Episode: 299 Total reward: -127.0 Training loss: 2.0093 Explore P: 0.0002 RunMean : -112.0800\n",
      "Episode: 300 Total reward: -109.0 Training loss: 4.4194 Explore P: 0.0002 RunMean : -112.1000\n",
      "Episode: 301 Total reward: -114.0 Training loss: 2.2983 Explore P: 0.0002 RunMean : -112.3100\n",
      "Episode: 302 Total reward: -96.0 Training loss: 3.1551 Explore P: 0.0001 RunMean : -112.4600\n",
      "Episode: 303 Total reward: -144.0 Training loss: 4.5212 Explore P: 0.0001 RunMean : -113.1800\n",
      "Episode: 304 Total reward: -174.0 Training loss: 3.3279 Explore P: 0.0001 RunMean : -113.9900\n",
      "Episode: 305 Total reward: -70.0 Training loss: 3.7010 Explore P: 0.0001 RunMean : -113.5000\n",
      "Episode: 306 Total reward: -122.0 Training loss: 2.6754 Explore P: 0.0001 RunMean : -113.9600\n",
      "Episode: 307 Total reward: -110.0 Training loss: 3.4110 Explore P: 0.0001 RunMean : -114.1200\n",
      "Episode: 308 Total reward: -127.0 Training loss: 3.7433 Explore P: 0.0001 RunMean : -114.5800\n",
      "Episode: 309 Total reward: -117.0 Training loss: 5.2504 Explore P: 0.0001 RunMean : -114.9200\n",
      "Episode: 310 Total reward: -138.0 Training loss: 3.6064 Explore P: 0.0001 RunMean : -115.2700\n",
      "Episode: 311 Total reward: -93.0 Training loss: 3.6876 Explore P: 0.0001 RunMean : -115.3800\n",
      "Episode: 312 Total reward: -113.0 Training loss: 5.8322 Explore P: 0.0001 RunMean : -115.6800\n",
      "Episode: 313 Total reward: -73.0 Training loss: 3.5799 Explore P: 0.0001 RunMean : -115.1300\n",
      "Episode: 314 Total reward: -62.0 Training loss: 5.3535 Explore P: 0.0001 RunMean : -110.7500\n",
      "Episode: 315 Total reward: -144.0 Training loss: 4.8513 Explore P: 0.0001 RunMean : -111.1400\n",
      "Episode: 316 Total reward: -141.0 Training loss: 2.6381 Explore P: 0.0001 RunMean : -111.7900\n",
      "Episode: 317 Total reward: -82.0 Training loss: 3.9530 Explore P: 0.0001 RunMean : -111.9000\n",
      "Episode: 318 Total reward: -124.0 Training loss: 5.0552 Explore P: 0.0001 RunMean : -112.1600\n",
      "Episode: 319 Total reward: -92.0 Training loss: 9.8707 Explore P: 0.0001 RunMean : -111.6000\n",
      "Episode: 320 Total reward: -119.0 Training loss: 2.9611 Explore P: 0.0001 RunMean : -112.0800\n",
      "Episode: 321 Total reward: -125.0 Training loss: 2.1981 Explore P: 0.0001 RunMean : -112.5400\n",
      "Episode: 322 Total reward: -123.0 Training loss: 2.8780 Explore P: 0.0001 RunMean : -112.6400\n",
      "Episode: 323 Total reward: -123.0 Training loss: 3.6941 Explore P: 0.0001 RunMean : -112.8200\n",
      "Episode: 324 Total reward: -165.0 Training loss: 3.2454 Explore P: 0.0001 RunMean : -113.5800\n",
      "Episode: 325 Total reward: -99.0 Training loss: 3.0917 Explore P: 0.0001 RunMean : -112.6800\n",
      "Episode: 326 Total reward: -125.0 Training loss: 4.2828 Explore P: 0.0001 RunMean : -113.2100\n",
      "Episode: 327 Total reward: -129.0 Training loss: 2.7471 Explore P: 0.0001 RunMean : -113.5600\n",
      "Episode: 328 Total reward: -130.0 Training loss: 1.9014 Explore P: 0.0001 RunMean : -114.1500\n",
      "Episode: 329 Total reward: -100.0 Training loss: 6.2777 Explore P: 0.0001 RunMean : -113.7700\n",
      "Episode: 330 Total reward: -101.0 Training loss: 2.6081 Explore P: 0.0001 RunMean : -112.4100\n",
      "Episode: 331 Total reward: -112.0 Training loss: 2.7589 Explore P: 0.0001 RunMean : -112.7000\n",
      "Episode: 332 Total reward: -86.0 Training loss: 4.8163 Explore P: 0.0001 RunMean : -112.3600\n",
      "Episode: 333 Total reward: -98.0 Training loss: 3.2065 Explore P: 0.0001 RunMean : -112.1500\n",
      "Episode: 334 Total reward: -112.0 Training loss: 2.6913 Explore P: 0.0001 RunMean : -112.2800\n",
      "Episode: 335 Total reward: -131.0 Training loss: 3.8481 Explore P: 0.0001 RunMean : -112.2400\n",
      "Episode: 336 Total reward: -112.0 Training loss: 6.4838 Explore P: 0.0001 RunMean : -112.4700\n",
      "Episode: 337 Total reward: -83.0 Training loss: 5.7304 Explore P: 0.0001 RunMean : -112.3700\n",
      "Episode: 338 Total reward: -101.0 Training loss: 4.6360 Explore P: 0.0001 RunMean : -112.3200\n",
      "Episode: 339 Total reward: -94.0 Training loss: 2.4647 Explore P: 0.0001 RunMean : -112.3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:19:37,325] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000343.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 340 Total reward: -120.0 Training loss: 2.8356 Explore P: 0.0001 RunMean : -112.3600\n",
      "Episode: 341 Total reward: -115.0 Training loss: 3.1086 Explore P: 0.0001 RunMean : -112.5600\n",
      "Episode: 342 Total reward: -143.0 Training loss: 2.8727 Explore P: 0.0001 RunMean : -113.0700\n",
      "Episode: 343 Total reward: -103.0 Training loss: 4.0272 Explore P: 0.0001 RunMean : -112.7400\n",
      "Episode: 344 Total reward: -171.0 Training loss: 2.6168 Explore P: 0.0001 RunMean : -112.7700\n",
      "Episode: 345 Total reward: -77.0 Training loss: 2.9806 Explore P: 0.0001 RunMean : -112.5100\n",
      "Episode: 346 Total reward: -97.0 Training loss: 3.6309 Explore P: 0.0001 RunMean : -112.2000\n",
      "Episode: 347 Total reward: -100.0 Training loss: 3.5664 Explore P: 0.0001 RunMean : -112.2000\n",
      "Episode: 348 Total reward: -87.0 Training loss: 2.9541 Explore P: 0.0001 RunMean : -111.8700\n",
      "Episode: 349 Total reward: -129.0 Training loss: 5.4393 Explore P: 0.0001 RunMean : -112.3100\n",
      "Episode: 350 Total reward: -127.0 Training loss: 2.7162 Explore P: 0.0000 RunMean : -112.4900\n",
      "Episode: 351 Total reward: -95.0 Training loss: 4.4257 Explore P: 0.0000 RunMean : -112.5700\n",
      "Episode: 352 Total reward: -129.0 Training loss: 4.2007 Explore P: 0.0000 RunMean : -112.9900\n",
      "Episode: 353 Total reward: -85.0 Training loss: 3.4254 Explore P: 0.0000 RunMean : -112.1200\n",
      "Episode: 354 Total reward: -71.0 Training loss: 3.6740 Explore P: 0.0000 RunMean : -111.7500\n",
      "Episode: 355 Total reward: -135.0 Training loss: 3.5928 Explore P: 0.0000 RunMean : -111.7500\n",
      "Episode: 356 Total reward: -103.0 Training loss: 2.4848 Explore P: 0.0000 RunMean : -111.8300\n",
      "Episode: 357 Total reward: -89.0 Training loss: 4.9441 Explore P: 0.0000 RunMean : -111.4900\n",
      "Episode: 358 Total reward: -104.0 Training loss: 4.9330 Explore P: 0.0000 RunMean : -111.5600\n",
      "Episode: 359 Total reward: -90.0 Training loss: 1.9921 Explore P: 0.0000 RunMean : -111.4500\n",
      "Episode: 360 Total reward: -155.0 Training loss: 3.0942 Explore P: 0.0000 RunMean : -112.1800\n",
      "Episode: 361 Total reward: -71.0 Training loss: 2.3181 Explore P: 0.0000 RunMean : -111.3700\n",
      "Episode: 362 Total reward: -101.0 Training loss: 2.4897 Explore P: 0.0000 RunMean : -111.5300\n",
      "Episode: 363 Total reward: -145.0 Training loss: 3.7685 Explore P: 0.0000 RunMean : -111.5700\n",
      "Episode: 364 Total reward: -173.0 Training loss: 3.9373 Explore P: 0.0000 RunMean : -112.4400\n",
      "Episode: 365 Total reward: -105.0 Training loss: 3.4121 Explore P: 0.0000 RunMean : -112.7800\n",
      "Episode: 366 Total reward: -95.0 Training loss: 2.3839 Explore P: 0.0000 RunMean : -112.6200\n",
      "Episode: 367 Total reward: -69.0 Training loss: 2.6070 Explore P: 0.0000 RunMean : -112.1800\n",
      "Episode: 368 Total reward: -107.0 Training loss: 3.2713 Explore P: 0.0000 RunMean : -112.1800\n",
      "Episode: 369 Total reward: -94.0 Training loss: 4.5248 Explore P: 0.0000 RunMean : -112.0300\n",
      "Episode: 370 Total reward: -119.0 Training loss: 2.9594 Explore P: 0.0000 RunMean : -112.1800\n",
      "Episode: 371 Total reward: -128.0 Training loss: 2.7911 Explore P: 0.0000 RunMean : -112.3800\n",
      "Episode: 372 Total reward: -79.0 Training loss: 4.5390 Explore P: 0.0000 RunMean : -111.6900\n",
      "Episode: 373 Total reward: -94.0 Training loss: 2.3723 Explore P: 0.0000 RunMean : -111.7100\n",
      "Episode: 374 Total reward: -110.0 Training loss: 4.8228 Explore P: 0.0000 RunMean : -112.0300\n",
      "Episode: 375 Total reward: -137.0 Training loss: 5.0947 Explore P: 0.0000 RunMean : -112.3300\n",
      "Episode: 376 Total reward: -84.0 Training loss: 3.2041 Explore P: 0.0000 RunMean : -112.2000\n",
      "Episode: 377 Total reward: -93.0 Training loss: 2.2112 Explore P: 0.0000 RunMean : -111.8200\n",
      "Episode: 378 Total reward: -114.0 Training loss: 2.5682 Explore P: 0.0000 RunMean : -111.9000\n",
      "Episode: 379 Total reward: -124.0 Training loss: 3.5822 Explore P: 0.0000 RunMean : -112.0600\n",
      "Episode: 380 Total reward: -101.0 Training loss: 5.3808 Explore P: 0.0000 RunMean : -111.9500\n",
      "Episode: 381 Total reward: -89.0 Training loss: 7.1292 Explore P: 0.0000 RunMean : -111.6200\n",
      "Episode: 382 Total reward: -117.0 Training loss: 5.0755 Explore P: 0.0000 RunMean : -111.6500\n",
      "Episode: 383 Total reward: -122.0 Training loss: 3.9678 Explore P: 0.0000 RunMean : -111.8200\n",
      "Episode: 384 Total reward: -113.0 Training loss: 2.3903 Explore P: 0.0000 RunMean : -111.8300\n",
      "Episode: 385 Total reward: -93.0 Training loss: 3.0136 Explore P: 0.0000 RunMean : -111.0800\n",
      "Episode: 386 Total reward: -137.0 Training loss: 4.0386 Explore P: 0.0000 RunMean : -111.1800\n",
      "Episode: 387 Total reward: -98.0 Training loss: 3.5572 Explore P: 0.0000 RunMean : -111.3300\n",
      "Episode: 388 Total reward: -95.0 Training loss: 8.9720 Explore P: 0.0000 RunMean : -111.5300\n",
      "Episode: 389 Total reward: -96.0 Training loss: 2.3441 Explore P: 0.0000 RunMean : -111.0800\n",
      "Episode: 390 Total reward: -132.0 Training loss: 1.9332 Explore P: 0.0000 RunMean : -111.4200\n",
      "Episode: 391 Total reward: -103.0 Training loss: 2.8909 Explore P: 0.0000 RunMean : -110.5500\n",
      "Episode: 392 Total reward: -106.0 Training loss: 3.2877 Explore P: 0.0000 RunMean : -110.2900\n",
      "Episode: 393 Total reward: -125.0 Training loss: 3.6622 Explore P: 0.0000 RunMean : -110.3200\n",
      "Episode: 394 Total reward: -79.0 Training loss: 3.7108 Explore P: 0.0000 RunMean : -110.4000\n",
      "Episode: 395 Total reward: -97.0 Training loss: 5.6557 Explore P: 0.0000 RunMean : -110.1500\n",
      "Episode: 396 Total reward: -99.0 Training loss: 5.3857 Explore P: 0.0000 RunMean : -109.8800\n",
      "Episode: 397 Total reward: -77.0 Training loss: 2.6288 Explore P: 0.0000 RunMean : -109.7800\n",
      "Episode: 398 Total reward: -111.0 Training loss: 2.7550 Explore P: 0.0000 RunMean : -109.9700\n",
      "Episode: 399 Total reward: -106.0 Training loss: 3.3614 Explore P: 0.0000 RunMean : -109.7600\n",
      "Episode: 400 Total reward: -86.0 Training loss: 3.5592 Explore P: 0.0000 RunMean : -109.5300\n",
      "Episode: 401 Total reward: -62.0 Training loss: 1.8880 Explore P: 0.0000 RunMean : -109.0100\n",
      "Episode: 402 Total reward: -111.0 Training loss: 3.2676 Explore P: 0.0000 RunMean : -109.1600\n",
      "Episode: 403 Total reward: -108.0 Training loss: 2.6512 Explore P: 0.0000 RunMean : -108.8000\n",
      "Episode: 404 Total reward: -99.0 Training loss: 3.8090 Explore P: 0.0000 RunMean : -108.0500\n",
      "Episode: 405 Total reward: -83.0 Training loss: 1.8888 Explore P: 0.0000 RunMean : -108.1800\n",
      "Episode: 406 Total reward: -73.0 Training loss: 4.3825 Explore P: 0.0000 RunMean : -107.6900\n",
      "Episode: 407 Total reward: -216.0 Training loss: 10.2958 Explore P: 0.0000 RunMean : -108.7500\n",
      "Episode: 408 Total reward: -139.0 Training loss: 7.0240 Explore P: 0.0000 RunMean : -108.8700\n",
      "Episode: 409 Total reward: -73.0 Training loss: 3.2134 Explore P: 0.0000 RunMean : -108.4300\n",
      "Episode: 410 Total reward: -63.0 Training loss: 6.0164 Explore P: 0.0000 RunMean : -107.6800\n",
      "Episode: 411 Total reward: -125.0 Training loss: 3.6170 Explore P: 0.0000 RunMean : -108.0000\n",
      "Episode: 412 Total reward: -114.0 Training loss: 4.2592 Explore P: 0.0000 RunMean : -108.0100\n",
      "Episode: 413 Total reward: -113.0 Training loss: 4.6482 Explore P: 0.0000 RunMean : -108.4100\n",
      "Episode: 414 Total reward: -128.0 Training loss: 3.7141 Explore P: 0.0000 RunMean : -109.0700\n",
      "Episode: 415 Total reward: -105.0 Training loss: 3.0625 Explore P: 0.0000 RunMean : -108.6800\n",
      "Episode: 416 Total reward: -76.0 Training loss: 3.5204 Explore P: 0.0000 RunMean : -108.0300\n",
      "Episode: 417 Total reward: -114.0 Training loss: 2.7362 Explore P: 0.0000 RunMean : -108.3500\n",
      "Episode: 418 Total reward: -120.0 Training loss: 2.5118 Explore P: 0.0000 RunMean : -108.3100\n",
      "Episode: 419 Total reward: -132.0 Training loss: 1.6518 Explore P: 0.0000 RunMean : -108.7100\n",
      "Episode: 420 Total reward: -82.0 Training loss: 2.5757 Explore P: 0.0000 RunMean : -108.3400\n",
      "Episode: 421 Total reward: -101.0 Training loss: 3.1217 Explore P: 0.0000 RunMean : -108.1000\n",
      "Episode: 422 Total reward: -91.0 Training loss: 4.0221 Explore P: 0.0000 RunMean : -107.7800\n",
      "Episode: 423 Total reward: -104.0 Training loss: 3.2927 Explore P: 0.0000 RunMean : -107.5900\n",
      "Episode: 424 Total reward: -153.0 Training loss: 1.9529 Explore P: 0.0000 RunMean : -107.4700\n",
      "Episode: 425 Total reward: -126.0 Training loss: 3.7395 Explore P: 0.0000 RunMean : -107.7400\n",
      "Episode: 426 Total reward: -96.0 Training loss: 7.0100 Explore P: 0.0000 RunMean : -107.4500\n",
      "Episode: 427 Total reward: -112.0 Training loss: 2.2125 Explore P: 0.0000 RunMean : -107.2800\n",
      "Episode: 428 Total reward: -98.0 Training loss: 4.3046 Explore P: 0.0000 RunMean : -106.9600\n",
      "Episode: 429 Total reward: -152.0 Training loss: 5.5722 Explore P: 0.0000 RunMean : -107.4800\n",
      "Episode: 430 Total reward: -105.0 Training loss: 2.7523 Explore P: 0.0000 RunMean : -107.5200\n",
      "Episode: 431 Total reward: -93.0 Training loss: 5.8583 Explore P: 0.0000 RunMean : -107.3300\n",
      "Episode: 432 Total reward: -500.0 Training loss: 3.8721 Explore P: 0.0000 RunMean : -111.4700\n",
      "Episode: 433 Total reward: -179.0 Training loss: 3.8843 Explore P: 0.0000 RunMean : -112.2800\n",
      "Episode: 434 Total reward: -192.0 Training loss: 3.4194 Explore P: 0.0000 RunMean : -113.0800\n",
      "Episode: 435 Total reward: -134.0 Training loss: 2.7622 Explore P: 0.0000 RunMean : -113.1100\n",
      "Episode: 436 Total reward: -106.0 Training loss: 5.1288 Explore P: 0.0000 RunMean : -113.0500\n",
      "Episode: 437 Total reward: -78.0 Training loss: 4.6185 Explore P: 0.0000 RunMean : -113.0000\n",
      "Episode: 438 Total reward: -112.0 Training loss: 4.1540 Explore P: 0.0000 RunMean : -113.1100\n",
      "Episode: 439 Total reward: -76.0 Training loss: 6.0317 Explore P: 0.0000 RunMean : -112.9300\n",
      "Episode: 440 Total reward: -94.0 Training loss: 3.6668 Explore P: 0.0000 RunMean : -112.6700\n",
      "Episode: 441 Total reward: -138.0 Training loss: 2.6916 Explore P: 0.0000 RunMean : -112.9000\n",
      "Episode: 442 Total reward: -101.0 Training loss: 2.7821 Explore P: 0.0000 RunMean : -112.4800\n",
      "Episode: 443 Total reward: -93.0 Training loss: 1.8591 Explore P: 0.0000 RunMean : -112.3800\n",
      "Episode: 444 Total reward: -71.0 Training loss: 4.3708 Explore P: 0.0000 RunMean : -111.3800\n",
      "Episode: 445 Total reward: -83.0 Training loss: 4.5423 Explore P: 0.0000 RunMean : -111.4400\n",
      "Episode: 446 Total reward: -108.0 Training loss: 8.3181 Explore P: 0.0000 RunMean : -111.5500\n",
      "Episode: 447 Total reward: -105.0 Training loss: 6.6025 Explore P: 0.0000 RunMean : -111.6000\n",
      "Episode: 448 Total reward: -105.0 Training loss: 4.4474 Explore P: 0.0000 RunMean : -111.7800\n",
      "Episode: 449 Total reward: -157.0 Training loss: 2.8782 Explore P: 0.0000 RunMean : -112.0600\n",
      "Episode: 450 Total reward: -97.0 Training loss: 2.9168 Explore P: 0.0000 RunMean : -111.7600\n",
      "Episode: 451 Total reward: -125.0 Training loss: 9.1914 Explore P: 0.0000 RunMean : -112.0600\n",
      "Episode: 452 Total reward: -124.0 Training loss: 4.6884 Explore P: 0.0000 RunMean : -112.0100\n",
      "Episode: 453 Total reward: -88.0 Training loss: 3.6672 Explore P: 0.0000 RunMean : -112.0400\n",
      "Episode: 454 Total reward: -130.0 Training loss: 2.7732 Explore P: 0.0000 RunMean : -112.6300\n",
      "Episode: 455 Total reward: -200.0 Training loss: 4.0433 Explore P: 0.0000 RunMean : -113.2800\n",
      "Episode: 456 Total reward: -75.0 Training loss: 3.5381 Explore P: 0.0000 RunMean : -113.0000\n",
      "Episode: 457 Total reward: -102.0 Training loss: 7.6420 Explore P: 0.0000 RunMean : -113.1300\n",
      "Episode: 458 Total reward: -100.0 Training loss: 5.3953 Explore P: 0.0000 RunMean : -113.0900\n",
      "Episode: 459 Total reward: -78.0 Training loss: 4.6025 Explore P: 0.0000 RunMean : -112.9700\n",
      "Episode: 460 Total reward: -108.0 Training loss: 5.4783 Explore P: 0.0000 RunMean : -112.5000\n",
      "Episode: 461 Total reward: -92.0 Training loss: 1.7347 Explore P: 0.0000 RunMean : -112.7100\n",
      "Episode: 462 Total reward: -134.0 Training loss: 3.0654 Explore P: 0.0000 RunMean : -113.0400\n",
      "Episode: 463 Total reward: -130.0 Training loss: 3.0962 Explore P: 0.0000 RunMean : -112.8900\n",
      "Episode: 464 Total reward: -104.0 Training loss: 7.8681 Explore P: 0.0000 RunMean : -112.2000\n",
      "Episode: 465 Total reward: -114.0 Training loss: 3.9249 Explore P: 0.0000 RunMean : -112.2900\n",
      "Episode: 466 Total reward: -157.0 Training loss: 2.8133 Explore P: 0.0000 RunMean : -112.9100\n",
      "Episode: 467 Total reward: -122.0 Training loss: 3.2972 Explore P: 0.0000 RunMean : -113.4400\n",
      "Episode: 468 Total reward: -84.0 Training loss: 5.6192 Explore P: 0.0000 RunMean : -113.2100\n",
      "Episode: 469 Total reward: -81.0 Training loss: 7.6923 Explore P: 0.0000 RunMean : -113.0800\n",
      "Episode: 470 Total reward: -96.0 Training loss: 4.0264 Explore P: 0.0000 RunMean : -112.8500\n",
      "Episode: 471 Total reward: -124.0 Training loss: 3.6033 Explore P: 0.0000 RunMean : -112.8100\n",
      "Episode: 472 Total reward: -86.0 Training loss: 3.1439 Explore P: 0.0000 RunMean : -112.8800\n",
      "Episode: 473 Total reward: -70.0 Training loss: 2.5308 Explore P: 0.0000 RunMean : -112.6400\n",
      "Episode: 474 Total reward: -108.0 Training loss: 4.4157 Explore P: 0.0000 RunMean : -112.6200\n",
      "Episode: 475 Total reward: -117.0 Training loss: 4.2278 Explore P: 0.0000 RunMean : -112.4200\n",
      "Episode: 476 Total reward: -94.0 Training loss: 3.0470 Explore P: 0.0000 RunMean : -112.5200\n",
      "Episode: 477 Total reward: -145.0 Training loss: 3.8778 Explore P: 0.0000 RunMean : -113.0400\n",
      "Episode: 478 Total reward: -112.0 Training loss: 7.9825 Explore P: 0.0000 RunMean : -113.0200\n",
      "Episode: 479 Total reward: -84.0 Training loss: 3.1400 Explore P: 0.0000 RunMean : -112.6200\n",
      "Episode: 480 Total reward: -125.0 Training loss: 4.8738 Explore P: 0.0000 RunMean : -112.8600\n",
      "Episode: 481 Total reward: -122.0 Training loss: 2.6686 Explore P: 0.0000 RunMean : -113.1900\n",
      "Episode: 482 Total reward: -107.0 Training loss: 6.2295 Explore P: 0.0000 RunMean : -113.0900\n",
      "Episode: 483 Total reward: -84.0 Training loss: 4.9685 Explore P: 0.0000 RunMean : -112.7100\n",
      "Episode: 484 Total reward: -120.0 Training loss: 2.6344 Explore P: 0.0000 RunMean : -112.7800\n",
      "Episode: 485 Total reward: -118.0 Training loss: 6.4304 Explore P: 0.0000 RunMean : -113.0300\n",
      "Episode: 486 Total reward: -109.0 Training loss: 5.2056 Explore P: 0.0000 RunMean : -112.7500\n",
      "Episode: 487 Total reward: -110.0 Training loss: 3.5544 Explore P: 0.0000 RunMean : -112.8700\n",
      "Episode: 488 Total reward: -111.0 Training loss: 1.8370 Explore P: 0.0000 RunMean : -113.0300\n",
      "Episode: 489 Total reward: -127.0 Training loss: 3.2287 Explore P: 0.0000 RunMean : -113.3400\n",
      "Episode: 490 Total reward: -190.0 Training loss: 3.1307 Explore P: 0.0000 RunMean : -113.9200\n",
      "Episode: 491 Total reward: -122.0 Training loss: 5.8929 Explore P: 0.0000 RunMean : -114.1100\n",
      "Episode: 492 Total reward: -132.0 Training loss: 2.8472 Explore P: 0.0000 RunMean : -114.3700\n",
      "Episode: 493 Total reward: -86.0 Training loss: 5.2685 Explore P: 0.0000 RunMean : -113.9800\n",
      "Episode: 494 Total reward: -62.0 Training loss: 4.0964 Explore P: 0.0000 RunMean : -113.8100\n",
      "Episode: 495 Total reward: -142.0 Training loss: 3.9298 Explore P: 0.0000 RunMean : -114.2600\n",
      "Episode: 496 Total reward: -98.0 Training loss: 2.0342 Explore P: 0.0000 RunMean : -114.2500\n",
      "Episode: 497 Total reward: -110.0 Training loss: 4.3712 Explore P: 0.0000 RunMean : -114.5800\n",
      "Episode: 498 Total reward: -93.0 Training loss: 4.3025 Explore P: 0.0000 RunMean : -114.4000\n",
      "Episode: 499 Total reward: -70.0 Training loss: 8.7709 Explore P: 0.0000 RunMean : -114.0400\n",
      "Episode: 500 Total reward: -151.0 Training loss: 4.2842 Explore P: 0.0000 RunMean : -114.6900\n",
      "Episode: 501 Total reward: -73.0 Training loss: 7.7264 Explore P: 0.0000 RunMean : -114.8000\n",
      "Episode: 502 Total reward: -122.0 Training loss: 5.9513 Explore P: 0.0000 RunMean : -114.9100\n",
      "Episode: 503 Total reward: -90.0 Training loss: 3.4992 Explore P: 0.0000 RunMean : -114.7300\n",
      "Episode: 504 Total reward: -104.0 Training loss: 4.7004 Explore P: 0.0000 RunMean : -114.7800\n",
      "Episode: 505 Total reward: -143.0 Training loss: 4.9412 Explore P: 0.0000 RunMean : -115.3800\n",
      "Episode: 506 Total reward: -137.0 Training loss: 4.4477 Explore P: 0.0000 RunMean : -116.0200\n",
      "Episode: 507 Total reward: -118.0 Training loss: 2.9962 Explore P: 0.0000 RunMean : -115.0400\n",
      "Episode: 508 Total reward: -115.0 Training loss: 5.2577 Explore P: 0.0000 RunMean : -114.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:22:10,508] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000512.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 509 Total reward: -124.0 Training loss: 2.9420 Explore P: 0.0000 RunMean : -115.3100\n",
      "Episode: 510 Total reward: -117.0 Training loss: 1.9882 Explore P: 0.0000 RunMean : -115.8500\n",
      "Episode: 511 Total reward: -86.0 Training loss: 2.2646 Explore P: 0.0000 RunMean : -115.4600\n",
      "Episode: 512 Total reward: -76.0 Training loss: 4.3098 Explore P: 0.0000 RunMean : -115.0800\n",
      "Episode: 513 Total reward: -112.0 Training loss: 3.7416 Explore P: 0.0000 RunMean : -115.0700\n",
      "Episode: 514 Total reward: -79.0 Training loss: 4.5391 Explore P: 0.0000 RunMean : -114.5800\n",
      "Episode: 515 Total reward: -92.0 Training loss: 2.7870 Explore P: 0.0000 RunMean : -114.4500\n",
      "Episode: 516 Total reward: -84.0 Training loss: 3.5792 Explore P: 0.0000 RunMean : -114.5300\n",
      "Episode: 517 Total reward: -62.0 Training loss: 12.3128 Explore P: 0.0000 RunMean : -114.0100\n",
      "Episode: 518 Total reward: -84.0 Training loss: 1.7972 Explore P: 0.0000 RunMean : -113.6500\n",
      "Episode: 519 Total reward: -152.0 Training loss: 4.0260 Explore P: 0.0000 RunMean : -113.8500\n",
      "Episode: 520 Total reward: -105.0 Training loss: 2.8048 Explore P: 0.0000 RunMean : -114.0800\n",
      "Episode: 521 Total reward: -82.0 Training loss: 4.3570 Explore P: 0.0000 RunMean : -113.8900\n",
      "Episode: 522 Total reward: -103.0 Training loss: 5.3338 Explore P: 0.0000 RunMean : -114.0100\n",
      "Episode: 523 Total reward: -115.0 Training loss: 2.3963 Explore P: 0.0000 RunMean : -114.1200\n",
      "Episode: 524 Total reward: -79.0 Training loss: 7.9251 Explore P: 0.0000 RunMean : -113.3800\n",
      "Episode: 525 Total reward: -90.0 Training loss: 2.2902 Explore P: 0.0000 RunMean : -113.0200\n",
      "Episode: 526 Total reward: -127.0 Training loss: 6.7683 Explore P: 0.0000 RunMean : -113.3300\n",
      "Episode: 527 Total reward: -94.0 Training loss: 2.8547 Explore P: 0.0000 RunMean : -113.1500\n",
      "Episode: 528 Total reward: -130.0 Training loss: 5.3794 Explore P: 0.0000 RunMean : -113.4700\n",
      "Episode: 529 Total reward: -92.0 Training loss: 3.7679 Explore P: 0.0000 RunMean : -112.8700\n",
      "Episode: 530 Total reward: -92.0 Training loss: 4.9613 Explore P: 0.0000 RunMean : -112.7400\n",
      "Episode: 531 Total reward: -76.0 Training loss: 1.9271 Explore P: 0.0000 RunMean : -112.5700\n",
      "Episode: 532 Total reward: -107.0 Training loss: 2.8117 Explore P: 0.0000 RunMean : -108.6400\n",
      "Episode: 533 Total reward: -82.0 Training loss: 2.3645 Explore P: 0.0000 RunMean : -107.6700\n",
      "Episode: 534 Total reward: -118.0 Training loss: 4.5829 Explore P: 0.0000 RunMean : -106.9300\n",
      "Episode: 535 Total reward: -180.0 Training loss: 2.2435 Explore P: 0.0000 RunMean : -107.3900\n",
      "Episode: 536 Total reward: -120.0 Training loss: 5.4310 Explore P: 0.0000 RunMean : -107.5300\n",
      "Episode: 537 Total reward: -107.0 Training loss: 4.6331 Explore P: 0.0000 RunMean : -107.8200\n",
      "Episode: 538 Total reward: -81.0 Training loss: 3.1700 Explore P: 0.0000 RunMean : -107.5100\n",
      "Episode: 539 Total reward: -91.0 Training loss: 4.1541 Explore P: 0.0000 RunMean : -107.6600\n",
      "Episode: 540 Total reward: -75.0 Training loss: 3.5529 Explore P: 0.0000 RunMean : -107.4700\n",
      "Episode: 541 Total reward: -82.0 Training loss: 4.4308 Explore P: 0.0000 RunMean : -106.9100\n",
      "Episode: 542 Total reward: -132.0 Training loss: 1.6598 Explore P: 0.0000 RunMean : -107.2200\n",
      "Episode: 543 Total reward: -103.0 Training loss: 5.0542 Explore P: 0.0000 RunMean : -107.3200\n",
      "Episode: 544 Total reward: -136.0 Training loss: 6.6318 Explore P: 0.0000 RunMean : -107.9700\n",
      "Episode: 545 Total reward: -420.0 Training loss: 3.6653 Explore P: 0.0000 RunMean : -111.3400\n",
      "Episode: 546 Total reward: -84.0 Training loss: 2.5494 Explore P: 0.0000 RunMean : -111.1000\n",
      "Episode: 547 Total reward: -110.0 Training loss: 3.8399 Explore P: 0.0000 RunMean : -111.1500\n",
      "Episode: 548 Total reward: -104.0 Training loss: 2.3754 Explore P: 0.0000 RunMean : -111.1400\n",
      "Episode: 549 Total reward: -94.0 Training loss: 3.1569 Explore P: 0.0000 RunMean : -110.5100\n",
      "Episode: 550 Total reward: -98.0 Training loss: 3.4201 Explore P: 0.0000 RunMean : -110.5200\n",
      "Episode: 551 Total reward: -87.0 Training loss: 4.5362 Explore P: 0.0000 RunMean : -110.1400\n",
      "Episode: 552 Total reward: -78.0 Training loss: 3.5574 Explore P: 0.0000 RunMean : -109.6800\n",
      "Episode: 553 Total reward: -70.0 Training loss: 4.0885 Explore P: 0.0000 RunMean : -109.5000\n",
      "Episode: 554 Total reward: -125.0 Training loss: 5.2402 Explore P: 0.0000 RunMean : -109.4500\n",
      "Episode: 555 Total reward: -144.0 Training loss: 4.0837 Explore P: 0.0000 RunMean : -108.8900\n",
      "Episode: 556 Total reward: -115.0 Training loss: 3.7902 Explore P: 0.0000 RunMean : -109.2900\n",
      "Episode: 557 Total reward: -92.0 Training loss: 5.4073 Explore P: 0.0000 RunMean : -109.1900\n",
      "Episode: 558 Total reward: -76.0 Training loss: 2.8067 Explore P: 0.0000 RunMean : -108.9500\n",
      "Episode: 559 Total reward: -124.0 Training loss: 1.8760 Explore P: 0.0000 RunMean : -109.4100\n",
      "Episode: 560 Total reward: -118.0 Training loss: 2.3658 Explore P: 0.0000 RunMean : -109.5100\n",
      "Episode: 561 Total reward: -94.0 Training loss: 4.3360 Explore P: 0.0000 RunMean : -109.5300\n",
      "Episode: 562 Total reward: -76.0 Training loss: 3.0505 Explore P: 0.0000 RunMean : -108.9500\n",
      "Episode: 563 Total reward: -99.0 Training loss: 3.4226 Explore P: 0.0000 RunMean : -108.6400\n",
      "Episode: 564 Total reward: -92.0 Training loss: 2.9033 Explore P: 0.0000 RunMean : -108.5200\n",
      "Episode: 565 Total reward: -145.0 Training loss: 4.3223 Explore P: 0.0000 RunMean : -108.8300\n",
      "Episode: 566 Total reward: -121.0 Training loss: 2.7690 Explore P: 0.0000 RunMean : -108.4700\n",
      "Episode: 567 Total reward: -103.0 Training loss: 6.7950 Explore P: 0.0000 RunMean : -108.2800\n",
      "Episode: 568 Total reward: -86.0 Training loss: 3.7955 Explore P: 0.0000 RunMean : -108.3000\n",
      "Episode: 569 Total reward: -109.0 Training loss: 3.2910 Explore P: 0.0000 RunMean : -108.5800\n",
      "Episode: 570 Total reward: -128.0 Training loss: 4.7837 Explore P: 0.0000 RunMean : -108.9000\n",
      "Episode: 571 Total reward: -98.0 Training loss: 3.2078 Explore P: 0.0000 RunMean : -108.6400\n",
      "Episode: 572 Total reward: -91.0 Training loss: 3.0045 Explore P: 0.0000 RunMean : -108.6900\n",
      "Episode: 573 Total reward: -87.0 Training loss: 9.4586 Explore P: 0.0000 RunMean : -108.8600\n",
      "Episode: 574 Total reward: -89.0 Training loss: 2.4595 Explore P: 0.0000 RunMean : -108.6700\n",
      "Episode: 575 Total reward: -97.0 Training loss: 2.6408 Explore P: 0.0000 RunMean : -108.4700\n",
      "Episode: 576 Total reward: -86.0 Training loss: 2.6947 Explore P: 0.0000 RunMean : -108.3900\n",
      "Episode: 577 Total reward: -168.0 Training loss: 3.2782 Explore P: 0.0000 RunMean : -108.6200\n",
      "Episode: 578 Total reward: -74.0 Training loss: 2.3657 Explore P: 0.0000 RunMean : -108.2400\n",
      "Episode: 579 Total reward: -91.0 Training loss: 2.4015 Explore P: 0.0000 RunMean : -108.3100\n",
      "Episode: 580 Total reward: -74.0 Training loss: 5.6590 Explore P: 0.0000 RunMean : -107.8000\n",
      "Episode: 581 Total reward: -110.0 Training loss: 4.9884 Explore P: 0.0000 RunMean : -107.6800\n",
      "Episode: 582 Total reward: -119.0 Training loss: 4.2667 Explore P: 0.0000 RunMean : -107.8000\n",
      "Episode: 583 Total reward: -121.0 Training loss: 2.9205 Explore P: 0.0000 RunMean : -108.1700\n",
      "Episode: 584 Total reward: -103.0 Training loss: 3.8944 Explore P: 0.0000 RunMean : -108.0000\n",
      "Episode: 585 Total reward: -109.0 Training loss: 2.7448 Explore P: 0.0000 RunMean : -107.9100\n",
      "Episode: 586 Total reward: -112.0 Training loss: 6.4006 Explore P: 0.0000 RunMean : -107.9400\n",
      "Episode: 587 Total reward: -106.0 Training loss: 6.6842 Explore P: 0.0000 RunMean : -107.9000\n",
      "Episode: 588 Total reward: -76.0 Training loss: 5.1298 Explore P: 0.0000 RunMean : -107.5500\n",
      "Episode: 589 Total reward: -104.0 Training loss: 8.4567 Explore P: 0.0000 RunMean : -107.3200\n",
      "Episode: 590 Total reward: -139.0 Training loss: 4.6755 Explore P: 0.0000 RunMean : -106.8100\n",
      "Episode: 591 Total reward: -93.0 Training loss: 2.5961 Explore P: 0.0000 RunMean : -106.5200\n",
      "Episode: 592 Total reward: -122.0 Training loss: 3.6108 Explore P: 0.0000 RunMean : -106.4200\n",
      "Episode: 593 Total reward: -123.0 Training loss: 2.8529 Explore P: 0.0000 RunMean : -106.7900\n",
      "Episode: 594 Total reward: -99.0 Training loss: 2.2953 Explore P: 0.0000 RunMean : -107.1600\n",
      "Episode: 595 Total reward: -91.0 Training loss: 4.0856 Explore P: 0.0000 RunMean : -106.6500\n",
      "Episode: 596 Total reward: -85.0 Training loss: 3.0611 Explore P: 0.0000 RunMean : -106.5200\n",
      "Episode: 597 Total reward: -88.0 Training loss: 5.3578 Explore P: 0.0000 RunMean : -106.3000\n",
      "Episode: 598 Total reward: -161.0 Training loss: 3.1019 Explore P: 0.0000 RunMean : -106.9800\n",
      "Episode: 599 Total reward: -121.0 Training loss: 4.6758 Explore P: 0.0000 RunMean : -107.4900\n",
      "Episode: 600 Total reward: -203.0 Training loss: 3.6783 Explore P: 0.0000 RunMean : -108.0100\n",
      "Episode: 601 Total reward: -62.0 Training loss: 4.3593 Explore P: 0.0000 RunMean : -107.9000\n",
      "Episode: 602 Total reward: -95.0 Training loss: 3.9908 Explore P: 0.0000 RunMean : -107.6300\n",
      "Episode: 603 Total reward: -86.0 Training loss: 4.1295 Explore P: 0.0000 RunMean : -107.5900\n",
      "Episode: 604 Total reward: -93.0 Training loss: 4.7249 Explore P: 0.0000 RunMean : -107.4800\n",
      "Episode: 605 Total reward: -79.0 Training loss: 4.2620 Explore P: 0.0000 RunMean : -106.8400\n",
      "Episode: 606 Total reward: -90.0 Training loss: 3.5879 Explore P: 0.0000 RunMean : -106.3700\n",
      "Episode: 607 Total reward: -91.0 Training loss: 3.7269 Explore P: 0.0000 RunMean : -106.1000\n",
      "Episode: 608 Total reward: -117.0 Training loss: 4.1397 Explore P: 0.0000 RunMean : -106.1200\n",
      "Episode: 609 Total reward: -148.0 Training loss: 2.2449 Explore P: 0.0000 RunMean : -106.3600\n",
      "Episode: 610 Total reward: -129.0 Training loss: 3.4760 Explore P: 0.0000 RunMean : -106.4800\n",
      "Episode: 611 Total reward: -107.0 Training loss: 4.7122 Explore P: 0.0000 RunMean : -106.6900\n",
      "Episode: 612 Total reward: -115.0 Training loss: 4.1017 Explore P: 0.0000 RunMean : -107.0800\n",
      "Episode: 613 Total reward: -138.0 Training loss: 6.3416 Explore P: 0.0000 RunMean : -107.3400\n",
      "Episode: 614 Total reward: -104.0 Training loss: 4.9241 Explore P: 0.0000 RunMean : -107.5900\n",
      "Episode: 615 Total reward: -88.0 Training loss: 3.1383 Explore P: 0.0000 RunMean : -107.5500\n",
      "Episode: 616 Total reward: -125.0 Training loss: 6.4810 Explore P: 0.0000 RunMean : -107.9600\n",
      "Episode: 617 Total reward: -105.0 Training loss: 2.5016 Explore P: 0.0000 RunMean : -108.3900\n",
      "Episode: 618 Total reward: -85.0 Training loss: 3.2668 Explore P: 0.0000 RunMean : -108.4000\n",
      "Episode: 619 Total reward: -85.0 Training loss: 1.7618 Explore P: 0.0000 RunMean : -107.7300\n",
      "Episode: 620 Total reward: -185.0 Training loss: 2.8837 Explore P: 0.0000 RunMean : -108.5300\n",
      "Episode: 621 Total reward: -123.0 Training loss: 2.8715 Explore P: 0.0000 RunMean : -108.9400\n",
      "Episode: 622 Total reward: -109.0 Training loss: 4.0813 Explore P: 0.0000 RunMean : -109.0000\n",
      "Episode: 623 Total reward: -112.0 Training loss: 2.9792 Explore P: 0.0000 RunMean : -108.9700\n",
      "Episode: 624 Total reward: -102.0 Training loss: 2.5605 Explore P: 0.0000 RunMean : -109.2000\n",
      "Episode: 625 Total reward: -70.0 Training loss: 3.6647 Explore P: 0.0000 RunMean : -109.0000\n",
      "Episode: 626 Total reward: -83.0 Training loss: 8.3879 Explore P: 0.0000 RunMean : -108.5600\n",
      "Episode: 627 Total reward: -62.0 Training loss: 2.3824 Explore P: 0.0000 RunMean : -108.2400\n",
      "Episode: 628 Total reward: -83.0 Training loss: 4.2587 Explore P: 0.0000 RunMean : -107.7700\n",
      "Episode: 629 Total reward: -155.0 Training loss: 7.8591 Explore P: 0.0000 RunMean : -108.4000\n",
      "Episode: 630 Total reward: -74.0 Training loss: 2.1695 Explore P: 0.0000 RunMean : -108.2200\n",
      "Episode: 631 Total reward: -93.0 Training loss: 1.8531 Explore P: 0.0000 RunMean : -108.3900\n",
      "Episode: 632 Total reward: -85.0 Training loss: 2.1572 Explore P: 0.0000 RunMean : -108.1700\n",
      "Episode: 633 Total reward: -94.0 Training loss: 3.5087 Explore P: 0.0000 RunMean : -108.2900\n",
      "Episode: 634 Total reward: -70.0 Training loss: 3.3893 Explore P: 0.0000 RunMean : -107.8100\n",
      "Episode: 635 Total reward: -90.0 Training loss: 4.2521 Explore P: 0.0000 RunMean : -106.9100\n",
      "Episode: 636 Total reward: -116.0 Training loss: 3.3902 Explore P: 0.0000 RunMean : -106.8700\n",
      "Episode: 637 Total reward: -120.0 Training loss: 3.4108 Explore P: 0.0000 RunMean : -107.0000\n",
      "Episode: 638 Total reward: -117.0 Training loss: 2.9343 Explore P: 0.0000 RunMean : -107.3600\n",
      "Episode: 639 Total reward: -112.0 Training loss: 3.8370 Explore P: 0.0000 RunMean : -107.5700\n",
      "Episode: 640 Total reward: -112.0 Training loss: 4.6209 Explore P: 0.0000 RunMean : -107.9400\n",
      "Episode: 641 Total reward: -124.0 Training loss: 6.1489 Explore P: 0.0000 RunMean : -108.3600\n",
      "Episode: 642 Total reward: -101.0 Training loss: 2.6172 Explore P: 0.0000 RunMean : -108.0500\n",
      "Episode: 643 Total reward: -156.0 Training loss: 3.2509 Explore P: 0.0000 RunMean : -108.5800\n",
      "Episode: 644 Total reward: -93.0 Training loss: 6.0746 Explore P: 0.0000 RunMean : -108.1500\n",
      "Episode: 645 Total reward: -107.0 Training loss: 5.2556 Explore P: 0.0000 RunMean : -105.0200\n",
      "Episode: 646 Total reward: -143.0 Training loss: 3.2357 Explore P: 0.0000 RunMean : -105.6100\n",
      "Episode: 647 Total reward: -116.0 Training loss: 3.7325 Explore P: 0.0000 RunMean : -105.6700\n",
      "Episode: 648 Total reward: -94.0 Training loss: 2.7839 Explore P: 0.0000 RunMean : -105.5700\n",
      "Episode: 649 Total reward: -200.0 Training loss: 4.1014 Explore P: 0.0000 RunMean : -106.6300\n",
      "Episode: 650 Total reward: -89.0 Training loss: 5.0926 Explore P: 0.0000 RunMean : -106.5400\n",
      "Episode: 651 Total reward: -110.0 Training loss: 1.8611 Explore P: 0.0000 RunMean : -106.7700\n",
      "Episode: 652 Total reward: -108.0 Training loss: 2.3215 Explore P: 0.0000 RunMean : -107.0700\n",
      "Episode: 653 Total reward: -83.0 Training loss: 2.9395 Explore P: 0.0000 RunMean : -107.2000\n",
      "Episode: 654 Total reward: -143.0 Training loss: 3.7417 Explore P: 0.0000 RunMean : -107.3800\n",
      "Episode: 655 Total reward: -112.0 Training loss: 4.0789 Explore P: 0.0000 RunMean : -107.0600\n",
      "Episode: 656 Total reward: -87.0 Training loss: 4.9633 Explore P: 0.0000 RunMean : -106.7800\n",
      "Episode: 657 Total reward: -83.0 Training loss: 2.6547 Explore P: 0.0000 RunMean : -106.6900\n",
      "Episode: 658 Total reward: -81.0 Training loss: 2.8758 Explore P: 0.0000 RunMean : -106.7400\n",
      "Episode: 659 Total reward: -89.0 Training loss: 2.9206 Explore P: 0.0000 RunMean : -106.3900\n",
      "Episode: 660 Total reward: -82.0 Training loss: 2.4075 Explore P: 0.0000 RunMean : -106.0300\n",
      "Episode: 661 Total reward: -139.0 Training loss: 4.6189 Explore P: 0.0000 RunMean : -106.4800\n",
      "Episode: 662 Total reward: -199.0 Training loss: 3.7932 Explore P: 0.0000 RunMean : -107.7100\n",
      "Episode: 663 Total reward: -123.0 Training loss: 4.1299 Explore P: 0.0000 RunMean : -107.9500\n",
      "Episode: 664 Total reward: -88.0 Training loss: 4.6269 Explore P: 0.0000 RunMean : -107.9100\n",
      "Episode: 665 Total reward: -82.0 Training loss: 3.1299 Explore P: 0.0000 RunMean : -107.2800\n",
      "Episode: 666 Total reward: -91.0 Training loss: 3.2012 Explore P: 0.0000 RunMean : -106.9800\n",
      "Episode: 667 Total reward: -115.0 Training loss: 1.8047 Explore P: 0.0000 RunMean : -107.1000\n",
      "Episode: 668 Total reward: -113.0 Training loss: 4.8057 Explore P: 0.0000 RunMean : -107.3700\n",
      "Episode: 669 Total reward: -117.0 Training loss: 4.1365 Explore P: 0.0000 RunMean : -107.4500\n",
      "Episode: 670 Total reward: -114.0 Training loss: 4.1268 Explore P: 0.0000 RunMean : -107.3100\n",
      "Episode: 671 Total reward: -71.0 Training loss: 2.3056 Explore P: 0.0000 RunMean : -107.0400\n",
      "Episode: 672 Total reward: -130.0 Training loss: 5.1468 Explore P: 0.0000 RunMean : -107.4300\n",
      "Episode: 673 Total reward: -78.0 Training loss: 2.8153 Explore P: 0.0000 RunMean : -107.3400\n",
      "Episode: 674 Total reward: -94.0 Training loss: 3.0337 Explore P: 0.0000 RunMean : -107.3900\n",
      "Episode: 675 Total reward: -87.0 Training loss: 2.6202 Explore P: 0.0000 RunMean : -107.2900\n",
      "Episode: 676 Total reward: -101.0 Training loss: 3.5050 Explore P: 0.0000 RunMean : -107.4400\n",
      "Episode: 677 Total reward: -128.0 Training loss: 2.8403 Explore P: 0.0000 RunMean : -107.0400\n",
      "Episode: 678 Total reward: -89.0 Training loss: 2.0860 Explore P: 0.0000 RunMean : -107.1900\n",
      "Episode: 679 Total reward: -111.0 Training loss: 2.2640 Explore P: 0.0000 RunMean : -107.3900\n",
      "Episode: 680 Total reward: -84.0 Training loss: 3.2861 Explore P: 0.0000 RunMean : -107.4900\n",
      "Episode: 681 Total reward: -123.0 Training loss: 4.5177 Explore P: 0.0000 RunMean : -107.6200\n",
      "Episode: 682 Total reward: -113.0 Training loss: 4.2961 Explore P: 0.0000 RunMean : -107.5600\n",
      "Episode: 683 Total reward: -111.0 Training loss: 2.8153 Explore P: 0.0000 RunMean : -107.4600\n",
      "Episode: 684 Total reward: -110.0 Training loss: 6.1210 Explore P: 0.0000 RunMean : -107.5300\n",
      "Episode: 685 Total reward: -69.0 Training loss: 2.8118 Explore P: 0.0000 RunMean : -107.1300\n",
      "Episode: 686 Total reward: -82.0 Training loss: 5.0117 Explore P: 0.0000 RunMean : -106.8300\n",
      "Episode: 687 Total reward: -97.0 Training loss: 2.5581 Explore P: 0.0000 RunMean : -106.7400\n",
      "Episode: 688 Total reward: -127.0 Training loss: 2.4404 Explore P: 0.0000 RunMean : -107.2500\n",
      "Episode: 689 Total reward: -114.0 Training loss: 1.8992 Explore P: 0.0000 RunMean : -107.3500\n",
      "Episode: 690 Total reward: -150.0 Training loss: 4.8188 Explore P: 0.0000 RunMean : -107.4600\n",
      "Episode: 691 Total reward: -84.0 Training loss: 1.7657 Explore P: 0.0000 RunMean : -107.3700\n",
      "Episode: 692 Total reward: -87.0 Training loss: 2.6203 Explore P: 0.0000 RunMean : -107.0200\n",
      "Episode: 693 Total reward: -69.0 Training loss: 3.3667 Explore P: 0.0000 RunMean : -106.4800\n",
      "Episode: 694 Total reward: -127.0 Training loss: 2.6997 Explore P: 0.0000 RunMean : -106.7600\n",
      "Episode: 695 Total reward: -117.0 Training loss: 2.7153 Explore P: 0.0000 RunMean : -107.0200\n",
      "Episode: 696 Total reward: -117.0 Training loss: 2.4797 Explore P: 0.0000 RunMean : -107.3400\n",
      "Episode: 697 Total reward: -74.0 Training loss: 3.2954 Explore P: 0.0000 RunMean : -107.2000\n",
      "Episode: 698 Total reward: -84.0 Training loss: 3.2122 Explore P: 0.0000 RunMean : -106.4300\n",
      "Episode: 699 Total reward: -97.0 Training loss: 3.2614 Explore P: 0.0000 RunMean : -106.1900\n",
      "Episode: 700 Total reward: -107.0 Training loss: 2.4623 Explore P: 0.0000 RunMean : -105.2300\n",
      "Episode: 701 Total reward: -90.0 Training loss: 3.1221 Explore P: 0.0000 RunMean : -105.5100\n",
      "Episode: 702 Total reward: -95.0 Training loss: 2.5241 Explore P: 0.0000 RunMean : -105.5100\n",
      "Episode: 703 Total reward: -130.0 Training loss: 3.4390 Explore P: 0.0000 RunMean : -105.9500\n",
      "Episode: 704 Total reward: -114.0 Training loss: 3.0863 Explore P: 0.0000 RunMean : -106.1600\n",
      "Episode: 705 Total reward: -119.0 Training loss: 1.8482 Explore P: 0.0000 RunMean : -106.5600\n",
      "Episode: 706 Total reward: -139.0 Training loss: 1.8916 Explore P: 0.0000 RunMean : -107.0500\n",
      "Episode: 707 Total reward: -116.0 Training loss: 2.3823 Explore P: 0.0000 RunMean : -107.3000\n",
      "Episode: 708 Total reward: -137.0 Training loss: 1.5036 Explore P: 0.0000 RunMean : -107.5000\n",
      "Episode: 709 Total reward: -79.0 Training loss: 2.9267 Explore P: 0.0000 RunMean : -106.8100\n",
      "Episode: 710 Total reward: -79.0 Training loss: 2.7953 Explore P: 0.0000 RunMean : -106.3100\n",
      "Episode: 711 Total reward: -102.0 Training loss: 2.7087 Explore P: 0.0000 RunMean : -106.2600\n",
      "Episode: 712 Total reward: -116.0 Training loss: 3.4235 Explore P: 0.0000 RunMean : -106.2700\n",
      "Episode: 713 Total reward: -84.0 Training loss: 2.2151 Explore P: 0.0000 RunMean : -105.7300\n",
      "Episode: 714 Total reward: -132.0 Training loss: 3.2235 Explore P: 0.0000 RunMean : -106.0100\n",
      "Episode: 715 Total reward: -93.0 Training loss: 3.6710 Explore P: 0.0000 RunMean : -106.0600\n",
      "Episode: 716 Total reward: -63.0 Training loss: 3.9697 Explore P: 0.0000 RunMean : -105.4400\n",
      "Episode: 717 Total reward: -82.0 Training loss: 2.1070 Explore P: 0.0000 RunMean : -105.2100\n",
      "Episode: 718 Total reward: -115.0 Training loss: 6.1981 Explore P: 0.0000 RunMean : -105.5100\n",
      "Episode: 719 Total reward: -101.0 Training loss: 3.1794 Explore P: 0.0000 RunMean : -105.6700\n",
      "Episode: 720 Total reward: -111.0 Training loss: 2.5087 Explore P: 0.0000 RunMean : -104.9300\n",
      "Episode: 721 Total reward: -152.0 Training loss: 3.8851 Explore P: 0.0000 RunMean : -105.2200\n",
      "Episode: 722 Total reward: -85.0 Training loss: 2.0496 Explore P: 0.0000 RunMean : -104.9800\n",
      "Episode: 723 Total reward: -123.0 Training loss: 3.8421 Explore P: 0.0000 RunMean : -105.0900\n",
      "Episode: 724 Total reward: -97.0 Training loss: 2.4645 Explore P: 0.0000 RunMean : -105.0400\n",
      "Episode: 725 Total reward: -100.0 Training loss: 3.9355 Explore P: 0.0000 RunMean : -105.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:24:35,216] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video000729.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 726 Total reward: -90.0 Training loss: 2.9891 Explore P: 0.0000 RunMean : -105.4100\n",
      "Episode: 727 Total reward: -134.0 Training loss: 2.3991 Explore P: 0.0000 RunMean : -106.1300\n",
      "Episode: 728 Total reward: -102.0 Training loss: 3.3943 Explore P: 0.0000 RunMean : -106.3200\n",
      "Episode: 729 Total reward: -90.0 Training loss: 4.0541 Explore P: 0.0000 RunMean : -105.6700\n",
      "Episode: 730 Total reward: -107.0 Training loss: 5.0604 Explore P: 0.0000 RunMean : -106.0000\n",
      "Episode: 731 Total reward: -118.0 Training loss: 3.4035 Explore P: 0.0000 RunMean : -106.2500\n",
      "Episode: 732 Total reward: -94.0 Training loss: 2.5027 Explore P: 0.0000 RunMean : -106.3400\n",
      "Episode: 733 Total reward: -121.0 Training loss: 4.7819 Explore P: 0.0000 RunMean : -106.6100\n",
      "Episode: 734 Total reward: -123.0 Training loss: 2.9136 Explore P: 0.0000 RunMean : -107.1400\n",
      "Episode: 735 Total reward: -116.0 Training loss: 2.6060 Explore P: 0.0000 RunMean : -107.4000\n",
      "Episode: 736 Total reward: -84.0 Training loss: 3.1666 Explore P: 0.0000 RunMean : -107.0800\n",
      "Episode: 737 Total reward: -91.0 Training loss: 1.8983 Explore P: 0.0000 RunMean : -106.7900\n",
      "Episode: 738 Total reward: -83.0 Training loss: 2.8036 Explore P: 0.0000 RunMean : -106.4500\n",
      "Episode: 739 Total reward: -107.0 Training loss: 1.5630 Explore P: 0.0000 RunMean : -106.4000\n",
      "Episode: 740 Total reward: -91.0 Training loss: 3.1098 Explore P: 0.0000 RunMean : -106.1900\n",
      "Episode: 741 Total reward: -97.0 Training loss: 3.7209 Explore P: 0.0000 RunMean : -105.9200\n",
      "Episode: 742 Total reward: -141.0 Training loss: 8.3803 Explore P: 0.0000 RunMean : -106.3200\n",
      "Episode: 743 Total reward: -92.0 Training loss: 2.1904 Explore P: 0.0000 RunMean : -105.6800\n",
      "Episode: 744 Total reward: -93.0 Training loss: 3.3685 Explore P: 0.0000 RunMean : -105.6800\n",
      "Episode: 745 Total reward: -99.0 Training loss: 3.3841 Explore P: 0.0000 RunMean : -105.6000\n",
      "Episode: 746 Total reward: -80.0 Training loss: 6.7924 Explore P: 0.0000 RunMean : -104.9700\n",
      "Episode: 747 Total reward: -99.0 Training loss: 1.6346 Explore P: 0.0000 RunMean : -104.8000\n",
      "Episode: 748 Total reward: -94.0 Training loss: 3.0005 Explore P: 0.0000 RunMean : -104.8000\n",
      "Episode: 749 Total reward: -125.0 Training loss: 1.7554 Explore P: 0.0000 RunMean : -104.0500\n",
      "Episode: 750 Total reward: -105.0 Training loss: 3.0211 Explore P: 0.0000 RunMean : -104.2100\n",
      "Episode: 751 Total reward: -153.0 Training loss: 2.2250 Explore P: 0.0000 RunMean : -104.6400\n",
      "Episode: 752 Total reward: -117.0 Training loss: 2.2666 Explore P: 0.0000 RunMean : -104.7300\n",
      "Episode: 753 Total reward: -113.0 Training loss: 8.1720 Explore P: 0.0000 RunMean : -105.0300\n",
      "Episode: 754 Total reward: -125.0 Training loss: 3.5568 Explore P: 0.0000 RunMean : -104.8500\n",
      "Episode: 755 Total reward: -121.0 Training loss: 4.1880 Explore P: 0.0000 RunMean : -104.9400\n",
      "Episode: 756 Total reward: -86.0 Training loss: 2.5866 Explore P: 0.0000 RunMean : -104.9300\n",
      "Episode: 757 Total reward: -81.0 Training loss: 5.2556 Explore P: 0.0000 RunMean : -104.9100\n",
      "Episode: 758 Total reward: -119.0 Training loss: 3.1780 Explore P: 0.0000 RunMean : -105.2900\n",
      "Episode: 759 Total reward: -104.0 Training loss: 2.6384 Explore P: 0.0000 RunMean : -105.4400\n",
      "Episode: 760 Total reward: -94.0 Training loss: 4.3400 Explore P: 0.0000 RunMean : -105.5600\n",
      "Episode: 761 Total reward: -129.0 Training loss: 3.3870 Explore P: 0.0000 RunMean : -105.4600\n",
      "Episode: 762 Total reward: -89.0 Training loss: 3.5327 Explore P: 0.0000 RunMean : -104.3600\n",
      "Episode: 763 Total reward: -125.0 Training loss: 2.7893 Explore P: 0.0000 RunMean : -104.3800\n",
      "Episode: 764 Total reward: -143.0 Training loss: 1.9889 Explore P: 0.0000 RunMean : -104.9300\n",
      "Episode: 765 Total reward: -104.0 Training loss: 5.4156 Explore P: 0.0000 RunMean : -105.1500\n",
      "Episode: 766 Total reward: -92.0 Training loss: 2.6514 Explore P: 0.0000 RunMean : -105.1600\n",
      "Episode: 767 Total reward: -119.0 Training loss: 6.1420 Explore P: 0.0000 RunMean : -105.2000\n",
      "Episode: 768 Total reward: -203.0 Training loss: 1.8504 Explore P: 0.0000 RunMean : -106.1000\n",
      "Episode: 769 Total reward: -85.0 Training loss: 3.1228 Explore P: 0.0000 RunMean : -105.7800\n",
      "Episode: 770 Total reward: -70.0 Training loss: 2.5928 Explore P: 0.0000 RunMean : -105.3400\n",
      "Episode: 771 Total reward: -90.0 Training loss: 2.1352 Explore P: 0.0000 RunMean : -105.5300\n",
      "Episode: 772 Total reward: -107.0 Training loss: 2.2286 Explore P: 0.0000 RunMean : -105.3000\n",
      "Episode: 773 Total reward: -112.0 Training loss: 2.3671 Explore P: 0.0000 RunMean : -105.6400\n",
      "Episode: 774 Total reward: -87.0 Training loss: 1.6689 Explore P: 0.0000 RunMean : -105.5700\n",
      "Episode: 775 Total reward: -96.0 Training loss: 6.7868 Explore P: 0.0000 RunMean : -105.6600\n",
      "Episode: 776 Total reward: -109.0 Training loss: 4.1126 Explore P: 0.0000 RunMean : -105.7400\n",
      "Episode: 777 Total reward: -87.0 Training loss: 2.4880 Explore P: 0.0000 RunMean : -105.3300\n",
      "Episode: 778 Total reward: -102.0 Training loss: 2.7656 Explore P: 0.0000 RunMean : -105.4600\n",
      "Episode: 779 Total reward: -79.0 Training loss: 1.7889 Explore P: 0.0000 RunMean : -105.1400\n",
      "Episode: 780 Total reward: -106.0 Training loss: 2.2048 Explore P: 0.0000 RunMean : -105.3600\n",
      "Episode: 781 Total reward: -85.0 Training loss: 2.8981 Explore P: 0.0000 RunMean : -104.9800\n",
      "Episode: 782 Total reward: -74.0 Training loss: 4.4545 Explore P: 0.0000 RunMean : -104.5900\n",
      "Episode: 783 Total reward: -126.0 Training loss: 2.2999 Explore P: 0.0000 RunMean : -104.7400\n",
      "Episode: 784 Total reward: -81.0 Training loss: 3.2591 Explore P: 0.0000 RunMean : -104.4500\n",
      "Episode: 785 Total reward: -90.0 Training loss: 3.1385 Explore P: 0.0000 RunMean : -104.6600\n",
      "Episode: 786 Total reward: -78.0 Training loss: 10.9399 Explore P: 0.0000 RunMean : -104.6200\n",
      "Episode: 787 Total reward: -100.0 Training loss: 3.8033 Explore P: 0.0000 RunMean : -104.6500\n",
      "Episode: 788 Total reward: -94.0 Training loss: 3.1711 Explore P: 0.0000 RunMean : -104.3200\n",
      "Episode: 789 Total reward: -83.0 Training loss: 3.1902 Explore P: 0.0000 RunMean : -104.0100\n",
      "Episode: 790 Total reward: -154.0 Training loss: 2.8760 Explore P: 0.0000 RunMean : -104.0500\n",
      "Episode: 791 Total reward: -95.0 Training loss: 3.5281 Explore P: 0.0000 RunMean : -104.1600\n",
      "Episode: 792 Total reward: -89.0 Training loss: 2.8366 Explore P: 0.0000 RunMean : -104.1800\n",
      "Episode: 793 Total reward: -120.0 Training loss: 2.6255 Explore P: 0.0000 RunMean : -104.6900\n",
      "Episode: 794 Total reward: -184.0 Training loss: 5.0564 Explore P: 0.0000 RunMean : -105.2600\n",
      "Episode: 795 Total reward: -138.0 Training loss: 2.2485 Explore P: 0.0000 RunMean : -105.4700\n",
      "Episode: 796 Total reward: -102.0 Training loss: 3.6561 Explore P: 0.0000 RunMean : -105.3200\n",
      "Episode: 797 Total reward: -85.0 Training loss: 2.2083 Explore P: 0.0000 RunMean : -105.4300\n",
      "Episode: 798 Total reward: -126.0 Training loss: 3.8075 Explore P: 0.0000 RunMean : -105.8500\n",
      "Episode: 799 Total reward: -105.0 Training loss: 3.1559 Explore P: 0.0000 RunMean : -105.9300\n",
      "Episode: 800 Total reward: -101.0 Training loss: 3.0739 Explore P: 0.0000 RunMean : -105.8700\n",
      "Episode: 801 Total reward: -141.0 Training loss: 3.3935 Explore P: 0.0000 RunMean : -106.3800\n",
      "Episode: 802 Total reward: -82.0 Training loss: 2.3523 Explore P: 0.0000 RunMean : -106.2500\n",
      "Episode: 803 Total reward: -132.0 Training loss: 2.8391 Explore P: 0.0000 RunMean : -106.2700\n",
      "Episode: 804 Total reward: -148.0 Training loss: 2.2574 Explore P: 0.0000 RunMean : -106.6100\n",
      "Episode: 805 Total reward: -102.0 Training loss: 4.7045 Explore P: 0.0000 RunMean : -106.4400\n",
      "Episode: 806 Total reward: -83.0 Training loss: 2.9389 Explore P: 0.0000 RunMean : -105.8800\n",
      "Episode: 807 Total reward: -100.0 Training loss: 4.5178 Explore P: 0.0000 RunMean : -105.7200\n",
      "Episode: 808 Total reward: -81.0 Training loss: 3.7386 Explore P: 0.0000 RunMean : -105.1600\n",
      "Episode: 809 Total reward: -78.0 Training loss: 3.8471 Explore P: 0.0000 RunMean : -105.1500\n",
      "Episode: 810 Total reward: -91.0 Training loss: 1.7181 Explore P: 0.0000 RunMean : -105.2700\n",
      "Episode: 811 Total reward: -121.0 Training loss: 2.1326 Explore P: 0.0000 RunMean : -105.4600\n",
      "Episode: 812 Total reward: -114.0 Training loss: 3.1491 Explore P: 0.0000 RunMean : -105.4400\n",
      "Episode: 813 Total reward: -94.0 Training loss: 3.5793 Explore P: 0.0000 RunMean : -105.5400\n",
      "Episode: 814 Total reward: -71.0 Training loss: 2.6047 Explore P: 0.0000 RunMean : -104.9300\n",
      "Episode: 815 Total reward: -81.0 Training loss: 2.1829 Explore P: 0.0000 RunMean : -104.8100\n",
      "Episode: 816 Total reward: -105.0 Training loss: 3.8320 Explore P: 0.0000 RunMean : -105.2300\n",
      "Episode: 817 Total reward: -82.0 Training loss: 4.4583 Explore P: 0.0000 RunMean : -105.2300\n",
      "Episode: 818 Total reward: -149.0 Training loss: 3.5457 Explore P: 0.0000 RunMean : -105.5700\n",
      "Episode: 819 Total reward: -76.0 Training loss: 3.5259 Explore P: 0.0000 RunMean : -105.3200\n",
      "Episode: 820 Total reward: -105.0 Training loss: 2.2699 Explore P: 0.0000 RunMean : -105.2600\n",
      "Episode: 821 Total reward: -127.0 Training loss: 3.5822 Explore P: 0.0000 RunMean : -105.0100\n",
      "Episode: 822 Total reward: -113.0 Training loss: 5.9426 Explore P: 0.0000 RunMean : -105.2900\n",
      "Episode: 823 Total reward: -73.0 Training loss: 3.0153 Explore P: 0.0000 RunMean : -104.7900\n",
      "Episode: 824 Total reward: -90.0 Training loss: 2.0256 Explore P: 0.0000 RunMean : -104.7200\n",
      "Episode: 825 Total reward: -90.0 Training loss: 3.6528 Explore P: 0.0000 RunMean : -104.6200\n",
      "Episode: 826 Total reward: -71.0 Training loss: 8.0785 Explore P: 0.0000 RunMean : -104.4300\n",
      "Episode: 827 Total reward: -77.0 Training loss: 4.2980 Explore P: 0.0000 RunMean : -103.8600\n",
      "Episode: 828 Total reward: -121.0 Training loss: 3.2497 Explore P: 0.0000 RunMean : -104.0500\n",
      "Episode: 829 Total reward: -73.0 Training loss: 2.7658 Explore P: 0.0000 RunMean : -103.8800\n",
      "Episode: 830 Total reward: -193.0 Training loss: 1.5034 Explore P: 0.0000 RunMean : -104.7400\n",
      "Episode: 831 Total reward: -71.0 Training loss: 5.1372 Explore P: 0.0000 RunMean : -104.2700\n",
      "Episode: 832 Total reward: -97.0 Training loss: 2.8394 Explore P: 0.0000 RunMean : -104.3000\n",
      "Episode: 833 Total reward: -92.0 Training loss: 1.8080 Explore P: 0.0000 RunMean : -104.0100\n",
      "Episode: 834 Total reward: -97.0 Training loss: 2.4121 Explore P: 0.0000 RunMean : -103.7500\n",
      "Episode: 835 Total reward: -135.0 Training loss: 3.7022 Explore P: 0.0000 RunMean : -103.9400\n",
      "Episode: 836 Total reward: -70.0 Training loss: 2.1058 Explore P: 0.0000 RunMean : -103.8000\n",
      "Episode: 837 Total reward: -466.0 Training loss: 2.3739 Explore P: 0.0000 RunMean : -107.5500\n",
      "Episode: 838 Total reward: -83.0 Training loss: 1.7600 Explore P: 0.0000 RunMean : -107.5500\n",
      "Episode: 839 Total reward: -75.0 Training loss: 1.8507 Explore P: 0.0000 RunMean : -107.2300\n",
      "Episode: 840 Total reward: -119.0 Training loss: 2.7071 Explore P: 0.0000 RunMean : -107.5100\n",
      "Episode: 841 Total reward: -121.0 Training loss: 2.5672 Explore P: 0.0000 RunMean : -107.7500\n",
      "Episode: 842 Total reward: -98.0 Training loss: 1.9902 Explore P: 0.0000 RunMean : -107.3200\n",
      "Episode: 843 Total reward: -105.0 Training loss: 5.5359 Explore P: 0.0000 RunMean : -107.4500\n",
      "Episode: 844 Total reward: -74.0 Training loss: 4.3409 Explore P: 0.0000 RunMean : -107.2600\n",
      "Episode: 845 Total reward: -70.0 Training loss: 3.8889 Explore P: 0.0000 RunMean : -106.9700\n",
      "Episode: 846 Total reward: -92.0 Training loss: 4.7687 Explore P: 0.0000 RunMean : -107.0900\n",
      "Episode: 847 Total reward: -104.0 Training loss: 4.1312 Explore P: 0.0000 RunMean : -107.1400\n",
      "Episode: 848 Total reward: -97.0 Training loss: 5.0530 Explore P: 0.0000 RunMean : -107.1700\n",
      "Episode: 849 Total reward: -105.0 Training loss: 4.7403 Explore P: 0.0000 RunMean : -106.9700\n",
      "Episode: 850 Total reward: -146.0 Training loss: 5.0105 Explore P: 0.0000 RunMean : -107.3800\n",
      "Episode: 851 Total reward: -144.0 Training loss: 2.5833 Explore P: 0.0000 RunMean : -107.2900\n",
      "Episode: 852 Total reward: -106.0 Training loss: 2.5921 Explore P: 0.0000 RunMean : -107.1800\n",
      "Episode: 853 Total reward: -100.0 Training loss: 6.0545 Explore P: 0.0000 RunMean : -107.0500\n",
      "Episode: 854 Total reward: -134.0 Training loss: 4.5754 Explore P: 0.0000 RunMean : -107.1400\n",
      "Episode: 855 Total reward: -82.0 Training loss: 4.2728 Explore P: 0.0000 RunMean : -106.7500\n",
      "Episode: 856 Total reward: -97.0 Training loss: 5.4772 Explore P: 0.0000 RunMean : -106.8600\n",
      "Episode: 857 Total reward: -104.0 Training loss: 4.0853 Explore P: 0.0000 RunMean : -107.0900\n",
      "Episode: 858 Total reward: -121.0 Training loss: 5.4498 Explore P: 0.0000 RunMean : -107.1100\n",
      "Episode: 859 Total reward: -89.0 Training loss: 2.5414 Explore P: 0.0000 RunMean : -106.9600\n",
      "Episode: 860 Total reward: -86.0 Training loss: 2.5394 Explore P: 0.0000 RunMean : -106.8800\n",
      "Episode: 861 Total reward: -71.0 Training loss: 2.6714 Explore P: 0.0000 RunMean : -106.3000\n",
      "Episode: 862 Total reward: -114.0 Training loss: 3.2462 Explore P: 0.0000 RunMean : -106.5500\n",
      "Episode: 863 Total reward: -100.0 Training loss: 5.2370 Explore P: 0.0000 RunMean : -106.3000\n",
      "Episode: 864 Total reward: -75.0 Training loss: 4.3379 Explore P: 0.0000 RunMean : -105.6200\n",
      "Episode: 865 Total reward: -80.0 Training loss: 4.1485 Explore P: 0.0000 RunMean : -105.3800\n",
      "Episode: 866 Total reward: -104.0 Training loss: 2.1459 Explore P: 0.0000 RunMean : -105.5000\n",
      "Episode: 867 Total reward: -93.0 Training loss: 3.1479 Explore P: 0.0000 RunMean : -105.2400\n",
      "Episode: 868 Total reward: -113.0 Training loss: 2.4155 Explore P: 0.0000 RunMean : -104.3400\n",
      "Episode: 869 Total reward: -75.0 Training loss: 3.3927 Explore P: 0.0000 RunMean : -104.2400\n",
      "Episode: 870 Total reward: -121.0 Training loss: 3.1653 Explore P: 0.0000 RunMean : -104.7500\n",
      "Episode: 871 Total reward: -116.0 Training loss: 2.9362 Explore P: 0.0000 RunMean : -105.0100\n",
      "Episode: 872 Total reward: -99.0 Training loss: 4.7737 Explore P: 0.0000 RunMean : -104.9300\n",
      "Episode: 873 Total reward: -125.0 Training loss: 2.1578 Explore P: 0.0000 RunMean : -105.0600\n",
      "Episode: 874 Total reward: -97.0 Training loss: 4.3113 Explore P: 0.0000 RunMean : -105.1600\n",
      "Episode: 875 Total reward: -76.0 Training loss: 1.4780 Explore P: 0.0000 RunMean : -104.9600\n",
      "Episode: 876 Total reward: -104.0 Training loss: 2.9124 Explore P: 0.0000 RunMean : -104.9100\n",
      "Episode: 877 Total reward: -82.0 Training loss: 3.4413 Explore P: 0.0000 RunMean : -104.8600\n",
      "Episode: 878 Total reward: -93.0 Training loss: 3.3679 Explore P: 0.0000 RunMean : -104.7700\n",
      "Episode: 879 Total reward: -96.0 Training loss: 3.3964 Explore P: 0.0000 RunMean : -104.9400\n",
      "Episode: 880 Total reward: -129.0 Training loss: 3.8909 Explore P: 0.0000 RunMean : -105.1700\n",
      "Episode: 881 Total reward: -100.0 Training loss: 4.7232 Explore P: 0.0000 RunMean : -105.3200\n",
      "Episode: 882 Total reward: -120.0 Training loss: 4.6708 Explore P: 0.0000 RunMean : -105.7800\n",
      "Episode: 883 Total reward: -165.0 Training loss: 4.7618 Explore P: 0.0000 RunMean : -106.1700\n",
      "Episode: 884 Total reward: -74.0 Training loss: 2.6539 Explore P: 0.0000 RunMean : -106.1000\n",
      "Episode: 885 Total reward: -91.0 Training loss: 3.0364 Explore P: 0.0000 RunMean : -106.1100\n",
      "Episode: 886 Total reward: -103.0 Training loss: 4.2642 Explore P: 0.0000 RunMean : -106.3600\n",
      "Episode: 887 Total reward: -89.0 Training loss: 3.3553 Explore P: 0.0000 RunMean : -106.2500\n",
      "Episode: 888 Total reward: -93.0 Training loss: 4.4505 Explore P: 0.0000 RunMean : -106.2400\n",
      "Episode: 889 Total reward: -77.0 Training loss: 4.2803 Explore P: 0.0000 RunMean : -106.1800\n",
      "Episode: 890 Total reward: -139.0 Training loss: 3.5317 Explore P: 0.0000 RunMean : -106.0300\n",
      "Episode: 891 Total reward: -74.0 Training loss: 2.8202 Explore P: 0.0000 RunMean : -105.8200\n",
      "Episode: 892 Total reward: -77.0 Training loss: 1.5082 Explore P: 0.0000 RunMean : -105.7000\n",
      "Episode: 893 Total reward: -134.0 Training loss: 3.2082 Explore P: 0.0000 RunMean : -105.8400\n",
      "Episode: 894 Total reward: -109.0 Training loss: 4.7818 Explore P: 0.0000 RunMean : -105.0900\n",
      "Episode: 895 Total reward: -151.0 Training loss: 3.1788 Explore P: 0.0000 RunMean : -105.2200\n",
      "Episode: 896 Total reward: -99.0 Training loss: 1.9262 Explore P: 0.0000 RunMean : -105.1900\n",
      "Episode: 897 Total reward: -79.0 Training loss: 1.5514 Explore P: 0.0000 RunMean : -105.1300\n",
      "Episode: 898 Total reward: -108.0 Training loss: 3.2977 Explore P: 0.0000 RunMean : -104.9500\n",
      "Episode: 899 Total reward: -132.0 Training loss: 2.5376 Explore P: 0.0000 RunMean : -105.2200\n",
      "Episode: 900 Total reward: -118.0 Training loss: 4.5788 Explore P: 0.0000 RunMean : -105.3900\n",
      "Episode: 901 Total reward: -107.0 Training loss: 1.2711 Explore P: 0.0000 RunMean : -105.0500\n",
      "Episode: 902 Total reward: -107.0 Training loss: 4.7147 Explore P: 0.0000 RunMean : -105.3000\n",
      "Episode: 903 Total reward: -88.0 Training loss: 2.4557 Explore P: 0.0000 RunMean : -104.8600\n",
      "Episode: 904 Total reward: -128.0 Training loss: 3.7329 Explore P: 0.0000 RunMean : -104.6600\n",
      "Episode: 905 Total reward: -154.0 Training loss: 3.1203 Explore P: 0.0000 RunMean : -105.1800\n",
      "Episode: 906 Total reward: -261.0 Training loss: 3.0709 Explore P: 0.0000 RunMean : -106.9600\n",
      "Episode: 907 Total reward: -119.0 Training loss: 8.1666 Explore P: 0.0000 RunMean : -107.1500\n",
      "Episode: 908 Total reward: -116.0 Training loss: 2.5283 Explore P: 0.0000 RunMean : -107.5000\n",
      "Episode: 909 Total reward: -82.0 Training loss: 2.3395 Explore P: 0.0000 RunMean : -107.5400\n",
      "Episode: 910 Total reward: -123.0 Training loss: 1.1917 Explore P: 0.0000 RunMean : -107.8600\n",
      "Episode: 911 Total reward: -92.0 Training loss: 1.8118 Explore P: 0.0000 RunMean : -107.5700\n",
      "Episode: 912 Total reward: -77.0 Training loss: 3.2529 Explore P: 0.0000 RunMean : -107.2000\n",
      "Episode: 913 Total reward: -101.0 Training loss: 2.9713 Explore P: 0.0000 RunMean : -107.2700\n",
      "Episode: 914 Total reward: -92.0 Training loss: 2.9060 Explore P: 0.0000 RunMean : -107.4800\n",
      "Episode: 915 Total reward: -90.0 Training loss: 3.3361 Explore P: 0.0000 RunMean : -107.5700\n",
      "Episode: 916 Total reward: -110.0 Training loss: 3.6652 Explore P: 0.0000 RunMean : -107.6200\n",
      "Episode: 917 Total reward: -110.0 Training loss: 2.4697 Explore P: 0.0000 RunMean : -107.9000\n",
      "Episode: 918 Total reward: -146.0 Training loss: 2.3067 Explore P: 0.0000 RunMean : -107.8700\n",
      "Episode: 919 Total reward: -76.0 Training loss: 2.4974 Explore P: 0.0000 RunMean : -107.8700\n",
      "Episode: 920 Total reward: -94.0 Training loss: 5.3240 Explore P: 0.0000 RunMean : -107.7600\n",
      "Episode: 921 Total reward: -127.0 Training loss: 3.4103 Explore P: 0.0000 RunMean : -107.7600\n",
      "Episode: 922 Total reward: -72.0 Training loss: 2.9441 Explore P: 0.0000 RunMean : -107.3500\n",
      "Episode: 923 Total reward: -85.0 Training loss: 3.7531 Explore P: 0.0000 RunMean : -107.4700\n",
      "Episode: 924 Total reward: -105.0 Training loss: 3.4354 Explore P: 0.0000 RunMean : -107.6200\n",
      "Episode: 925 Total reward: -97.0 Training loss: 5.4868 Explore P: 0.0000 RunMean : -107.6900\n",
      "Episode: 926 Total reward: -98.0 Training loss: 3.0193 Explore P: 0.0000 RunMean : -107.9600\n",
      "Episode: 927 Total reward: -83.0 Training loss: 3.6175 Explore P: 0.0000 RunMean : -108.0200\n",
      "Episode: 928 Total reward: -129.0 Training loss: 2.4959 Explore P: 0.0000 RunMean : -108.1000\n",
      "Episode: 929 Total reward: -119.0 Training loss: 4.9840 Explore P: 0.0000 RunMean : -108.5600\n",
      "Episode: 930 Total reward: -163.0 Training loss: 2.5043 Explore P: 0.0000 RunMean : -108.2600\n",
      "Episode: 931 Total reward: -96.0 Training loss: 2.6992 Explore P: 0.0000 RunMean : -108.5100\n",
      "Episode: 932 Total reward: -79.0 Training loss: 2.7501 Explore P: 0.0000 RunMean : -108.3300\n",
      "Episode: 933 Total reward: -107.0 Training loss: 6.3559 Explore P: 0.0000 RunMean : -108.4800\n",
      "Episode: 934 Total reward: -91.0 Training loss: 3.5085 Explore P: 0.0000 RunMean : -108.4200\n",
      "Episode: 935 Total reward: -113.0 Training loss: 3.3179 Explore P: 0.0000 RunMean : -108.2000\n",
      "Episode: 936 Total reward: -76.0 Training loss: 3.3893 Explore P: 0.0000 RunMean : -108.2600\n",
      "Episode: 937 Total reward: -104.0 Training loss: 3.8002 Explore P: 0.0000 RunMean : -104.6400\n",
      "Episode: 938 Total reward: -120.0 Training loss: 4.7014 Explore P: 0.0000 RunMean : -105.0100\n",
      "Episode: 939 Total reward: -101.0 Training loss: 2.9096 Explore P: 0.0000 RunMean : -105.2700\n",
      "Episode: 940 Total reward: -101.0 Training loss: 3.0457 Explore P: 0.0000 RunMean : -105.0900\n",
      "Episode: 941 Total reward: -123.0 Training loss: 1.5351 Explore P: 0.0000 RunMean : -105.1100\n",
      "Episode: 942 Total reward: -109.0 Training loss: 3.3886 Explore P: 0.0000 RunMean : -105.2200\n",
      "Episode: 943 Total reward: -122.0 Training loss: 3.2756 Explore P: 0.0000 RunMean : -105.3900\n",
      "Episode: 944 Total reward: -83.0 Training loss: 3.5619 Explore P: 0.0000 RunMean : -105.4800\n",
      "Episode: 945 Total reward: -119.0 Training loss: 4.4842 Explore P: 0.0000 RunMean : -105.9700\n",
      "Episode: 946 Total reward: -137.0 Training loss: 6.0308 Explore P: 0.0000 RunMean : -106.4200\n",
      "Episode: 947 Total reward: -86.0 Training loss: 3.7696 Explore P: 0.0000 RunMean : -106.2400\n",
      "Episode: 948 Total reward: -119.0 Training loss: 1.2732 Explore P: 0.0000 RunMean : -106.4600\n",
      "Episode: 949 Total reward: -93.0 Training loss: 2.2568 Explore P: 0.0000 RunMean : -106.3400\n",
      "Episode: 950 Total reward: -151.0 Training loss: 1.7000 Explore P: 0.0000 RunMean : -106.3900\n",
      "Episode: 951 Total reward: -110.0 Training loss: 2.9318 Explore P: 0.0000 RunMean : -106.0500\n",
      "Episode: 952 Total reward: -85.0 Training loss: 1.8192 Explore P: 0.0000 RunMean : -105.8400\n",
      "Episode: 953 Total reward: -135.0 Training loss: 2.2051 Explore P: 0.0000 RunMean : -106.1900\n",
      "Episode: 954 Total reward: -92.0 Training loss: 2.2848 Explore P: 0.0000 RunMean : -105.7700\n",
      "Episode: 955 Total reward: -63.0 Training loss: 3.5472 Explore P: 0.0000 RunMean : -105.5800\n",
      "Episode: 956 Total reward: -104.0 Training loss: 3.8455 Explore P: 0.0000 RunMean : -105.6500\n",
      "Episode: 957 Total reward: -105.0 Training loss: 1.7733 Explore P: 0.0000 RunMean : -105.6600\n",
      "Episode: 958 Total reward: -91.0 Training loss: 2.7341 Explore P: 0.0000 RunMean : -105.3600\n",
      "Episode: 959 Total reward: -83.0 Training loss: 2.3645 Explore P: 0.0000 RunMean : -105.3000\n",
      "Episode: 960 Total reward: -84.0 Training loss: 4.3632 Explore P: 0.0000 RunMean : -105.2800\n",
      "Episode: 961 Total reward: -124.0 Training loss: 3.3535 Explore P: 0.0000 RunMean : -105.8100\n",
      "Episode: 962 Total reward: -87.0 Training loss: 2.6297 Explore P: 0.0000 RunMean : -105.5400\n",
      "Episode: 963 Total reward: -93.0 Training loss: 3.4167 Explore P: 0.0000 RunMean : -105.4700\n",
      "Episode: 964 Total reward: -81.0 Training loss: 3.2514 Explore P: 0.0000 RunMean : -105.5300\n",
      "Episode: 965 Total reward: -105.0 Training loss: 5.5889 Explore P: 0.0000 RunMean : -105.7800\n",
      "Episode: 966 Total reward: -109.0 Training loss: 2.5397 Explore P: 0.0000 RunMean : -105.8300\n",
      "Episode: 967 Total reward: -144.0 Training loss: 1.9877 Explore P: 0.0000 RunMean : -106.3400\n",
      "Episode: 968 Total reward: -101.0 Training loss: 3.2755 Explore P: 0.0000 RunMean : -106.2200\n",
      "Episode: 969 Total reward: -145.0 Training loss: 3.2026 Explore P: 0.0000 RunMean : -106.9200\n",
      "Episode: 970 Total reward: -88.0 Training loss: 4.8737 Explore P: 0.0000 RunMean : -106.5900\n",
      "Episode: 971 Total reward: -160.0 Training loss: 3.2274 Explore P: 0.0000 RunMean : -107.0300\n",
      "Episode: 972 Total reward: -143.0 Training loss: 5.1535 Explore P: 0.0000 RunMean : -107.4700\n",
      "Episode: 973 Total reward: -81.0 Training loss: 3.4592 Explore P: 0.0000 RunMean : -107.0300\n",
      "Episode: 974 Total reward: -70.0 Training loss: 2.2562 Explore P: 0.0000 RunMean : -106.7600\n",
      "Episode: 975 Total reward: -130.0 Training loss: 3.4712 Explore P: 0.0000 RunMean : -107.3000\n",
      "Episode: 976 Total reward: -92.0 Training loss: 1.7248 Explore P: 0.0000 RunMean : -107.1800\n",
      "Episode: 977 Total reward: -109.0 Training loss: 4.5879 Explore P: 0.0000 RunMean : -107.4500\n",
      "Episode: 978 Total reward: -87.0 Training loss: 2.4313 Explore P: 0.0000 RunMean : -107.3900\n",
      "Episode: 979 Total reward: -72.0 Training loss: 1.9980 Explore P: 0.0000 RunMean : -107.1500\n",
      "Episode: 980 Total reward: -118.0 Training loss: 2.0217 Explore P: 0.0000 RunMean : -107.0400\n",
      "Episode: 981 Total reward: -95.0 Training loss: 3.6743 Explore P: 0.0000 RunMean : -106.9900\n",
      "Episode: 982 Total reward: -107.0 Training loss: 2.9232 Explore P: 0.0000 RunMean : -106.8600\n",
      "Episode: 983 Total reward: -122.0 Training loss: 1.9161 Explore P: 0.0000 RunMean : -106.4300\n",
      "Episode: 984 Total reward: -104.0 Training loss: 2.2604 Explore P: 0.0000 RunMean : -106.7300\n",
      "Episode: 985 Total reward: -82.0 Training loss: 3.4671 Explore P: 0.0000 RunMean : -106.6400\n",
      "Episode: 986 Total reward: -107.0 Training loss: 2.3224 Explore P: 0.0000 RunMean : -106.6800\n",
      "Episode: 987 Total reward: -84.0 Training loss: 3.2852 Explore P: 0.0000 RunMean : -106.6300\n",
      "Episode: 988 Total reward: -97.0 Training loss: 2.2815 Explore P: 0.0000 RunMean : -106.6700\n",
      "Episode: 989 Total reward: -156.0 Training loss: 1.9532 Explore P: 0.0000 RunMean : -107.4600\n",
      "Episode: 990 Total reward: -110.0 Training loss: 2.1644 Explore P: 0.0000 RunMean : -107.1700\n",
      "Episode: 991 Total reward: -95.0 Training loss: 2.1173 Explore P: 0.0000 RunMean : -107.3800\n",
      "Episode: 992 Total reward: -100.0 Training loss: 2.7096 Explore P: 0.0000 RunMean : -107.6100\n",
      "Episode: 993 Total reward: -69.0 Training loss: 4.1433 Explore P: 0.0000 RunMean : -106.9600\n",
      "Episode: 994 Total reward: -85.0 Training loss: 3.5991 Explore P: 0.0000 RunMean : -106.7200\n",
      "Episode: 995 Total reward: -107.0 Training loss: 2.7971 Explore P: 0.0000 RunMean : -106.2800\n",
      "Episode: 996 Total reward: -69.0 Training loss: 3.3350 Explore P: 0.0000 RunMean : -105.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:26:43,629] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video001000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 997 Total reward: -104.0 Training loss: 1.7296 Explore P: 0.0000 RunMean : -106.2300\n",
      "Episode: 998 Total reward: -90.0 Training loss: 2.3726 Explore P: 0.0000 RunMean : -106.0500\n",
      "Episode: 999 Total reward: -139.0 Training loss: 2.6700 Explore P: 0.0000 RunMean : -106.1200\n",
      "Episode: 1000 Total reward: -91.0 Training loss: 3.7353 Explore P: 0.0000 RunMean : -105.8500\n",
      "Episode: 1001 Total reward: -101.0 Training loss: 3.3039 Explore P: 0.0000 RunMean : -105.7900\n",
      "Episode: 1002 Total reward: -102.0 Training loss: 2.0436 Explore P: 0.0000 RunMean : -105.7400\n",
      "Episode: 1003 Total reward: -112.0 Training loss: 1.9255 Explore P: 0.0000 RunMean : -105.9800\n",
      "Episode: 1004 Total reward: -119.0 Training loss: 3.1433 Explore P: 0.0000 RunMean : -105.8900\n",
      "Episode: 1005 Total reward: -120.0 Training loss: 3.6602 Explore P: 0.0000 RunMean : -105.5500\n",
      "Episode: 1006 Total reward: -90.0 Training loss: 2.7404 Explore P: 0.0000 RunMean : -103.8400\n",
      "Episode: 1007 Total reward: -104.0 Training loss: 5.1396 Explore P: 0.0000 RunMean : -103.6900\n",
      "Episode: 1008 Total reward: -149.0 Training loss: 5.4886 Explore P: 0.0000 RunMean : -104.0200\n",
      "Episode: 1009 Total reward: -108.0 Training loss: 3.9322 Explore P: 0.0000 RunMean : -104.2800\n",
      "Episode: 1010 Total reward: -130.0 Training loss: 3.7189 Explore P: 0.0000 RunMean : -104.3500\n",
      "Episode: 1011 Total reward: -87.0 Training loss: 3.3585 Explore P: 0.0000 RunMean : -104.3000\n",
      "Episode: 1012 Total reward: -97.0 Training loss: 2.7783 Explore P: 0.0000 RunMean : -104.5000\n",
      "Episode: 1013 Total reward: -62.0 Training loss: 9.8291 Explore P: 0.0000 RunMean : -104.1100\n",
      "Episode: 1014 Total reward: -77.0 Training loss: 2.2306 Explore P: 0.0000 RunMean : -103.9600\n",
      "Episode: 1015 Total reward: -146.0 Training loss: 5.0312 Explore P: 0.0000 RunMean : -104.5200\n",
      "Episode: 1016 Total reward: -183.0 Training loss: 4.0100 Explore P: 0.0000 RunMean : -105.2500\n",
      "Episode: 1017 Total reward: -110.0 Training loss: 2.5058 Explore P: 0.0000 RunMean : -105.2500\n",
      "Episode: 1018 Total reward: -146.0 Training loss: 2.7719 Explore P: 0.0000 RunMean : -105.2500\n",
      "Episode: 1019 Total reward: -91.0 Training loss: 2.5137 Explore P: 0.0000 RunMean : -105.4000\n",
      "Episode: 1020 Total reward: -75.0 Training loss: 2.6364 Explore P: 0.0000 RunMean : -105.2100\n",
      "Episode: 1021 Total reward: -94.0 Training loss: 2.0357 Explore P: 0.0000 RunMean : -104.8800\n",
      "Episode: 1022 Total reward: -99.0 Training loss: 2.1180 Explore P: 0.0000 RunMean : -105.1500\n",
      "Episode: 1023 Total reward: -89.0 Training loss: 6.0355 Explore P: 0.0000 RunMean : -105.1900\n",
      "Episode: 1024 Total reward: -106.0 Training loss: 2.1717 Explore P: 0.0000 RunMean : -105.2000\n",
      "Episode: 1025 Total reward: -85.0 Training loss: 1.7558 Explore P: 0.0000 RunMean : -105.0800\n",
      "Episode: 1026 Total reward: -150.0 Training loss: 6.0389 Explore P: 0.0000 RunMean : -105.6000\n",
      "Episode: 1027 Total reward: -107.0 Training loss: 2.8727 Explore P: 0.0000 RunMean : -105.8400\n",
      "Episode: 1028 Total reward: -95.0 Training loss: 2.3495 Explore P: 0.0000 RunMean : -105.5000\n",
      "Episode: 1029 Total reward: -96.0 Training loss: 2.8365 Explore P: 0.0000 RunMean : -105.2700\n",
      "Episode: 1030 Total reward: -130.0 Training loss: 4.7134 Explore P: 0.0000 RunMean : -104.9400\n",
      "Episode: 1031 Total reward: -122.0 Training loss: 2.8219 Explore P: 0.0000 RunMean : -105.2000\n",
      "Episode: 1032 Total reward: -92.0 Training loss: 2.6427 Explore P: 0.0000 RunMean : -105.3300\n",
      "Episode: 1033 Total reward: -84.0 Training loss: 2.3765 Explore P: 0.0000 RunMean : -105.1000\n",
      "Episode: 1034 Total reward: -75.0 Training loss: 1.9895 Explore P: 0.0000 RunMean : -104.9400\n",
      "Episode: 1035 Total reward: -74.0 Training loss: 2.6993 Explore P: 0.0000 RunMean : -104.5500\n",
      "Episode: 1036 Total reward: -80.0 Training loss: 3.3672 Explore P: 0.0000 RunMean : -104.5900\n",
      "Episode: 1037 Total reward: -88.0 Training loss: 7.0405 Explore P: 0.0000 RunMean : -104.4300\n",
      "Episode: 1038 Total reward: -143.0 Training loss: 3.2733 Explore P: 0.0000 RunMean : -104.6600\n",
      "Episode: 1039 Total reward: -94.0 Training loss: 1.9855 Explore P: 0.0000 RunMean : -104.5900\n",
      "Episode: 1040 Total reward: -142.0 Training loss: 2.4687 Explore P: 0.0000 RunMean : -105.0000\n",
      "Episode: 1041 Total reward: -112.0 Training loss: 1.8573 Explore P: 0.0000 RunMean : -104.8900\n",
      "Episode: 1042 Total reward: -87.0 Training loss: 5.2794 Explore P: 0.0000 RunMean : -104.6700\n",
      "Episode: 1043 Total reward: -100.0 Training loss: 2.8715 Explore P: 0.0000 RunMean : -104.4500\n",
      "Episode: 1044 Total reward: -88.0 Training loss: 1.9116 Explore P: 0.0000 RunMean : -104.5000\n",
      "Episode: 1045 Total reward: -117.0 Training loss: 3.7648 Explore P: 0.0000 RunMean : -104.4800\n",
      "Episode: 1046 Total reward: -69.0 Training loss: 2.2163 Explore P: 0.0000 RunMean : -103.8000\n",
      "Episode: 1047 Total reward: -62.0 Training loss: 3.4922 Explore P: 0.0000 RunMean : -103.5600\n",
      "Episode: 1048 Total reward: -70.0 Training loss: 2.9530 Explore P: 0.0000 RunMean : -103.0700\n",
      "Episode: 1049 Total reward: -119.0 Training loss: 4.2978 Explore P: 0.0000 RunMean : -103.3300\n",
      "Episode: 1050 Total reward: -85.0 Training loss: 6.2945 Explore P: 0.0000 RunMean : -102.6700\n",
      "Episode: 1051 Total reward: -78.0 Training loss: 1.7849 Explore P: 0.0000 RunMean : -102.3500\n",
      "Episode: 1052 Total reward: -90.0 Training loss: 2.2163 Explore P: 0.0000 RunMean : -102.4000\n",
      "Episode: 1053 Total reward: -102.0 Training loss: 2.0705 Explore P: 0.0000 RunMean : -102.0700\n",
      "Episode: 1054 Total reward: -103.0 Training loss: 1.0936 Explore P: 0.0000 RunMean : -102.1800\n",
      "Episode: 1055 Total reward: -113.0 Training loss: 1.6482 Explore P: 0.0000 RunMean : -102.6800\n",
      "Episode: 1056 Total reward: -79.0 Training loss: 2.0942 Explore P: 0.0000 RunMean : -102.4300\n",
      "Episode: 1057 Total reward: -94.0 Training loss: 2.1974 Explore P: 0.0000 RunMean : -102.3200\n",
      "Episode: 1058 Total reward: -103.0 Training loss: 2.5619 Explore P: 0.0000 RunMean : -102.4400\n",
      "Episode: 1059 Total reward: -110.0 Training loss: 3.4085 Explore P: 0.0000 RunMean : -102.7100\n",
      "Episode: 1060 Total reward: -79.0 Training loss: 3.2561 Explore P: 0.0000 RunMean : -102.6600\n",
      "Episode: 1061 Total reward: -136.0 Training loss: 2.9775 Explore P: 0.0000 RunMean : -102.7800\n",
      "Episode: 1062 Total reward: -92.0 Training loss: 2.7277 Explore P: 0.0000 RunMean : -102.8300\n",
      "Episode: 1063 Total reward: -128.0 Training loss: 2.9771 Explore P: 0.0000 RunMean : -103.1800\n",
      "Episode: 1064 Total reward: -125.0 Training loss: 2.7407 Explore P: 0.0000 RunMean : -103.6200\n",
      "Episode: 1065 Total reward: -135.0 Training loss: 2.5502 Explore P: 0.0000 RunMean : -103.9200\n",
      "Episode: 1066 Total reward: -83.0 Training loss: 2.8346 Explore P: 0.0000 RunMean : -103.6600\n",
      "Episode: 1067 Total reward: -88.0 Training loss: 3.4968 Explore P: 0.0000 RunMean : -103.1000\n",
      "Episode: 1068 Total reward: -79.0 Training loss: 2.2777 Explore P: 0.0000 RunMean : -102.8800\n",
      "Episode: 1069 Total reward: -101.0 Training loss: 2.7281 Explore P: 0.0000 RunMean : -102.4400\n",
      "Episode: 1070 Total reward: -109.0 Training loss: 4.0572 Explore P: 0.0000 RunMean : -102.6500\n",
      "Episode: 1071 Total reward: -126.0 Training loss: 2.1429 Explore P: 0.0000 RunMean : -102.3100\n",
      "Episode: 1072 Total reward: -88.0 Training loss: 1.7791 Explore P: 0.0000 RunMean : -101.7600\n",
      "Episode: 1073 Total reward: -94.0 Training loss: 3.9746 Explore P: 0.0000 RunMean : -101.8900\n",
      "Episode: 1074 Total reward: -87.0 Training loss: 3.1350 Explore P: 0.0000 RunMean : -102.0600\n",
      "Episode: 1075 Total reward: -142.0 Training loss: 4.3459 Explore P: 0.0000 RunMean : -102.1800\n",
      "Episode: 1076 Total reward: -121.0 Training loss: 2.0932 Explore P: 0.0000 RunMean : -102.4700\n",
      "Episode: 1077 Total reward: -76.0 Training loss: 3.6162 Explore P: 0.0000 RunMean : -102.1400\n",
      "Episode: 1078 Total reward: -86.0 Training loss: 2.1510 Explore P: 0.0000 RunMean : -102.1300\n",
      "Episode: 1079 Total reward: -123.0 Training loss: 2.9999 Explore P: 0.0000 RunMean : -102.6400\n",
      "Episode: 1080 Total reward: -82.0 Training loss: 1.3499 Explore P: 0.0000 RunMean : -102.2800\n",
      "Episode: 1081 Total reward: -101.0 Training loss: 2.5759 Explore P: 0.0000 RunMean : -102.3400\n",
      "Episode: 1082 Total reward: -77.0 Training loss: 3.3780 Explore P: 0.0000 RunMean : -102.0400\n",
      "Episode: 1083 Total reward: -111.0 Training loss: 1.0767 Explore P: 0.0000 RunMean : -101.9300\n",
      "Episode: 1084 Total reward: -127.0 Training loss: 1.6924 Explore P: 0.0000 RunMean : -102.1600\n",
      "Episode: 1085 Total reward: -75.0 Training loss: 2.9861 Explore P: 0.0000 RunMean : -102.0900\n",
      "Episode: 1086 Total reward: -84.0 Training loss: 1.5260 Explore P: 0.0000 RunMean : -101.8600\n",
      "Episode: 1087 Total reward: -83.0 Training loss: 1.8692 Explore P: 0.0000 RunMean : -101.8500\n",
      "Episode: 1088 Total reward: -77.0 Training loss: 2.0978 Explore P: 0.0000 RunMean : -101.6500\n",
      "Episode: 1089 Total reward: -92.0 Training loss: 1.8073 Explore P: 0.0000 RunMean : -101.0100\n",
      "Episode: 1090 Total reward: -103.0 Training loss: 3.1877 Explore P: 0.0000 RunMean : -100.9400\n",
      "Episode: 1091 Total reward: -83.0 Training loss: 3.1843 Explore P: 0.0000 RunMean : -100.8200\n",
      "Episode: 1092 Total reward: -79.0 Training loss: 2.4626 Explore P: 0.0000 RunMean : -100.6100\n",
      "Episode: 1093 Total reward: -120.0 Training loss: 3.3005 Explore P: 0.0000 RunMean : -101.1200\n",
      "Episode: 1094 Total reward: -106.0 Training loss: 2.9069 Explore P: 0.0000 RunMean : -101.3300\n",
      "Episode: 1095 Total reward: -95.0 Training loss: 2.5956 Explore P: 0.0000 RunMean : -101.2100\n",
      "Episode: 1096 Total reward: -134.0 Training loss: 2.5373 Explore P: 0.0000 RunMean : -101.8600\n",
      "Episode: 1097 Total reward: -109.0 Training loss: 2.8583 Explore P: 0.0000 RunMean : -101.9100\n",
      "Episode: 1098 Total reward: -96.0 Training loss: 2.8103 Explore P: 0.0000 RunMean : -101.9700\n",
      "Episode: 1099 Total reward: -95.0 Training loss: 2.5840 Explore P: 0.0000 RunMean : -101.5300\n",
      "Episode: 1100 Total reward: -91.0 Training loss: 1.8277 Explore P: 0.0000 RunMean : -101.5300\n",
      "Episode: 1101 Total reward: -131.0 Training loss: 1.7892 Explore P: 0.0000 RunMean : -101.8300\n",
      "Episode: 1102 Total reward: -111.0 Training loss: 1.9212 Explore P: 0.0000 RunMean : -101.9200\n",
      "Episode: 1103 Total reward: -75.0 Training loss: 1.3398 Explore P: 0.0000 RunMean : -101.5500\n",
      "Episode: 1104 Total reward: -78.0 Training loss: 3.4710 Explore P: 0.0000 RunMean : -101.1400\n",
      "Episode: 1105 Total reward: -92.0 Training loss: 1.6414 Explore P: 0.0000 RunMean : -100.8600\n",
      "Episode: 1106 Total reward: -101.0 Training loss: 1.5217 Explore P: 0.0000 RunMean : -100.9700\n",
      "Episode: 1107 Total reward: -94.0 Training loss: 1.3051 Explore P: 0.0000 RunMean : -100.8700\n",
      "Episode: 1108 Total reward: -95.0 Training loss: 2.4899 Explore P: 0.0000 RunMean : -100.3300\n",
      "Episode: 1109 Total reward: -86.0 Training loss: 2.1725 Explore P: 0.0000 RunMean : -100.1100\n",
      "Episode: 1110 Total reward: -94.0 Training loss: 2.4353 Explore P: 0.0000 RunMean : -99.7500\n",
      "Episode: 1111 Total reward: -131.0 Training loss: 4.2766 Explore P: 0.0000 RunMean : -100.1900\n",
      "Episode: 1112 Total reward: -96.0 Training loss: 4.6302 Explore P: 0.0000 RunMean : -100.1800\n",
      "Episode: 1113 Total reward: -156.0 Training loss: 12.4260 Explore P: 0.0000 RunMean : -101.1200\n",
      "Episode: 1114 Total reward: -96.0 Training loss: 4.2058 Explore P: 0.0000 RunMean : -101.3100\n",
      "Episode: 1115 Total reward: -148.0 Training loss: 2.1661 Explore P: 0.0000 RunMean : -101.3300\n",
      "Episode: 1116 Total reward: -152.0 Training loss: 2.4392 Explore P: 0.0000 RunMean : -101.0200\n",
      "Episode: 1117 Total reward: -95.0 Training loss: 4.0455 Explore P: 0.0000 RunMean : -100.8700\n",
      "Episode: 1118 Total reward: -123.0 Training loss: 2.8048 Explore P: 0.0000 RunMean : -100.6400\n",
      "Episode: 1119 Total reward: -70.0 Training loss: 3.3874 Explore P: 0.0000 RunMean : -100.4300\n",
      "Episode: 1120 Total reward: -134.0 Training loss: 2.0462 Explore P: 0.0000 RunMean : -101.0200\n",
      "Episode: 1121 Total reward: -132.0 Training loss: 1.1340 Explore P: 0.0000 RunMean : -101.4000\n",
      "Episode: 1122 Total reward: -161.0 Training loss: 1.4986 Explore P: 0.0000 RunMean : -102.0200\n",
      "Episode: 1123 Total reward: -82.0 Training loss: 2.6691 Explore P: 0.0000 RunMean : -101.9500\n",
      "Episode: 1124 Total reward: -72.0 Training loss: 1.9024 Explore P: 0.0000 RunMean : -101.6100\n",
      "Episode: 1125 Total reward: -88.0 Training loss: 1.5438 Explore P: 0.0000 RunMean : -101.6400\n",
      "Episode: 1126 Total reward: -108.0 Training loss: 2.9747 Explore P: 0.0000 RunMean : -101.2200\n",
      "Episode: 1127 Total reward: -79.0 Training loss: 5.4744 Explore P: 0.0000 RunMean : -100.9400\n",
      "Episode: 1128 Total reward: -135.0 Training loss: 2.1436 Explore P: 0.0000 RunMean : -101.3400\n",
      "Episode: 1129 Total reward: -110.0 Training loss: 2.0957 Explore P: 0.0000 RunMean : -101.4800\n",
      "Episode: 1130 Total reward: -79.0 Training loss: 3.0970 Explore P: 0.0000 RunMean : -100.9700\n",
      "Episode: 1131 Total reward: -71.0 Training loss: 4.4309 Explore P: 0.0000 RunMean : -100.4600\n",
      "Episode: 1132 Total reward: -91.0 Training loss: 2.6228 Explore P: 0.0000 RunMean : -100.4500\n",
      "Episode: 1133 Total reward: -174.0 Training loss: 3.6241 Explore P: 0.0000 RunMean : -101.3500\n",
      "Episode: 1134 Total reward: -102.0 Training loss: 2.7136 Explore P: 0.0000 RunMean : -101.6200\n",
      "Episode: 1135 Total reward: -122.0 Training loss: 2.0112 Explore P: 0.0000 RunMean : -102.1000\n",
      "Episode: 1136 Total reward: -127.0 Training loss: 3.6828 Explore P: 0.0000 RunMean : -102.5700\n",
      "Episode: 1137 Total reward: -118.0 Training loss: 2.5989 Explore P: 0.0000 RunMean : -102.8700\n",
      "Episode: 1138 Total reward: -87.0 Training loss: 1.2855 Explore P: 0.0000 RunMean : -102.3100\n",
      "Episode: 1139 Total reward: -100.0 Training loss: 3.2056 Explore P: 0.0000 RunMean : -102.3700\n",
      "Episode: 1140 Total reward: -77.0 Training loss: 2.5846 Explore P: 0.0000 RunMean : -101.7200\n",
      "Episode: 1141 Total reward: -88.0 Training loss: 3.1472 Explore P: 0.0000 RunMean : -101.4800\n",
      "Episode: 1142 Total reward: -74.0 Training loss: 3.6562 Explore P: 0.0000 RunMean : -101.3500\n",
      "Episode: 1143 Total reward: -138.0 Training loss: 3.1419 Explore P: 0.0000 RunMean : -101.7300\n",
      "Episode: 1144 Total reward: -122.0 Training loss: 2.2791 Explore P: 0.0000 RunMean : -102.0700\n",
      "Episode: 1145 Total reward: -115.0 Training loss: 8.9525 Explore P: 0.0000 RunMean : -102.0500\n",
      "Episode: 1146 Total reward: -84.0 Training loss: 2.8491 Explore P: 0.0000 RunMean : -102.2000\n",
      "Episode: 1147 Total reward: -100.0 Training loss: 2.2365 Explore P: 0.0000 RunMean : -102.5800\n",
      "Episode: 1148 Total reward: -125.0 Training loss: 2.5876 Explore P: 0.0000 RunMean : -103.1300\n",
      "Episode: 1149 Total reward: -137.0 Training loss: 3.4279 Explore P: 0.0000 RunMean : -103.3100\n",
      "Episode: 1150 Total reward: -76.0 Training loss: 3.3796 Explore P: 0.0000 RunMean : -103.2200\n",
      "Episode: 1151 Total reward: -103.0 Training loss: 2.1770 Explore P: 0.0000 RunMean : -103.4700\n",
      "Episode: 1152 Total reward: -79.0 Training loss: 2.7884 Explore P: 0.0000 RunMean : -103.3600\n",
      "Episode: 1153 Total reward: -106.0 Training loss: 3.6403 Explore P: 0.0000 RunMean : -103.4000\n",
      "Episode: 1154 Total reward: -96.0 Training loss: 1.5347 Explore P: 0.0000 RunMean : -103.3300\n",
      "Episode: 1155 Total reward: -89.0 Training loss: 2.0771 Explore P: 0.0000 RunMean : -103.0900\n",
      "Episode: 1156 Total reward: -88.0 Training loss: 4.4174 Explore P: 0.0000 RunMean : -103.1800\n",
      "Episode: 1157 Total reward: -107.0 Training loss: 3.4405 Explore P: 0.0000 RunMean : -103.3100\n",
      "Episode: 1158 Total reward: -83.0 Training loss: 4.7990 Explore P: 0.0000 RunMean : -103.1100\n",
      "Episode: 1159 Total reward: -85.0 Training loss: 1.7513 Explore P: 0.0000 RunMean : -102.8600\n",
      "Episode: 1160 Total reward: -100.0 Training loss: 2.2076 Explore P: 0.0000 RunMean : -103.0700\n",
      "Episode: 1161 Total reward: -104.0 Training loss: 1.2181 Explore P: 0.0000 RunMean : -102.7500\n",
      "Episode: 1162 Total reward: -112.0 Training loss: 1.3964 Explore P: 0.0000 RunMean : -102.9500\n",
      "Episode: 1163 Total reward: -106.0 Training loss: 3.4867 Explore P: 0.0000 RunMean : -102.7300\n",
      "Episode: 1164 Total reward: -116.0 Training loss: 1.8396 Explore P: 0.0000 RunMean : -102.6400\n",
      "Episode: 1165 Total reward: -101.0 Training loss: 2.7415 Explore P: 0.0000 RunMean : -102.3000\n",
      "Episode: 1166 Total reward: -82.0 Training loss: 2.7251 Explore P: 0.0000 RunMean : -102.2900\n",
      "Episode: 1167 Total reward: -77.0 Training loss: 1.5099 Explore P: 0.0000 RunMean : -102.1800\n",
      "Episode: 1168 Total reward: -101.0 Training loss: 2.4487 Explore P: 0.0000 RunMean : -102.4000\n",
      "Episode: 1169 Total reward: -105.0 Training loss: 2.6166 Explore P: 0.0000 RunMean : -102.4400\n",
      "Episode: 1170 Total reward: -122.0 Training loss: 1.9538 Explore P: 0.0000 RunMean : -102.5700\n",
      "Episode: 1171 Total reward: -140.0 Training loss: 2.0429 Explore P: 0.0000 RunMean : -102.7100\n",
      "Episode: 1172 Total reward: -86.0 Training loss: 3.0440 Explore P: 0.0000 RunMean : -102.6900\n",
      "Episode: 1173 Total reward: -94.0 Training loss: 2.4301 Explore P: 0.0000 RunMean : -102.6900\n",
      "Episode: 1174 Total reward: -112.0 Training loss: 2.2600 Explore P: 0.0000 RunMean : -102.9400\n",
      "Episode: 1175 Total reward: -102.0 Training loss: 3.4733 Explore P: 0.0000 RunMean : -102.5400\n",
      "Episode: 1176 Total reward: -110.0 Training loss: 3.5591 Explore P: 0.0000 RunMean : -102.4300\n",
      "Episode: 1177 Total reward: -88.0 Training loss: 2.7147 Explore P: 0.0000 RunMean : -102.5500\n",
      "Episode: 1178 Total reward: -99.0 Training loss: 3.1262 Explore P: 0.0000 RunMean : -102.6800\n",
      "Episode: 1179 Total reward: -71.0 Training loss: 2.3557 Explore P: 0.0000 RunMean : -102.1600\n",
      "Episode: 1180 Total reward: -85.0 Training loss: 2.4145 Explore P: 0.0000 RunMean : -102.1900\n",
      "Episode: 1181 Total reward: -127.0 Training loss: 1.6259 Explore P: 0.0000 RunMean : -102.4500\n",
      "Episode: 1182 Total reward: -88.0 Training loss: 3.1405 Explore P: 0.0000 RunMean : -102.5600\n",
      "Episode: 1183 Total reward: -83.0 Training loss: 2.1979 Explore P: 0.0000 RunMean : -102.2800\n",
      "Episode: 1184 Total reward: -89.0 Training loss: 4.0211 Explore P: 0.0000 RunMean : -101.9000\n",
      "Episode: 1185 Total reward: -86.0 Training loss: 1.7311 Explore P: 0.0000 RunMean : -102.0100\n",
      "Episode: 1186 Total reward: -99.0 Training loss: 2.3036 Explore P: 0.0000 RunMean : -102.1600\n",
      "Episode: 1187 Total reward: -101.0 Training loss: 2.8557 Explore P: 0.0000 RunMean : -102.3400\n",
      "Episode: 1188 Total reward: -104.0 Training loss: 2.1224 Explore P: 0.0000 RunMean : -102.6100\n",
      "Episode: 1189 Total reward: -102.0 Training loss: 1.2792 Explore P: 0.0000 RunMean : -102.7100\n",
      "Episode: 1190 Total reward: -129.0 Training loss: 1.5463 Explore P: 0.0000 RunMean : -102.9700\n",
      "Episode: 1191 Total reward: -127.0 Training loss: 1.9206 Explore P: 0.0000 RunMean : -103.4100\n",
      "Episode: 1192 Total reward: -123.0 Training loss: 2.3657 Explore P: 0.0000 RunMean : -103.8500\n",
      "Episode: 1193 Total reward: -90.0 Training loss: 2.6694 Explore P: 0.0000 RunMean : -103.5500\n",
      "Episode: 1194 Total reward: -97.0 Training loss: 1.6527 Explore P: 0.0000 RunMean : -103.4600\n",
      "Episode: 1195 Total reward: -111.0 Training loss: 3.1031 Explore P: 0.0000 RunMean : -103.6200\n",
      "Episode: 1196 Total reward: -99.0 Training loss: 1.7172 Explore P: 0.0000 RunMean : -103.2700\n",
      "Episode: 1197 Total reward: -80.0 Training loss: 2.2728 Explore P: 0.0000 RunMean : -102.9800\n",
      "Episode: 1198 Total reward: -75.0 Training loss: 3.6379 Explore P: 0.0000 RunMean : -102.7700\n",
      "Episode: 1199 Total reward: -89.0 Training loss: 1.8221 Explore P: 0.0000 RunMean : -102.7100\n",
      "Episode: 1200 Total reward: -137.0 Training loss: 2.7532 Explore P: 0.0000 RunMean : -103.1700\n",
      "Episode: 1201 Total reward: -80.0 Training loss: 1.9446 Explore P: 0.0000 RunMean : -102.6600\n",
      "Episode: 1202 Total reward: -90.0 Training loss: 1.4976 Explore P: 0.0000 RunMean : -102.4500\n",
      "Episode: 1203 Total reward: -86.0 Training loss: 3.2855 Explore P: 0.0000 RunMean : -102.5600\n",
      "Episode: 1204 Total reward: -102.0 Training loss: 1.6639 Explore P: 0.0000 RunMean : -102.8000\n",
      "Episode: 1205 Total reward: -94.0 Training loss: 2.6935 Explore P: 0.0000 RunMean : -102.8200\n",
      "Episode: 1206 Total reward: -126.0 Training loss: 2.6530 Explore P: 0.0000 RunMean : -103.0700\n",
      "Episode: 1207 Total reward: -133.0 Training loss: 1.9944 Explore P: 0.0000 RunMean : -103.4600\n",
      "Episode: 1208 Total reward: -112.0 Training loss: 1.6720 Explore P: 0.0000 RunMean : -103.6300\n",
      "Episode: 1209 Total reward: -119.0 Training loss: 2.2295 Explore P: 0.0000 RunMean : -103.9600\n",
      "Episode: 1210 Total reward: -78.0 Training loss: 1.7785 Explore P: 0.0000 RunMean : -103.8000\n",
      "Episode: 1211 Total reward: -116.0 Training loss: 2.1209 Explore P: 0.0000 RunMean : -103.6500\n",
      "Episode: 1212 Total reward: -97.0 Training loss: 1.5631 Explore P: 0.0000 RunMean : -103.6600\n",
      "Episode: 1213 Total reward: -71.0 Training loss: 2.3051 Explore P: 0.0000 RunMean : -102.8100\n",
      "Episode: 1214 Total reward: -81.0 Training loss: 3.2273 Explore P: 0.0000 RunMean : -102.6600\n",
      "Episode: 1215 Total reward: -98.0 Training loss: 2.9228 Explore P: 0.0000 RunMean : -102.1600\n",
      "Episode: 1216 Total reward: -113.0 Training loss: 2.6881 Explore P: 0.0000 RunMean : -101.7700\n",
      "Episode: 1217 Total reward: -121.0 Training loss: 3.3038 Explore P: 0.0000 RunMean : -102.0300\n",
      "Episode: 1218 Total reward: -131.0 Training loss: 2.6872 Explore P: 0.0000 RunMean : -102.1100\n",
      "Episode: 1219 Total reward: -102.0 Training loss: 2.3119 Explore P: 0.0000 RunMean : -102.4300\n",
      "Episode: 1220 Total reward: -128.0 Training loss: 3.6690 Explore P: 0.0000 RunMean : -102.3700\n",
      "Episode: 1221 Total reward: -74.0 Training loss: 1.9491 Explore P: 0.0000 RunMean : -101.7900\n",
      "Episode: 1222 Total reward: -120.0 Training loss: 1.6790 Explore P: 0.0000 RunMean : -101.3800\n",
      "Episode: 1223 Total reward: -71.0 Training loss: 2.5399 Explore P: 0.0000 RunMean : -101.2700\n",
      "Episode: 1224 Total reward: -84.0 Training loss: 1.6755 Explore P: 0.0000 RunMean : -101.3900\n",
      "Episode: 1225 Total reward: -82.0 Training loss: 2.2952 Explore P: 0.0000 RunMean : -101.3300\n",
      "Episode: 1226 Total reward: -92.0 Training loss: 3.4007 Explore P: 0.0000 RunMean : -101.1700\n",
      "Episode: 1227 Total reward: -142.0 Training loss: 3.0482 Explore P: 0.0000 RunMean : -101.8000\n",
      "Episode: 1228 Total reward: -75.0 Training loss: 3.1833 Explore P: 0.0000 RunMean : -101.2000\n",
      "Episode: 1229 Total reward: -118.0 Training loss: 2.7910 Explore P: 0.0000 RunMean : -101.2800\n",
      "Episode: 1230 Total reward: -91.0 Training loss: 3.2069 Explore P: 0.0000 RunMean : -101.4000\n",
      "Episode: 1231 Total reward: -88.0 Training loss: 3.8985 Explore P: 0.0000 RunMean : -101.5700\n",
      "Episode: 1232 Total reward: -90.0 Training loss: 2.4347 Explore P: 0.0000 RunMean : -101.5600\n",
      "Episode: 1233 Total reward: -91.0 Training loss: 1.8308 Explore P: 0.0000 RunMean : -100.7300\n",
      "Episode: 1234 Total reward: -83.0 Training loss: 3.8169 Explore P: 0.0000 RunMean : -100.5400\n",
      "Episode: 1235 Total reward: -112.0 Training loss: 2.1147 Explore P: 0.0000 RunMean : -100.4400\n",
      "Episode: 1236 Total reward: -127.0 Training loss: 2.5173 Explore P: 0.0000 RunMean : -100.4400\n",
      "Episode: 1237 Total reward: -99.0 Training loss: 3.6777 Explore P: 0.0000 RunMean : -100.2500\n",
      "Episode: 1238 Total reward: -189.0 Training loss: 4.5181 Explore P: 0.0000 RunMean : -101.2700\n",
      "Episode: 1239 Total reward: -81.0 Training loss: 2.4263 Explore P: 0.0000 RunMean : -101.0800\n",
      "Episode: 1240 Total reward: -112.0 Training loss: 2.4521 Explore P: 0.0000 RunMean : -101.4300\n",
      "Episode: 1241 Total reward: -108.0 Training loss: 3.8842 Explore P: 0.0000 RunMean : -101.6300\n",
      "Episode: 1242 Total reward: -115.0 Training loss: 2.2003 Explore P: 0.0000 RunMean : -102.0400\n",
      "Episode: 1243 Total reward: -81.0 Training loss: 5.2406 Explore P: 0.0000 RunMean : -101.4700\n",
      "Episode: 1244 Total reward: -95.0 Training loss: 2.3325 Explore P: 0.0000 RunMean : -101.2000\n",
      "Episode: 1245 Total reward: -62.0 Training loss: 3.2399 Explore P: 0.0000 RunMean : -100.6700\n",
      "Episode: 1246 Total reward: -77.0 Training loss: 2.6994 Explore P: 0.0000 RunMean : -100.6000\n",
      "Episode: 1247 Total reward: -86.0 Training loss: 2.8581 Explore P: 0.0000 RunMean : -100.4600\n",
      "Episode: 1248 Total reward: -77.0 Training loss: 3.3656 Explore P: 0.0000 RunMean : -99.9800\n",
      "Episode: 1249 Total reward: -113.0 Training loss: 1.6524 Explore P: 0.0000 RunMean : -99.7400\n",
      "Episode: 1250 Total reward: -105.0 Training loss: 1.9681 Explore P: 0.0000 RunMean : -100.0300\n",
      "Episode: 1251 Total reward: -97.0 Training loss: 1.5930 Explore P: 0.0000 RunMean : -99.9700\n",
      "Episode: 1252 Total reward: -93.0 Training loss: 2.6182 Explore P: 0.0000 RunMean : -100.1100\n",
      "Episode: 1253 Total reward: -109.0 Training loss: 2.3659 Explore P: 0.0000 RunMean : -100.1400\n",
      "Episode: 1254 Total reward: -111.0 Training loss: 4.9079 Explore P: 0.0000 RunMean : -100.2900\n",
      "Episode: 1255 Total reward: -134.0 Training loss: 3.9367 Explore P: 0.0000 RunMean : -100.7400\n",
      "Episode: 1256 Total reward: -62.0 Training loss: 4.7618 Explore P: 0.0000 RunMean : -100.4800\n",
      "Episode: 1257 Total reward: -103.0 Training loss: 3.2370 Explore P: 0.0000 RunMean : -100.4400\n",
      "Episode: 1258 Total reward: -122.0 Training loss: 3.1239 Explore P: 0.0000 RunMean : -100.8300\n",
      "Episode: 1259 Total reward: -114.0 Training loss: 2.6414 Explore P: 0.0000 RunMean : -101.1200\n",
      "Episode: 1260 Total reward: -70.0 Training loss: 2.6466 Explore P: 0.0000 RunMean : -100.8200\n",
      "Episode: 1261 Total reward: -95.0 Training loss: 1.8980 Explore P: 0.0000 RunMean : -100.7300\n",
      "Episode: 1262 Total reward: -123.0 Training loss: 2.8093 Explore P: 0.0000 RunMean : -100.8400\n",
      "Episode: 1263 Total reward: -95.0 Training loss: 1.8394 Explore P: 0.0000 RunMean : -100.7300\n",
      "Episode: 1264 Total reward: -90.0 Training loss: 1.7975 Explore P: 0.0000 RunMean : -100.4700\n",
      "Episode: 1265 Total reward: -83.0 Training loss: 1.2210 Explore P: 0.0000 RunMean : -100.2900\n",
      "Episode: 1266 Total reward: -71.0 Training loss: 1.9221 Explore P: 0.0000 RunMean : -100.1800\n",
      "Episode: 1267 Total reward: -74.0 Training loss: 1.3313 Explore P: 0.0000 RunMean : -100.1500\n",
      "Episode: 1268 Total reward: -105.0 Training loss: 3.2704 Explore P: 0.0000 RunMean : -100.1900\n",
      "Episode: 1269 Total reward: -72.0 Training loss: 2.0005 Explore P: 0.0000 RunMean : -99.8600\n",
      "Episode: 1270 Total reward: -62.0 Training loss: 1.6599 Explore P: 0.0000 RunMean : -99.2600\n",
      "Episode: 1271 Total reward: -71.0 Training loss: 1.8043 Explore P: 0.0000 RunMean : -98.5700\n",
      "Episode: 1272 Total reward: -109.0 Training loss: 1.9540 Explore P: 0.0000 RunMean : -98.8000\n",
      "Episode: 1273 Total reward: -68.0 Training loss: 2.7504 Explore P: 0.0000 RunMean : -98.5400\n",
      "Episode: 1274 Total reward: -87.0 Training loss: 3.2292 Explore P: 0.0000 RunMean : -98.2900\n",
      "Episode: 1275 Total reward: -83.0 Training loss: 1.6260 Explore P: 0.0000 RunMean : -98.1000\n",
      "Episode: 1276 Total reward: -106.0 Training loss: 2.3012 Explore P: 0.0000 RunMean : -98.0600\n",
      "Episode: 1277 Total reward: -71.0 Training loss: 1.4675 Explore P: 0.0000 RunMean : -97.8900\n",
      "Episode: 1278 Total reward: -82.0 Training loss: 1.7595 Explore P: 0.0000 RunMean : -97.7200\n",
      "Episode: 1279 Total reward: -95.0 Training loss: 2.2710 Explore P: 0.0000 RunMean : -97.9600\n",
      "Episode: 1280 Total reward: -77.0 Training loss: 3.1158 Explore P: 0.0000 RunMean : -97.8800\n",
      "Episode: 1281 Total reward: -62.0 Training loss: 2.8507 Explore P: 0.0000 RunMean : -97.2300\n",
      "Episode: 1282 Total reward: -103.0 Training loss: 2.1018 Explore P: 0.0000 RunMean : -97.3800\n",
      "Episode: 1283 Total reward: -134.0 Training loss: 2.6999 Explore P: 0.0000 RunMean : -97.8900\n",
      "Episode: 1284 Total reward: -86.0 Training loss: 2.4515 Explore P: 0.0000 RunMean : -97.8600\n",
      "Episode: 1285 Total reward: -106.0 Training loss: 2.3615 Explore P: 0.0000 RunMean : -98.0600\n",
      "Episode: 1286 Total reward: -69.0 Training loss: 2.5907 Explore P: 0.0000 RunMean : -97.7600\n",
      "Episode: 1287 Total reward: -89.0 Training loss: 1.7350 Explore P: 0.0000 RunMean : -97.6400\n",
      "Episode: 1288 Total reward: -155.0 Training loss: 1.7545 Explore P: 0.0000 RunMean : -98.1500\n",
      "Episode: 1289 Total reward: -62.0 Training loss: 2.0808 Explore P: 0.0000 RunMean : -97.7500\n",
      "Episode: 1290 Total reward: -69.0 Training loss: 2.4042 Explore P: 0.0000 RunMean : -97.1500\n",
      "Episode: 1291 Total reward: -76.0 Training loss: 2.8978 Explore P: 0.0000 RunMean : -96.6400\n",
      "Episode: 1292 Total reward: -72.0 Training loss: 3.9566 Explore P: 0.0000 RunMean : -96.1300\n",
      "Episode: 1293 Total reward: -83.0 Training loss: 5.3843 Explore P: 0.0000 RunMean : -96.0600\n",
      "Episode: 1294 Total reward: -102.0 Training loss: 2.9394 Explore P: 0.0000 RunMean : -96.1100\n",
      "Episode: 1295 Total reward: -145.0 Training loss: 2.1642 Explore P: 0.0000 RunMean : -96.4500\n",
      "Episode: 1296 Total reward: -69.0 Training loss: 2.5860 Explore P: 0.0000 RunMean : -96.1500\n",
      "Episode: 1297 Total reward: -71.0 Training loss: 2.3355 Explore P: 0.0000 RunMean : -96.0600\n",
      "Episode: 1298 Total reward: -105.0 Training loss: 1.7896 Explore P: 0.0000 RunMean : -96.3600\n",
      "Episode: 1299 Total reward: -85.0 Training loss: 2.9642 Explore P: 0.0000 RunMean : -96.3200\n",
      "Episode: 1300 Total reward: -142.0 Training loss: 1.7785 Explore P: 0.0000 RunMean : -96.3700\n",
      "Episode: 1301 Total reward: -102.0 Training loss: 3.3252 Explore P: 0.0000 RunMean : -96.5900\n",
      "Episode: 1302 Total reward: -106.0 Training loss: 4.0450 Explore P: 0.0000 RunMean : -96.7500\n",
      "Episode: 1303 Total reward: -76.0 Training loss: 3.0345 Explore P: 0.0000 RunMean : -96.6500\n",
      "Episode: 1304 Total reward: -95.0 Training loss: 2.0320 Explore P: 0.0000 RunMean : -96.5800\n",
      "Episode: 1305 Total reward: -99.0 Training loss: 3.4883 Explore P: 0.0000 RunMean : -96.6300\n",
      "Episode: 1306 Total reward: -96.0 Training loss: 2.1301 Explore P: 0.0000 RunMean : -96.3300\n",
      "Episode: 1307 Total reward: -76.0 Training loss: 4.0013 Explore P: 0.0000 RunMean : -95.7600\n",
      "Episode: 1308 Total reward: -86.0 Training loss: 2.2045 Explore P: 0.0000 RunMean : -95.5000\n",
      "Episode: 1309 Total reward: -99.0 Training loss: 3.1727 Explore P: 0.0000 RunMean : -95.3000\n",
      "Episode: 1310 Total reward: -86.0 Training loss: 1.4030 Explore P: 0.0000 RunMean : -95.3800\n",
      "Episode: 1311 Total reward: -91.0 Training loss: 1.7578 Explore P: 0.0000 RunMean : -95.1300\n",
      "Episode: 1312 Total reward: -103.0 Training loss: 1.7113 Explore P: 0.0000 RunMean : -95.1900\n",
      "Episode: 1313 Total reward: -127.0 Training loss: 1.0452 Explore P: 0.0000 RunMean : -95.7500\n",
      "Episode: 1314 Total reward: -128.0 Training loss: 1.6629 Explore P: 0.0000 RunMean : -96.2200\n",
      "Episode: 1315 Total reward: -103.0 Training loss: 3.5365 Explore P: 0.0000 RunMean : -96.2700\n",
      "Episode: 1316 Total reward: -73.0 Training loss: 6.8623 Explore P: 0.0000 RunMean : -95.8700\n",
      "Episode: 1317 Total reward: -123.0 Training loss: 1.9818 Explore P: 0.0000 RunMean : -95.8900\n",
      "Episode: 1318 Total reward: -84.0 Training loss: 1.4040 Explore P: 0.0000 RunMean : -95.4200\n",
      "Episode: 1319 Total reward: -128.0 Training loss: 3.2182 Explore P: 0.0000 RunMean : -95.6800\n",
      "Episode: 1320 Total reward: -117.0 Training loss: 3.0486 Explore P: 0.0000 RunMean : -95.5700\n",
      "Episode: 1321 Total reward: -114.0 Training loss: 4.3614 Explore P: 0.0000 RunMean : -95.9700\n",
      "Episode: 1322 Total reward: -93.0 Training loss: 3.0797 Explore P: 0.0000 RunMean : -95.7000\n",
      "Episode: 1323 Total reward: -124.0 Training loss: 3.9484 Explore P: 0.0000 RunMean : -96.2300\n",
      "Episode: 1324 Total reward: -95.0 Training loss: 1.5280 Explore P: 0.0000 RunMean : -96.3400\n",
      "Episode: 1325 Total reward: -98.0 Training loss: 1.8471 Explore P: 0.0000 RunMean : -96.5000\n",
      "Episode: 1326 Total reward: -99.0 Training loss: 1.7308 Explore P: 0.0000 RunMean : -96.5700\n",
      "Episode: 1327 Total reward: -86.0 Training loss: 1.9092 Explore P: 0.0000 RunMean : -96.0100\n",
      "Episode: 1328 Total reward: -74.0 Training loss: 1.6304 Explore P: 0.0000 RunMean : -96.0000\n",
      "Episode: 1329 Total reward: -103.0 Training loss: 2.2553 Explore P: 0.0000 RunMean : -95.8500\n",
      "Episode: 1330 Total reward: -75.0 Training loss: 1.1967 Explore P: 0.0000 RunMean : -95.6900\n",
      "Episode: 1331 Total reward: -97.0 Training loss: 1.2586 Explore P: 0.0000 RunMean : -95.7800\n",
      "Episode: 1332 Total reward: -88.0 Training loss: 2.5273 Explore P: 0.0000 RunMean : -95.7600\n",
      "Episode: 1333 Total reward: -76.0 Training loss: 2.2271 Explore P: 0.0000 RunMean : -95.6100\n",
      "Episode: 1334 Total reward: -110.0 Training loss: 2.4635 Explore P: 0.0000 RunMean : -95.8800\n",
      "Episode: 1335 Total reward: -61.0 Training loss: 2.5106 Explore P: 0.0000 RunMean : -95.3700\n",
      "Episode: 1336 Total reward: -116.0 Training loss: 1.7620 Explore P: 0.0000 RunMean : -95.2600\n",
      "Episode: 1337 Total reward: -85.0 Training loss: 2.8690 Explore P: 0.0000 RunMean : -95.1200\n",
      "Episode: 1338 Total reward: -107.0 Training loss: 2.3607 Explore P: 0.0000 RunMean : -94.3000\n",
      "Episode: 1339 Total reward: -70.0 Training loss: 2.9461 Explore P: 0.0000 RunMean : -94.1900\n",
      "Episode: 1340 Total reward: -82.0 Training loss: 2.4893 Explore P: 0.0000 RunMean : -93.8900\n",
      "Episode: 1341 Total reward: -82.0 Training loss: 4.6247 Explore P: 0.0000 RunMean : -93.6300\n",
      "Episode: 1342 Total reward: -69.0 Training loss: 2.1928 Explore P: 0.0000 RunMean : -93.1700\n",
      "Episode: 1343 Total reward: -63.0 Training loss: 1.7841 Explore P: 0.0000 RunMean : -92.9900\n",
      "Episode: 1344 Total reward: -109.0 Training loss: 2.3287 Explore P: 0.0000 RunMean : -93.1300\n",
      "Episode: 1345 Total reward: -70.0 Training loss: 1.7601 Explore P: 0.0000 RunMean : -93.2100\n",
      "Episode: 1346 Total reward: -97.0 Training loss: 1.2845 Explore P: 0.0000 RunMean : -93.4100\n",
      "Episode: 1347 Total reward: -78.0 Training loss: 1.1235 Explore P: 0.0000 RunMean : -93.3300\n",
      "Episode: 1348 Total reward: -69.0 Training loss: 1.5636 Explore P: 0.0000 RunMean : -93.2500\n",
      "Episode: 1349 Total reward: -106.0 Training loss: 1.0119 Explore P: 0.0000 RunMean : -93.1800\n",
      "Episode: 1350 Total reward: -118.0 Training loss: 1.9769 Explore P: 0.0000 RunMean : -93.3100\n",
      "Episode: 1351 Total reward: -166.0 Training loss: 6.4874 Explore P: 0.0000 RunMean : -94.0000\n",
      "Episode: 1352 Total reward: -91.0 Training loss: 2.7363 Explore P: 0.0000 RunMean : -93.9800\n",
      "Episode: 1353 Total reward: -94.0 Training loss: 2.3057 Explore P: 0.0000 RunMean : -93.8300\n",
      "Episode: 1354 Total reward: -115.0 Training loss: 2.2957 Explore P: 0.0000 RunMean : -93.8700\n",
      "Episode: 1355 Total reward: -95.0 Training loss: 3.4218 Explore P: 0.0000 RunMean : -93.4800\n",
      "Episode: 1356 Total reward: -107.0 Training loss: 2.7348 Explore P: 0.0000 RunMean : -93.9300\n",
      "Episode: 1357 Total reward: -86.0 Training loss: 1.5017 Explore P: 0.0000 RunMean : -93.7600\n",
      "Episode: 1358 Total reward: -96.0 Training loss: 2.7165 Explore P: 0.0000 RunMean : -93.5000\n",
      "Episode: 1359 Total reward: -96.0 Training loss: 2.3545 Explore P: 0.0000 RunMean : -93.3200\n",
      "Episode: 1360 Total reward: -107.0 Training loss: 2.3896 Explore P: 0.0000 RunMean : -93.6900\n",
      "Episode: 1361 Total reward: -114.0 Training loss: 2.2531 Explore P: 0.0000 RunMean : -93.8800\n",
      "Episode: 1362 Total reward: -90.0 Training loss: 1.6247 Explore P: 0.0000 RunMean : -93.5500\n",
      "Episode: 1363 Total reward: -149.0 Training loss: 2.3973 Explore P: 0.0000 RunMean : -94.0900\n",
      "Episode: 1364 Total reward: -113.0 Training loss: 1.5948 Explore P: 0.0000 RunMean : -94.3200\n",
      "Episode: 1365 Total reward: -121.0 Training loss: 1.1882 Explore P: 0.0000 RunMean : -94.7000\n",
      "Episode: 1366 Total reward: -150.0 Training loss: 2.0451 Explore P: 0.0000 RunMean : -95.4900\n",
      "Episode: 1367 Total reward: -112.0 Training loss: 2.1106 Explore P: 0.0000 RunMean : -95.8700\n",
      "Episode: 1368 Total reward: -107.0 Training loss: 3.0342 Explore P: 0.0000 RunMean : -95.8900\n",
      "Episode: 1369 Total reward: -107.0 Training loss: 2.5400 Explore P: 0.0000 RunMean : -96.2400\n",
      "Episode: 1370 Total reward: -89.0 Training loss: 2.2170 Explore P: 0.0000 RunMean : -96.5100\n",
      "Episode: 1371 Total reward: -93.0 Training loss: 2.1156 Explore P: 0.0000 RunMean : -96.7300\n",
      "Episode: 1372 Total reward: -101.0 Training loss: 2.7686 Explore P: 0.0000 RunMean : -96.6500\n",
      "Episode: 1373 Total reward: -122.0 Training loss: 2.8226 Explore P: 0.0000 RunMean : -97.1900\n",
      "Episode: 1374 Total reward: -122.0 Training loss: 1.4606 Explore P: 0.0000 RunMean : -97.5400\n",
      "Episode: 1375 Total reward: -71.0 Training loss: 2.9013 Explore P: 0.0000 RunMean : -97.4200\n",
      "Episode: 1376 Total reward: -103.0 Training loss: 2.7662 Explore P: 0.0000 RunMean : -97.3900\n",
      "Episode: 1377 Total reward: -173.0 Training loss: 5.6508 Explore P: 0.0000 RunMean : -98.4100\n",
      "Episode: 1378 Total reward: -72.0 Training loss: 3.2096 Explore P: 0.0000 RunMean : -98.3100\n",
      "Episode: 1379 Total reward: -83.0 Training loss: 3.2840 Explore P: 0.0000 RunMean : -98.1900\n",
      "Episode: 1380 Total reward: -63.0 Training loss: 2.1712 Explore P: 0.0000 RunMean : -98.0500\n",
      "Episode: 1381 Total reward: -100.0 Training loss: 4.4131 Explore P: 0.0000 RunMean : -98.4300\n",
      "Episode: 1382 Total reward: -98.0 Training loss: 1.3015 Explore P: 0.0000 RunMean : -98.3800\n",
      "Episode: 1383 Total reward: -119.0 Training loss: 1.4350 Explore P: 0.0000 RunMean : -98.2300\n",
      "Episode: 1384 Total reward: -125.0 Training loss: 1.5890 Explore P: 0.0000 RunMean : -98.6200\n",
      "Episode: 1385 Total reward: -101.0 Training loss: 2.3233 Explore P: 0.0000 RunMean : -98.5700\n",
      "Episode: 1386 Total reward: -70.0 Training loss: 4.0951 Explore P: 0.0000 RunMean : -98.5800\n",
      "Episode: 1387 Total reward: -114.0 Training loss: 1.4892 Explore P: 0.0000 RunMean : -98.8300\n",
      "Episode: 1388 Total reward: -90.0 Training loss: 2.8673 Explore P: 0.0000 RunMean : -98.1800\n",
      "Episode: 1389 Total reward: -152.0 Training loss: 1.7714 Explore P: 0.0000 RunMean : -99.0800\n",
      "Episode: 1390 Total reward: -106.0 Training loss: 2.0303 Explore P: 0.0000 RunMean : -99.4500\n",
      "Episode: 1391 Total reward: -78.0 Training loss: 1.9730 Explore P: 0.0000 RunMean : -99.4700\n",
      "Episode: 1392 Total reward: -85.0 Training loss: 4.6197 Explore P: 0.0000 RunMean : -99.6000\n",
      "Episode: 1393 Total reward: -142.0 Training loss: 2.4904 Explore P: 0.0000 RunMean : -100.1900\n",
      "Episode: 1394 Total reward: -84.0 Training loss: 3.6281 Explore P: 0.0000 RunMean : -100.0100\n",
      "Episode: 1395 Total reward: -74.0 Training loss: 3.7180 Explore P: 0.0000 RunMean : -99.3000\n",
      "Episode: 1396 Total reward: -88.0 Training loss: 3.9970 Explore P: 0.0000 RunMean : -99.4900\n",
      "Episode: 1397 Total reward: -74.0 Training loss: 2.4415 Explore P: 0.0000 RunMean : -99.5200\n",
      "Episode: 1398 Total reward: -101.0 Training loss: 1.5529 Explore P: 0.0000 RunMean : -99.4800\n",
      "Episode: 1399 Total reward: -101.0 Training loss: 2.1550 Explore P: 0.0000 RunMean : -99.6400\n",
      "Episode: 1400 Total reward: -92.0 Training loss: 3.2436 Explore P: 0.0000 RunMean : -99.1400\n",
      "Episode: 1401 Total reward: -89.0 Training loss: 1.5220 Explore P: 0.0000 RunMean : -99.0100\n",
      "Episode: 1402 Total reward: -103.0 Training loss: 2.7844 Explore P: 0.0000 RunMean : -98.9800\n",
      "Episode: 1403 Total reward: -103.0 Training loss: 1.7139 Explore P: 0.0000 RunMean : -99.2500\n",
      "Episode: 1404 Total reward: -140.0 Training loss: 1.6308 Explore P: 0.0000 RunMean : -99.7000\n",
      "Episode: 1405 Total reward: -85.0 Training loss: 2.0704 Explore P: 0.0000 RunMean : -99.5600\n",
      "Episode: 1406 Total reward: -108.0 Training loss: 1.5176 Explore P: 0.0000 RunMean : -99.6800\n",
      "Episode: 1407 Total reward: -114.0 Training loss: 1.2344 Explore P: 0.0000 RunMean : -100.0600\n",
      "Episode: 1408 Total reward: -112.0 Training loss: 4.8412 Explore P: 0.0000 RunMean : -100.3200\n",
      "Episode: 1409 Total reward: -92.0 Training loss: 3.0270 Explore P: 0.0000 RunMean : -100.2500\n",
      "Episode: 1410 Total reward: -72.0 Training loss: 3.4946 Explore P: 0.0000 RunMean : -100.1100\n",
      "Episode: 1411 Total reward: -120.0 Training loss: 1.2737 Explore P: 0.0000 RunMean : -100.4000\n",
      "Episode: 1412 Total reward: -123.0 Training loss: 3.0309 Explore P: 0.0000 RunMean : -100.6000\n",
      "Episode: 1413 Total reward: -105.0 Training loss: 3.6505 Explore P: 0.0000 RunMean : -100.3800\n",
      "Episode: 1414 Total reward: -103.0 Training loss: 1.8022 Explore P: 0.0000 RunMean : -100.1300\n",
      "Episode: 1415 Total reward: -71.0 Training loss: 2.8313 Explore P: 0.0000 RunMean : -99.8100\n",
      "Episode: 1416 Total reward: -74.0 Training loss: 1.8258 Explore P: 0.0000 RunMean : -99.8200\n",
      "Episode: 1417 Total reward: -80.0 Training loss: 1.9350 Explore P: 0.0000 RunMean : -99.3900\n",
      "Episode: 1418 Total reward: -74.0 Training loss: 2.6685 Explore P: 0.0000 RunMean : -99.2900\n",
      "Episode: 1419 Total reward: -87.0 Training loss: 2.0081 Explore P: 0.0000 RunMean : -98.8800\n",
      "Episode: 1420 Total reward: -113.0 Training loss: 4.6419 Explore P: 0.0000 RunMean : -98.8400\n",
      "Episode: 1421 Total reward: -110.0 Training loss: 2.4656 Explore P: 0.0000 RunMean : -98.8000\n",
      "Episode: 1422 Total reward: -69.0 Training loss: 2.9350 Explore P: 0.0000 RunMean : -98.5600\n",
      "Episode: 1423 Total reward: -97.0 Training loss: 2.5253 Explore P: 0.0000 RunMean : -98.2900\n",
      "Episode: 1424 Total reward: -96.0 Training loss: 2.1033 Explore P: 0.0000 RunMean : -98.3000\n",
      "Episode: 1425 Total reward: -109.0 Training loss: 2.4891 Explore P: 0.0000 RunMean : -98.4100\n",
      "Episode: 1426 Total reward: -121.0 Training loss: 2.4402 Explore P: 0.0000 RunMean : -98.6300\n",
      "Episode: 1427 Total reward: -133.0 Training loss: 2.7739 Explore P: 0.0000 RunMean : -99.1000\n",
      "Episode: 1428 Total reward: -85.0 Training loss: 1.2958 Explore P: 0.0000 RunMean : -99.2100\n",
      "Episode: 1429 Total reward: -96.0 Training loss: 3.4337 Explore P: 0.0000 RunMean : -99.1400\n",
      "Episode: 1430 Total reward: -93.0 Training loss: 3.0591 Explore P: 0.0000 RunMean : -99.3200\n",
      "Episode: 1431 Total reward: -115.0 Training loss: 3.4439 Explore P: 0.0000 RunMean : -99.5000\n",
      "Episode: 1432 Total reward: -75.0 Training loss: 2.6180 Explore P: 0.0000 RunMean : -99.3700\n",
      "Episode: 1433 Total reward: -98.0 Training loss: 1.8141 Explore P: 0.0000 RunMean : -99.5900\n",
      "Episode: 1434 Total reward: -130.0 Training loss: 3.1959 Explore P: 0.0000 RunMean : -99.7900\n",
      "Episode: 1435 Total reward: -122.0 Training loss: 2.5065 Explore P: 0.0000 RunMean : -100.4000\n",
      "Episode: 1436 Total reward: -88.0 Training loss: 3.0795 Explore P: 0.0000 RunMean : -100.1200\n",
      "Episode: 1437 Total reward: -82.0 Training loss: 2.1539 Explore P: 0.0000 RunMean : -100.0900\n",
      "Episode: 1438 Total reward: -92.0 Training loss: 2.3454 Explore P: 0.0000 RunMean : -99.9400\n",
      "Episode: 1439 Total reward: -82.0 Training loss: 2.4624 Explore P: 0.0000 RunMean : -100.0600\n",
      "Episode: 1440 Total reward: -85.0 Training loss: 3.4692 Explore P: 0.0000 RunMean : -100.0900\n",
      "Episode: 1441 Total reward: -71.0 Training loss: 3.9333 Explore P: 0.0000 RunMean : -99.9800\n",
      "Episode: 1442 Total reward: -80.0 Training loss: 2.1742 Explore P: 0.0000 RunMean : -100.0900\n",
      "Episode: 1443 Total reward: -74.0 Training loss: 1.7398 Explore P: 0.0000 RunMean : -100.2000\n",
      "Episode: 1444 Total reward: -77.0 Training loss: 2.1896 Explore P: 0.0000 RunMean : -99.8800\n",
      "Episode: 1445 Total reward: -111.0 Training loss: 2.6775 Explore P: 0.0000 RunMean : -100.2900\n",
      "Episode: 1446 Total reward: -108.0 Training loss: 3.2506 Explore P: 0.0000 RunMean : -100.4000\n",
      "Episode: 1447 Total reward: -95.0 Training loss: 1.4526 Explore P: 0.0000 RunMean : -100.5700\n",
      "Episode: 1448 Total reward: -111.0 Training loss: 1.4254 Explore P: 0.0000 RunMean : -100.9900\n",
      "Episode: 1449 Total reward: -87.0 Training loss: 1.4277 Explore P: 0.0000 RunMean : -100.8000\n",
      "Episode: 1450 Total reward: -70.0 Training loss: 3.9173 Explore P: 0.0000 RunMean : -100.3200\n",
      "Episode: 1451 Total reward: -89.0 Training loss: 1.7340 Explore P: 0.0000 RunMean : -99.5500\n",
      "Episode: 1452 Total reward: -101.0 Training loss: 2.0130 Explore P: 0.0000 RunMean : -99.6500\n",
      "Episode: 1453 Total reward: -114.0 Training loss: 1.8106 Explore P: 0.0000 RunMean : -99.8500\n",
      "Episode: 1454 Total reward: -84.0 Training loss: 1.5860 Explore P: 0.0000 RunMean : -99.5400\n",
      "Episode: 1455 Total reward: -83.0 Training loss: 4.4298 Explore P: 0.0000 RunMean : -99.4200\n",
      "Episode: 1456 Total reward: -101.0 Training loss: 1.6834 Explore P: 0.0000 RunMean : -99.3600\n",
      "Episode: 1457 Total reward: -99.0 Training loss: 1.5547 Explore P: 0.0000 RunMean : -99.4900\n",
      "Episode: 1458 Total reward: -70.0 Training loss: 1.7571 Explore P: 0.0000 RunMean : -99.2300\n",
      "Episode: 1459 Total reward: -84.0 Training loss: 1.8681 Explore P: 0.0000 RunMean : -99.1100\n",
      "Episode: 1460 Total reward: -118.0 Training loss: 2.3153 Explore P: 0.0000 RunMean : -99.2200\n",
      "Episode: 1461 Total reward: -69.0 Training loss: 1.6992 Explore P: 0.0000 RunMean : -98.7700\n",
      "Episode: 1462 Total reward: -94.0 Training loss: 1.7325 Explore P: 0.0000 RunMean : -98.8100\n",
      "Episode: 1463 Total reward: -75.0 Training loss: 1.9471 Explore P: 0.0000 RunMean : -98.0700\n",
      "Episode: 1464 Total reward: -114.0 Training loss: 1.7570 Explore P: 0.0000 RunMean : -98.0800\n",
      "Episode: 1465 Total reward: -126.0 Training loss: 2.5091 Explore P: 0.0000 RunMean : -98.1300\n",
      "Episode: 1466 Total reward: -106.0 Training loss: 1.7797 Explore P: 0.0000 RunMean : -97.6900\n",
      "Episode: 1467 Total reward: -88.0 Training loss: 2.2714 Explore P: 0.0000 RunMean : -97.4500\n",
      "Episode: 1468 Total reward: -93.0 Training loss: 3.3656 Explore P: 0.0000 RunMean : -97.3100\n",
      "Episode: 1469 Total reward: -148.0 Training loss: 0.6749 Explore P: 0.0000 RunMean : -97.7200\n",
      "Episode: 1470 Total reward: -74.0 Training loss: 2.5605 Explore P: 0.0000 RunMean : -97.5700\n",
      "Episode: 1471 Total reward: -90.0 Training loss: 1.1793 Explore P: 0.0000 RunMean : -97.5400\n",
      "Episode: 1472 Total reward: -155.0 Training loss: 1.6498 Explore P: 0.0000 RunMean : -98.0800\n",
      "Episode: 1473 Total reward: -107.0 Training loss: 1.4714 Explore P: 0.0000 RunMean : -97.9300\n",
      "Episode: 1474 Total reward: -84.0 Training loss: 1.9344 Explore P: 0.0000 RunMean : -97.5500\n",
      "Episode: 1475 Total reward: -100.0 Training loss: 1.7685 Explore P: 0.0000 RunMean : -97.8400\n",
      "Episode: 1476 Total reward: -76.0 Training loss: 2.3357 Explore P: 0.0000 RunMean : -97.5700\n",
      "Episode: 1477 Total reward: -180.0 Training loss: 2.0405 Explore P: 0.0000 RunMean : -97.6400\n",
      "Episode: 1478 Total reward: -87.0 Training loss: 3.1896 Explore P: 0.0000 RunMean : -97.7900\n",
      "Episode: 1479 Total reward: -142.0 Training loss: 2.9194 Explore P: 0.0000 RunMean : -98.3800\n",
      "Episode: 1480 Total reward: -128.0 Training loss: 3.1033 Explore P: 0.0000 RunMean : -99.0300\n",
      "Episode: 1481 Total reward: -118.0 Training loss: 2.0854 Explore P: 0.0000 RunMean : -99.2100\n",
      "Episode: 1482 Total reward: -88.0 Training loss: 9.1473 Explore P: 0.0000 RunMean : -99.1100\n",
      "Episode: 1483 Total reward: -71.0 Training loss: 2.6473 Explore P: 0.0000 RunMean : -98.6300\n",
      "Episode: 1484 Total reward: -103.0 Training loss: 2.0535 Explore P: 0.0000 RunMean : -98.4100\n",
      "Episode: 1485 Total reward: -254.0 Training loss: 2.4642 Explore P: 0.0000 RunMean : -99.9400\n",
      "Episode: 1486 Total reward: -124.0 Training loss: 2.9207 Explore P: 0.0000 RunMean : -100.4800\n",
      "Episode: 1487 Total reward: -114.0 Training loss: 1.9673 Explore P: 0.0000 RunMean : -100.4800\n",
      "Episode: 1488 Total reward: -63.0 Training loss: 1.2933 Explore P: 0.0000 RunMean : -100.2100\n",
      "Episode: 1489 Total reward: -80.0 Training loss: 3.0169 Explore P: 0.0000 RunMean : -99.4900\n",
      "Episode: 1490 Total reward: -89.0 Training loss: 1.7975 Explore P: 0.0000 RunMean : -99.3200\n",
      "Episode: 1491 Total reward: -88.0 Training loss: 1.6693 Explore P: 0.0000 RunMean : -99.4200\n",
      "Episode: 1492 Total reward: -90.0 Training loss: 3.3421 Explore P: 0.0000 RunMean : -99.4700\n",
      "Episode: 1493 Total reward: -83.0 Training loss: 1.7488 Explore P: 0.0000 RunMean : -98.8800\n",
      "Episode: 1494 Total reward: -91.0 Training loss: 2.2496 Explore P: 0.0000 RunMean : -98.9500\n",
      "Episode: 1495 Total reward: -128.0 Training loss: 2.4675 Explore P: 0.0000 RunMean : -99.4900\n",
      "Episode: 1496 Total reward: -82.0 Training loss: 3.0248 Explore P: 0.0000 RunMean : -99.4300\n",
      "Episode: 1497 Total reward: -127.0 Training loss: 2.4085 Explore P: 0.0000 RunMean : -99.9600\n",
      "Episode: 1498 Total reward: -102.0 Training loss: 3.4108 Explore P: 0.0000 RunMean : -99.9700\n",
      "Episode: 1499 Total reward: -88.0 Training loss: 1.4561 Explore P: 0.0000 RunMean : -99.8400\n",
      "Episode: 1500 Total reward: -85.0 Training loss: 1.9151 Explore P: 0.0000 RunMean : -99.7700\n",
      "Episode: 1501 Total reward: -104.0 Training loss: 3.4449 Explore P: 0.0000 RunMean : -99.9200\n",
      "Episode: 1502 Total reward: -109.0 Training loss: 3.0829 Explore P: 0.0000 RunMean : -99.9800\n",
      "Episode: 1503 Total reward: -94.0 Training loss: 2.3548 Explore P: 0.0000 RunMean : -99.8900\n",
      "Episode: 1504 Total reward: -104.0 Training loss: 1.5940 Explore P: 0.0000 RunMean : -99.5300\n",
      "Episode: 1505 Total reward: -81.0 Training loss: 2.4823 Explore P: 0.0000 RunMean : -99.4900\n",
      "Episode: 1506 Total reward: -75.0 Training loss: 1.8146 Explore P: 0.0000 RunMean : -99.1600\n",
      "Episode: 1507 Total reward: -111.0 Training loss: 1.5701 Explore P: 0.0000 RunMean : -99.1300\n",
      "Episode: 1508 Total reward: -105.0 Training loss: 2.0702 Explore P: 0.0000 RunMean : -99.0600\n",
      "Episode: 1509 Total reward: -91.0 Training loss: 2.2886 Explore P: 0.0000 RunMean : -99.0500\n",
      "Episode: 1510 Total reward: -98.0 Training loss: 1.5212 Explore P: 0.0000 RunMean : -99.3100\n",
      "Episode: 1511 Total reward: -100.0 Training loss: 3.8258 Explore P: 0.0000 RunMean : -99.1100\n",
      "Episode: 1512 Total reward: -93.0 Training loss: 2.3509 Explore P: 0.0000 RunMean : -98.8100\n",
      "Episode: 1513 Total reward: -74.0 Training loss: 2.2919 Explore P: 0.0000 RunMean : -98.5000\n",
      "Episode: 1514 Total reward: -81.0 Training loss: 3.4919 Explore P: 0.0000 RunMean : -98.2800\n",
      "Episode: 1515 Total reward: -87.0 Training loss: 1.6973 Explore P: 0.0000 RunMean : -98.4400\n",
      "Episode: 1516 Total reward: -89.0 Training loss: 2.3380 Explore P: 0.0000 RunMean : -98.5900\n",
      "Episode: 1517 Total reward: -79.0 Training loss: 2.1524 Explore P: 0.0000 RunMean : -98.5800\n",
      "Episode: 1518 Total reward: -74.0 Training loss: 3.1523 Explore P: 0.0000 RunMean : -98.5800\n",
      "Episode: 1519 Total reward: -105.0 Training loss: 2.1743 Explore P: 0.0000 RunMean : -98.7600\n",
      "Episode: 1520 Total reward: -88.0 Training loss: 2.4957 Explore P: 0.0000 RunMean : -98.5100\n",
      "Episode: 1521 Total reward: -86.0 Training loss: 1.7116 Explore P: 0.0000 RunMean : -98.2700\n",
      "Episode: 1522 Total reward: -131.0 Training loss: 3.1773 Explore P: 0.0000 RunMean : -98.8900\n",
      "Episode: 1523 Total reward: -116.0 Training loss: 1.9885 Explore P: 0.0000 RunMean : -99.0800\n",
      "Episode: 1524 Total reward: -86.0 Training loss: 1.7315 Explore P: 0.0000 RunMean : -98.9800\n",
      "Episode: 1525 Total reward: -102.0 Training loss: 2.7523 Explore P: 0.0000 RunMean : -98.9100\n",
      "Episode: 1526 Total reward: -96.0 Training loss: 2.7237 Explore P: 0.0000 RunMean : -98.6600\n",
      "Episode: 1527 Total reward: -94.0 Training loss: 2.1120 Explore P: 0.0000 RunMean : -98.2700\n",
      "Episode: 1528 Total reward: -90.0 Training loss: 1.8701 Explore P: 0.0000 RunMean : -98.3200\n",
      "Episode: 1529 Total reward: -114.0 Training loss: 1.5250 Explore P: 0.0000 RunMean : -98.5000\n",
      "Episode: 1530 Total reward: -65.0 Training loss: 2.9415 Explore P: 0.0000 RunMean : -98.2200\n",
      "Episode: 1531 Total reward: -85.0 Training loss: 2.3450 Explore P: 0.0000 RunMean : -97.9200\n",
      "Episode: 1532 Total reward: -69.0 Training loss: 2.5955 Explore P: 0.0000 RunMean : -97.8600\n",
      "Episode: 1533 Total reward: -95.0 Training loss: 3.7809 Explore P: 0.0000 RunMean : -97.8300\n",
      "Episode: 1534 Total reward: -109.0 Training loss: 2.1516 Explore P: 0.0000 RunMean : -97.6200\n",
      "Episode: 1535 Total reward: -117.0 Training loss: 1.8094 Explore P: 0.0000 RunMean : -97.5700\n",
      "Episode: 1536 Total reward: -87.0 Training loss: 1.9799 Explore P: 0.0000 RunMean : -97.5600\n",
      "Episode: 1537 Total reward: -75.0 Training loss: 0.8102 Explore P: 0.0000 RunMean : -97.4900\n",
      "Episode: 1538 Total reward: -82.0 Training loss: 1.7337 Explore P: 0.0000 RunMean : -97.3900\n",
      "Episode: 1539 Total reward: -94.0 Training loss: 3.2185 Explore P: 0.0000 RunMean : -97.5100\n",
      "Episode: 1540 Total reward: -89.0 Training loss: 1.7396 Explore P: 0.0000 RunMean : -97.5500\n",
      "Episode: 1541 Total reward: -83.0 Training loss: 1.4600 Explore P: 0.0000 RunMean : -97.6700\n",
      "Episode: 1542 Total reward: -94.0 Training loss: 1.8094 Explore P: 0.0000 RunMean : -97.8100\n",
      "Episode: 1543 Total reward: -83.0 Training loss: 1.8091 Explore P: 0.0000 RunMean : -97.9000\n",
      "Episode: 1544 Total reward: -100.0 Training loss: 4.3799 Explore P: 0.0000 RunMean : -98.1300\n",
      "Episode: 1545 Total reward: -126.0 Training loss: 2.3071 Explore P: 0.0000 RunMean : -98.2800\n",
      "Episode: 1546 Total reward: -90.0 Training loss: 3.2975 Explore P: 0.0000 RunMean : -98.1000\n",
      "Episode: 1547 Total reward: -103.0 Training loss: 1.1423 Explore P: 0.0000 RunMean : -98.1800\n",
      "Episode: 1548 Total reward: -99.0 Training loss: 1.9072 Explore P: 0.0000 RunMean : -98.0600\n",
      "Episode: 1549 Total reward: -107.0 Training loss: 3.3236 Explore P: 0.0000 RunMean : -98.2600\n",
      "Episode: 1550 Total reward: -115.0 Training loss: 2.4581 Explore P: 0.0000 RunMean : -98.7100\n",
      "Episode: 1551 Total reward: -157.0 Training loss: 1.9410 Explore P: 0.0000 RunMean : -99.3900\n",
      "Episode: 1552 Total reward: -75.0 Training loss: 2.7181 Explore P: 0.0000 RunMean : -99.1300\n",
      "Episode: 1553 Total reward: -170.0 Training loss: 1.8457 Explore P: 0.0000 RunMean : -99.6900\n",
      "Episode: 1554 Total reward: -127.0 Training loss: 2.9891 Explore P: 0.0000 RunMean : -100.1200\n",
      "Episode: 1555 Total reward: -84.0 Training loss: 3.7912 Explore P: 0.0000 RunMean : -100.1300\n",
      "Episode: 1556 Total reward: -135.0 Training loss: 1.6798 Explore P: 0.0000 RunMean : -100.4700\n",
      "Episode: 1557 Total reward: -110.0 Training loss: 3.0647 Explore P: 0.0000 RunMean : -100.5800\n",
      "Episode: 1558 Total reward: -102.0 Training loss: 4.6500 Explore P: 0.0000 RunMean : -100.9000\n",
      "Episode: 1559 Total reward: -89.0 Training loss: 3.0394 Explore P: 0.0000 RunMean : -100.9500\n",
      "Episode: 1560 Total reward: -74.0 Training loss: 1.8806 Explore P: 0.0000 RunMean : -100.5100\n",
      "Episode: 1561 Total reward: -110.0 Training loss: 2.5427 Explore P: 0.0000 RunMean : -100.9200\n",
      "Episode: 1562 Total reward: -120.0 Training loss: 2.1811 Explore P: 0.0000 RunMean : -101.1800\n",
      "Episode: 1563 Total reward: -103.0 Training loss: 1.1904 Explore P: 0.0000 RunMean : -101.4600\n",
      "Episode: 1564 Total reward: -170.0 Training loss: 3.3173 Explore P: 0.0000 RunMean : -102.0200\n",
      "Episode: 1565 Total reward: -83.0 Training loss: 3.4762 Explore P: 0.0000 RunMean : -101.5900\n",
      "Episode: 1566 Total reward: -70.0 Training loss: 2.5530 Explore P: 0.0000 RunMean : -101.2300\n",
      "Episode: 1567 Total reward: -110.0 Training loss: 2.2604 Explore P: 0.0000 RunMean : -101.4500\n",
      "Episode: 1568 Total reward: -119.0 Training loss: 3.4945 Explore P: 0.0000 RunMean : -101.7100\n",
      "Episode: 1569 Total reward: -75.0 Training loss: 2.0332 Explore P: 0.0000 RunMean : -100.9800\n",
      "Episode: 1570 Total reward: -129.0 Training loss: 2.1012 Explore P: 0.0000 RunMean : -101.5300\n",
      "Episode: 1571 Total reward: -104.0 Training loss: 3.4036 Explore P: 0.0000 RunMean : -101.6700\n",
      "Episode: 1572 Total reward: -93.0 Training loss: 3.1390 Explore P: 0.0000 RunMean : -101.0500\n",
      "Episode: 1573 Total reward: -86.0 Training loss: 1.3979 Explore P: 0.0000 RunMean : -100.8400\n",
      "Episode: 1574 Total reward: -135.0 Training loss: 4.2655 Explore P: 0.0000 RunMean : -101.3500\n",
      "Episode: 1575 Total reward: -105.0 Training loss: 3.3497 Explore P: 0.0000 RunMean : -101.4000\n",
      "Episode: 1576 Total reward: -111.0 Training loss: 2.9428 Explore P: 0.0000 RunMean : -101.7500\n",
      "Episode: 1577 Total reward: -97.0 Training loss: 2.2785 Explore P: 0.0000 RunMean : -100.9200\n",
      "Episode: 1578 Total reward: -82.0 Training loss: 5.6748 Explore P: 0.0000 RunMean : -100.8700\n",
      "Episode: 1579 Total reward: -89.0 Training loss: 2.8528 Explore P: 0.0000 RunMean : -100.3400\n",
      "Episode: 1580 Total reward: -97.0 Training loss: 4.8788 Explore P: 0.0000 RunMean : -100.0300\n",
      "Episode: 1581 Total reward: -119.0 Training loss: 3.8705 Explore P: 0.0000 RunMean : -100.0400\n",
      "Episode: 1582 Total reward: -102.0 Training loss: 2.5636 Explore P: 0.0000 RunMean : -100.1800\n",
      "Episode: 1583 Total reward: -129.0 Training loss: 2.1559 Explore P: 0.0000 RunMean : -100.7600\n",
      "Episode: 1584 Total reward: -102.0 Training loss: 1.5841 Explore P: 0.0000 RunMean : -100.7500\n",
      "Episode: 1585 Total reward: -107.0 Training loss: 2.5723 Explore P: 0.0000 RunMean : -99.2800\n",
      "Episode: 1586 Total reward: -86.0 Training loss: 2.1063 Explore P: 0.0000 RunMean : -98.9000\n",
      "Episode: 1587 Total reward: -121.0 Training loss: 1.4158 Explore P: 0.0000 RunMean : -98.9700\n",
      "Episode: 1588 Total reward: -94.0 Training loss: 3.1748 Explore P: 0.0000 RunMean : -99.2800\n",
      "Episode: 1589 Total reward: -155.0 Training loss: 3.3258 Explore P: 0.0000 RunMean : -100.0300\n",
      "Episode: 1590 Total reward: -144.0 Training loss: 2.0004 Explore P: 0.0000 RunMean : -100.5800\n",
      "Episode: 1591 Total reward: -92.0 Training loss: 1.5727 Explore P: 0.0000 RunMean : -100.6200\n",
      "Episode: 1592 Total reward: -129.0 Training loss: 1.8514 Explore P: 0.0000 RunMean : -101.0100\n",
      "Episode: 1593 Total reward: -148.0 Training loss: 2.5049 Explore P: 0.0000 RunMean : -101.6600\n",
      "Episode: 1594 Total reward: -162.0 Training loss: 3.6930 Explore P: 0.0000 RunMean : -102.3700\n",
      "Episode: 1595 Total reward: -133.0 Training loss: 1.9765 Explore P: 0.0000 RunMean : -102.4200\n",
      "Episode: 1596 Total reward: -78.0 Training loss: 4.0771 Explore P: 0.0000 RunMean : -102.3800\n",
      "Episode: 1597 Total reward: -94.0 Training loss: 3.0158 Explore P: 0.0000 RunMean : -102.0500\n",
      "Episode: 1598 Total reward: -81.0 Training loss: 8.5264 Explore P: 0.0000 RunMean : -101.8400\n",
      "Episode: 1599 Total reward: -112.0 Training loss: 2.8251 Explore P: 0.0000 RunMean : -102.0800\n",
      "Episode: 1600 Total reward: -101.0 Training loss: 1.8589 Explore P: 0.0000 RunMean : -102.2400\n",
      "Episode: 1601 Total reward: -75.0 Training loss: 2.1386 Explore P: 0.0000 RunMean : -101.9500\n",
      "Episode: 1602 Total reward: -92.0 Training loss: 1.6078 Explore P: 0.0000 RunMean : -101.7800\n",
      "Episode: 1603 Total reward: -108.0 Training loss: 1.3309 Explore P: 0.0000 RunMean : -101.9200\n",
      "Episode: 1604 Total reward: -95.0 Training loss: 1.9264 Explore P: 0.0000 RunMean : -101.8300\n",
      "Episode: 1605 Total reward: -85.0 Training loss: 1.8478 Explore P: 0.0000 RunMean : -101.8700\n",
      "Episode: 1606 Total reward: -94.0 Training loss: 2.7394 Explore P: 0.0000 RunMean : -102.0600\n",
      "Episode: 1607 Total reward: -104.0 Training loss: 2.9729 Explore P: 0.0000 RunMean : -101.9900\n",
      "Episode: 1608 Total reward: -106.0 Training loss: 3.6212 Explore P: 0.0000 RunMean : -102.0000\n",
      "Episode: 1609 Total reward: -69.0 Training loss: 1.4867 Explore P: 0.0000 RunMean : -101.7800\n",
      "Episode: 1610 Total reward: -75.0 Training loss: 3.2863 Explore P: 0.0000 RunMean : -101.5500\n",
      "Episode: 1611 Total reward: -91.0 Training loss: 2.6235 Explore P: 0.0000 RunMean : -101.4600\n",
      "Episode: 1612 Total reward: -77.0 Training loss: 3.0453 Explore P: 0.0000 RunMean : -101.3000\n",
      "Episode: 1613 Total reward: -75.0 Training loss: 1.9268 Explore P: 0.0000 RunMean : -101.3100\n",
      "Episode: 1614 Total reward: -135.0 Training loss: 1.5123 Explore P: 0.0000 RunMean : -101.8500\n",
      "Episode: 1615 Total reward: -110.0 Training loss: 1.7231 Explore P: 0.0000 RunMean : -102.0800\n",
      "Episode: 1616 Total reward: -91.0 Training loss: 2.0434 Explore P: 0.0000 RunMean : -102.1000\n",
      "Episode: 1617 Total reward: -96.0 Training loss: 3.2016 Explore P: 0.0000 RunMean : -102.2700\n",
      "Episode: 1618 Total reward: -79.0 Training loss: 3.6060 Explore P: 0.0000 RunMean : -102.3200\n",
      "Episode: 1619 Total reward: -63.0 Training loss: 2.6078 Explore P: 0.0000 RunMean : -101.9000\n",
      "Episode: 1620 Total reward: -97.0 Training loss: 2.5052 Explore P: 0.0000 RunMean : -101.9900\n",
      "Episode: 1621 Total reward: -77.0 Training loss: 2.1605 Explore P: 0.0000 RunMean : -101.9000\n",
      "Episode: 1622 Total reward: -88.0 Training loss: 2.6595 Explore P: 0.0000 RunMean : -101.4700\n",
      "Episode: 1623 Total reward: -90.0 Training loss: 5.1570 Explore P: 0.0000 RunMean : -101.2100\n",
      "Episode: 1624 Total reward: -97.0 Training loss: 3.0025 Explore P: 0.0000 RunMean : -101.3200\n",
      "Episode: 1625 Total reward: -62.0 Training loss: 3.2813 Explore P: 0.0000 RunMean : -100.9200\n",
      "Episode: 1626 Total reward: -109.0 Training loss: 4.0414 Explore P: 0.0000 RunMean : -101.0500\n",
      "Episode: 1627 Total reward: -106.0 Training loss: 2.4519 Explore P: 0.0000 RunMean : -101.1700\n",
      "Episode: 1628 Total reward: -99.0 Training loss: 3.0870 Explore P: 0.0000 RunMean : -101.2600\n",
      "Episode: 1629 Total reward: -83.0 Training loss: 2.8698 Explore P: 0.0000 RunMean : -100.9500\n",
      "Episode: 1630 Total reward: -101.0 Training loss: 2.2386 Explore P: 0.0000 RunMean : -101.3100\n",
      "Episode: 1631 Total reward: -131.0 Training loss: 2.4881 Explore P: 0.0000 RunMean : -101.7700\n",
      "Episode: 1632 Total reward: -114.0 Training loss: 2.6226 Explore P: 0.0000 RunMean : -102.2200\n",
      "Episode: 1633 Total reward: -88.0 Training loss: 2.4066 Explore P: 0.0000 RunMean : -102.1500\n",
      "Episode: 1634 Total reward: -77.0 Training loss: 3.3844 Explore P: 0.0000 RunMean : -101.8300\n",
      "Episode: 1635 Total reward: -97.0 Training loss: 2.9701 Explore P: 0.0000 RunMean : -101.6300\n",
      "Episode: 1636 Total reward: -103.0 Training loss: 1.6332 Explore P: 0.0000 RunMean : -101.7900\n",
      "Episode: 1637 Total reward: -75.0 Training loss: 4.3535 Explore P: 0.0000 RunMean : -101.7900\n",
      "Episode: 1638 Total reward: -74.0 Training loss: 2.3216 Explore P: 0.0000 RunMean : -101.7100\n",
      "Episode: 1639 Total reward: -112.0 Training loss: 2.9765 Explore P: 0.0000 RunMean : -101.8900\n",
      "Episode: 1640 Total reward: -91.0 Training loss: 2.9235 Explore P: 0.0000 RunMean : -101.9100\n",
      "Episode: 1641 Total reward: -100.0 Training loss: 2.5560 Explore P: 0.0000 RunMean : -102.0800\n",
      "Episode: 1642 Total reward: -89.0 Training loss: 2.4007 Explore P: 0.0000 RunMean : -102.0300\n",
      "Episode: 1643 Total reward: -166.0 Training loss: 3.7092 Explore P: 0.0000 RunMean : -102.8600\n",
      "Episode: 1644 Total reward: -98.0 Training loss: 3.1350 Explore P: 0.0000 RunMean : -102.8400\n",
      "Episode: 1645 Total reward: -120.0 Training loss: 2.0658 Explore P: 0.0000 RunMean : -102.7800\n",
      "Episode: 1646 Total reward: -88.0 Training loss: 1.8355 Explore P: 0.0000 RunMean : -102.7600\n",
      "Episode: 1647 Total reward: -74.0 Training loss: 2.5685 Explore P: 0.0000 RunMean : -102.4700\n",
      "Episode: 1648 Total reward: -106.0 Training loss: 1.3531 Explore P: 0.0000 RunMean : -102.5400\n",
      "Episode: 1649 Total reward: -101.0 Training loss: 2.7740 Explore P: 0.0000 RunMean : -102.4800\n",
      "Episode: 1650 Total reward: -76.0 Training loss: 1.9718 Explore P: 0.0000 RunMean : -102.0900\n",
      "Episode: 1651 Total reward: -146.0 Training loss: 2.2711 Explore P: 0.0000 RunMean : -101.9800\n",
      "Episode: 1652 Total reward: -110.0 Training loss: 2.1189 Explore P: 0.0000 RunMean : -102.3300\n",
      "Episode: 1653 Total reward: -70.0 Training loss: 1.5116 Explore P: 0.0000 RunMean : -101.3300\n",
      "Episode: 1654 Total reward: -62.0 Training loss: 1.6611 Explore P: 0.0000 RunMean : -100.6800\n",
      "Episode: 1655 Total reward: -100.0 Training loss: 2.4014 Explore P: 0.0000 RunMean : -100.8400\n",
      "Episode: 1656 Total reward: -91.0 Training loss: 2.9152 Explore P: 0.0000 RunMean : -100.4000\n",
      "Episode: 1657 Total reward: -95.0 Training loss: 1.0105 Explore P: 0.0000 RunMean : -100.2500\n",
      "Episode: 1658 Total reward: -125.0 Training loss: 1.9613 Explore P: 0.0000 RunMean : -100.4800\n",
      "Episode: 1659 Total reward: -115.0 Training loss: 2.5701 Explore P: 0.0000 RunMean : -100.7400\n",
      "Episode: 1660 Total reward: -92.0 Training loss: 4.0740 Explore P: 0.0000 RunMean : -100.9200\n",
      "Episode: 1661 Total reward: -91.0 Training loss: 4.0531 Explore P: 0.0000 RunMean : -100.7300\n",
      "Episode: 1662 Total reward: -91.0 Training loss: 2.4469 Explore P: 0.0000 RunMean : -100.4400\n",
      "Episode: 1663 Total reward: -129.0 Training loss: 2.9568 Explore P: 0.0000 RunMean : -100.7000\n",
      "Episode: 1664 Total reward: -81.0 Training loss: 2.2736 Explore P: 0.0000 RunMean : -99.8100\n",
      "Episode: 1665 Total reward: -108.0 Training loss: 2.9409 Explore P: 0.0000 RunMean : -100.0600\n",
      "Episode: 1666 Total reward: -78.0 Training loss: 4.9483 Explore P: 0.0000 RunMean : -100.1400\n",
      "Episode: 1667 Total reward: -142.0 Training loss: 2.3934 Explore P: 0.0000 RunMean : -100.4600\n",
      "Episode: 1668 Total reward: -99.0 Training loss: 3.0825 Explore P: 0.0000 RunMean : -100.2600\n",
      "Episode: 1669 Total reward: -76.0 Training loss: 2.5121 Explore P: 0.0000 RunMean : -100.2700\n",
      "Episode: 1670 Total reward: -147.0 Training loss: 1.5186 Explore P: 0.0000 RunMean : -100.4500\n",
      "Episode: 1671 Total reward: -88.0 Training loss: 2.9910 Explore P: 0.0000 RunMean : -100.2900\n",
      "Episode: 1672 Total reward: -105.0 Training loss: 2.3433 Explore P: 0.0000 RunMean : -100.4100\n",
      "Episode: 1673 Total reward: -78.0 Training loss: 2.9303 Explore P: 0.0000 RunMean : -100.3300\n",
      "Episode: 1674 Total reward: -87.0 Training loss: 2.6013 Explore P: 0.0000 RunMean : -99.8500\n",
      "Episode: 1675 Total reward: -75.0 Training loss: 2.7947 Explore P: 0.0000 RunMean : -99.5500\n",
      "Episode: 1676 Total reward: -90.0 Training loss: 2.4923 Explore P: 0.0000 RunMean : -99.3400\n",
      "Episode: 1677 Total reward: -96.0 Training loss: 3.0555 Explore P: 0.0000 RunMean : -99.3300\n",
      "Episode: 1678 Total reward: -106.0 Training loss: 2.8263 Explore P: 0.0000 RunMean : -99.5700\n",
      "Episode: 1679 Total reward: -112.0 Training loss: 2.6529 Explore P: 0.0000 RunMean : -99.8000\n",
      "Episode: 1680 Total reward: -99.0 Training loss: 2.4323 Explore P: 0.0000 RunMean : -99.8200\n",
      "Episode: 1681 Total reward: -102.0 Training loss: 2.5480 Explore P: 0.0000 RunMean : -99.6500\n",
      "Episode: 1682 Total reward: -103.0 Training loss: 1.8119 Explore P: 0.0000 RunMean : -99.6600\n",
      "Episode: 1683 Total reward: -93.0 Training loss: 2.0202 Explore P: 0.0000 RunMean : -99.3000\n",
      "Episode: 1684 Total reward: -94.0 Training loss: 1.8945 Explore P: 0.0000 RunMean : -99.2200\n",
      "Episode: 1685 Total reward: -74.0 Training loss: 1.0716 Explore P: 0.0000 RunMean : -98.8900\n",
      "Episode: 1686 Total reward: -103.0 Training loss: 2.4489 Explore P: 0.0000 RunMean : -99.0600\n",
      "Episode: 1687 Total reward: -107.0 Training loss: 1.4314 Explore P: 0.0000 RunMean : -98.9200\n",
      "Episode: 1688 Total reward: -89.0 Training loss: 2.3281 Explore P: 0.0000 RunMean : -98.8700\n",
      "Episode: 1689 Total reward: -62.0 Training loss: 1.8762 Explore P: 0.0000 RunMean : -97.9400\n",
      "Episode: 1690 Total reward: -117.0 Training loss: 2.0178 Explore P: 0.0000 RunMean : -97.6700\n",
      "Episode: 1691 Total reward: -97.0 Training loss: 5.8407 Explore P: 0.0000 RunMean : -97.7200\n",
      "Episode: 1692 Total reward: -134.0 Training loss: 3.4042 Explore P: 0.0000 RunMean : -97.7700\n",
      "Episode: 1693 Total reward: -122.0 Training loss: 3.1732 Explore P: 0.0000 RunMean : -97.5100\n",
      "Episode: 1694 Total reward: -71.0 Training loss: 3.9923 Explore P: 0.0000 RunMean : -96.6000\n",
      "Episode: 1695 Total reward: -95.0 Training loss: 2.9062 Explore P: 0.0000 RunMean : -96.2200\n",
      "Episode: 1696 Total reward: -102.0 Training loss: 2.8476 Explore P: 0.0000 RunMean : -96.4600\n",
      "Episode: 1697 Total reward: -73.0 Training loss: 2.3839 Explore P: 0.0000 RunMean : -96.2500\n",
      "Episode: 1698 Total reward: -87.0 Training loss: 1.3760 Explore P: 0.0000 RunMean : -96.3100\n",
      "Episode: 1699 Total reward: -124.0 Training loss: 2.6303 Explore P: 0.0000 RunMean : -96.4300\n",
      "Episode: 1700 Total reward: -64.0 Training loss: 2.3535 Explore P: 0.0000 RunMean : -96.0600\n",
      "Episode: 1701 Total reward: -75.0 Training loss: 1.8827 Explore P: 0.0000 RunMean : -96.0600\n",
      "Episode: 1702 Total reward: -72.0 Training loss: 2.0487 Explore P: 0.0000 RunMean : -95.8600\n",
      "Episode: 1703 Total reward: -101.0 Training loss: 2.0301 Explore P: 0.0000 RunMean : -95.7900\n",
      "Episode: 1704 Total reward: -131.0 Training loss: 3.4996 Explore P: 0.0000 RunMean : -96.1500\n",
      "Episode: 1705 Total reward: -112.0 Training loss: 1.6366 Explore P: 0.0000 RunMean : -96.4200\n",
      "Episode: 1706 Total reward: -98.0 Training loss: 2.4138 Explore P: 0.0000 RunMean : -96.4600\n",
      "Episode: 1707 Total reward: -71.0 Training loss: 2.2655 Explore P: 0.0000 RunMean : -96.1300\n",
      "Episode: 1708 Total reward: -74.0 Training loss: 2.7788 Explore P: 0.0000 RunMean : -95.8100\n",
      "Episode: 1709 Total reward: -101.0 Training loss: 1.4757 Explore P: 0.0000 RunMean : -96.1300\n",
      "Episode: 1710 Total reward: -63.0 Training loss: 2.8877 Explore P: 0.0000 RunMean : -96.0100\n",
      "Episode: 1711 Total reward: -75.0 Training loss: 1.5946 Explore P: 0.0000 RunMean : -95.8500\n",
      "Episode: 1712 Total reward: -75.0 Training loss: 1.4503 Explore P: 0.0000 RunMean : -95.8300\n",
      "Episode: 1713 Total reward: -127.0 Training loss: 2.6406 Explore P: 0.0000 RunMean : -96.3500\n",
      "Episode: 1714 Total reward: -160.0 Training loss: 2.3558 Explore P: 0.0000 RunMean : -96.6000\n",
      "Episode: 1715 Total reward: -110.0 Training loss: 2.6449 Explore P: 0.0000 RunMean : -96.6000\n",
      "Episode: 1716 Total reward: -95.0 Training loss: 1.3730 Explore P: 0.0000 RunMean : -96.6400\n",
      "Episode: 1717 Total reward: -94.0 Training loss: 1.5610 Explore P: 0.0000 RunMean : -96.6200\n",
      "Episode: 1718 Total reward: -102.0 Training loss: 2.5573 Explore P: 0.0000 RunMean : -96.8500\n",
      "Episode: 1719 Total reward: -75.0 Training loss: 3.2251 Explore P: 0.0000 RunMean : -96.9700\n",
      "Episode: 1720 Total reward: -86.0 Training loss: 2.0694 Explore P: 0.0000 RunMean : -96.8600\n",
      "Episode: 1721 Total reward: -82.0 Training loss: 3.1030 Explore P: 0.0000 RunMean : -96.9100\n",
      "Episode: 1722 Total reward: -86.0 Training loss: 1.7604 Explore P: 0.0000 RunMean : -96.8900\n",
      "Episode: 1723 Total reward: -86.0 Training loss: 1.7116 Explore P: 0.0000 RunMean : -96.8500\n",
      "Episode: 1724 Total reward: -104.0 Training loss: 2.3422 Explore P: 0.0000 RunMean : -96.9200\n",
      "Episode: 1725 Total reward: -106.0 Training loss: 2.9057 Explore P: 0.0000 RunMean : -97.3600\n",
      "Episode: 1726 Total reward: -108.0 Training loss: 2.1325 Explore P: 0.0000 RunMean : -97.3500\n",
      "Episode: 1727 Total reward: -69.0 Training loss: 1.6999 Explore P: 0.0000 RunMean : -96.9800\n",
      "Episode: 1728 Total reward: -127.0 Training loss: 2.5829 Explore P: 0.0000 RunMean : -97.2600\n",
      "Episode: 1729 Total reward: -126.0 Training loss: 2.1796 Explore P: 0.0000 RunMean : -97.6900\n",
      "Episode: 1730 Total reward: -75.0 Training loss: 2.4788 Explore P: 0.0000 RunMean : -97.4300\n",
      "Episode: 1731 Total reward: -83.0 Training loss: 1.4816 Explore P: 0.0000 RunMean : -96.9500\n",
      "Episode: 1732 Total reward: -115.0 Training loss: 1.5436 Explore P: 0.0000 RunMean : -96.9600\n",
      "Episode: 1733 Total reward: -99.0 Training loss: 1.2932 Explore P: 0.0000 RunMean : -97.0700\n",
      "Episode: 1734 Total reward: -70.0 Training loss: 1.3432 Explore P: 0.0000 RunMean : -97.0000\n",
      "Episode: 1735 Total reward: -81.0 Training loss: 4.3128 Explore P: 0.0000 RunMean : -96.8400\n",
      "Episode: 1736 Total reward: -97.0 Training loss: 2.3724 Explore P: 0.0000 RunMean : -96.7800\n",
      "Episode: 1737 Total reward: -71.0 Training loss: 1.9605 Explore P: 0.0000 RunMean : -96.7400\n",
      "Episode: 1738 Total reward: -94.0 Training loss: 0.8402 Explore P: 0.0000 RunMean : -96.9400\n",
      "Episode: 1739 Total reward: -98.0 Training loss: 2.0519 Explore P: 0.0000 RunMean : -96.8000\n",
      "Episode: 1740 Total reward: -62.0 Training loss: 1.7332 Explore P: 0.0000 RunMean : -96.5100\n",
      "Episode: 1741 Total reward: -92.0 Training loss: 2.0228 Explore P: 0.0000 RunMean : -96.4300\n",
      "Episode: 1742 Total reward: -89.0 Training loss: 2.1935 Explore P: 0.0000 RunMean : -96.4300\n",
      "Episode: 1743 Total reward: -71.0 Training loss: 2.5626 Explore P: 0.0000 RunMean : -95.4800\n",
      "Episode: 1744 Total reward: -161.0 Training loss: 1.5776 Explore P: 0.0000 RunMean : -96.1100\n",
      "Episode: 1745 Total reward: -101.0 Training loss: 2.6557 Explore P: 0.0000 RunMean : -95.9200\n",
      "Episode: 1746 Total reward: -88.0 Training loss: 1.8624 Explore P: 0.0000 RunMean : -95.9200\n",
      "Episode: 1747 Total reward: -102.0 Training loss: 1.8747 Explore P: 0.0000 RunMean : -96.2000\n",
      "Episode: 1748 Total reward: -74.0 Training loss: 1.8364 Explore P: 0.0000 RunMean : -95.8800\n",
      "Episode: 1749 Total reward: -103.0 Training loss: 3.9221 Explore P: 0.0000 RunMean : -95.9000\n",
      "Episode: 1750 Total reward: -99.0 Training loss: 2.0170 Explore P: 0.0000 RunMean : -96.1300\n",
      "Episode: 1751 Total reward: -80.0 Training loss: 2.1963 Explore P: 0.0000 RunMean : -95.4700\n",
      "Episode: 1752 Total reward: -95.0 Training loss: 2.4796 Explore P: 0.0000 RunMean : -95.3200\n",
      "Episode: 1753 Total reward: -101.0 Training loss: 1.9203 Explore P: 0.0000 RunMean : -95.6300\n",
      "Episode: 1754 Total reward: -74.0 Training loss: 1.8902 Explore P: 0.0000 RunMean : -95.7500\n",
      "Episode: 1755 Total reward: -157.0 Training loss: 5.3834 Explore P: 0.0000 RunMean : -96.3200\n",
      "Episode: 1756 Total reward: -64.0 Training loss: 2.9903 Explore P: 0.0000 RunMean : -96.0500\n",
      "Episode: 1757 Total reward: -97.0 Training loss: 1.0974 Explore P: 0.0000 RunMean : -96.0700\n",
      "Episode: 1758 Total reward: -197.0 Training loss: 1.3646 Explore P: 0.0000 RunMean : -96.7900\n",
      "Episode: 1759 Total reward: -98.0 Training loss: 4.4400 Explore P: 0.0000 RunMean : -96.6200\n",
      "Episode: 1760 Total reward: -102.0 Training loss: 1.5780 Explore P: 0.0000 RunMean : -96.7200\n",
      "Episode: 1761 Total reward: -134.0 Training loss: 1.5190 Explore P: 0.0000 RunMean : -97.1500\n",
      "Episode: 1762 Total reward: -71.0 Training loss: 1.8177 Explore P: 0.0000 RunMean : -96.9500\n",
      "Episode: 1763 Total reward: -90.0 Training loss: 1.5996 Explore P: 0.0000 RunMean : -96.5600\n",
      "Episode: 1764 Total reward: -97.0 Training loss: 2.5939 Explore P: 0.0000 RunMean : -96.7200\n",
      "Episode: 1765 Total reward: -84.0 Training loss: 2.1244 Explore P: 0.0000 RunMean : -96.4800\n",
      "Episode: 1766 Total reward: -76.0 Training loss: 2.0864 Explore P: 0.0000 RunMean : -96.4600\n",
      "Episode: 1767 Total reward: -95.0 Training loss: 2.4249 Explore P: 0.0000 RunMean : -95.9900\n",
      "Episode: 1768 Total reward: -82.0 Training loss: 1.0522 Explore P: 0.0000 RunMean : -95.8200\n",
      "Episode: 1769 Total reward: -75.0 Training loss: 2.6089 Explore P: 0.0000 RunMean : -95.8100\n",
      "Episode: 1770 Total reward: -94.0 Training loss: 1.9547 Explore P: 0.0000 RunMean : -95.2800\n",
      "Episode: 1771 Total reward: -81.0 Training loss: 1.4655 Explore P: 0.0000 RunMean : -95.2100\n",
      "Episode: 1772 Total reward: -63.0 Training loss: 1.7697 Explore P: 0.0000 RunMean : -94.7900\n",
      "Episode: 1773 Total reward: -96.0 Training loss: 3.9231 Explore P: 0.0000 RunMean : -94.9700\n",
      "Episode: 1774 Total reward: -105.0 Training loss: 1.6926 Explore P: 0.0000 RunMean : -95.1500\n",
      "Episode: 1775 Total reward: -83.0 Training loss: 0.8598 Explore P: 0.0000 RunMean : -95.2300\n",
      "Episode: 1776 Total reward: -63.0 Training loss: 1.3440 Explore P: 0.0000 RunMean : -94.9600\n",
      "Episode: 1777 Total reward: -93.0 Training loss: 2.0542 Explore P: 0.0000 RunMean : -94.9300\n",
      "Episode: 1778 Total reward: -63.0 Training loss: 3.3469 Explore P: 0.0000 RunMean : -94.5000\n",
      "Episode: 1779 Total reward: -63.0 Training loss: 1.5582 Explore P: 0.0000 RunMean : -94.0100\n",
      "Episode: 1780 Total reward: -83.0 Training loss: 1.6161 Explore P: 0.0000 RunMean : -93.8500\n",
      "Episode: 1781 Total reward: -71.0 Training loss: 1.6940 Explore P: 0.0000 RunMean : -93.5400\n",
      "Episode: 1782 Total reward: -91.0 Training loss: 1.8709 Explore P: 0.0000 RunMean : -93.4200\n",
      "Episode: 1783 Total reward: -93.0 Training loss: 1.5550 Explore P: 0.0000 RunMean : -93.4200\n",
      "Episode: 1784 Total reward: -101.0 Training loss: 1.8402 Explore P: 0.0000 RunMean : -93.4900\n",
      "Episode: 1785 Total reward: -71.0 Training loss: 2.0248 Explore P: 0.0000 RunMean : -93.4600\n",
      "Episode: 1786 Total reward: -88.0 Training loss: 1.9801 Explore P: 0.0000 RunMean : -93.3100\n",
      "Episode: 1787 Total reward: -71.0 Training loss: 1.3212 Explore P: 0.0000 RunMean : -92.9500\n",
      "Episode: 1788 Total reward: -85.0 Training loss: 2.0404 Explore P: 0.0000 RunMean : -92.9100\n",
      "Episode: 1789 Total reward: -91.0 Training loss: 2.5558 Explore P: 0.0000 RunMean : -93.2000\n",
      "Episode: 1790 Total reward: -109.0 Training loss: 1.6893 Explore P: 0.0000 RunMean : -93.1200\n",
      "Episode: 1791 Total reward: -102.0 Training loss: 1.3999 Explore P: 0.0000 RunMean : -93.1700\n",
      "Episode: 1792 Total reward: -83.0 Training loss: 2.4917 Explore P: 0.0000 RunMean : -92.6600\n",
      "Episode: 1793 Total reward: -91.0 Training loss: 1.3941 Explore P: 0.0000 RunMean : -92.3500\n",
      "Episode: 1794 Total reward: -75.0 Training loss: 0.8857 Explore P: 0.0000 RunMean : -92.3900\n",
      "Episode: 1795 Total reward: -500.0 Training loss: 3.5862 Explore P: 0.0000 RunMean : -96.4400\n",
      "Episode: 1796 Total reward: -128.0 Training loss: 3.8665 Explore P: 0.0000 RunMean : -96.7000\n",
      "Episode: 1797 Total reward: -95.0 Training loss: 2.4166 Explore P: 0.0000 RunMean : -96.9200\n",
      "Episode: 1798 Total reward: -106.0 Training loss: 3.0019 Explore P: 0.0000 RunMean : -97.1100\n",
      "Episode: 1799 Total reward: -90.0 Training loss: 1.5919 Explore P: 0.0000 RunMean : -96.7700\n",
      "Episode: 1800 Total reward: -101.0 Training loss: 2.4624 Explore P: 0.0000 RunMean : -97.1400\n",
      "Episode: 1801 Total reward: -86.0 Training loss: 1.7791 Explore P: 0.0000 RunMean : -97.2500\n",
      "Episode: 1802 Total reward: -85.0 Training loss: 2.3741 Explore P: 0.0000 RunMean : -97.3800\n",
      "Episode: 1803 Total reward: -90.0 Training loss: 1.3253 Explore P: 0.0000 RunMean : -97.2700\n",
      "Episode: 1804 Total reward: -64.0 Training loss: 2.4129 Explore P: 0.0000 RunMean : -96.6000\n",
      "Episode: 1805 Total reward: -92.0 Training loss: 1.4950 Explore P: 0.0000 RunMean : -96.4000\n",
      "Episode: 1806 Total reward: -105.0 Training loss: 2.6087 Explore P: 0.0000 RunMean : -96.4700\n",
      "Episode: 1807 Total reward: -90.0 Training loss: 1.7339 Explore P: 0.0000 RunMean : -96.6600\n",
      "Episode: 1808 Total reward: -95.0 Training loss: 1.8782 Explore P: 0.0000 RunMean : -96.8700\n",
      "Episode: 1809 Total reward: -121.0 Training loss: 2.0818 Explore P: 0.0000 RunMean : -97.0700\n",
      "Episode: 1810 Total reward: -76.0 Training loss: 4.0938 Explore P: 0.0000 RunMean : -97.2000\n",
      "Episode: 1811 Total reward: -88.0 Training loss: 2.5710 Explore P: 0.0000 RunMean : -97.3300\n",
      "Episode: 1812 Total reward: -87.0 Training loss: 1.6824 Explore P: 0.0000 RunMean : -97.4500\n",
      "Episode: 1813 Total reward: -120.0 Training loss: 1.9222 Explore P: 0.0000 RunMean : -97.3800\n",
      "Episode: 1814 Total reward: -93.0 Training loss: 2.1337 Explore P: 0.0000 RunMean : -96.7100\n",
      "Episode: 1815 Total reward: -84.0 Training loss: 2.3948 Explore P: 0.0000 RunMean : -96.4500\n",
      "Episode: 1816 Total reward: -163.0 Training loss: 2.8469 Explore P: 0.0000 RunMean : -97.1300\n",
      "Episode: 1817 Total reward: -74.0 Training loss: 1.6854 Explore P: 0.0000 RunMean : -96.9300\n",
      "Episode: 1818 Total reward: -93.0 Training loss: 2.2385 Explore P: 0.0000 RunMean : -96.8400\n",
      "Episode: 1819 Total reward: -74.0 Training loss: 2.6495 Explore P: 0.0000 RunMean : -96.8300\n",
      "Episode: 1820 Total reward: -85.0 Training loss: 2.4113 Explore P: 0.0000 RunMean : -96.8200\n",
      "Episode: 1821 Total reward: -115.0 Training loss: 3.1452 Explore P: 0.0000 RunMean : -97.1500\n",
      "Episode: 1822 Total reward: -83.0 Training loss: 2.4786 Explore P: 0.0000 RunMean : -97.1200\n",
      "Episode: 1823 Total reward: -119.0 Training loss: 1.2928 Explore P: 0.0000 RunMean : -97.4500\n",
      "Episode: 1824 Total reward: -93.0 Training loss: 1.9208 Explore P: 0.0000 RunMean : -97.3400\n",
      "Episode: 1825 Total reward: -88.0 Training loss: 2.9162 Explore P: 0.0000 RunMean : -97.1600\n",
      "Episode: 1826 Total reward: -104.0 Training loss: 1.8100 Explore P: 0.0000 RunMean : -97.1200\n",
      "Episode: 1827 Total reward: -99.0 Training loss: 2.0246 Explore P: 0.0000 RunMean : -97.4200\n",
      "Episode: 1828 Total reward: -91.0 Training loss: 3.0433 Explore P: 0.0000 RunMean : -97.0600\n",
      "Episode: 1829 Total reward: -63.0 Training loss: 1.9893 Explore P: 0.0000 RunMean : -96.4300\n",
      "Episode: 1830 Total reward: -87.0 Training loss: 2.3104 Explore P: 0.0000 RunMean : -96.5500\n",
      "Episode: 1831 Total reward: -120.0 Training loss: 1.2380 Explore P: 0.0000 RunMean : -96.9200\n",
      "Episode: 1832 Total reward: -79.0 Training loss: 1.3865 Explore P: 0.0000 RunMean : -96.5600\n",
      "Episode: 1833 Total reward: -62.0 Training loss: 1.5580 Explore P: 0.0000 RunMean : -96.1900\n",
      "Episode: 1834 Total reward: -84.0 Training loss: 2.6365 Explore P: 0.0000 RunMean : -96.3300\n",
      "Episode: 1835 Total reward: -96.0 Training loss: 2.5771 Explore P: 0.0000 RunMean : -96.4800\n",
      "Episode: 1836 Total reward: -69.0 Training loss: 3.2572 Explore P: 0.0000 RunMean : -96.2000\n",
      "Episode: 1837 Total reward: -87.0 Training loss: 1.6142 Explore P: 0.0000 RunMean : -96.3600\n",
      "Episode: 1838 Total reward: -98.0 Training loss: 2.7997 Explore P: 0.0000 RunMean : -96.4000\n",
      "Episode: 1839 Total reward: -83.0 Training loss: 3.2180 Explore P: 0.0000 RunMean : -96.2500\n",
      "Episode: 1840 Total reward: -87.0 Training loss: 2.7036 Explore P: 0.0000 RunMean : -96.5000\n",
      "Episode: 1841 Total reward: -116.0 Training loss: 2.6172 Explore P: 0.0000 RunMean : -96.7400\n",
      "Episode: 1842 Total reward: -104.0 Training loss: 3.6724 Explore P: 0.0000 RunMean : -96.8900\n",
      "Episode: 1843 Total reward: -129.0 Training loss: 3.5291 Explore P: 0.0000 RunMean : -97.4700\n",
      "Episode: 1844 Total reward: -95.0 Training loss: 3.6632 Explore P: 0.0000 RunMean : -96.8100\n",
      "Episode: 1845 Total reward: -62.0 Training loss: 3.5478 Explore P: 0.0000 RunMean : -96.4200\n",
      "Episode: 1846 Total reward: -103.0 Training loss: 2.0948 Explore P: 0.0000 RunMean : -96.5700\n",
      "Episode: 1847 Total reward: -98.0 Training loss: 3.4735 Explore P: 0.0000 RunMean : -96.5300\n",
      "Episode: 1848 Total reward: -92.0 Training loss: 1.4570 Explore P: 0.0000 RunMean : -96.7100\n",
      "Episode: 1849 Total reward: -78.0 Training loss: 1.6215 Explore P: 0.0000 RunMean : -96.4600\n",
      "Episode: 1850 Total reward: -94.0 Training loss: 1.2576 Explore P: 0.0000 RunMean : -96.4100\n",
      "Episode: 1851 Total reward: -77.0 Training loss: 3.0480 Explore P: 0.0000 RunMean : -96.3800\n",
      "Episode: 1852 Total reward: -70.0 Training loss: 2.1772 Explore P: 0.0000 RunMean : -96.1300\n",
      "Episode: 1853 Total reward: -62.0 Training loss: 1.7106 Explore P: 0.0000 RunMean : -95.7400\n",
      "Episode: 1854 Total reward: -101.0 Training loss: 1.0656 Explore P: 0.0000 RunMean : -96.0100\n",
      "Episode: 1855 Total reward: -79.0 Training loss: 2.3225 Explore P: 0.0000 RunMean : -95.2300\n",
      "Episode: 1856 Total reward: -75.0 Training loss: 1.9163 Explore P: 0.0000 RunMean : -95.3400\n",
      "Episode: 1857 Total reward: -130.0 Training loss: 0.9932 Explore P: 0.0000 RunMean : -95.6700\n",
      "Episode: 1858 Total reward: -87.0 Training loss: 2.8511 Explore P: 0.0000 RunMean : -94.5700\n",
      "Episode: 1859 Total reward: -129.0 Training loss: 1.7588 Explore P: 0.0000 RunMean : -94.8800\n",
      "Episode: 1860 Total reward: -86.0 Training loss: 1.8862 Explore P: 0.0000 RunMean : -94.7200\n",
      "Episode: 1861 Total reward: -69.0 Training loss: 1.4729 Explore P: 0.0000 RunMean : -94.0700\n",
      "Episode: 1862 Total reward: -63.0 Training loss: 0.8594 Explore P: 0.0000 RunMean : -93.9900\n",
      "Episode: 1863 Total reward: -81.0 Training loss: 1.8433 Explore P: 0.0000 RunMean : -93.9000\n",
      "Episode: 1864 Total reward: -87.0 Training loss: 2.2930 Explore P: 0.0000 RunMean : -93.8000\n",
      "Episode: 1865 Total reward: -89.0 Training loss: 1.7730 Explore P: 0.0000 RunMean : -93.8500\n",
      "Episode: 1866 Total reward: -62.0 Training loss: 2.1417 Explore P: 0.0000 RunMean : -93.7100\n",
      "Episode: 1867 Total reward: -78.0 Training loss: 0.9191 Explore P: 0.0000 RunMean : -93.5400\n",
      "Episode: 1868 Total reward: -83.0 Training loss: 2.2183 Explore P: 0.0000 RunMean : -93.5500\n",
      "Episode: 1869 Total reward: -128.0 Training loss: 2.1423 Explore P: 0.0000 RunMean : -94.0800\n",
      "Episode: 1870 Total reward: -91.0 Training loss: 3.6709 Explore P: 0.0000 RunMean : -94.0500\n",
      "Episode: 1871 Total reward: -120.0 Training loss: 3.0476 Explore P: 0.0000 RunMean : -94.4400\n",
      "Episode: 1872 Total reward: -74.0 Training loss: 2.3813 Explore P: 0.0000 RunMean : -94.5500\n",
      "Episode: 1873 Total reward: -73.0 Training loss: 2.4850 Explore P: 0.0000 RunMean : -94.3200\n",
      "Episode: 1874 Total reward: -110.0 Training loss: 2.7636 Explore P: 0.0000 RunMean : -94.3700\n",
      "Episode: 1875 Total reward: -107.0 Training loss: 3.2339 Explore P: 0.0000 RunMean : -94.6100\n",
      "Episode: 1876 Total reward: -81.0 Training loss: 4.0245 Explore P: 0.0000 RunMean : -94.7900\n",
      "Episode: 1877 Total reward: -79.0 Training loss: 3.2170 Explore P: 0.0000 RunMean : -94.6500\n",
      "Episode: 1878 Total reward: -103.0 Training loss: 2.0584 Explore P: 0.0000 RunMean : -95.0500\n",
      "Episode: 1879 Total reward: -92.0 Training loss: 1.4113 Explore P: 0.0000 RunMean : -95.3400\n",
      "Episode: 1880 Total reward: -63.0 Training loss: 2.7558 Explore P: 0.0000 RunMean : -95.1400\n",
      "Episode: 1881 Total reward: -71.0 Training loss: 1.6166 Explore P: 0.0000 RunMean : -95.1400\n",
      "Episode: 1882 Total reward: -69.0 Training loss: 1.4861 Explore P: 0.0000 RunMean : -94.9200\n",
      "Episode: 1883 Total reward: -89.0 Training loss: 2.0170 Explore P: 0.0000 RunMean : -94.8800\n",
      "Episode: 1884 Total reward: -96.0 Training loss: 2.5947 Explore P: 0.0000 RunMean : -94.8300\n",
      "Episode: 1885 Total reward: -69.0 Training loss: 1.8003 Explore P: 0.0000 RunMean : -94.8100\n",
      "Episode: 1886 Total reward: -108.0 Training loss: 1.7812 Explore P: 0.0000 RunMean : -95.0100\n",
      "Episode: 1887 Total reward: -101.0 Training loss: 1.8860 Explore P: 0.0000 RunMean : -95.3100\n",
      "Episode: 1888 Total reward: -98.0 Training loss: 4.1020 Explore P: 0.0000 RunMean : -95.4400\n",
      "Episode: 1889 Total reward: -94.0 Training loss: 2.7170 Explore P: 0.0000 RunMean : -95.4700\n",
      "Episode: 1890 Total reward: -154.0 Training loss: 2.1002 Explore P: 0.0000 RunMean : -95.9200\n",
      "Episode: 1891 Total reward: -92.0 Training loss: 3.2905 Explore P: 0.0000 RunMean : -95.8200\n",
      "Episode: 1892 Total reward: -125.0 Training loss: 2.9056 Explore P: 0.0000 RunMean : -96.2400\n",
      "Episode: 1893 Total reward: -70.0 Training loss: 2.9942 Explore P: 0.0000 RunMean : -96.0300\n",
      "Episode: 1894 Total reward: -124.0 Training loss: 1.4298 Explore P: 0.0000 RunMean : -96.5200\n",
      "Episode: 1895 Total reward: -91.0 Training loss: 0.9810 Explore P: 0.0000 RunMean : -92.4300\n",
      "Episode: 1896 Total reward: -95.0 Training loss: 2.4635 Explore P: 0.0000 RunMean : -92.1000\n",
      "Episode: 1897 Total reward: -87.0 Training loss: 1.1833 Explore P: 0.0000 RunMean : -92.0200\n",
      "Episode: 1898 Total reward: -71.0 Training loss: 2.4107 Explore P: 0.0000 RunMean : -91.6700\n",
      "Episode: 1899 Total reward: -70.0 Training loss: 0.9187 Explore P: 0.0000 RunMean : -91.4700\n",
      "Episode: 1900 Total reward: -134.0 Training loss: 0.9416 Explore P: 0.0000 RunMean : -91.8000\n",
      "Episode: 1901 Total reward: -76.0 Training loss: 3.7644 Explore P: 0.0000 RunMean : -91.7000\n",
      "Episode: 1902 Total reward: -63.0 Training loss: 3.5861 Explore P: 0.0000 RunMean : -91.4800\n",
      "Episode: 1903 Total reward: -115.0 Training loss: 1.7737 Explore P: 0.0000 RunMean : -91.7300\n",
      "Episode: 1904 Total reward: -99.0 Training loss: 1.4036 Explore P: 0.0000 RunMean : -92.0800\n",
      "Episode: 1905 Total reward: -119.0 Training loss: 1.4111 Explore P: 0.0000 RunMean : -92.3500\n",
      "Episode: 1906 Total reward: -134.0 Training loss: 2.1205 Explore P: 0.0000 RunMean : -92.6400\n",
      "Episode: 1907 Total reward: -113.0 Training loss: 3.1568 Explore P: 0.0000 RunMean : -92.8700\n",
      "Episode: 1908 Total reward: -119.0 Training loss: 3.0263 Explore P: 0.0000 RunMean : -93.1100\n",
      "Episode: 1909 Total reward: -124.0 Training loss: 3.5365 Explore P: 0.0000 RunMean : -93.1400\n",
      "Episode: 1910 Total reward: -130.0 Training loss: 1.8974 Explore P: 0.0000 RunMean : -93.6800\n",
      "Episode: 1911 Total reward: -105.0 Training loss: 3.3422 Explore P: 0.0000 RunMean : -93.8500\n",
      "Episode: 1912 Total reward: -114.0 Training loss: 2.4762 Explore P: 0.0000 RunMean : -94.1200\n",
      "Episode: 1913 Total reward: -113.0 Training loss: 2.5698 Explore P: 0.0000 RunMean : -94.0500\n",
      "Episode: 1914 Total reward: -63.0 Training loss: 1.8257 Explore P: 0.0000 RunMean : -93.7500\n",
      "Episode: 1915 Total reward: -74.0 Training loss: 1.9489 Explore P: 0.0000 RunMean : -93.6500\n",
      "Episode: 1916 Total reward: -143.0 Training loss: 2.3071 Explore P: 0.0000 RunMean : -93.4500\n",
      "Episode: 1917 Total reward: -63.0 Training loss: 1.5466 Explore P: 0.0000 RunMean : -93.3400\n",
      "Episode: 1918 Total reward: -91.0 Training loss: 0.7897 Explore P: 0.0000 RunMean : -93.3200\n",
      "Episode: 1919 Total reward: -85.0 Training loss: 1.2199 Explore P: 0.0000 RunMean : -93.4300\n",
      "Episode: 1920 Total reward: -78.0 Training loss: 1.4445 Explore P: 0.0000 RunMean : -93.3600\n",
      "Episode: 1921 Total reward: -77.0 Training loss: 1.5757 Explore P: 0.0000 RunMean : -92.9800\n",
      "Episode: 1922 Total reward: -70.0 Training loss: 1.8686 Explore P: 0.0000 RunMean : -92.8500\n",
      "Episode: 1923 Total reward: -78.0 Training loss: 1.5820 Explore P: 0.0000 RunMean : -92.4400\n",
      "Episode: 1924 Total reward: -78.0 Training loss: 1.4468 Explore P: 0.0000 RunMean : -92.2900\n",
      "Episode: 1925 Total reward: -86.0 Training loss: 2.7382 Explore P: 0.0000 RunMean : -92.2700\n",
      "Episode: 1926 Total reward: -110.0 Training loss: 2.2516 Explore P: 0.0000 RunMean : -92.3300\n",
      "Episode: 1927 Total reward: -87.0 Training loss: 3.0371 Explore P: 0.0000 RunMean : -92.2100\n",
      "Episode: 1928 Total reward: -107.0 Training loss: 1.4591 Explore P: 0.0000 RunMean : -92.3700\n",
      "Episode: 1929 Total reward: -79.0 Training loss: 2.0566 Explore P: 0.0000 RunMean : -92.5300\n",
      "Episode: 1930 Total reward: -104.0 Training loss: 1.4029 Explore P: 0.0000 RunMean : -92.7000\n",
      "Episode: 1931 Total reward: -90.0 Training loss: 0.9741 Explore P: 0.0000 RunMean : -92.4000\n",
      "Episode: 1932 Total reward: -62.0 Training loss: 1.7020 Explore P: 0.0000 RunMean : -92.2300\n",
      "Episode: 1933 Total reward: -87.0 Training loss: 2.9920 Explore P: 0.0000 RunMean : -92.4800\n",
      "Episode: 1934 Total reward: -92.0 Training loss: 1.4320 Explore P: 0.0000 RunMean : -92.5600\n",
      "Episode: 1935 Total reward: -134.0 Training loss: 1.8559 Explore P: 0.0000 RunMean : -92.9400\n",
      "Episode: 1936 Total reward: -129.0 Training loss: 5.6730 Explore P: 0.0000 RunMean : -93.5400\n",
      "Episode: 1937 Total reward: -101.0 Training loss: 2.5524 Explore P: 0.0000 RunMean : -93.6800\n",
      "Episode: 1938 Total reward: -111.0 Training loss: 1.7019 Explore P: 0.0000 RunMean : -93.8100\n",
      "Episode: 1939 Total reward: -70.0 Training loss: 2.0045 Explore P: 0.0000 RunMean : -93.6800\n",
      "Episode: 1940 Total reward: -70.0 Training loss: 3.5159 Explore P: 0.0000 RunMean : -93.5100\n",
      "Episode: 1941 Total reward: -106.0 Training loss: 2.2202 Explore P: 0.0000 RunMean : -93.4100\n",
      "Episode: 1942 Total reward: -108.0 Training loss: 1.9030 Explore P: 0.0000 RunMean : -93.4500\n",
      "Episode: 1943 Total reward: -79.0 Training loss: 1.6928 Explore P: 0.0000 RunMean : -92.9500\n",
      "Episode: 1944 Total reward: -116.0 Training loss: 3.2587 Explore P: 0.0000 RunMean : -93.1600\n",
      "Episode: 1945 Total reward: -144.0 Training loss: 4.1336 Explore P: 0.0000 RunMean : -93.9800\n",
      "Episode: 1946 Total reward: -138.0 Training loss: 2.0133 Explore P: 0.0000 RunMean : -94.3300\n",
      "Episode: 1947 Total reward: -106.0 Training loss: 2.5996 Explore P: 0.0000 RunMean : -94.4100\n",
      "Episode: 1948 Total reward: -94.0 Training loss: 2.9705 Explore P: 0.0000 RunMean : -94.4300\n",
      "Episode: 1949 Total reward: -110.0 Training loss: 2.0738 Explore P: 0.0000 RunMean : -94.7500\n",
      "Episode: 1950 Total reward: -64.0 Training loss: 2.2042 Explore P: 0.0000 RunMean : -94.4500\n",
      "Episode: 1951 Total reward: -102.0 Training loss: 2.2540 Explore P: 0.0000 RunMean : -94.7000\n",
      "Episode: 1952 Total reward: -145.0 Training loss: 1.1970 Explore P: 0.0000 RunMean : -95.4500\n",
      "Episode: 1953 Total reward: -121.0 Training loss: 2.1960 Explore P: 0.0000 RunMean : -96.0400\n",
      "Episode: 1954 Total reward: -87.0 Training loss: 2.6993 Explore P: 0.0000 RunMean : -95.9000\n",
      "Episode: 1955 Total reward: -89.0 Training loss: 4.8931 Explore P: 0.0000 RunMean : -96.0000\n",
      "Episode: 1956 Total reward: -120.0 Training loss: 2.0524 Explore P: 0.0000 RunMean : -96.4500\n",
      "Episode: 1957 Total reward: -88.0 Training loss: 1.8448 Explore P: 0.0000 RunMean : -96.0300\n",
      "Episode: 1958 Total reward: -87.0 Training loss: 1.5050 Explore P: 0.0000 RunMean : -96.0300\n",
      "Episode: 1959 Total reward: -87.0 Training loss: 2.5688 Explore P: 0.0000 RunMean : -95.6100\n",
      "Episode: 1960 Total reward: -87.0 Training loss: 2.9294 Explore P: 0.0000 RunMean : -95.6200\n",
      "Episode: 1961 Total reward: -71.0 Training loss: 2.3336 Explore P: 0.0000 RunMean : -95.6400\n",
      "Episode: 1962 Total reward: -72.0 Training loss: 3.2372 Explore P: 0.0000 RunMean : -95.7300\n",
      "Episode: 1963 Total reward: -94.0 Training loss: 2.3022 Explore P: 0.0000 RunMean : -95.8600\n",
      "Episode: 1964 Total reward: -100.0 Training loss: 2.0346 Explore P: 0.0000 RunMean : -95.9900\n",
      "Episode: 1965 Total reward: -63.0 Training loss: 3.1895 Explore P: 0.0000 RunMean : -95.7300\n",
      "Episode: 1966 Total reward: -85.0 Training loss: 1.5148 Explore P: 0.0000 RunMean : -95.9600\n",
      "Episode: 1967 Total reward: -88.0 Training loss: 2.2244 Explore P: 0.0000 RunMean : -96.0600\n",
      "Episode: 1968 Total reward: -99.0 Training loss: 2.3407 Explore P: 0.0000 RunMean : -96.2200\n",
      "Episode: 1969 Total reward: -97.0 Training loss: 1.6883 Explore P: 0.0000 RunMean : -95.9100\n",
      "Episode: 1970 Total reward: -93.0 Training loss: 2.1453 Explore P: 0.0000 RunMean : -95.9300\n",
      "Episode: 1971 Total reward: -85.0 Training loss: 4.2527 Explore P: 0.0000 RunMean : -95.5800\n",
      "Episode: 1972 Total reward: -83.0 Training loss: 2.2949 Explore P: 0.0000 RunMean : -95.6700\n",
      "Episode: 1973 Total reward: -134.0 Training loss: 2.0953 Explore P: 0.0000 RunMean : -96.2800\n",
      "Episode: 1974 Total reward: -100.0 Training loss: 2.4636 Explore P: 0.0000 RunMean : -96.1800\n",
      "Episode: 1975 Total reward: -72.0 Training loss: 2.3485 Explore P: 0.0000 RunMean : -95.8300\n",
      "Episode: 1976 Total reward: -107.0 Training loss: 2.0370 Explore P: 0.0000 RunMean : -96.0900\n",
      "Episode: 1977 Total reward: -96.0 Training loss: 1.7549 Explore P: 0.0000 RunMean : -96.2600\n",
      "Episode: 1978 Total reward: -63.0 Training loss: 1.5812 Explore P: 0.0000 RunMean : -95.8600\n",
      "Episode: 1979 Total reward: -84.0 Training loss: 1.9571 Explore P: 0.0000 RunMean : -95.7800\n",
      "Episode: 1980 Total reward: -82.0 Training loss: 1.4419 Explore P: 0.0000 RunMean : -95.9700\n",
      "Episode: 1981 Total reward: -101.0 Training loss: 2.4413 Explore P: 0.0000 RunMean : -96.2700\n",
      "Episode: 1982 Total reward: -112.0 Training loss: 1.5675 Explore P: 0.0000 RunMean : -96.7000\n",
      "Episode: 1983 Total reward: -104.0 Training loss: 1.7597 Explore P: 0.0000 RunMean : -96.8500\n",
      "Episode: 1984 Total reward: -91.0 Training loss: 2.1706 Explore P: 0.0000 RunMean : -96.8000\n",
      "Episode: 1985 Total reward: -80.0 Training loss: 1.3127 Explore P: 0.0000 RunMean : -96.9100\n",
      "Episode: 1986 Total reward: -181.0 Training loss: 1.9029 Explore P: 0.0000 RunMean : -97.6400\n",
      "Episode: 1987 Total reward: -89.0 Training loss: 0.8993 Explore P: 0.0000 RunMean : -97.5200\n",
      "Episode: 1988 Total reward: -70.0 Training loss: 2.9174 Explore P: 0.0000 RunMean : -97.2400\n",
      "Episode: 1989 Total reward: -94.0 Training loss: 1.9553 Explore P: 0.0000 RunMean : -97.2400\n",
      "Episode: 1990 Total reward: -273.0 Training loss: 1.5748 Explore P: 0.0000 RunMean : -98.4300\n",
      "Episode: 1991 Total reward: -86.0 Training loss: 3.2315 Explore P: 0.0000 RunMean : -98.3700\n",
      "Episode: 1992 Total reward: -93.0 Training loss: 1.2068 Explore P: 0.0000 RunMean : -98.0500\n",
      "Episode: 1993 Total reward: -98.0 Training loss: 4.9536 Explore P: 0.0000 RunMean : -98.3300\n",
      "Episode: 1994 Total reward: -69.0 Training loss: 1.8805 Explore P: 0.0000 RunMean : -97.7800\n",
      "Episode: 1995 Total reward: -112.0 Training loss: 1.4339 Explore P: 0.0000 RunMean : -97.9900\n",
      "Episode: 1996 Total reward: -144.0 Training loss: 2.4131 Explore P: 0.0000 RunMean : -98.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:34:59,735] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.0.10772.video002000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1997 Total reward: -107.0 Training loss: 3.0632 Explore P: 0.0000 RunMean : -98.6800\n",
      "Episode: 1998 Total reward: -77.0 Training loss: 1.0444 Explore P: 0.0000 RunMean : -98.7400\n",
      "Episode: 1999 Total reward: -69.0 Training loss: 3.3945 Explore P: 0.0000 RunMean : -98.7300\n",
      "average training reward =  -108.735\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 14:35:01,820] Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test reward =  -86.2\n",
      "average test reward =  (-86.200000000000003, -98.730000000000004, <__main__.QNetwork object at 0x0000022260D2F4A8>, <tensorflow.python.training.saver.Saver object at 0x000002225F9D2C18>, 2000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Monitor.close of <Monitor<TimeLimit<AcrobotEnv<Acrobot-v1>>>>>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAF5CAYAAABjkgsvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nM7Om4nBjZmZmTcXhxszMzJrK/wf8cSIjxfuBBAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x222635ee0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('Acrobot-v1')\n",
    "env = wrappers.Monitor(env, '/tmp/acrobot-experiment-1',force=True)\n",
    "\n",
    "# test implementation\n",
    "average_rewards = test_and_train_qnetwork(train_episodes=2000, verbose=True,\\\n",
    "                                         gamma=0.999,\\\n",
    "                                         decay_rate=0.0002,\\\n",
    "                                         explore_start=1.0,\\\n",
    "                                         explore_stop=0.0,\\\n",
    "                                         hidden_size=64,\\\n",
    "                                         hidden_layers=2,\\\n",
    "                                         learning_rate=0.0005,\\\n",
    "                                         batch_size=64,\\\n",
    "                                         alpha=0.1)\n",
    "print('average test reward = ', average_rewards)\n",
    "\n",
    "env.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 15:04:32,774] Making new env: Acrobot-v1\n"
     ]
    }
   ],
   "source": [
    "train_eps = 10000\n",
    "verb = False\n",
    "gamma = [0.999,0.99]\n",
    "decay_rate = [0.0001,0.00002]\n",
    "exp_start=1.0\n",
    "exp_stop=0.0\n",
    "hidden_size=[32]\n",
    "hidden_layers=[2]\n",
    "learning_rate=[0.00001,0.0001,0.001]\n",
    "batch_size=[64]\n",
    "num_averages = 1\n",
    "results = []\n",
    "alpha_relu = [0.1]\n",
    "mem_size = [10000]\n",
    "env = gym.make('Acrobot-v1')\n",
    "env.reset()\n",
    "\n",
    "for gaIndex in range(len(gamma)):\n",
    "    for drIndex in range(len(decay_rate)):\n",
    "        for hs in hidden_size:\n",
    "            for hl in hidden_layers:\n",
    "                for lr in learning_rate:\n",
    "                    for bs in batch_size:\n",
    "                        for alu in alpha_relu:\n",
    "                            for mems in mem_size:\n",
    "                                ga = gamma[gaIndex]\n",
    "                                dr = decay_rate[drIndex]\n",
    "                                train_params_name = 'dr='+str(dr)+'_ga='+str(ga)+'_hs='+str(hs)+'_hl'+str(hl)+'_lr'+str(lr)+'_bs'+str(bs)+'_alu='+str(alu)+'_mm='+str(mems)\n",
    "                                average_test_rewards = 0.\n",
    "                                average_train_rewards = 0.\n",
    "                                for i in range(num_averages):\n",
    "                                    test,train, mainQN, saver, num_episodes = test_and_train_qnetwork(memory_size=mems,\\\n",
    "                                                           train_episodes=train_eps,\\\n",
    "                                                           gamma=ga,\\\n",
    "                                                           explore_start=exp_start,\\\n",
    "                                                           explore_stop=exp_stop,\\\n",
    "                                                           decay_rate=dr,\\\n",
    "                                                           hidden_layers=hl,\\\n",
    "                                                           hidden_size=hs,\\\n",
    "                                                           learning_rate=lr,\\\n",
    "                                                           batch_size=bs,\\\n",
    "                                                           alpha = alu,\\\n",
    "                                                           verbose=verb)\n",
    "                                    average_test_rewards += test\n",
    "                                    average_train_rewards += train\n",
    "\n",
    "                                average_test_rewards = average_test_rewards / num_averages\n",
    "                                average_train_rewards = average_train_rewards / num_averages\n",
    "                                results.append([train_params_name+' test='+str(average_test_rewards)+'  train='+str(average_train_rewards)+'  numpEps='+str(num_episodes)])\n",
    "                                clear_output()\n",
    "                                for each in results:\n",
    "                                    print(each)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 13:19:28,522] Making new env: CartPole-v1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (64, 4) for Tensor 'main/inputs:0', which has shape '(?, 6)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bbc2d2e4cda2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmainQN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_and_train_qnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m                                     \u001b[0mtrain_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.999\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mexplore_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mexplore_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00002\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mhidden_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mhidden_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-3a06cf46fd7a>\u001b[0m in \u001b[0;36mtest_and_train_qnetwork\u001b[0;34m(train_episodes, gamma, explore_start, explore_stop, decay_rate, hidden_size, hidden_layers, learning_rate, memory_size, batch_size, test_episodes, render, alpha, verbose)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[1;31m# train q-network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrewards_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmainQN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunMean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_q_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_episodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_episodes\u001b[0m\u001b[1;33m,\u001b[0m                                                   \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mexplore_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplore_start\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mexplore_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexplore_stop\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecay_rate\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mhidden_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mhidden_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mmemory_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory_size\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m                                                  \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-43a664c65a90>\u001b[0m in \u001b[0;36mtrain_q_network\u001b[0;34m(train_episodes, gamma, explore_start, explore_stop, decay_rate, hidden_size, hidden_layers, learning_rate, memory_size, batch_size, max_steps, alpha, verbose)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[1;31m# Train network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0mtarget_Qs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[1;31m# Set target_Qs to 0 for states where episode ends\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    959\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    962\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (64, 4) for Tensor 'main/inputs:0', which has shape '(?, 6)'"
     ]
    }
   ],
   "source": [
    "from gym import wrappers\n",
    "    \n",
    "env = gym.make('CartPole-v1')\n",
    "#env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\n",
    "\n",
    "test,train, mainQN, saver, num_episodes = test_and_train_qnetwork(memory_size=10000,\\\n",
    "                                     train_episodes=4000,\\\n",
    "                                           gamma=0.999,\\\n",
    "                                           explore_start=1.,\\\n",
    "                                           explore_stop=0.0,\\\n",
    "                                           decay_rate=0.00002,\\\n",
    "                                           hidden_layers=1,\\\n",
    "                                           hidden_size=32,\\\n",
    "                                           learning_rate=0.001,\\\n",
    "                                           batch_size=64,\\\n",
    "                                           alpha=0.1,\\\n",
    "                                           verbose=True)\n",
    "print('test=',str(test))\n",
    "print(train)\n",
    "print('number of episodes=',str(num_episodes))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 23:50:18,379] Making new env: CartPole-v0\n",
      "[2017-05-22 23:50:18,382] Clearing 4 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 23:50:18,392] Restoring parameters from checkpoints\\cartpole.ckpt\n",
      "[2017-05-22 23:50:18,484] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000000.mp4\n",
      "[2017-05-22 23:50:21,927] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000001.mp4\n",
      "[2017-05-22 23:50:25,823] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000008.mp4\n",
      "[2017-05-22 23:50:30,765] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000027.mp4\n",
      "[2017-05-22 23:50:37,157] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000064.mp4\n",
      "[2017-05-22 23:50:45,686] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.9999999998906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Monitor.close of <Monitor<TimeLimit<CartPoleEnv<CartPole-v0>>>>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\n",
    "avg_test_rewards = test_q_network(mainQN, saver, test_episodes=200, render=False)\n",
    "print(avg_test_rewards)\n",
    "env.close\n",
    "#     if verbose:\n",
    "#         print('average test reward = ', avg_test_rewards)\n",
    "    \n",
    "#     return avg_test_rewards, avg_train_rewards, mainQN, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 13:46:29,408] Finished writing results. You can upload them to the scoreboard via gym.upload('D:\\\\tmp\\\\acrobot-experiment-1')\n",
      "[2017-05-27 13:46:29,411] [Acrobot-v1] Uploading 1011 episodes of training data\n",
      "[2017-05-27 13:46:31,125] [Acrobot-v1] Uploading videos of 11 training episodes (1329615 bytes)\n",
      "[2017-05-27 13:46:32,559] [Acrobot-v1] Creating evaluation object from /tmp/acrobot-experiment-1 with learning curve and training video\n",
      "[2017-05-27 13:46:32,866] \n",
      "****************************************************\n",
      "You successfully uploaded your evaluation on Acrobot-v1 to\n",
      "OpenAI Gym! You can find it at:\n",
      "\n",
      "    https://gym.openai.com/evaluations/eval_PfjvHi6oSPOyruibcH6beQ\n",
      "\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "gym.upload('/tmp/acrobot-experiment-1', api_key='sk_2nAEHbARwKPuKcao8nWRw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 13:18:59,153] Making new env: CartPole-v1\n",
      "[2017-05-27 13:18:59,155] Clearing 22 monitor files from previous run (because force=True was provided)\n",
      "[2017-05-27 13:18:59,161] Starting new video recorder writing to D:\\tmp\\acrobot-experiment-1\\openaigym.video.3.5636.video000000.mp4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m_ctypes/callbacks.c\u001b[0m in \u001b[0;36m'calling callback function'\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(hwnd, msg, wParam, lParam)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_window_proc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_handlers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhwnd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwParam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlParam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m             \u001b[0mevent_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent_handlers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-27 13:19:07,935] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-19-52903a4260e1>\", line 6, in <module>\n",
      "    observation = env.reset()\n",
      "  File \"d:\\git\\gym\\gym\\core.py\", line 107, in reset\n",
      "    return self._reset()\n",
      "  File \"d:\\git\\gym\\gym\\wrappers\\monitoring.py\", line 41, in _reset\n",
      "    self._after_reset(observation)\n",
      "  File \"d:\\git\\gym\\gym\\wrappers\\monitoring.py\", line 198, in _after_reset\n",
      "    self._reset_video_recorder()\n",
      "  File \"d:\\git\\gym\\gym\\wrappers\\monitoring.py\", line 219, in _reset_video_recorder\n",
      "    self.video_recorder.capture_frame()\n",
      "  File \"d:\\git\\gym\\gym\\monitoring\\video_recorder.py\", line 106, in capture_frame\n",
      "    frame = self.env.render(mode=render_mode)\n",
      "  File \"d:\\git\\gym\\gym\\core.py\", line 153, in render\n",
      "    return self._render(mode=mode, close=close)\n",
      "  File \"d:\\git\\gym\\gym\\core.py\", line 285, in _render\n",
      "    return self.env.render(mode, close)\n",
      "  File \"d:\\git\\gym\\gym\\core.py\", line 153, in render\n",
      "    return self._render(mode=mode, close=close)\n",
      "  File \"d:\\git\\gym\\gym\\envs\\classic_control\\cartpole.py\", line 145, in _render\n",
      "    return self.viewer.render(return_rgb_array = mode=='rgb_array')\n",
      "  File \"d:\\git\\gym\\gym\\envs\\classic_control\\rendering.py\", line 84, in render\n",
      "    self.window.dispatch_events()\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pyglet\\window\\win32\\__init__.py\", line 598, in dispatch_events\n",
      "    _user32.DispatchMessageW(byref(msg))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\inspect.py\", line 1414, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"C:\\Users\\drbur\\AppData\\Local\\Continuum\\Anaconda3\\lib\\tokenize.py\", line 454, in open\n",
      "    buffer = _builtin_open(filename, 'rb')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "env = gym.make('CartPole-v1')\n",
    "env = wrappers.Monitor(env, '/tmp/acrobot-experiment-1',force=True)\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
