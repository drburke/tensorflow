{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "# base code from udacity-deep-learning/reinforcement/Q-learning-cart.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-25 16:34:37,338] Making new env: PredictObsCartpole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0440894  -0.00764544  0.02559768  0.03428343]\n",
      "[ 0.04393649  0.18710026  0.02628334 -0.25021452] 1.0 (1, array([ -3.61109359e+00,   2.42795025e+38,  -8.40544658e-02,\n",
      "        -8.07169099e+37]), array([ -4.58905310e+00,  -8.52388870e+37,   1.35387805e-01,\n",
      "         8.53143651e+37]), array([  3.97431569e+00,   1.16917136e+38,  -1.47376140e-01,\n",
      "        -1.25074189e+38]), array([  3.19983175e+00,   1.87701933e+38,  -1.83340862e-01,\n",
      "         1.45591296e+38]), array([  5.91141897e-01,  -6.82878515e+37,   2.58533225e-02,\n",
      "        -2.82275735e+38])) False\n",
      "[ 0.0476785   0.38183721  0.02127905 -0.53449264] 1.0 (1, array([  1.29394870e+00,   3.12476006e+38,  -3.32340160e-01,\n",
      "         2.49881005e+38]), array([ -4.51977375e+00,   2.37631787e+37,  -8.02206790e-02,\n",
      "         1.64586815e+37]), array([ -1.29504118e+00,  -2.10589233e+38,  -4.02858659e-01,\n",
      "         1.23521225e+37]), array([  3.29065788e+00,  -8.62847442e+37,  -2.32173065e-01,\n",
      "        -2.85475108e+38]), array([ -3.98101514e+00,  -1.89607742e+38,  -3.35091437e-01,\n",
      "        -1.59905686e+38])) False\n",
      "[ 0.05531524  0.57665355  0.0105892  -0.82039544] 1.0 (1, array([  1.32093434e-01,  -1.88749219e+38,  -1.09336059e-01,\n",
      "        -3.02778279e+38]), array([  3.94749275e+00,   2.61984667e+38,   3.32822063e-01,\n",
      "        -1.14204957e+38]), array([  2.04409779e+00,  -4.97197355e+37,  -1.66133731e-01,\n",
      "        -2.92363221e+38]), array([ -7.50292629e-01,  -7.60057348e+37,  -2.84508046e-01,\n",
      "        -1.01943649e+38]), array([ -3.88204913e+00,   2.52559282e+38,   1.40402639e-01,\n",
      "        -2.09125296e+38])) False\n",
      "[ 0.06684831  0.771629   -0.00581871 -1.10972905] 1.0 (1, array([  2.48911154e+00,  -9.21861451e+37,   8.90681591e-04,\n",
      "        -8.41251767e+37]), array([ -1.29684637e+00,  -1.62719956e+38,  -3.37591745e-03,\n",
      "         1.23685790e+38]), array([ -2.13753340e+00,   1.65920386e+37,  -3.20542735e-01,\n",
      "        -2.31497288e+38]), array([ -4.35065899e+00,   3.20363200e+38,  -4.15644980e-01,\n",
      "        -2.18747125e+38]), array([  1.08352083e+00,  -2.84905071e+38,   3.19936866e-01,\n",
      "         1.49465725e+38])) False\n",
      "[ 0.08228089  0.57658399 -0.02801329 -0.81887717] 1.0 (0, array([ -1.64756209e+00,   2.06001583e+38,   2.81791669e-01,\n",
      "        -5.76574771e+37]), array([ -8.10160695e-01,   2.97146188e+38,   1.86136453e-01,\n",
      "        -3.17890860e+38]), array([ -7.10918927e-01,  -2.76381086e+38,   4.00907054e-01,\n",
      "         5.11869517e+37]), array([  1.37930964e+00,  -9.22419116e+37,   1.40504497e-01,\n",
      "         4.88942435e+37]), array([  2.63696136e+00,   2.72295384e+38,  -8.01679771e-02,\n",
      "         2.69057926e+38])) False\n",
      "[ 0.09381257  0.38185644 -0.04439083 -0.53513527] 1.0 (0, array([  2.80204387e+00,   1.19567831e+38,  -2.13720890e-01,\n",
      "        -1.92969177e+38]), array([ -3.20594088e+00,   2.87713223e+38,  -1.72513932e-01,\n",
      "        -3.19224005e+37]), array([ -5.80047937e-02,   1.89313767e+38,   2.88385607e-01,\n",
      "        -2.45634376e+38]), array([ -7.01718142e-01,   2.33334932e+38,   2.66434959e-01,\n",
      "        -2.70583159e+38]), array([ -3.29871985e+00,  -1.33255457e+38,  -3.55746354e-01,\n",
      "        -5.12717004e+37])) False\n",
      "[ 0.1014497   0.57757358 -0.05509354 -0.8414684 ] 1.0 (1, array([  3.62640757e+00,  -4.62826293e+37,  -1.80883577e-01,\n",
      "         2.96251094e+38]), array([  2.61374960e+00,   7.55334987e+37,  -4.16636283e-01,\n",
      "         2.93667091e+38]), array([  1.66883850e+00,  -1.87518074e+38,  -3.98141929e-01,\n",
      "        -3.35199673e+38]), array([  4.10306449e+00,   1.31452978e+38,   1.71864002e-01,\n",
      "         6.53784405e+37]), array([  3.57462284e-01,  -3.02316632e+37,   8.39376666e-02,\n",
      "         1.04862722e+38])) False\n",
      "[ 0.11300117  0.38324523 -0.07192291 -0.56660746] 1.0 (0, array([ -1.36872334e+00,   8.28012004e+37,  -1.77127218e-01,\n",
      "         2.54803365e+38]), array([ -3.72069775e+00,  -1.95707021e+38,  -2.65541408e-01,\n",
      "        -6.59970789e+37]), array([  2.35423642e+00,   1.83122598e+37,  -1.03242591e-02,\n",
      "        -3.39910782e+38]), array([ -7.16143437e-01,  -2.97029891e+38,  -2.44413184e-01,\n",
      "         2.94272048e+38]), array([ -2.73217724e+00,   2.43871945e+38,   2.53751358e-01,\n",
      "        -2.31973037e+38])) False\n",
      "[ 0.12066608  0.57929852 -0.08325505 -0.8810542 ] 1.0 (1, array([  2.18159910e+00,   1.11148413e+38,   2.96951739e-01,\n",
      "         3.71611387e+37]), array([ -4.55273799e+00,  -3.01271954e+38,  -3.51807196e-01,\n",
      "         1.16630252e+37]), array([  2.44901932e+00,  -3.18318286e+38,  -3.62853170e-02,\n",
      "         2.21045851e+38]), array([  1.61861614e+00,   3.12498950e+37,   7.44027238e-02,\n",
      "         2.69830289e+38]), array([  7.20746999e-01,  -5.32070784e+37,   1.70024428e-01,\n",
      "        -9.71795856e+37])) False\n",
      "[ 0.13225205  0.3854002  -0.10087614 -0.61566284] 1.0 (0, array([  2.27787437e+00,  -3.36775421e+38,   1.62657301e-01,\n",
      "         2.85501930e+38]), array([  2.02037529e+00,  -2.19818461e+38,  -1.38078213e-02,\n",
      "        -2.44788219e+38]), array([ -1.35364533e+00,   2.97486426e+38,   3.54627425e-01,\n",
      "        -1.47793571e+38]), array([ -1.53954198e+00,   6.82013399e+37,   3.88047259e-01,\n",
      "        -2.39693977e+38]), array([ -2.33360022e+00,   2.54229588e+38,  -6.79234808e-03,\n",
      "         2.71518833e+38])) False\n",
      "[ 0.13996005  0.19182157 -0.1131894  -0.35637835] 1.0 (0, array([  2.00541655e+00,   5.94645497e+37,   2.59364345e-01,\n",
      "        -2.01398107e+38]), array([  2.84540895e+00,  -1.58974534e+38,  -1.69005604e-01,\n",
      "         3.25427099e+38]), array([ -4.35826966e+00,  -2.11142735e+38,   1.74880275e-02,\n",
      "        -8.43939210e+37]), array([ -2.47584280e+00,   1.25600078e+38,   1.41779627e-01,\n",
      "         3.15605748e+38]), array([  3.63456360e+00,   3.38537466e+38,  -1.14866683e-01,\n",
      "        -3.09497350e+38])) False\n",
      "[ 0.14379648 -0.00152443 -0.12031696 -0.10142189] 1.0 (0, array([ -4.95655883e-01,   4.61735932e+37,   1.01510511e-01,\n",
      "        -1.23892327e+36]), array([  3.52117002e+00,   8.69317652e+37,  -8.25795281e-02,\n",
      "        -5.66966489e+37]), array([  2.98405071e+00,  -1.03315204e+38,  -2.41731065e-01,\n",
      "        -2.99868246e+38]), array([  3.60985774e+00,   2.84847937e+38,  -3.18247372e-01,\n",
      "        -1.12651327e+38]), array([ -3.11642813e+00,  -2.61405941e+38,   3.34991579e-01,\n",
      "        -3.01573692e+38])) False\n",
      "[ 0.14376599 -0.194735   -0.1223454   0.15101088] 1.0 (0, array([ -3.96112618e+00,  -7.72798861e+37,   1.92222003e-01,\n",
      "         5.32272023e+37]), array([ -1.85872655e+00,   3.32625315e+38,   6.20207689e-02,\n",
      "         3.02816711e+38]), array([  5.73832620e-01,   4.40097610e+37,  -3.76010575e-01,\n",
      "        -2.69450013e+38]), array([  1.09860541e+00,   1.57641727e+38,  -2.14438892e-01,\n",
      "         3.15765498e+38]), array([  2.31588551e+00,  -1.78300275e+38,   1.20989252e-01,\n",
      "        -1.09056150e+38])) False\n",
      "[ 0.13987129  0.0019071  -0.11932518 -0.17762733] 1.0 (1, array([ -3.84256371e+00,  -1.66131850e+37,   2.68101369e-01,\n",
      "        -1.37346558e+38]), array([ -3.35102499e+00,  -1.15514263e+38,   2.62955613e-01,\n",
      "        -2.44741981e+38]), array([ -2.61732049e+00,  -2.93424131e+38,   1.72335243e-01,\n",
      "        -7.13005555e+37]), array([ -1.81593622e+00,   1.48789402e+38,  -1.37411133e-01,\n",
      "         1.55013087e+38]), array([  3.02591420e+00,  -1.92148700e+38,   3.96945423e-01,\n",
      "        -2.29787260e+38])) False\n",
      "[ 0.13990944 -0.19132306 -0.12287773  0.07515846] 1.0 (0, array([  1.92890941e+00,  -4.03049518e+37,  -2.45215146e-01,\n",
      "         1.12269152e+38]), array([  2.43734464e+00,   7.08315038e+37,  -3.67207749e-03,\n",
      "        -2.59947425e+38]), array([  2.73341347e+00,  -5.72257779e+36,   2.96662592e-01,\n",
      "        -2.48529536e+38]), array([  4.46485809e+00,  -5.98826075e+36,  -3.58266918e-01,\n",
      "        -1.49646819e+38]), array([  3.86476999e+00,  -1.12961524e+38,   3.93811710e-01,\n",
      "        -3.80289960e+37])) False\n",
      "[ 0.13608297  0.00532661 -0.12137456 -0.25362715] 1.0 (1, array([  4.79816235e+00,  -2.06034513e+38,   2.92446239e-02,\n",
      "        -1.42749777e+38]), array([ -1.87993385e+00,   6.19758830e+37,   3.53298539e-01,\n",
      "         2.07751802e+38]), array([  2.14983743e+00,   4.02715869e+37,   3.53783967e-01,\n",
      "        -5.19855691e+36]), array([  3.58878891e+00,   2.27296115e+38,  -2.39736739e-01,\n",
      "         1.84586474e+38]), array([ -4.68315689e+00,  -1.20575961e+38,  -2.26557048e-01,\n",
      "         4.67068724e+36])) False\n",
      "[ 0.13618951 -0.18787206 -0.1264471  -0.00155772] 1.0 (0, array([ -2.58804766e+00,  -2.59889484e+38,  -3.84773671e-01,\n",
      "        -1.38105950e+37]), array([  8.44484401e-01,   2.70834760e+38,   3.52086042e-01,\n",
      "        -9.10293936e+37]), array([  4.13605876e+00,   3.11558027e+37,   6.20710812e-02,\n",
      "        -2.18709238e+38]), array([ -3.68773005e+00,  -1.73968620e+38,  -3.14755000e-01,\n",
      "        -1.88317920e+38]), array([  3.82208427e-01,   2.50621340e+38,   2.47128390e-01,\n",
      "        -3.18261837e+38])) False\n",
      "[ 0.13243207  0.00881518 -0.12647826 -0.33130957] 1.0 (1, array([ -8.48491069e-01,  -7.17408054e+36,  -2.14735921e-01,\n",
      "         6.03245740e+37]), array([  2.43110515e+00,  -1.79781900e+38,   1.00949760e-01,\n",
      "         9.50219690e+37]), array([  4.30598689e+00,   1.89384934e+38,   2.91829051e-01,\n",
      "        -6.51987208e+36]), array([ -3.02065356e+00,   3.37434383e+38,  -3.10510192e-01,\n",
      "        -1.94251407e+37]), array([ -4.14630625e+00,   3.02069223e+38,   3.89494608e-01,\n",
      "         1.49308450e+38])) False\n",
      "[ 0.13260837 -0.18430085 -0.13310445 -0.08103492] 1.0 (0, array([ -2.03231469e+00,   2.86648546e+38,  -4.17126732e-02,\n",
      "         2.58517050e+38]), array([ -4.37744292e+00,   2.43655225e+37,  -3.96004067e-02,\n",
      "        -1.18338159e+38]), array([ -1.91818120e+00,  -1.58715746e+38,  -2.51721549e-01,\n",
      "        -5.01410619e+36]), array([ -1.48667740e+00,  -1.15287299e+38,  -3.63413429e-01,\n",
      "        -3.30846286e+38]), array([  3.95190486e+00,  -5.86929684e+37,   1.48320486e-01,\n",
      "        -3.23955838e+37])) False\n",
      "[ 0.12892235 -0.3772885  -0.13472515  0.16686874] 1.0 (0, array([ -1.81795950e+00,   1.98199107e+38,   1.80237989e-01,\n",
      "         3.95076221e+37]), array([  1.96750139e+00,  -5.53728780e+37,  -4.14430485e-01,\n",
      "        -3.32554447e+38]), array([  1.07729161e-01,  -2.83597447e+38,  -3.76090126e-01,\n",
      "         3.16814189e+38]), array([  3.44642534e+00,  -2.36817983e+38,  -4.18322566e-01,\n",
      "         3.00583508e+38]), array([ -2.12807714e+00,  -2.13767002e+38,   1.60437457e-01,\n",
      "        -2.66166307e+38])) False\n",
      "[ 0.12137658 -0.57025051 -0.13138777  0.41419942] 1.0 (0, array([  2.49647233e+00,   4.28398065e+37,   1.93084841e-01,\n",
      "        -2.09038100e+38]), array([ -8.44296543e-01,  -1.09700377e+36,  -2.14781454e-01,\n",
      "         3.38865087e+38]), array([  1.64270951e+00,   2.61186735e+38,  -8.96679450e-02,\n",
      "         2.89130979e+38]), array([ -2.38438314e+00,  -2.32832159e+38,   2.40319295e-01,\n",
      "         3.21918420e+38]), array([ -4.20445612e+00,  -2.72224055e+38,  -1.52557524e-01,\n",
      "         1.76612926e+37])) False\n",
      "[ 0.10997157 -0.76328927 -0.12310378  0.66274492] 1.0 (0, array([  4.48372721e+00,   7.83044265e+37,   4.39312433e-02,\n",
      "        -1.38869339e+38]), array([  4.12120005e+00,  -1.59316365e+38,   2.74907464e-01,\n",
      "         3.30147840e+38]), array([  2.72060780e+00,   1.29238693e+37,  -3.63524775e-01,\n",
      "        -1.87742011e+37]), array([ -5.92742909e-01,  -2.02266521e+38,  -6.40150718e-02,\n",
      "        -9.68049620e+37]), array([ -3.22863109e+00,  -3.98986882e+37,  -1.98716244e-01,\n",
      "         1.50149046e+37])) False\n",
      "[ 0.09470579 -0.56668914 -0.10984889  0.33397527] 1.0 (1, array([ -1.61806155e+00,  -2.00042778e+38,  -1.61542411e-01,\n",
      "         3.29919029e+38]), array([  1.61834070e+00,  -1.73354839e+38,  -2.50409214e-01,\n",
      "        -2.89311341e+38]), array([ -1.31314581e+00,   2.20334970e+38,  -1.88139291e-01,\n",
      "        -8.95004087e+37]), array([  2.50979226e+00,   1.33354514e+38,  -7.33594981e-02,\n",
      "        -2.28452421e+38]), array([  3.78021846e+00,   5.10843502e+37,  -2.03769718e-01,\n",
      "        -1.79131408e+38])) False\n",
      "[ 0.083372   -0.76009019 -0.10316938  0.59009765] 1.0 (0, array([ -1.63534889e+00,   1.98562522e+38,  -3.28262483e-01,\n",
      "        -7.32839275e+37]), array([ -2.67630597e+00,   1.25037733e+38,  -3.33053824e-01,\n",
      "        -7.00805829e+37]), array([ -2.14416259e+00,   4.31676694e+36,  -1.25749425e-01,\n",
      "         1.40475751e+38]), array([ -4.56406057e+00,   9.11867680e+37,  -2.25716069e-01,\n",
      "        -1.57408469e+38]), array([  2.88245379e+00,   3.10043764e+38,  -1.53686537e-01,\n",
      "         2.22412129e+38])) False\n",
      "[ 0.0681702  -0.56368653 -0.09136743  0.26678062] 1.0 (1, array([ -4.74897561e+00,  -2.99220242e+38,   3.33588766e-01,\n",
      "        -2.59341241e+38]), array([  9.17603008e-01,  -9.88036122e+37,  -3.90586619e-01,\n",
      "        -2.83879750e+38]), array([  2.55199180e+00,   2.33026587e+38,  -1.14585226e-01,\n",
      "        -1.72337762e+38]), array([ -6.15302046e-02,  -2.36643841e+38,   9.79678527e-02,\n",
      "         1.63000533e+38]), array([  1.95806949e+00,   2.94058147e+38,   8.52113486e-02,\n",
      "         6.47880056e+37])) False\n",
      "[ 0.05689647 -0.75739376 -0.08603181  0.52930485] 1.0 (0, array([ -3.49873504e+00,   1.49905162e+38,   3.56378103e-01,\n",
      "         1.12065584e+38]), array([ -7.38677374e-01,  -2.04856139e+38,  -1.11023614e-01,\n",
      "         1.40789650e+38]), array([  1.43552855e+00,   2.91265469e+38,   3.07340680e-01,\n",
      "         2.15161040e+38]), array([  3.94992840e+00,  -1.52217037e+38,  -1.09307703e-01,\n",
      "        -8.17399685e+37]), array([  5.80325652e-01,   1.14483388e+38,  -1.78679814e-01,\n",
      "        -3.27036879e+38])) False\n",
      "[ 0.04174859 -0.95120675 -0.07544572  0.79368695] 1.0 (0, array([ -1.90743432e+00,   1.74134409e+38,  -1.31594368e-01,\n",
      "         7.05401367e+37]), array([  1.16536887e+00,  -1.37056431e+38,  -3.27484703e-02,\n",
      "         1.25767781e+38]), array([  2.62712682e+00,   1.00191354e+38,  -9.57230162e-02,\n",
      "        -3.18793790e+38]), array([  3.84967595e+00,  -3.33901932e+38,  -3.33101016e-01,\n",
      "         1.92786409e+38]), array([ -4.21543463e+00,   2.62559367e+38,   3.33520666e-01,\n",
      "        -3.02183356e+38])) False\n",
      "[ 0.02272446 -0.75513473 -0.05957198  0.47825556] 1.0 (1, array([  4.63679170e+00,   3.28200811e+38,   4.12735735e-01,\n",
      "        -2.59556813e+38]), array([  4.20725891e+00,  -1.73836906e+38,  -3.50080154e-02,\n",
      "         1.75181814e+38]), array([ -2.84523905e+00,   4.51293375e+37,  -2.63209546e-01,\n",
      "        -2.69002650e+38]), array([ -3.68103732e+00,  -9.68858466e+37,  -4.14979393e-01,\n",
      "        -5.11417681e+37]), array([  1.57629221e+00,  -6.69075502e+37,  -3.47003904e-01,\n",
      "        -2.97618520e+38])) False\n",
      "[ 0.00762177 -0.55922454 -0.05000687  0.16740776] 1.0 (1, array([ -3.59205711e-01,   9.95864780e+37,   9.17652646e-02,\n",
      "        -2.03522489e+38]), array([ -1.55672768e+00,  -1.33899184e+38,   4.02467171e-01,\n",
      "        -1.74290031e+38]), array([ -2.58906638e+00,  -3.01169863e+38,   3.75686816e-01,\n",
      "        -1.63314034e+37]), array([  4.69470849e+00,   1.69937987e+38,  -3.90189235e-01,\n",
      "         2.01137756e+38]), array([  3.92384103e+00,   1.60436379e+38,  -1.96093616e-01,\n",
      "        -2.41304010e+38])) False\n",
      "[-0.00356273 -0.36342378 -0.04665871 -0.14062212] 1.0 (1, array([  2.47865968e+00,  -2.73075172e+37,   6.16671574e-02,\n",
      "         3.09688705e+38]), array([  4.60114867e+00,   2.46086043e+38,  -1.18042548e-01,\n",
      "         2.63855500e+38]), array([  1.33064811e+00,  -4.76417196e+37,  -3.88935301e-01,\n",
      "         1.83839664e+38]), array([  2.02135750e-02,   1.94769788e+38,   2.07783094e-01,\n",
      "         1.99791586e+38]), array([ -1.91374888e+00,   2.04712906e+38,   4.09214044e-02,\n",
      "        -1.81532462e+37])) False\n",
      "[-0.0108312  -0.5578475  -0.04947115  0.13698338] 1.0 (0, array([ -2.23732030e+00,   2.70223303e+38,   5.41419648e-02,\n",
      "        -2.54659713e+38]), array([ -2.83189043e+00,   2.97301070e+38,  -1.06306566e-01,\n",
      "        -1.01821314e+38]), array([ -2.88060499e-01,  -7.20303725e+37,  -1.35481064e-01,\n",
      "        -9.08690413e+37]), array([  3.51800323e+00,   1.32525073e+38,  -4.03993167e-01,\n",
      "         3.11797799e+38]), array([  3.10629065e+00,   2.86558294e+38,  -2.17234026e-01,\n",
      "         1.28261216e+38])) False\n",
      "[-0.02198815 -0.75222724 -0.04673149  0.41365769] 1.0 (0, array([ -6.20606723e-01,   2.01077281e+38,   1.48709053e-01,\n",
      "         2.97995034e+38]), array([  1.16294712e+00,  -2.73716204e+38,   3.22000985e-01,\n",
      "         1.83177747e+38]), array([  2.03395633e+00,  -3.03713191e+38,  -8.69402301e-02,\n",
      "        -2.26331440e+38]), array([  3.09027752e+00,   1.36472701e+38,   3.20926337e-01,\n",
      "         3.17534545e+38]), array([  2.63757710e+00,   3.36357587e+38,   9.61493950e-02,\n",
      "        -3.15013249e+38])) False\n",
      "[-0.0370327  -0.55647512 -0.03845833  0.10661601] 1.0 (1, array([  4.64669089e+00,   2.51705539e+38,  -2.46720475e-01,\n",
      "        -5.11426406e+37]), array([  1.46413773e+00,   3.58289203e+37,  -2.08434103e-01,\n",
      "        -1.19743778e+38]), array([  2.76638028e+00,  -2.29724115e+38,  -3.50533795e-01,\n",
      "         8.97305240e+36]), array([ -2.67523438e+00,  -1.82175939e+38,   2.17118735e-02,\n",
      "        -9.98014983e+35]), array([  4.10840029e+00,   2.34745683e+36,  -2.54365002e-01,\n",
      "        -3.21853858e+38])) False\n",
      "[-0.0481622  -0.36082376 -0.03632601 -0.197948  ] 1.0 (1, array([  4.31308704e+00,   1.32089015e+38,   2.35571566e-01,\n",
      "        -2.25317196e+38]), array([ -1.20899880e+00,  -5.86781382e+37,   1.56141536e-01,\n",
      "        -1.38908714e+38]), array([ -1.88839755e+00,  -9.80767533e+37,   2.59958064e-01,\n",
      "         5.28050758e+37]), array([ -4.07733811e+00,  -2.87030814e+38,  -1.07830397e-01,\n",
      "         1.81432457e+38]), array([  1.81136089e+00,   1.41545447e+38,   2.23857381e-01,\n",
      "        -1.44856349e+38])) False\n",
      "[-0.05537867 -0.16520156 -0.04028497 -0.5018652 ] 1.0 (1, array([  2.30347005e-01,   2.62778289e+38,   3.04382728e-01,\n",
      "         1.87445791e+38]), array([  2.85401150e+00,   1.91572507e+38,   5.83967972e-02,\n",
      "         1.54386801e+38]), array([ -4.11363606e-01,   2.05677388e+38,   2.04020238e-01,\n",
      "         2.49285117e+38]), array([  4.10390204e+00,  -3.31000977e+38,  -1.64021082e-02,\n",
      "         2.83898901e+38]), array([ -3.16862414e+00,  -3.13589034e+38,  -5.85210682e-02,\n",
      "        -4.67865599e+37])) False\n",
      "[-0.0586827   0.03046439 -0.05032228 -0.80696659] 1.0 (1, array([  2.29756215e-02,   2.72552301e+37,   1.21930903e-01,\n",
      "        -1.05585130e+38]), array([ -3.82936809e+00,  -1.23604883e+38,  -2.78016609e-01,\n",
      "         3.82022601e+37]), array([ -1.74692514e+00,   3.11744348e+38,   3.90172636e-01,\n",
      "         8.17534331e+37]), array([  1.12797377e+00,   3.30331514e+38,   3.24449574e-01,\n",
      "         1.80397249e+38]), array([ -1.78953013e+00,  -9.15093901e+37,  -2.50266169e-01,\n",
      "        -8.74653106e+36])) False\n",
      "[-0.05807342  0.22623862 -0.06646161 -1.11504469] 1.0 (1, array([  4.07320403e+00,   4.25367292e+36,  -2.98091865e-01,\n",
      "        -7.06191481e+37]), array([ -3.36984125e+00,  -2.56746559e+38,   3.88646839e-01,\n",
      "        -1.33784547e+38]), array([ -2.23987025e+00,   1.84495573e+38,   2.37253015e-02,\n",
      "         2.53844215e+38]), array([  4.79859675e+00,  -2.85643322e+38,  -2.99013922e-01,\n",
      "         3.01560293e+38]), array([ -2.77150504e+00,  -3.09704724e+38,   3.01896216e-01,\n",
      "        -2.90210520e+38])) False\n",
      "[-0.05354864  0.42216713 -0.0887625  -1.42781394] 1.0 (1, array([ -2.35138766e+00,   1.70506401e+38,   4.17222595e-01,\n",
      "         2.31241752e+37]), array([  4.26434609e+00,  -7.03635073e+37,  -3.29504943e-01,\n",
      "        -6.20853108e+37]), array([ -1.95717338e+00,  -4.48698869e+36,   1.31564603e-01,\n",
      "        -2.65078457e+37]), array([  4.17754092e+00,   2.61857353e+38,   1.69208354e-01,\n",
      "        -7.02008445e+36]), array([ -3.53580209e+00,  -7.00888623e+37,   1.71239033e-01,\n",
      "        -1.46399320e+38])) False\n",
      "[-0.0451053   0.22824668 -0.11731878 -1.16414033] 1.0 (0, array([  6.68709689e-02,  -1.89345994e+38,   1.92686448e-01,\n",
      "        -2.89293458e+38]), array([  5.11826337e-01,   5.21698606e+37,  -1.54423168e-01,\n",
      "        -3.10019102e+38]), array([  1.18176575e-01,  -2.96845056e+38,   2.91592555e-01,\n",
      "         3.05825286e+38]), array([ -2.25640197e+00,  -2.71290754e+38,  -1.78672135e-01,\n",
      "        -2.06451826e+38]), array([ -4.71452161e+00,   2.66305917e+38,   2.42124916e-01,\n",
      "        -1.34154148e+38])) False\n",
      "[-0.04054037  0.42468407 -0.14060159 -1.49118362] 1.0 (1, array([ -1.72959466e+00,  -2.06584738e+38,   1.43698707e-01,\n",
      "         2.33415516e+38]), array([ -4.64397323e+00,   9.71869353e+37,  -4.78585830e-02,\n",
      "         2.70924471e+38]), array([ -1.71385986e+00,  -1.75689053e+37,   1.23712601e-02,\n",
      "        -2.44704167e+38]), array([  2.04376611e+00,   2.24910532e+38,  -3.70365058e-01,\n",
      "        -1.41973403e+38]), array([ -4.43477106e+00,   3.10707799e+38,   1.40047024e-01,\n",
      "         3.15918416e+38])) False\n",
      "[-0.03204669  0.62120956 -0.17042526 -1.82426365] 1.0 (1, array([ -1.66773333e-01,   3.25026139e+38,  -2.11309946e-01,\n",
      "         1.19138205e+38]), array([  4.67875633e+00,   2.89916048e+38,  -2.07288942e-01,\n",
      "         1.49362936e+38]), array([ -1.08923085e+00,   1.76599798e+38,  -3.13566726e-01,\n",
      "         3.21972296e+38]), array([ -3.36481410e+00,   1.35797100e+38,  -1.29421715e-01,\n",
      "        -2.13059489e+38]), array([ -1.04779805e+00,   3.20790835e+38,  -3.22731740e-01,\n",
      "        -3.17759940e+38])) False\n",
      "[-0.0196225   0.81776426 -0.20691053 -2.16468721] 1.0 (1, array([  4.89542114e-01,   3.26988508e+38,   7.42774330e-02,\n",
      "        -3.09309362e+38]), array([ -2.89936512e+00,  -6.48077060e+37,   8.48457657e-02,\n",
      "         1.85066547e+38]), array([ -8.34373191e-01,   1.42958266e+38,   2.42840507e-01,\n",
      "        -1.24366258e+38]), array([  4.60099430e+00,   1.01850927e+38,   3.19184189e-01,\n",
      "         3.80692160e+37]), array([  2.31938983e+00,   1.84122736e+38,   3.42013362e-01,\n",
      "        -2.37959610e+38])) False\n",
      "[-0.00326721  0.62518128 -0.25020428 -1.94237294] 1.0 (0, array([  2.61174548e+00,   1.72241574e+38,  -7.98858252e-02,\n",
      "        -2.81103608e+38]), array([  4.13641955e+00,   1.32297617e+38,   2.33099244e-01,\n",
      "         1.98462558e+38]), array([  3.10407119e+00,  -8.00740158e+37,   3.64241446e-01,\n",
      "        -2.06972378e+37]), array([ -2.72678822e+00,   9.95317969e+36,   1.20634594e-01,\n",
      "        -1.22896598e+38]), array([ -3.77465912e+00,  -2.93561581e+37,  -1.02212589e-02,\n",
      "         1.84709153e+38])) True\n"
     ]
    }
   ],
   "source": [
    "# Create new cart pole environment\n",
    "env = gym.make('PredictObsCartpole-v0')\n",
    "state = env.reset()\n",
    "print(state)\n",
    "done = 0\n",
    "while not done:\n",
    "    #env.render()\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    print(next_state,reward,action,done)\n",
    "    \n",
    "\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create class QNetwork\n",
    "class QNetwork:\n",
    "    def __init__(self, \\\n",
    "                 learning_rate=0.01, \\\n",
    "                 state_size=6, \n",
    "                 action_size=3, \\\n",
    "                 hidden_size=10, \\\n",
    "                 hidden_layers=2, \\\n",
    "                 alpha=0., \\\n",
    "                 name='QNetwork'):\n",
    "        \n",
    "        # create Q Network\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, \\\n",
    "                                          [None, state_size], \\\n",
    "                                          name='inputs')\n",
    "            \n",
    "            # placeholder for actions, to be one-hot encoded next\n",
    "            self.actions_ = tf.placeholder(tf.int32, \\\n",
    "                                           [None], \\\n",
    "                                           name='actions')\n",
    "            \n",
    "            # one hot encode actions\n",
    "            one_hot_actions = tf.one_hot(self.actions_, \\\n",
    "                                         action_size)\n",
    "            \n",
    "            # placeholder for target Qs\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, \\\n",
    "                                            [None], \\\n",
    "                                            name='target')\n",
    "            \n",
    "                \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.layers.dense(self.inputs_, \\\n",
    "                                        hidden_size,\\\n",
    "                                        activation=None,\\\n",
    "                                        kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.fc1 = tf.maximum(alpha*self.fc1,self.fc1)\n",
    "            \n",
    "            if hidden_layers == 1:\n",
    "                out_layer = self.fc1\n",
    "            else:\n",
    "                \n",
    "                self.fc2 = tf.layers.dense(self.fc1, hidden_size,\\\n",
    "                                            activation=None,\\\n",
    "                                            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                self.fc2 = tf.maximum(alpha*self.fc2,self.fc2)\n",
    "                \n",
    "                if hidden_layers == 2:\n",
    "                    out_layer = self.fc2\n",
    "                else:\n",
    "                    self.fc3 = tf.layers.dense(self.fc2, hidden_size,\\\n",
    "                                            activation=None,\\\n",
    "                                            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                    self.fc3 = tf.maximum(alpha*self.fc3,self.fc3)\n",
    "                    out_layer = self.fc3\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.layers.dense(out_layer, action_size, \\\n",
    "                                          activation=None,\\\n",
    "                                          kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            ### Train with loss (targetQ - Q)^2\n",
    "            # output has length 2, for two actions. This next line chooses\n",
    "            # one value from output (per row) according to the one-hot encoded actions.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create memory class for storing previous experiences\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_memory_rand_states(memory_size=1000,pretrain_length=20):\n",
    "    # Initialize the simulation\n",
    "    state = env.reset()\n",
    "    \n",
    "    memory = Memory(max_size=memory_size)\n",
    "\n",
    "    # Make a bunch of random actions and store the experiences\n",
    "    for ii in range(pretrain_length):\n",
    "\n",
    "        # Make a random action\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            # The simulation fails so no next state\n",
    "            next_state = np.zeros(state.shape)\n",
    "            # Add experience to memory\n",
    "            memory.add((state, action, reward, next_state))\n",
    "\n",
    "            # Start new episode\n",
    "            state = env.reset()\n",
    "\n",
    "        else:\n",
    "            # Add experience to memory\n",
    "            memory.add((state, action, reward, next_state))\n",
    "            state = next_state\n",
    "            \n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_q_network(train_episodes=500,\\\n",
    "                   gamma=0.99,\\\n",
    "                   explore_start=1.0,\\\n",
    "                   explore_stop=0.01,\\\n",
    "                   decay_rate=0.0001,\\\n",
    "                   hidden_size=64,\\\n",
    "                   hidden_layers=2,\\\n",
    "                   learning_rate=0.0001,\\\n",
    "                   memory_size=10000,\\\n",
    "                   batch_size=20,\\\n",
    "                   max_steps=500,\\\n",
    "                   alpha=0.,\\\n",
    "                   verbose=True):\n",
    "    \n",
    "    \n",
    "    mainQN = QNetwork(name='main', hidden_size=hidden_size, hidden_layers=hidden_layers, learning_rate=learning_rate, alpha=alpha)\n",
    "    \n",
    "    memory = initialize_memory_rand_states(memory_size=memory_size,pretrain_length=batch_size)\n",
    "\n",
    "    state = env.reset()\n",
    "    \n",
    "    # Now train with experiences\n",
    "    saver = tf.train.Saver()\n",
    "    rewards_list = []\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        steps_list = []\n",
    "        \n",
    "        for ep in range(train_episodes):\n",
    "            total_reward = 0\n",
    "            t = 0\n",
    "            \n",
    "            while t < max_steps:\n",
    "                step += 1\n",
    "                # Uncomment this next line to watch the training\n",
    "                # env.render() \n",
    "\n",
    "                # Explore or Exploit\n",
    "                explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "                if explore_p > np.random.rand():\n",
    "                    # Make a random action\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    # Get action from Q-network\n",
    "                    feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                    Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                    action = np.argmax(Qs)\n",
    "\n",
    "                # Take action, get new state and reward\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "                total_reward += reward\n",
    "\n",
    "                if done:\n",
    "                    t = t+1\n",
    "                    # the episode ends so no next state\n",
    "                    next_state = np.zeros(state.shape)\n",
    "                    steps_list.append(total_reward)\n",
    "                    t = max_steps\n",
    "\n",
    "                    # Add experience to memory\n",
    "                    memory.add((state, action, reward, next_state))\n",
    "                    state = env.reset()\n",
    "                else:\n",
    "                    # Add experience to memory\n",
    "                    memory.add((state, action, reward, next_state))\n",
    "                    state = next_state\n",
    "                    t += 1\n",
    "\n",
    "                # Sample mini-batch from memory\n",
    "                batch = memory.sample(batch_size)\n",
    "                states = np.array([each[0] for each in batch])\n",
    "                actions = np.array([each[1] for each in batch])\n",
    "                rewards = np.array([each[2] for each in batch])\n",
    "                next_states = np.array([each[3] for each in batch])\n",
    "\n",
    "                # Train network\n",
    "                target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "\n",
    "                # Set target_Qs to 0 for states where episode ends\n",
    "                episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "                target_Qs[episode_ends] = (0, 0, 0)\n",
    "\n",
    "                targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "                loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                    feed_dict={mainQN.inputs_: states,\n",
    "                                               mainQN.targetQs_: targets,\n",
    "                                               mainQN.actions_: actions})\n",
    "            \n",
    "            rewards_list.append((ep, total_reward))   \n",
    "            runningMean = np.mean(steps_list[-100:])\n",
    "            if verbose:\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p),\n",
    "                      'RunMean : {:.4f}'.format(runningMean))\n",
    "               \n",
    "            \n",
    "            \n",
    "            if runningMean > -80.:\n",
    "                saver.save(sess, \"checkpoints/cartpole.ckpt\")\n",
    "                return rewards_list, mainQN, saver\n",
    "            \n",
    "        saver.save(sess, \"checkpoints/cartpole.ckpt\")\n",
    "        return rewards_list, mainQN, saver, runningMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rewards(rewards_list):\n",
    "    eps, rews = np.array(rewards_list).T\n",
    "    smoothed_rews = running_mean(rews, 10)\n",
    "    plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "    plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_q_network(mainQN, saver, test_episodes=100, test_max_steps=500, render=True):\n",
    "\n",
    "\n",
    "    tot_rewards = 0.\n",
    "    rewards_list = []\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "   \n",
    "        state = env.reset()\n",
    "        for ep in range(test_episodes):\n",
    "            t = 0\n",
    "            while t < test_max_steps:\n",
    "                if render:\n",
    "                    env.render() \n",
    "\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "\n",
    "                # Take action, get new state and reward\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                \n",
    "                tot_rewards = tot_rewards + reward\n",
    "                \n",
    "                if done:\n",
    "                    t = test_max_steps\n",
    "                    state = env.reset()\n",
    "                    # Take one random step to get the pole and cart moving\n",
    "                    #state, reward, done, _ = env.step(env.action_space.sample())\n",
    "                    rewards_list.append(tot_rewards)\n",
    "                    tot_rewards = 0.\n",
    "                else:\n",
    "                    state = next_state\n",
    "                    t += 1\n",
    "    mean_rewards = np.mean(rewards_list)         \n",
    "    return mean_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_and_train_qnetwork(train_episodes=1000,\\\n",
    "                   gamma=0.99,\\\n",
    "                   explore_start=1.0,\\\n",
    "                   explore_stop=0.01,\\\n",
    "                   decay_rate=0.0001,\\\n",
    "                   hidden_size=64,\\\n",
    "                   hidden_layers=2,\\\n",
    "                   learning_rate=0.0001,\\\n",
    "                   memory_size=10000,\\\n",
    "                   batch_size=20,\\\n",
    "                   test_episodes=10,\\\n",
    "                   render=False,\\\n",
    "                   alpha=0.,\\\n",
    "                   verbose=True):\n",
    "    \n",
    "    # reset graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # train q-network\n",
    "    rewards_list, mainQN, saver, runMean = train_q_network(train_episodes = train_episodes, \\\n",
    "                                                  gamma=gamma,\\\n",
    "                                                  explore_start=explore_start,\\\n",
    "                                                  explore_stop=explore_stop,\\\n",
    "                                                  decay_rate=decay_rate,\\\n",
    "                                                  hidden_size=hidden_size,\\\n",
    "                                                  hidden_layers=hidden_layers,\\\n",
    "                                                  learning_rate=learning_rate,\\\n",
    "                                                  memory_size=memory_size,\\\n",
    "                                                  batch_size=batch_size,\\\n",
    "                                                  alpha=alpha,\\\n",
    "                                                  verbose=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        # plot training\n",
    "        plot_rewards(rewards_list)\n",
    "    \n",
    "\n",
    "    avg_train_rewards = np.sum([each[1] for each in rewards_list]) / len(rewards_list)\n",
    "#     max_train_rewards = np.max([each[1] for each in rewards_list])\n",
    "    if verbose:\n",
    "        print('average training reward = ',avg_train_rewards)\n",
    "\n",
    "    # test q-network\n",
    "    avg_test_rewards = test_q_network(mainQN, saver, test_episodes=test_episodes, render=verbose)\n",
    "    \n",
    "    if verbose:\n",
    "        print('average test reward = ', avg_test_rewards)\n",
    "    \n",
    "    return avg_test_rewards, runMean, mainQN, saver, len(rewards_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Total reward: -500.0 Training loss: 1.3482 Explore P: 0.9517 RunMean : -500.0000\n",
      "Episode: 1 Total reward: -500.0 Training loss: 5.6733 Explore P: 0.9058 RunMean : -500.0000\n",
      "Episode: 2 Total reward: -500.0 Training loss: 11.1184 Explore P: 0.8621 RunMean : -500.0000\n",
      "Episode: 3 Total reward: -500.0 Training loss: 5.6828 Explore P: 0.8205 RunMean : -500.0000\n",
      "Episode: 4 Total reward: -500.0 Training loss: 4.6951 Explore P: 0.7810 RunMean : -500.0000\n",
      "Episode: 5 Total reward: -299.0 Training loss: 3.4650 Explore P: 0.7582 RunMean : -466.5000\n",
      "Episode: 6 Total reward: -304.0 Training loss: 2.8535 Explore P: 0.7357 RunMean : -443.2857\n",
      "Episode: 7 Total reward: -346.0 Training loss: 2.8387 Explore P: 0.7110 RunMean : -431.1250\n",
      "Episode: 8 Total reward: -258.0 Training loss: 4.2000 Explore P: 0.6931 RunMean : -411.8889\n",
      "Episode: 9 Total reward: -268.0 Training loss: 3.0957 Explore P: 0.6749 RunMean : -397.5000\n",
      "Episode: 10 Total reward: -317.0 Training loss: 2.5088 Explore P: 0.6541 RunMean : -390.1818\n",
      "Episode: 11 Total reward: -266.0 Training loss: 3.2488 Explore P: 0.6372 RunMean : -379.8333\n",
      "Episode: 12 Total reward: -211.0 Training loss: 3.6971 Explore P: 0.6240 RunMean : -366.8462\n",
      "Episode: 13 Total reward: -167.0 Training loss: 3.2749 Explore P: 0.6138 RunMean : -352.5714\n",
      "Episode: 14 Total reward: -184.0 Training loss: 2.1750 Explore P: 0.6027 RunMean : -341.3333\n",
      "Episode: 15 Total reward: -234.0 Training loss: 4.4720 Explore P: 0.5889 RunMean : -334.6250\n",
      "Episode: 16 Total reward: -172.0 Training loss: 2.4467 Explore P: 0.5790 RunMean : -325.0588\n",
      "Episode: 17 Total reward: -171.0 Training loss: 2.1814 Explore P: 0.5693 RunMean : -316.5000\n",
      "Episode: 18 Total reward: -151.0 Training loss: 2.3040 Explore P: 0.5609 RunMean : -307.7895\n",
      "Episode: 19 Total reward: -175.0 Training loss: 2.8417 Explore P: 0.5513 RunMean : -301.1500\n",
      "Episode: 20 Total reward: -177.0 Training loss: 2.1386 Explore P: 0.5417 RunMean : -295.2381\n",
      "Episode: 21 Total reward: -185.0 Training loss: 2.1697 Explore P: 0.5319 RunMean : -290.2273\n",
      "Episode: 22 Total reward: -125.0 Training loss: 1.7907 Explore P: 0.5254 RunMean : -283.0435\n",
      "Episode: 23 Total reward: -209.0 Training loss: 1.7988 Explore P: 0.5147 RunMean : -279.9583\n",
      "Episode: 24 Total reward: -203.0 Training loss: 3.5379 Explore P: 0.5045 RunMean : -276.8800\n",
      "Episode: 25 Total reward: -209.0 Training loss: 5.5101 Explore P: 0.4942 RunMean : -274.2692\n",
      "Episode: 26 Total reward: -217.0 Training loss: 1.9501 Explore P: 0.4838 RunMean : -272.1481\n",
      "Episode: 27 Total reward: -155.0 Training loss: 23.5210 Explore P: 0.4764 RunMean : -267.9643\n",
      "Episode: 28 Total reward: -167.0 Training loss: 1.8018 Explore P: 0.4687 RunMean : -264.4828\n",
      "Episode: 29 Total reward: -164.0 Training loss: 2.3127 Explore P: 0.4612 RunMean : -261.1333\n",
      "Episode: 30 Total reward: -158.0 Training loss: 1.5072 Explore P: 0.4540 RunMean : -257.8065\n",
      "Episode: 31 Total reward: -120.0 Training loss: 1.9144 Explore P: 0.4487 RunMean : -253.5000\n",
      "Episode: 32 Total reward: -156.0 Training loss: 30.8792 Explore P: 0.4419 RunMean : -250.5455\n",
      "Episode: 33 Total reward: -150.0 Training loss: 1.8183 Explore P: 0.4354 RunMean : -247.5882\n",
      "Episode: 34 Total reward: -169.0 Training loss: 2.3509 Explore P: 0.4282 RunMean : -245.3429\n",
      "Episode: 35 Total reward: -124.0 Training loss: 2.5618 Explore P: 0.4230 RunMean : -241.9722\n",
      "Episode: 36 Total reward: -166.0 Training loss: 2.0835 Explore P: 0.4162 RunMean : -239.9189\n",
      "Episode: 37 Total reward: -174.0 Training loss: 1.3422 Explore P: 0.4091 RunMean : -238.1842\n",
      "Episode: 38 Total reward: -170.0 Training loss: 1.9772 Explore P: 0.4024 RunMean : -236.4359\n",
      "Episode: 39 Total reward: -140.0 Training loss: 1.6626 Explore P: 0.3969 RunMean : -234.0250\n",
      "Episode: 40 Total reward: -182.0 Training loss: 1.5639 Explore P: 0.3899 RunMean : -232.7561\n",
      "Episode: 41 Total reward: -108.0 Training loss: 1.2591 Explore P: 0.3857 RunMean : -229.7857\n",
      "Episode: 42 Total reward: -162.0 Training loss: 2.1349 Explore P: 0.3797 RunMean : -228.2093\n",
      "Episode: 43 Total reward: -161.0 Training loss: 1.9014 Explore P: 0.3737 RunMean : -226.6818\n",
      "Episode: 44 Total reward: -125.0 Training loss: 1.7488 Explore P: 0.3692 RunMean : -224.4222\n",
      "Episode: 45 Total reward: -109.0 Training loss: 2.6362 Explore P: 0.3652 RunMean : -221.9130\n",
      "Episode: 46 Total reward: -172.0 Training loss: 4.2708 Explore P: 0.3592 RunMean : -220.8511\n",
      "Episode: 47 Total reward: -215.0 Training loss: 12.4367 Explore P: 0.3517 RunMean : -220.7292\n",
      "Episode: 48 Total reward: -143.0 Training loss: 16.8154 Explore P: 0.3468 RunMean : -219.1429\n",
      "Episode: 49 Total reward: -220.0 Training loss: 1.9744 Explore P: 0.3394 RunMean : -219.1600\n",
      "Episode: 50 Total reward: -116.0 Training loss: 2.0328 Explore P: 0.3356 RunMean : -217.1373\n",
      "Episode: 51 Total reward: -107.0 Training loss: 7.3071 Explore P: 0.3321 RunMean : -215.0192\n",
      "Episode: 52 Total reward: -154.0 Training loss: 1.2979 Explore P: 0.3272 RunMean : -213.8679\n",
      "Episode: 53 Total reward: -126.0 Training loss: 2.1586 Explore P: 0.3232 RunMean : -212.2407\n",
      "Episode: 54 Total reward: -161.0 Training loss: 8.7254 Explore P: 0.3181 RunMean : -211.3091\n",
      "Episode: 55 Total reward: -217.0 Training loss: 11.2505 Explore P: 0.3115 RunMean : -211.4107\n",
      "Episode: 56 Total reward: -121.0 Training loss: 11.6119 Explore P: 0.3078 RunMean : -209.8246\n",
      "Episode: 57 Total reward: -172.0 Training loss: 1.5972 Explore P: 0.3027 RunMean : -209.1724\n",
      "Episode: 58 Total reward: -131.0 Training loss: 1.7744 Explore P: 0.2989 RunMean : -207.8475\n",
      "Episode: 59 Total reward: -83.0 Training loss: 13.4211 Explore P: 0.2965 RunMean : -205.7667\n",
      "Episode: 60 Total reward: -133.0 Training loss: 2.0355 Explore P: 0.2926 RunMean : -204.5738\n",
      "Episode: 61 Total reward: -100.0 Training loss: 1.0971 Explore P: 0.2898 RunMean : -202.8871\n",
      "Episode: 62 Total reward: -134.0 Training loss: 1.4550 Explore P: 0.2861 RunMean : -201.7937\n",
      "Episode: 63 Total reward: -111.0 Training loss: 1.4072 Explore P: 0.2830 RunMean : -200.3750\n",
      "Episode: 64 Total reward: -93.0 Training loss: 1.5905 Explore P: 0.2804 RunMean : -198.7231\n",
      "Episode: 65 Total reward: -92.0 Training loss: 1.0275 Explore P: 0.2779 RunMean : -197.1061\n",
      "Episode: 66 Total reward: -129.0 Training loss: 7.3372 Explore P: 0.2745 RunMean : -196.0896\n",
      "Episode: 67 Total reward: -134.0 Training loss: 1.5636 Explore P: 0.2709 RunMean : -195.1765\n",
      "Episode: 68 Total reward: -139.0 Training loss: 0.6360 Explore P: 0.2673 RunMean : -194.3623\n",
      "Episode: 69 Total reward: -96.0 Training loss: 2.0343 Explore P: 0.2648 RunMean : -192.9571\n",
      "Episode: 70 Total reward: -144.0 Training loss: 15.4078 Explore P: 0.2611 RunMean : -192.2676\n",
      "Episode: 71 Total reward: -120.0 Training loss: 21.1091 Explore P: 0.2581 RunMean : -191.2639\n",
      "Episode: 72 Total reward: -97.0 Training loss: 2.4912 Explore P: 0.2557 RunMean : -189.9726\n",
      "Episode: 73 Total reward: -169.0 Training loss: 6.5802 Explore P: 0.2516 RunMean : -189.6892\n",
      "Episode: 74 Total reward: -92.0 Training loss: 1.2782 Explore P: 0.2493 RunMean : -188.3867\n",
      "Episode: 75 Total reward: -104.0 Training loss: 1.3778 Explore P: 0.2468 RunMean : -187.2763\n",
      "Episode: 76 Total reward: -113.0 Training loss: 1.3177 Explore P: 0.2441 RunMean : -186.3117\n",
      "Episode: 77 Total reward: -87.0 Training loss: 1.5709 Explore P: 0.2421 RunMean : -185.0385\n",
      "Episode: 78 Total reward: -168.0 Training loss: 11.6304 Explore P: 0.2382 RunMean : -184.8228\n",
      "Episode: 79 Total reward: -155.0 Training loss: 6.4619 Explore P: 0.2347 RunMean : -184.4500\n",
      "Episode: 80 Total reward: -171.0 Training loss: 6.7511 Explore P: 0.2308 RunMean : -184.2840\n",
      "Episode: 81 Total reward: -123.0 Training loss: 1.6361 Explore P: 0.2281 RunMean : -183.5366\n",
      "Episode: 82 Total reward: -101.0 Training loss: 5.1021 Explore P: 0.2259 RunMean : -182.5422\n",
      "Episode: 83 Total reward: -104.0 Training loss: 1.2098 Explore P: 0.2236 RunMean : -181.6071\n",
      "Episode: 84 Total reward: -105.0 Training loss: 1.1235 Explore P: 0.2214 RunMean : -180.7059\n",
      "Episode: 85 Total reward: -257.0 Training loss: 4.8395 Explore P: 0.2160 RunMean : -181.5930\n",
      "Episode: 86 Total reward: -96.0 Training loss: 1.3665 Explore P: 0.2140 RunMean : -180.6092\n",
      "Episode: 87 Total reward: -141.0 Training loss: 3.5387 Explore P: 0.2111 RunMean : -180.1591\n",
      "Episode: 88 Total reward: -84.0 Training loss: 5.2446 Explore P: 0.2094 RunMean : -179.0787\n",
      "Episode: 89 Total reward: -112.0 Training loss: 8.3352 Explore P: 0.2072 RunMean : -178.3333\n",
      "Episode: 90 Total reward: -87.0 Training loss: 3.2062 Explore P: 0.2055 RunMean : -177.3297\n",
      "Episode: 91 Total reward: -87.0 Training loss: 2.0838 Explore P: 0.2038 RunMean : -176.3478\n",
      "Episode: 92 Total reward: -118.0 Training loss: 1.2931 Explore P: 0.2015 RunMean : -175.7204\n",
      "Episode: 93 Total reward: -109.0 Training loss: 0.6110 Explore P: 0.1994 RunMean : -175.0106\n",
      "Episode: 94 Total reward: -114.0 Training loss: 1.0780 Explore P: 0.1972 RunMean : -174.3684\n",
      "Episode: 95 Total reward: -69.0 Training loss: 4.8409 Explore P: 0.1959 RunMean : -173.2708\n",
      "Episode: 96 Total reward: -98.0 Training loss: 0.9893 Explore P: 0.1941 RunMean : -172.4948\n",
      "Episode: 97 Total reward: -103.0 Training loss: 16.2420 Explore P: 0.1922 RunMean : -171.7857\n",
      "Episode: 98 Total reward: -110.0 Training loss: 1.1628 Explore P: 0.1902 RunMean : -171.1616\n",
      "Episode: 99 Total reward: -93.0 Training loss: 1.5998 Explore P: 0.1885 RunMean : -170.3800\n",
      "Episode: 100 Total reward: -110.0 Training loss: 1.8446 Explore P: 0.1865 RunMean : -166.4800\n",
      "Episode: 101 Total reward: -76.0 Training loss: 9.5409 Explore P: 0.1851 RunMean : -162.2400\n",
      "Episode: 102 Total reward: -77.0 Training loss: 1.2081 Explore P: 0.1838 RunMean : -158.0100\n",
      "Episode: 103 Total reward: -115.0 Training loss: 2.6282 Explore P: 0.1818 RunMean : -154.1600\n",
      "Episode: 104 Total reward: -100.0 Training loss: 0.9353 Explore P: 0.1801 RunMean : -150.1600\n",
      "Episode: 105 Total reward: -134.0 Training loss: 2.7097 Explore P: 0.1778 RunMean : -148.5100\n",
      "Episode: 106 Total reward: -107.0 Training loss: 1.4544 Explore P: 0.1760 RunMean : -146.5400\n",
      "Episode: 107 Total reward: -137.0 Training loss: 1.4328 Explore P: 0.1737 RunMean : -144.4500\n",
      "Episode: 108 Total reward: -94.0 Training loss: 1.8184 Explore P: 0.1721 RunMean : -142.8100\n",
      "Episode: 109 Total reward: -98.0 Training loss: 2.2373 Explore P: 0.1705 RunMean : -141.1100\n",
      "Episode: 110 Total reward: -89.0 Training loss: 0.9704 Explore P: 0.1691 RunMean : -138.8300\n",
      "Episode: 111 Total reward: -103.0 Training loss: 5.4859 Explore P: 0.1675 RunMean : -137.2000\n",
      "Episode: 112 Total reward: -100.0 Training loss: 2.7973 Explore P: 0.1659 RunMean : -136.0900\n",
      "Episode: 113 Total reward: -76.0 Training loss: 1.7711 Explore P: 0.1647 RunMean : -135.1800\n",
      "Episode: 114 Total reward: -103.0 Training loss: 0.8587 Explore P: 0.1631 RunMean : -134.3700\n",
      "Episode: 115 Total reward: -95.0 Training loss: 1.0170 Explore P: 0.1616 RunMean : -132.9800\n",
      "Episode: 116 Total reward: -111.0 Training loss: 1.9726 Explore P: 0.1599 RunMean : -132.3700\n",
      "Episode: 117 Total reward: -220.0 Training loss: 10.9933 Explore P: 0.1567 RunMean : -132.8600\n",
      "Episode: 118 Total reward: -97.0 Training loss: 0.8044 Explore P: 0.1552 RunMean : -132.3200\n",
      "Episode: 119 Total reward: -95.0 Training loss: 4.2078 Explore P: 0.1538 RunMean : -131.5200\n",
      "Episode: 120 Total reward: -100.0 Training loss: 0.7890 Explore P: 0.1524 RunMean : -130.7500\n",
      "Episode: 121 Total reward: -100.0 Training loss: 0.7887 Explore P: 0.1510 RunMean : -129.9000\n",
      "Episode: 122 Total reward: -107.0 Training loss: 2.2393 Explore P: 0.1494 RunMean : -129.7200\n",
      "Episode: 123 Total reward: -107.0 Training loss: 1.1907 Explore P: 0.1480 RunMean : -128.7000\n",
      "Episode: 124 Total reward: -96.0 Training loss: 0.9306 Explore P: 0.1466 RunMean : -127.6300\n",
      "Episode: 125 Total reward: -111.0 Training loss: 2.2586 Explore P: 0.1451 RunMean : -126.6500\n",
      "Episode: 126 Total reward: -95.0 Training loss: 1.4400 Explore P: 0.1438 RunMean : -125.4300\n",
      "Episode: 127 Total reward: -83.0 Training loss: 1.0071 Explore P: 0.1427 RunMean : -124.7100\n",
      "Episode: 128 Total reward: -80.0 Training loss: 5.8371 Explore P: 0.1416 RunMean : -123.8400\n",
      "Episode: 129 Total reward: -72.0 Training loss: 1.2432 Explore P: 0.1407 RunMean : -122.9200\n",
      "Episode: 130 Total reward: -92.0 Training loss: 2.2984 Explore P: 0.1395 RunMean : -122.2600\n",
      "Episode: 131 Total reward: -88.0 Training loss: 0.8381 Explore P: 0.1383 RunMean : -121.9400\n",
      "Episode: 132 Total reward: -99.0 Training loss: 8.4495 Explore P: 0.1370 RunMean : -121.3700\n",
      "Episode: 133 Total reward: -80.0 Training loss: 2.4629 Explore P: 0.1360 RunMean : -120.6700\n",
      "Episode: 134 Total reward: -104.0 Training loss: 0.8766 Explore P: 0.1347 RunMean : -120.0200\n",
      "Episode: 135 Total reward: -143.0 Training loss: 1.0928 Explore P: 0.1329 RunMean : -120.2100\n",
      "Episode: 136 Total reward: -90.0 Training loss: 1.9801 Explore P: 0.1318 RunMean : -119.4500\n",
      "Episode: 137 Total reward: -75.0 Training loss: 8.3139 Explore P: 0.1309 RunMean : -118.4600\n",
      "Episode: 138 Total reward: -110.0 Training loss: 11.7099 Explore P: 0.1295 RunMean : -117.8600\n",
      "Episode: 139 Total reward: -123.0 Training loss: 2.3171 Explore P: 0.1281 RunMean : -117.6900\n",
      "Episode: 140 Total reward: -104.0 Training loss: 1.3417 Explore P: 0.1268 RunMean : -116.9100\n",
      "Episode: 141 Total reward: -94.0 Training loss: 1.1941 Explore P: 0.1257 RunMean : -116.7700\n",
      "Episode: 142 Total reward: -64.0 Training loss: 1.0323 Explore P: 0.1250 RunMean : -115.7900\n",
      "Episode: 143 Total reward: -171.0 Training loss: 0.8164 Explore P: 0.1230 RunMean : -115.8900\n",
      "Episode: 144 Total reward: -106.0 Training loss: 6.1994 Explore P: 0.1218 RunMean : -115.7000\n",
      "Episode: 145 Total reward: -73.0 Training loss: 2.4718 Explore P: 0.1210 RunMean : -115.3400\n",
      "Episode: 146 Total reward: -126.0 Training loss: 2.0790 Explore P: 0.1196 RunMean : -114.8800\n",
      "Episode: 147 Total reward: -101.0 Training loss: 1.5842 Explore P: 0.1185 RunMean : -113.7400\n",
      "Episode: 148 Total reward: -84.0 Training loss: 10.3653 Explore P: 0.1176 RunMean : -113.1500\n",
      "Episode: 149 Total reward: -85.0 Training loss: 2.7728 Explore P: 0.1166 RunMean : -111.8000\n",
      "Episode: 150 Total reward: -91.0 Training loss: 4.8344 Explore P: 0.1157 RunMean : -111.5500\n",
      "Episode: 151 Total reward: -102.0 Training loss: 1.4270 Explore P: 0.1146 RunMean : -111.5000\n",
      "Episode: 152 Total reward: -118.0 Training loss: 1.4177 Explore P: 0.1133 RunMean : -111.1400\n",
      "Episode: 153 Total reward: -88.0 Training loss: 1.2569 Explore P: 0.1124 RunMean : -110.7600\n",
      "Episode: 154 Total reward: -87.0 Training loss: 1.3903 Explore P: 0.1115 RunMean : -110.0200\n",
      "Episode: 155 Total reward: -78.0 Training loss: 5.1277 Explore P: 0.1107 RunMean : -108.6300\n",
      "Episode: 156 Total reward: -101.0 Training loss: 1.6617 Explore P: 0.1097 RunMean : -108.4300\n",
      "Episode: 157 Total reward: -132.0 Training loss: 1.8576 Explore P: 0.1084 RunMean : -108.0300\n",
      "Episode: 158 Total reward: -88.0 Training loss: 3.0193 Explore P: 0.1075 RunMean : -107.6000\n",
      "Episode: 159 Total reward: -95.0 Training loss: 1.0053 Explore P: 0.1066 RunMean : -107.7200\n",
      "Episode: 160 Total reward: -94.0 Training loss: 2.0127 Explore P: 0.1057 RunMean : -107.3300\n",
      "Episode: 161 Total reward: -94.0 Training loss: 7.3543 Explore P: 0.1048 RunMean : -107.2700\n",
      "Episode: 162 Total reward: -82.0 Training loss: 0.9346 Explore P: 0.1040 RunMean : -106.7500\n",
      "Episode: 163 Total reward: -71.0 Training loss: 6.6264 Explore P: 0.1033 RunMean : -106.3500\n",
      "Episode: 164 Total reward: -103.0 Training loss: 0.8261 Explore P: 0.1023 RunMean : -106.4500\n",
      "Episode: 165 Total reward: -115.0 Training loss: 1.1927 Explore P: 0.1013 RunMean : -106.6800\n",
      "Episode: 166 Total reward: -106.0 Training loss: 1.0278 Explore P: 0.1003 RunMean : -106.4500\n",
      "Episode: 167 Total reward: -94.0 Training loss: 1.3197 Explore P: 0.0995 RunMean : -106.0500\n",
      "Episode: 168 Total reward: -103.0 Training loss: 1.2352 Explore P: 0.0985 RunMean : -105.6900\n",
      "Episode: 169 Total reward: -79.0 Training loss: 0.6143 Explore P: 0.0978 RunMean : -105.5200\n",
      "Episode: 170 Total reward: -79.0 Training loss: 7.0996 Explore P: 0.0971 RunMean : -104.8700\n",
      "Episode: 171 Total reward: -89.0 Training loss: 3.8847 Explore P: 0.0963 RunMean : -104.5600\n",
      "Episode: 172 Total reward: -111.0 Training loss: 5.9456 Explore P: 0.0954 RunMean : -104.7000\n",
      "Episode: 173 Total reward: -84.0 Training loss: 1.5847 Explore P: 0.0947 RunMean : -103.8500\n",
      "Episode: 174 Total reward: -91.0 Training loss: 2.4244 Explore P: 0.0939 RunMean : -103.8400\n",
      "Episode: 175 Total reward: -90.0 Training loss: 1.0831 Explore P: 0.0931 RunMean : -103.7000\n",
      "Episode: 176 Total reward: -91.0 Training loss: 2.5633 Explore P: 0.0924 RunMean : -103.4800\n",
      "Episode: 177 Total reward: -85.0 Training loss: 0.9482 Explore P: 0.0917 RunMean : -103.4600\n",
      "Episode: 178 Total reward: -71.0 Training loss: 1.3670 Explore P: 0.0911 RunMean : -102.4900\n",
      "Episode: 179 Total reward: -109.0 Training loss: 1.5674 Explore P: 0.0902 RunMean : -102.0300\n",
      "Episode: 180 Total reward: -217.0 Training loss: 7.1422 Explore P: 0.0885 RunMean : -102.4900\n",
      "Episode: 181 Total reward: -123.0 Training loss: 1.1596 Explore P: 0.0875 RunMean : -102.4900\n",
      "Episode: 182 Total reward: -144.0 Training loss: 1.6755 Explore P: 0.0864 RunMean : -102.9200\n",
      "Episode: 183 Total reward: -98.0 Training loss: 1.5965 Explore P: 0.0856 RunMean : -102.8600\n",
      "Episode: 184 Total reward: -86.0 Training loss: 0.8590 Explore P: 0.0850 RunMean : -102.6700\n",
      "Episode: 185 Total reward: -77.0 Training loss: 0.8960 Explore P: 0.0844 RunMean : -100.8700\n",
      "Episode: 186 Total reward: -155.0 Training loss: 2.4039 Explore P: 0.0832 RunMean : -101.4600\n",
      "Episode: 187 Total reward: -78.0 Training loss: 6.5779 Explore P: 0.0827 RunMean : -100.8300\n",
      "Episode: 188 Total reward: -79.0 Training loss: 1.9433 Explore P: 0.0821 RunMean : -100.7800\n",
      "Episode: 189 Total reward: -72.0 Training loss: 1.3725 Explore P: 0.0816 RunMean : -100.3800\n",
      "Episode: 190 Total reward: -96.0 Training loss: 5.6108 Explore P: 0.0809 RunMean : -100.4700\n",
      "Episode: 191 Total reward: -82.0 Training loss: 2.6037 Explore P: 0.0803 RunMean : -100.4200\n",
      "Episode: 192 Total reward: -76.0 Training loss: 0.8387 Explore P: 0.0797 RunMean : -100.0000\n",
      "Episode: 193 Total reward: -63.0 Training loss: 1.2920 Explore P: 0.0793 RunMean : -99.5400\n",
      "Episode: 194 Total reward: -102.0 Training loss: 2.3284 Explore P: 0.0786 RunMean : -99.4200\n",
      "Episode: 195 Total reward: -93.0 Training loss: 1.0554 Explore P: 0.0779 RunMean : -99.6600\n",
      "Episode: 196 Total reward: -80.0 Training loss: 2.3552 Explore P: 0.0774 RunMean : -99.4800\n",
      "Episode: 197 Total reward: -141.0 Training loss: 2.8044 Explore P: 0.0764 RunMean : -99.8600\n",
      "Episode: 198 Total reward: -100.0 Training loss: 1.0508 Explore P: 0.0758 RunMean : -99.7600\n",
      "Episode: 199 Total reward: -91.0 Training loss: 1.5046 Explore P: 0.0752 RunMean : -99.7400\n",
      "Episode: 200 Total reward: -83.0 Training loss: 3.4560 Explore P: 0.0746 RunMean : -99.4700\n",
      "Episode: 201 Total reward: -99.0 Training loss: 1.0110 Explore P: 0.0740 RunMean : -99.7000\n",
      "Episode: 202 Total reward: -101.0 Training loss: 1.5170 Explore P: 0.0733 RunMean : -99.9400\n",
      "Episode: 203 Total reward: -82.0 Training loss: 3.4150 Explore P: 0.0728 RunMean : -99.6100\n",
      "Episode: 204 Total reward: -103.0 Training loss: 5.7016 Explore P: 0.0722 RunMean : -99.6400\n",
      "Episode: 205 Total reward: -81.0 Training loss: 1.6580 Explore P: 0.0717 RunMean : -99.1100\n",
      "Episode: 206 Total reward: -79.0 Training loss: 1.8311 Explore P: 0.0712 RunMean : -98.8300\n",
      "Episode: 207 Total reward: -102.0 Training loss: 2.4334 Explore P: 0.0705 RunMean : -98.4800\n",
      "Episode: 208 Total reward: -83.0 Training loss: 0.9308 Explore P: 0.0700 RunMean : -98.3700\n",
      "Episode: 209 Total reward: -77.0 Training loss: 2.2594 Explore P: 0.0696 RunMean : -98.1600\n",
      "Episode: 210 Total reward: -80.0 Training loss: 11.7532 Explore P: 0.0691 RunMean : -98.0700\n",
      "Episode: 211 Total reward: -159.0 Training loss: 0.7394 Explore P: 0.0681 RunMean : -98.6300\n",
      "Episode: 212 Total reward: -78.0 Training loss: 4.1432 Explore P: 0.0677 RunMean : -98.4100\n",
      "Episode: 213 Total reward: -86.0 Training loss: 1.2577 Explore P: 0.0672 RunMean : -98.5100\n",
      "Episode: 214 Total reward: -92.0 Training loss: 1.7508 Explore P: 0.0667 RunMean : -98.4000\n",
      "Episode: 215 Total reward: -104.0 Training loss: 7.0229 Explore P: 0.0661 RunMean : -98.4900\n",
      "Episode: 216 Total reward: -118.0 Training loss: 1.4497 Explore P: 0.0654 RunMean : -98.5600\n",
      "Episode: 217 Total reward: -98.0 Training loss: 1.2458 Explore P: 0.0649 RunMean : -97.3400\n",
      "Episode: 218 Total reward: -117.0 Training loss: 1.9108 Explore P: 0.0642 RunMean : -97.5400\n",
      "Episode: 219 Total reward: -84.0 Training loss: 1.4252 Explore P: 0.0638 RunMean : -97.4300\n",
      "Episode: 220 Total reward: -80.0 Training loss: 7.8391 Explore P: 0.0633 RunMean : -97.2300\n",
      "Episode: 221 Total reward: -107.0 Training loss: 1.9267 Explore P: 0.0627 RunMean : -97.3000\n",
      "Episode: 222 Total reward: -106.0 Training loss: 4.9568 Explore P: 0.0622 RunMean : -97.2900\n",
      "Episode: 223 Total reward: -85.0 Training loss: 1.2808 Explore P: 0.0617 RunMean : -97.0700\n",
      "Episode: 224 Total reward: -82.0 Training loss: 1.4514 Explore P: 0.0613 RunMean : -96.9300\n",
      "Episode: 225 Total reward: -80.0 Training loss: 1.4391 Explore P: 0.0609 RunMean : -96.6200\n",
      "Episode: 226 Total reward: -92.0 Training loss: 1.7558 Explore P: 0.0604 RunMean : -96.5900\n",
      "Episode: 227 Total reward: -106.0 Training loss: 1.4177 Explore P: 0.0599 RunMean : -96.8200\n",
      "Episode: 228 Total reward: -70.0 Training loss: 0.9127 Explore P: 0.0595 RunMean : -96.7200\n",
      "Episode: 229 Total reward: -71.0 Training loss: 1.2918 Explore P: 0.0592 RunMean : -96.7100\n",
      "Episode: 230 Total reward: -107.0 Training loss: 1.7546 Explore P: 0.0587 RunMean : -96.8600\n",
      "Episode: 231 Total reward: -126.0 Training loss: 1.4015 Explore P: 0.0580 RunMean : -97.2400\n",
      "Episode: 232 Total reward: -97.0 Training loss: 1.3637 Explore P: 0.0576 RunMean : -97.2200\n",
      "Episode: 233 Total reward: -86.0 Training loss: 1.1471 Explore P: 0.0572 RunMean : -97.2800\n",
      "Episode: 234 Total reward: -69.0 Training loss: 1.5636 Explore P: 0.0568 RunMean : -96.9300\n",
      "Episode: 235 Total reward: -82.0 Training loss: 0.9273 Explore P: 0.0564 RunMean : -96.3200\n",
      "Episode: 236 Total reward: -83.0 Training loss: 0.4888 Explore P: 0.0561 RunMean : -96.2500\n",
      "Episode: 237 Total reward: -102.0 Training loss: 0.6522 Explore P: 0.0556 RunMean : -96.5200\n",
      "Episode: 238 Total reward: -85.0 Training loss: 1.2194 Explore P: 0.0552 RunMean : -96.2700\n",
      "Episode: 239 Total reward: -87.0 Training loss: 1.6989 Explore P: 0.0548 RunMean : -95.9100\n",
      "Episode: 240 Total reward: -86.0 Training loss: 0.9531 Explore P: 0.0544 RunMean : -95.7300\n",
      "Episode: 241 Total reward: -68.0 Training loss: 1.3983 Explore P: 0.0541 RunMean : -95.4700\n",
      "Episode: 242 Total reward: -82.0 Training loss: 0.7812 Explore P: 0.0537 RunMean : -95.6500\n",
      "Episode: 243 Total reward: -133.0 Training loss: 1.8356 Explore P: 0.0532 RunMean : -95.2700\n",
      "Episode: 244 Total reward: -74.0 Training loss: 1.6049 Explore P: 0.0528 RunMean : -94.9500\n",
      "Episode: 245 Total reward: -95.0 Training loss: 1.4519 Explore P: 0.0524 RunMean : -95.1700\n",
      "Episode: 246 Total reward: -99.0 Training loss: 1.2562 Explore P: 0.0520 RunMean : -94.9000\n",
      "Episode: 247 Total reward: -93.0 Training loss: 1.1587 Explore P: 0.0516 RunMean : -94.8200\n",
      "Episode: 248 Total reward: -142.0 Training loss: 0.8946 Explore P: 0.0510 RunMean : -95.4000\n",
      "Episode: 249 Total reward: -86.0 Training loss: 1.1834 Explore P: 0.0507 RunMean : -95.4100\n",
      "Episode: 250 Total reward: -107.0 Training loss: 2.6850 Explore P: 0.0502 RunMean : -95.5700\n",
      "Episode: 251 Total reward: -139.0 Training loss: 5.4794 Explore P: 0.0497 RunMean : -95.9400\n",
      "Episode: 252 Total reward: -69.0 Training loss: 1.5263 Explore P: 0.0494 RunMean : -95.4500\n",
      "Episode: 253 Total reward: -107.0 Training loss: 3.3112 Explore P: 0.0490 RunMean : -95.6400\n",
      "Episode: 254 Total reward: -75.0 Training loss: 1.4974 Explore P: 0.0487 RunMean : -95.5200\n",
      "Episode: 255 Total reward: -83.0 Training loss: 3.1531 Explore P: 0.0483 RunMean : -95.5700\n",
      "Episode: 256 Total reward: -92.0 Training loss: 0.7957 Explore P: 0.0480 RunMean : -95.4800\n",
      "Episode: 257 Total reward: -81.0 Training loss: 1.0688 Explore P: 0.0477 RunMean : -94.9700\n",
      "Episode: 258 Total reward: -73.0 Training loss: 1.4512 Explore P: 0.0474 RunMean : -94.8200\n",
      "Episode: 259 Total reward: -101.0 Training loss: 1.9544 Explore P: 0.0470 RunMean : -94.8800\n",
      "Episode: 260 Total reward: -133.0 Training loss: 1.5412 Explore P: 0.0465 RunMean : -95.2700\n",
      "Episode: 261 Total reward: -101.0 Training loss: 5.8032 Explore P: 0.0462 RunMean : -95.3400\n",
      "Episode: 262 Total reward: -87.0 Training loss: 1.9219 Explore P: 0.0458 RunMean : -95.3900\n",
      "Episode: 263 Total reward: -103.0 Training loss: 1.2105 Explore P: 0.0455 RunMean : -95.7100\n",
      "Episode: 264 Total reward: -87.0 Training loss: 0.9556 Explore P: 0.0452 RunMean : -95.5500\n",
      "Episode: 265 Total reward: -88.0 Training loss: 1.0889 Explore P: 0.0449 RunMean : -95.2800\n",
      "Episode: 266 Total reward: -105.0 Training loss: 2.1429 Explore P: 0.0445 RunMean : -95.2700\n",
      "Episode: 267 Total reward: -62.0 Training loss: 1.1409 Explore P: 0.0443 RunMean : -94.9500\n",
      "Episode: 268 Total reward: -99.0 Training loss: 1.9239 Explore P: 0.0439 RunMean : -94.9100\n",
      "Episode: 269 Total reward: -71.0 Training loss: 2.5928 Explore P: 0.0437 RunMean : -94.8300\n",
      "Episode: 270 Total reward: -99.0 Training loss: 1.9912 Explore P: 0.0433 RunMean : -95.0300\n",
      "Episode: 271 Total reward: -83.0 Training loss: 12.1115 Explore P: 0.0431 RunMean : -94.9700\n",
      "Episode: 272 Total reward: -106.0 Training loss: 1.2268 Explore P: 0.0427 RunMean : -94.9200\n",
      "Episode: 273 Total reward: -76.0 Training loss: 4.6740 Explore P: 0.0425 RunMean : -94.8400\n",
      "Episode: 274 Total reward: -75.0 Training loss: 1.4944 Explore P: 0.0422 RunMean : -94.6800\n",
      "Episode: 275 Total reward: -119.0 Training loss: 2.8200 Explore P: 0.0418 RunMean : -94.9700\n",
      "Episode: 276 Total reward: -95.0 Training loss: 3.0490 Explore P: 0.0415 RunMean : -95.0100\n",
      "Episode: 277 Total reward: -92.0 Training loss: 1.4703 Explore P: 0.0412 RunMean : -95.0800\n",
      "Episode: 278 Total reward: -147.0 Training loss: 2.9583 Explore P: 0.0408 RunMean : -95.8400\n",
      "Episode: 279 Total reward: -90.0 Training loss: 4.8451 Explore P: 0.0405 RunMean : -95.6500\n",
      "Episode: 280 Total reward: -71.0 Training loss: 0.7406 Explore P: 0.0403 RunMean : -94.1900\n",
      "Episode: 281 Total reward: -70.0 Training loss: 1.8245 Explore P: 0.0401 RunMean : -93.6600\n",
      "Episode: 282 Total reward: -70.0 Training loss: 1.2760 Explore P: 0.0399 RunMean : -92.9200\n",
      "Episode: 283 Total reward: -86.0 Training loss: 1.3220 Explore P: 0.0396 RunMean : -92.8000\n",
      "Episode: 284 Total reward: -92.0 Training loss: 1.1911 Explore P: 0.0393 RunMean : -92.8600\n",
      "Episode: 285 Total reward: -94.0 Training loss: 1.4982 Explore P: 0.0390 RunMean : -93.0300\n",
      "Episode: 286 Total reward: -108.0 Training loss: 1.9194 Explore P: 0.0387 RunMean : -92.5600\n",
      "Episode: 287 Total reward: -118.0 Training loss: 2.2554 Explore P: 0.0384 RunMean : -92.9600\n",
      "Episode: 288 Total reward: -113.0 Training loss: 2.0004 Explore P: 0.0381 RunMean : -93.3000\n",
      "Episode: 289 Total reward: -84.0 Training loss: 1.1855 Explore P: 0.0378 RunMean : -93.4200\n",
      "Episode: 290 Total reward: -118.0 Training loss: 1.1459 Explore P: 0.0375 RunMean : -93.6400\n",
      "Episode: 291 Total reward: -105.0 Training loss: 3.2866 Explore P: 0.0372 RunMean : -93.8700\n",
      "Episode: 292 Total reward: -500.0 Training loss: 1.0786 Explore P: 0.0359 RunMean : -98.1100\n",
      "Episode: 293 Total reward: -127.0 Training loss: 1.6607 Explore P: 0.0356 RunMean : -98.7500\n",
      "Episode: 294 Total reward: -62.0 Training loss: 0.7202 Explore P: 0.0354 RunMean : -98.3500\n",
      "Episode: 295 Total reward: -87.0 Training loss: 1.1968 Explore P: 0.0352 RunMean : -98.2900\n",
      "Episode: 296 Total reward: -100.0 Training loss: 1.7872 Explore P: 0.0349 RunMean : -98.4900\n",
      "Episode: 297 Total reward: -89.0 Training loss: 1.4800 Explore P: 0.0347 RunMean : -97.9700\n",
      "Episode: 298 Total reward: -84.0 Training loss: 1.2666 Explore P: 0.0345 RunMean : -97.8100\n",
      "Episode: 299 Total reward: -101.0 Training loss: 3.5022 Explore P: 0.0342 RunMean : -97.9100\n",
      "Episode: 300 Total reward: -76.0 Training loss: 3.2559 Explore P: 0.0341 RunMean : -97.8400\n",
      "Episode: 301 Total reward: -84.0 Training loss: 7.6274 Explore P: 0.0339 RunMean : -97.6900\n",
      "Episode: 302 Total reward: -104.0 Training loss: 1.4520 Explore P: 0.0336 RunMean : -97.7200\n",
      "Episode: 303 Total reward: -93.0 Training loss: 1.1409 Explore P: 0.0334 RunMean : -97.8300\n",
      "Episode: 304 Total reward: -101.0 Training loss: 1.6239 Explore P: 0.0331 RunMean : -97.8100\n",
      "Episode: 305 Total reward: -87.0 Training loss: 6.9074 Explore P: 0.0329 RunMean : -97.8700\n",
      "Episode: 306 Total reward: -241.0 Training loss: 1.0549 Explore P: 0.0324 RunMean : -99.4900\n",
      "Episode: 307 Total reward: -95.0 Training loss: 2.1989 Explore P: 0.0322 RunMean : -99.4200\n",
      "Episode: 308 Total reward: -75.0 Training loss: 6.0690 Explore P: 0.0320 RunMean : -99.3400\n",
      "Episode: 309 Total reward: -78.0 Training loss: 1.1321 Explore P: 0.0318 RunMean : -99.3500\n",
      "Episode: 310 Total reward: -75.0 Training loss: 2.4621 Explore P: 0.0317 RunMean : -99.3000\n",
      "Episode: 311 Total reward: -86.0 Training loss: 1.2322 Explore P: 0.0315 RunMean : -98.5700\n",
      "Episode: 312 Total reward: -94.0 Training loss: 4.0644 Explore P: 0.0313 RunMean : -98.7300\n",
      "Episode: 313 Total reward: -72.0 Training loss: 8.3057 Explore P: 0.0311 RunMean : -98.5900\n",
      "Episode: 314 Total reward: -74.0 Training loss: 2.8765 Explore P: 0.0310 RunMean : -98.4100\n",
      "Episode: 315 Total reward: -90.0 Training loss: 11.8322 Explore P: 0.0308 RunMean : -98.2700\n",
      "Episode: 316 Total reward: -87.0 Training loss: 0.7223 Explore P: 0.0306 RunMean : -97.9600\n",
      "Episode: 317 Total reward: -89.0 Training loss: 2.5551 Explore P: 0.0304 RunMean : -97.8700\n",
      "Episode: 318 Total reward: -80.0 Training loss: 1.4605 Explore P: 0.0302 RunMean : -97.5000\n",
      "Episode: 319 Total reward: -79.0 Training loss: 8.5289 Explore P: 0.0301 RunMean : -97.4500\n",
      "Episode: 320 Total reward: -114.0 Training loss: 1.1668 Explore P: 0.0299 RunMean : -97.7900\n",
      "Episode: 321 Total reward: -97.0 Training loss: 1.6545 Explore P: 0.0297 RunMean : -97.6900\n",
      "Episode: 322 Total reward: -100.0 Training loss: 2.5574 Explore P: 0.0295 RunMean : -97.6300\n",
      "Episode: 323 Total reward: -87.0 Training loss: 1.4406 Explore P: 0.0293 RunMean : -97.6500\n",
      "Episode: 324 Total reward: -82.0 Training loss: 1.1122 Explore P: 0.0291 RunMean : -97.6500\n",
      "Episode: 325 Total reward: -85.0 Training loss: 2.5129 Explore P: 0.0290 RunMean : -97.7000\n",
      "Episode: 326 Total reward: -101.0 Training loss: 0.7181 Explore P: 0.0288 RunMean : -97.7900\n",
      "Episode: 327 Total reward: -85.0 Training loss: 2.5781 Explore P: 0.0286 RunMean : -97.5800\n",
      "Episode: 328 Total reward: -75.0 Training loss: 0.8572 Explore P: 0.0285 RunMean : -97.6300\n",
      "Episode: 329 Total reward: -96.0 Training loss: 2.0139 Explore P: 0.0283 RunMean : -97.8800\n",
      "Episode: 330 Total reward: -84.0 Training loss: 0.9417 Explore P: 0.0281 RunMean : -97.6500\n",
      "Episode: 331 Total reward: -101.0 Training loss: 2.3513 Explore P: 0.0280 RunMean : -97.4000\n",
      "Episode: 332 Total reward: -81.0 Training loss: 2.3324 Explore P: 0.0278 RunMean : -97.2400\n",
      "Episode: 333 Total reward: -70.0 Training loss: 5.5616 Explore P: 0.0277 RunMean : -97.0800\n",
      "Episode: 334 Total reward: -103.0 Training loss: 2.5948 Explore P: 0.0275 RunMean : -97.4200\n",
      "Episode: 335 Total reward: -75.0 Training loss: 5.5495 Explore P: 0.0274 RunMean : -97.3500\n",
      "Episode: 336 Total reward: -156.0 Training loss: 2.6302 Explore P: 0.0271 RunMean : -98.0800\n",
      "Episode: 337 Total reward: -72.0 Training loss: 1.4561 Explore P: 0.0270 RunMean : -97.7800\n",
      "Episode: 338 Total reward: -105.0 Training loss: 1.5832 Explore P: 0.0268 RunMean : -97.9800\n",
      "Episode: 339 Total reward: -75.0 Training loss: 3.1220 Explore P: 0.0267 RunMean : -97.8600\n",
      "Episode: 340 Total reward: -95.0 Training loss: 1.2061 Explore P: 0.0265 RunMean : -97.9500\n",
      "Episode: 341 Total reward: -77.0 Training loss: 1.0114 Explore P: 0.0264 RunMean : -98.0400\n",
      "Episode: 342 Total reward: -95.0 Training loss: 2.6181 Explore P: 0.0262 RunMean : -98.1700\n",
      "Episode: 343 Total reward: -86.0 Training loss: 1.5214 Explore P: 0.0261 RunMean : -97.7000\n",
      "Episode: 344 Total reward: -78.0 Training loss: 1.8420 Explore P: 0.0260 RunMean : -97.7400\n",
      "Episode: 345 Total reward: -78.0 Training loss: 8.3028 Explore P: 0.0258 RunMean : -97.5700\n",
      "Episode: 346 Total reward: -97.0 Training loss: 0.9545 Explore P: 0.0257 RunMean : -97.5500\n",
      "Episode: 347 Total reward: -92.0 Training loss: 6.6821 Explore P: 0.0255 RunMean : -97.5400\n",
      "Episode: 348 Total reward: -85.0 Training loss: 1.8821 Explore P: 0.0254 RunMean : -96.9700\n",
      "Episode: 349 Total reward: -86.0 Training loss: 1.2790 Explore P: 0.0253 RunMean : -96.9700\n",
      "Episode: 350 Total reward: -94.0 Training loss: 3.5762 Explore P: 0.0251 RunMean : -96.8400\n",
      "Episode: 351 Total reward: -124.0 Training loss: 0.9715 Explore P: 0.0249 RunMean : -96.6900\n",
      "Episode: 352 Total reward: -75.0 Training loss: 1.9688 Explore P: 0.0248 RunMean : -96.7500\n",
      "Episode: 353 Total reward: -82.0 Training loss: 2.9695 Explore P: 0.0247 RunMean : -96.5000\n",
      "Episode: 354 Total reward: -95.0 Training loss: 2.1718 Explore P: 0.0246 RunMean : -96.7000\n",
      "Episode: 355 Total reward: -90.0 Training loss: 7.4996 Explore P: 0.0244 RunMean : -96.7700\n",
      "Episode: 356 Total reward: -142.0 Training loss: 2.6648 Explore P: 0.0242 RunMean : -97.2700\n",
      "Episode: 357 Total reward: -126.0 Training loss: 4.9103 Explore P: 0.0240 RunMean : -97.7200\n",
      "Episode: 358 Total reward: -83.0 Training loss: 4.2823 Explore P: 0.0239 RunMean : -97.8200\n",
      "Episode: 359 Total reward: -81.0 Training loss: 1.5517 Explore P: 0.0238 RunMean : -97.6200\n",
      "Episode: 360 Total reward: -75.0 Training loss: 2.2443 Explore P: 0.0237 RunMean : -97.0400\n",
      "Episode: 361 Total reward: -79.0 Training loss: 2.4420 Explore P: 0.0236 RunMean : -96.8200\n",
      "Episode: 362 Total reward: -87.0 Training loss: 2.6666 Explore P: 0.0235 RunMean : -96.8200\n",
      "Episode: 363 Total reward: -95.0 Training loss: 5.9296 Explore P: 0.0233 RunMean : -96.7400\n",
      "Episode: 364 Total reward: -76.0 Training loss: 8.1479 Explore P: 0.0232 RunMean : -96.6300\n",
      "Episode: 365 Total reward: -75.0 Training loss: 1.8659 Explore P: 0.0231 RunMean : -96.5000\n",
      "Episode: 366 Total reward: -112.0 Training loss: 3.1698 Explore P: 0.0230 RunMean : -96.5700\n",
      "Episode: 367 Total reward: -94.0 Training loss: 3.5241 Explore P: 0.0229 RunMean : -96.8900\n",
      "Episode: 368 Total reward: -122.0 Training loss: 4.4977 Explore P: 0.0227 RunMean : -97.1200\n",
      "Episode: 369 Total reward: -80.0 Training loss: 4.2692 Explore P: 0.0226 RunMean : -97.2100\n",
      "Episode: 370 Total reward: -71.0 Training loss: 3.1299 Explore P: 0.0225 RunMean : -96.9300\n",
      "Episode: 371 Total reward: -77.0 Training loss: 1.4045 Explore P: 0.0224 RunMean : -96.8700\n",
      "Episode: 372 Total reward: -93.0 Training loss: 3.2835 Explore P: 0.0223 RunMean : -96.7400\n",
      "Episode: 373 Total reward: -78.0 Training loss: 2.0453 Explore P: 0.0222 RunMean : -96.7600\n",
      "Episode: 374 Total reward: -86.0 Training loss: 1.2996 Explore P: 0.0221 RunMean : -96.8700\n",
      "Episode: 375 Total reward: -70.0 Training loss: 1.3936 Explore P: 0.0220 RunMean : -96.3800\n",
      "Episode: 376 Total reward: -99.0 Training loss: 3.1415 Explore P: 0.0219 RunMean : -96.4200\n",
      "Episode: 377 Total reward: -110.0 Training loss: 3.6814 Explore P: 0.0218 RunMean : -96.6000\n",
      "Episode: 378 Total reward: -83.0 Training loss: 2.4156 Explore P: 0.0217 RunMean : -95.9600\n",
      "Episode: 379 Total reward: -100.0 Training loss: 1.0549 Explore P: 0.0216 RunMean : -96.0600\n",
      "Episode: 380 Total reward: -102.0 Training loss: 2.8657 Explore P: 0.0214 RunMean : -96.3700\n",
      "Episode: 381 Total reward: -95.0 Training loss: 4.7638 Explore P: 0.0213 RunMean : -96.6200\n",
      "Episode: 382 Total reward: -94.0 Training loss: 5.7139 Explore P: 0.0212 RunMean : -96.8600\n",
      "Episode: 383 Total reward: -115.0 Training loss: 1.4547 Explore P: 0.0211 RunMean : -97.1500\n",
      "Episode: 384 Total reward: -62.0 Training loss: 3.9265 Explore P: 0.0210 RunMean : -96.8500\n",
      "Episode: 385 Total reward: -104.0 Training loss: 3.7752 Explore P: 0.0209 RunMean : -96.9500\n",
      "Episode: 386 Total reward: -101.0 Training loss: 1.4106 Explore P: 0.0208 RunMean : -96.8800\n",
      "Episode: 387 Total reward: -107.0 Training loss: 1.7173 Explore P: 0.0207 RunMean : -96.7700\n",
      "Episode: 388 Total reward: -85.0 Training loss: 1.4526 Explore P: 0.0206 RunMean : -96.4900\n",
      "Episode: 389 Total reward: -62.0 Training loss: 3.2075 Explore P: 0.0205 RunMean : -96.2700\n",
      "Episode: 390 Total reward: -69.0 Training loss: 2.6725 Explore P: 0.0205 RunMean : -95.7800\n",
      "Episode: 391 Total reward: -79.0 Training loss: 2.8500 Explore P: 0.0204 RunMean : -95.5200\n",
      "Episode: 392 Total reward: -92.0 Training loss: 1.6669 Explore P: 0.0203 RunMean : -91.4400\n",
      "Episode: 393 Total reward: -84.0 Training loss: 0.8814 Explore P: 0.0202 RunMean : -91.0100\n",
      "Episode: 394 Total reward: -74.0 Training loss: 1.6172 Explore P: 0.0201 RunMean : -91.1300\n",
      "Episode: 395 Total reward: -70.0 Training loss: 1.1449 Explore P: 0.0200 RunMean : -90.9600\n",
      "Episode: 396 Total reward: -79.0 Training loss: 3.9691 Explore P: 0.0200 RunMean : -90.7500\n",
      "Episode: 397 Total reward: -102.0 Training loss: 1.8597 Explore P: 0.0199 RunMean : -90.8800\n",
      "Episode: 398 Total reward: -76.0 Training loss: 3.3577 Explore P: 0.0198 RunMean : -90.8000\n",
      "Episode: 399 Total reward: -100.0 Training loss: 1.1079 Explore P: 0.0197 RunMean : -90.7900\n",
      "Episode: 400 Total reward: -72.0 Training loss: 2.0562 Explore P: 0.0196 RunMean : -90.7500\n",
      "Episode: 401 Total reward: -101.0 Training loss: 2.3790 Explore P: 0.0195 RunMean : -90.9200\n",
      "Episode: 402 Total reward: -141.0 Training loss: 1.8827 Explore P: 0.0194 RunMean : -91.2900\n",
      "Episode: 403 Total reward: -88.0 Training loss: 1.9397 Explore P: 0.0193 RunMean : -91.2400\n",
      "Episode: 404 Total reward: -100.0 Training loss: 1.5159 Explore P: 0.0192 RunMean : -91.2300\n",
      "Episode: 405 Total reward: -63.0 Training loss: 1.7298 Explore P: 0.0191 RunMean : -90.9900\n",
      "Episode: 406 Total reward: -70.0 Training loss: 3.0267 Explore P: 0.0191 RunMean : -89.2800\n",
      "Episode: 407 Total reward: -75.0 Training loss: 0.7941 Explore P: 0.0190 RunMean : -89.0800\n",
      "Episode: 408 Total reward: -105.0 Training loss: 0.9828 Explore P: 0.0189 RunMean : -89.3800\n",
      "Episode: 409 Total reward: -78.0 Training loss: 4.9908 Explore P: 0.0188 RunMean : -89.3800\n",
      "Episode: 410 Total reward: -166.0 Training loss: 4.6839 Explore P: 0.0187 RunMean : -90.2900\n",
      "Episode: 411 Total reward: -79.0 Training loss: 1.6412 Explore P: 0.0186 RunMean : -90.2200\n",
      "Episode: 412 Total reward: -100.0 Training loss: 1.3448 Explore P: 0.0185 RunMean : -90.2800\n",
      "Episode: 413 Total reward: -70.0 Training loss: 1.3719 Explore P: 0.0185 RunMean : -90.2600\n",
      "Episode: 414 Total reward: -127.0 Training loss: 1.9220 Explore P: 0.0184 RunMean : -90.7900\n",
      "Episode: 415 Total reward: -141.0 Training loss: 1.1858 Explore P: 0.0183 RunMean : -91.3000\n",
      "Episode: 416 Total reward: -86.0 Training loss: 2.0351 Explore P: 0.0182 RunMean : -91.2900\n",
      "Episode: 417 Total reward: -112.0 Training loss: 0.9715 Explore P: 0.0181 RunMean : -91.5200\n",
      "Episode: 418 Total reward: -75.0 Training loss: 1.5458 Explore P: 0.0180 RunMean : -91.4700\n",
      "Episode: 419 Total reward: -92.0 Training loss: 1.2472 Explore P: 0.0180 RunMean : -91.6000\n",
      "Episode: 420 Total reward: -92.0 Training loss: 1.4568 Explore P: 0.0179 RunMean : -91.3800\n",
      "Episode: 421 Total reward: -91.0 Training loss: 0.7135 Explore P: 0.0178 RunMean : -91.3200\n",
      "Episode: 422 Total reward: -77.0 Training loss: 3.4099 Explore P: 0.0178 RunMean : -91.0900\n",
      "Episode: 423 Total reward: -89.0 Training loss: 1.7818 Explore P: 0.0177 RunMean : -91.1100\n",
      "Episode: 424 Total reward: -96.0 Training loss: 1.5155 Explore P: 0.0176 RunMean : -91.2500\n",
      "Episode: 425 Total reward: -106.0 Training loss: 1.3829 Explore P: 0.0175 RunMean : -91.4600\n",
      "Episode: 426 Total reward: -70.0 Training loss: 1.3600 Explore P: 0.0175 RunMean : -91.1500\n",
      "Episode: 427 Total reward: -104.0 Training loss: 0.5066 Explore P: 0.0174 RunMean : -91.3400\n",
      "Episode: 428 Total reward: -71.0 Training loss: 1.2883 Explore P: 0.0173 RunMean : -91.3000\n",
      "Episode: 429 Total reward: -85.0 Training loss: 1.1270 Explore P: 0.0173 RunMean : -91.1900\n",
      "Episode: 430 Total reward: -98.0 Training loss: 3.1495 Explore P: 0.0172 RunMean : -91.3300\n",
      "Episode: 431 Total reward: -95.0 Training loss: 1.5993 Explore P: 0.0171 RunMean : -91.2700\n",
      "Episode: 432 Total reward: -75.0 Training loss: 1.5619 Explore P: 0.0171 RunMean : -91.2100\n",
      "Episode: 433 Total reward: -110.0 Training loss: 1.6120 Explore P: 0.0170 RunMean : -91.6100\n",
      "Episode: 434 Total reward: -140.0 Training loss: 0.9285 Explore P: 0.0169 RunMean : -91.9800\n",
      "Episode: 435 Total reward: -71.0 Training loss: 2.4712 Explore P: 0.0169 RunMean : -91.9400\n",
      "Episode: 436 Total reward: -77.0 Training loss: 1.3893 Explore P: 0.0168 RunMean : -91.1500\n",
      "Episode: 437 Total reward: -132.0 Training loss: 1.5170 Explore P: 0.0167 RunMean : -91.7500\n",
      "Episode: 438 Total reward: -84.0 Training loss: 1.5144 Explore P: 0.0167 RunMean : -91.5400\n",
      "Episode: 439 Total reward: -86.0 Training loss: 2.0089 Explore P: 0.0166 RunMean : -91.6500\n",
      "Episode: 440 Total reward: -85.0 Training loss: 1.4409 Explore P: 0.0165 RunMean : -91.5500\n",
      "Episode: 441 Total reward: -119.0 Training loss: 1.5227 Explore P: 0.0165 RunMean : -91.9700\n",
      "Episode: 442 Total reward: -95.0 Training loss: 2.0059 Explore P: 0.0164 RunMean : -91.9700\n",
      "Episode: 443 Total reward: -113.0 Training loss: 2.0102 Explore P: 0.0163 RunMean : -92.2400\n",
      "Episode: 444 Total reward: -87.0 Training loss: 3.4465 Explore P: 0.0163 RunMean : -92.3300\n",
      "Episode: 445 Total reward: -89.0 Training loss: 2.6745 Explore P: 0.0162 RunMean : -92.4400\n",
      "Episode: 446 Total reward: -120.0 Training loss: 6.1951 Explore P: 0.0161 RunMean : -92.6700\n",
      "Episode: 447 Total reward: -124.0 Training loss: 1.3813 Explore P: 0.0161 RunMean : -92.9900\n",
      "Episode: 448 Total reward: -149.0 Training loss: 2.1243 Explore P: 0.0160 RunMean : -93.6300\n",
      "Episode: 449 Total reward: -112.0 Training loss: 1.0108 Explore P: 0.0159 RunMean : -93.8900\n",
      "Episode: 450 Total reward: -148.0 Training loss: 1.7189 Explore P: 0.0158 RunMean : -94.4300\n",
      "Episode: 451 Total reward: -90.0 Training loss: 1.0265 Explore P: 0.0158 RunMean : -94.0900\n",
      "Episode: 452 Total reward: -88.0 Training loss: 1.2847 Explore P: 0.0157 RunMean : -94.2200\n",
      "Episode: 453 Total reward: -101.0 Training loss: 1.1756 Explore P: 0.0157 RunMean : -94.4100\n",
      "Episode: 454 Total reward: -105.0 Training loss: 1.3059 Explore P: 0.0156 RunMean : -94.5100\n",
      "Episode: 455 Total reward: -110.0 Training loss: 2.9496 Explore P: 0.0155 RunMean : -94.7100\n",
      "Episode: 456 Total reward: -96.0 Training loss: 1.4169 Explore P: 0.0155 RunMean : -94.2500\n",
      "Episode: 457 Total reward: -76.0 Training loss: 2.3903 Explore P: 0.0154 RunMean : -93.7500\n",
      "Episode: 458 Total reward: -86.0 Training loss: 2.5186 Explore P: 0.0154 RunMean : -93.7800\n",
      "Episode: 459 Total reward: -70.0 Training loss: 0.6372 Explore P: 0.0154 RunMean : -93.6700\n",
      "Episode: 460 Total reward: -63.0 Training loss: 1.2012 Explore P: 0.0153 RunMean : -93.5500\n",
      "Episode: 461 Total reward: -91.0 Training loss: 1.3436 Explore P: 0.0153 RunMean : -93.6700\n",
      "Episode: 462 Total reward: -109.0 Training loss: 0.9068 Explore P: 0.0152 RunMean : -93.8900\n",
      "Episode: 463 Total reward: -98.0 Training loss: 0.9680 Explore P: 0.0152 RunMean : -93.9200\n",
      "Episode: 464 Total reward: -86.0 Training loss: 1.2388 Explore P: 0.0151 RunMean : -94.0200\n",
      "Episode: 465 Total reward: -100.0 Training loss: 1.2816 Explore P: 0.0151 RunMean : -94.2700\n",
      "Episode: 466 Total reward: -76.0 Training loss: 0.9314 Explore P: 0.0150 RunMean : -93.9100\n",
      "Episode: 467 Total reward: -90.0 Training loss: 4.4030 Explore P: 0.0150 RunMean : -93.8700\n",
      "Episode: 468 Total reward: -91.0 Training loss: 7.4301 Explore P: 0.0149 RunMean : -93.5600\n",
      "Episode: 469 Total reward: -154.0 Training loss: 1.3955 Explore P: 0.0149 RunMean : -94.3000\n",
      "Episode: 470 Total reward: -75.0 Training loss: 1.7603 Explore P: 0.0148 RunMean : -94.3400\n",
      "Episode: 471 Total reward: -99.0 Training loss: 1.2073 Explore P: 0.0148 RunMean : -94.5600\n",
      "Episode: 472 Total reward: -117.0 Training loss: 2.8491 Explore P: 0.0147 RunMean : -94.8000\n",
      "Episode: 473 Total reward: -119.0 Training loss: 0.7078 Explore P: 0.0147 RunMean : -95.2100\n",
      "Episode: 474 Total reward: -92.0 Training loss: 1.3502 Explore P: 0.0146 RunMean : -95.2700\n",
      "Episode: 475 Total reward: -95.0 Training loss: 1.0814 Explore P: 0.0146 RunMean : -95.5200\n",
      "Episode: 476 Total reward: -89.0 Training loss: 0.9801 Explore P: 0.0145 RunMean : -95.4200\n",
      "Episode: 477 Total reward: -79.0 Training loss: 0.9835 Explore P: 0.0145 RunMean : -95.1100\n",
      "Episode: 478 Total reward: -71.0 Training loss: 0.8682 Explore P: 0.0145 RunMean : -94.9900\n",
      "Episode: 479 Total reward: -92.0 Training loss: 1.4035 Explore P: 0.0144 RunMean : -94.9100\n",
      "Episode: 480 Total reward: -113.0 Training loss: 1.2716 Explore P: 0.0144 RunMean : -95.0200\n",
      "Episode: 481 Total reward: -189.0 Training loss: 0.7608 Explore P: 0.0143 RunMean : -95.9600\n",
      "Episode: 482 Total reward: -155.0 Training loss: 1.0756 Explore P: 0.0142 RunMean : -96.5700\n",
      "Episode: 483 Total reward: -88.0 Training loss: 2.4646 Explore P: 0.0142 RunMean : -96.3000\n",
      "Episode: 484 Total reward: -97.0 Training loss: 0.8975 Explore P: 0.0142 RunMean : -96.6500\n",
      "Episode: 485 Total reward: -112.0 Training loss: 1.1668 Explore P: 0.0141 RunMean : -96.7300\n",
      "Episode: 486 Total reward: -106.0 Training loss: 2.3188 Explore P: 0.0141 RunMean : -96.7800\n",
      "Episode: 487 Total reward: -98.0 Training loss: 8.5651 Explore P: 0.0140 RunMean : -96.6900\n",
      "Episode: 488 Total reward: -93.0 Training loss: 1.1087 Explore P: 0.0140 RunMean : -96.7700\n",
      "Episode: 489 Total reward: -91.0 Training loss: 4.2022 Explore P: 0.0139 RunMean : -97.0600\n",
      "Episode: 490 Total reward: -119.0 Training loss: 2.0958 Explore P: 0.0139 RunMean : -97.5600\n",
      "Episode: 491 Total reward: -187.0 Training loss: 1.5560 Explore P: 0.0138 RunMean : -98.6400\n",
      "Episode: 492 Total reward: -103.0 Training loss: 5.9425 Explore P: 0.0138 RunMean : -98.7500\n",
      "Episode: 493 Total reward: -97.0 Training loss: 1.0992 Explore P: 0.0138 RunMean : -98.8800\n",
      "Episode: 494 Total reward: -94.0 Training loss: 1.1271 Explore P: 0.0137 RunMean : -99.0800\n",
      "Episode: 495 Total reward: -89.0 Training loss: 2.0445 Explore P: 0.0137 RunMean : -99.2700\n",
      "Episode: 496 Total reward: -129.0 Training loss: 2.0144 Explore P: 0.0136 RunMean : -99.7700\n",
      "Episode: 497 Total reward: -115.0 Training loss: 0.7943 Explore P: 0.0136 RunMean : -99.9000\n",
      "Episode: 498 Total reward: -153.0 Training loss: 1.8607 Explore P: 0.0135 RunMean : -100.6700\n",
      "Episode: 499 Total reward: -125.0 Training loss: 0.8327 Explore P: 0.0135 RunMean : -100.9200\n",
      "Episode: 500 Total reward: -96.0 Training loss: 0.7613 Explore P: 0.0135 RunMean : -101.1600\n",
      "Episode: 501 Total reward: -117.0 Training loss: 1.6535 Explore P: 0.0134 RunMean : -101.3200\n",
      "Episode: 502 Total reward: -70.0 Training loss: 1.2034 Explore P: 0.0134 RunMean : -100.6100\n",
      "Episode: 503 Total reward: -62.0 Training loss: 1.4733 Explore P: 0.0134 RunMean : -100.3500\n",
      "Episode: 504 Total reward: -102.0 Training loss: 1.3814 Explore P: 0.0133 RunMean : -100.3700\n",
      "Episode: 505 Total reward: -77.0 Training loss: 1.3474 Explore P: 0.0133 RunMean : -100.5100\n",
      "Episode: 506 Total reward: -82.0 Training loss: 1.4701 Explore P: 0.0133 RunMean : -100.6300\n",
      "Episode: 507 Total reward: -63.0 Training loss: 0.9852 Explore P: 0.0133 RunMean : -100.5100\n",
      "Episode: 508 Total reward: -90.0 Training loss: 0.8300 Explore P: 0.0132 RunMean : -100.3600\n",
      "Episode: 509 Total reward: -67.0 Training loss: 3.7602 Explore P: 0.0132 RunMean : -100.2500\n",
      "Episode: 510 Total reward: -74.0 Training loss: 0.9828 Explore P: 0.0132 RunMean : -99.3300\n",
      "Episode: 511 Total reward: -102.0 Training loss: 0.8908 Explore P: 0.0132 RunMean : -99.5600\n",
      "Episode: 512 Total reward: -95.0 Training loss: 1.1222 Explore P: 0.0131 RunMean : -99.5100\n",
      "Episode: 513 Total reward: -104.0 Training loss: 1.1878 Explore P: 0.0131 RunMean : -99.8500\n",
      "Episode: 514 Total reward: -69.0 Training loss: 0.5741 Explore P: 0.0131 RunMean : -99.2700\n",
      "Episode: 515 Total reward: -97.0 Training loss: 1.8089 Explore P: 0.0130 RunMean : -98.8300\n",
      "Episode: 516 Total reward: -63.0 Training loss: 2.6666 Explore P: 0.0130 RunMean : -98.6000\n",
      "Episode: 517 Total reward: -82.0 Training loss: 2.8405 Explore P: 0.0130 RunMean : -98.3000\n",
      "Episode: 518 Total reward: -97.0 Training loss: 1.1306 Explore P: 0.0130 RunMean : -98.5200\n",
      "Episode: 519 Total reward: -122.0 Training loss: 0.5889 Explore P: 0.0129 RunMean : -98.8200\n",
      "Episode: 520 Total reward: -89.0 Training loss: 1.0771 Explore P: 0.0129 RunMean : -98.7900\n",
      "Episode: 521 Total reward: -80.0 Training loss: 1.5032 Explore P: 0.0129 RunMean : -98.6800\n",
      "Episode: 522 Total reward: -180.0 Training loss: 1.3066 Explore P: 0.0128 RunMean : -99.7100\n",
      "Episode: 523 Total reward: -114.0 Training loss: 1.7665 Explore P: 0.0128 RunMean : -99.9600\n",
      "Episode: 524 Total reward: -119.0 Training loss: 1.3016 Explore P: 0.0128 RunMean : -100.1900\n",
      "Episode: 525 Total reward: -86.0 Training loss: 0.9614 Explore P: 0.0127 RunMean : -99.9900\n",
      "Episode: 526 Total reward: -102.0 Training loss: 0.8904 Explore P: 0.0127 RunMean : -100.3100\n",
      "Episode: 527 Total reward: -103.0 Training loss: 1.0241 Explore P: 0.0127 RunMean : -100.3000\n",
      "Episode: 528 Total reward: -74.0 Training loss: 4.3968 Explore P: 0.0127 RunMean : -100.3300\n",
      "Episode: 529 Total reward: -109.0 Training loss: 1.7351 Explore P: 0.0126 RunMean : -100.5700\n",
      "Episode: 530 Total reward: -91.0 Training loss: 1.0023 Explore P: 0.0126 RunMean : -100.5000\n",
      "Episode: 531 Total reward: -143.0 Training loss: 1.2451 Explore P: 0.0126 RunMean : -100.9800\n",
      "Episode: 532 Total reward: -116.0 Training loss: 1.5691 Explore P: 0.0125 RunMean : -101.3900\n",
      "Episode: 533 Total reward: -74.0 Training loss: 0.8171 Explore P: 0.0125 RunMean : -101.0300\n",
      "Episode: 534 Total reward: -131.0 Training loss: 1.6889 Explore P: 0.0125 RunMean : -100.9400\n",
      "Episode: 535 Total reward: -90.0 Training loss: 1.9609 Explore P: 0.0125 RunMean : -101.1300\n",
      "Episode: 536 Total reward: -104.0 Training loss: 2.3528 Explore P: 0.0124 RunMean : -101.4000\n",
      "Episode: 537 Total reward: -84.0 Training loss: 3.3156 Explore P: 0.0124 RunMean : -100.9200\n",
      "Episode: 538 Total reward: -124.0 Training loss: 4.1965 Explore P: 0.0124 RunMean : -101.3200\n",
      "Episode: 539 Total reward: -123.0 Training loss: 0.9811 Explore P: 0.0124 RunMean : -101.6900\n",
      "Episode: 540 Total reward: -140.0 Training loss: 2.2957 Explore P: 0.0123 RunMean : -102.2400\n",
      "Episode: 541 Total reward: -108.0 Training loss: 1.0672 Explore P: 0.0123 RunMean : -102.1300\n",
      "Episode: 542 Total reward: -127.0 Training loss: 1.4756 Explore P: 0.0123 RunMean : -102.4500\n",
      "Episode: 543 Total reward: -126.0 Training loss: 1.7433 Explore P: 0.0122 RunMean : -102.5800\n",
      "Episode: 544 Total reward: -115.0 Training loss: 1.9699 Explore P: 0.0122 RunMean : -102.8600\n",
      "Episode: 545 Total reward: -110.0 Training loss: 1.7272 Explore P: 0.0122 RunMean : -103.0700\n",
      "Episode: 546 Total reward: -95.0 Training loss: 3.0153 Explore P: 0.0122 RunMean : -102.8200\n",
      "Episode: 547 Total reward: -111.0 Training loss: 1.0798 Explore P: 0.0122 RunMean : -102.6900\n",
      "Episode: 548 Total reward: -76.0 Training loss: 2.5285 Explore P: 0.0121 RunMean : -101.9600\n",
      "Episode: 549 Total reward: -76.0 Training loss: 1.1510 Explore P: 0.0121 RunMean : -101.6000\n",
      "Episode: 550 Total reward: -86.0 Training loss: 3.8700 Explore P: 0.0121 RunMean : -100.9800\n",
      "Episode: 551 Total reward: -92.0 Training loss: 1.1418 Explore P: 0.0121 RunMean : -101.0000\n",
      "Episode: 552 Total reward: -102.0 Training loss: 5.4643 Explore P: 0.0121 RunMean : -101.1400\n",
      "Episode: 553 Total reward: -111.0 Training loss: 3.0607 Explore P: 0.0120 RunMean : -101.2400\n",
      "Episode: 554 Total reward: -87.0 Training loss: 1.7917 Explore P: 0.0120 RunMean : -101.0600\n",
      "Episode: 555 Total reward: -107.0 Training loss: 1.0099 Explore P: 0.0120 RunMean : -101.0300\n",
      "Episode: 556 Total reward: -98.0 Training loss: 1.0974 Explore P: 0.0120 RunMean : -101.0500\n",
      "Episode: 557 Total reward: -76.0 Training loss: 1.2772 Explore P: 0.0120 RunMean : -101.0500\n",
      "Episode: 558 Total reward: -84.0 Training loss: 2.3547 Explore P: 0.0119 RunMean : -101.0300\n",
      "Episode: 559 Total reward: -92.0 Training loss: 1.4011 Explore P: 0.0119 RunMean : -101.2500\n",
      "Episode: 560 Total reward: -85.0 Training loss: 1.0267 Explore P: 0.0119 RunMean : -101.4700\n",
      "Episode: 561 Total reward: -82.0 Training loss: 1.1282 Explore P: 0.0119 RunMean : -101.3800\n",
      "Episode: 562 Total reward: -86.0 Training loss: 1.8226 Explore P: 0.0119 RunMean : -101.1500\n",
      "Episode: 563 Total reward: -93.0 Training loss: 2.9978 Explore P: 0.0119 RunMean : -101.1000\n",
      "Episode: 564 Total reward: -86.0 Training loss: 1.0731 Explore P: 0.0118 RunMean : -101.1000\n",
      "Episode: 565 Total reward: -112.0 Training loss: 1.1275 Explore P: 0.0118 RunMean : -101.2200\n",
      "Episode: 566 Total reward: -80.0 Training loss: 0.7516 Explore P: 0.0118 RunMean : -101.2600\n",
      "Episode: 567 Total reward: -94.0 Training loss: 4.5418 Explore P: 0.0118 RunMean : -101.3000\n",
      "Episode: 568 Total reward: -79.0 Training loss: 1.7771 Explore P: 0.0118 RunMean : -101.1800\n",
      "Episode: 569 Total reward: -70.0 Training loss: 1.4680 Explore P: 0.0118 RunMean : -100.3400\n",
      "Episode: 570 Total reward: -74.0 Training loss: 3.3566 Explore P: 0.0118 RunMean : -100.3300\n",
      "Episode: 571 Total reward: -83.0 Training loss: 0.9921 Explore P: 0.0117 RunMean : -100.1700\n",
      "Episode: 572 Total reward: -82.0 Training loss: 2.8813 Explore P: 0.0117 RunMean : -99.8200\n",
      "Episode: 573 Total reward: -97.0 Training loss: 1.9480 Explore P: 0.0117 RunMean : -99.6000\n",
      "Episode: 574 Total reward: -122.0 Training loss: 1.1924 Explore P: 0.0117 RunMean : -99.9000\n",
      "Episode: 575 Total reward: -85.0 Training loss: 4.0510 Explore P: 0.0117 RunMean : -99.8000\n",
      "Episode: 576 Total reward: -78.0 Training loss: 2.9167 Explore P: 0.0117 RunMean : -99.6900\n",
      "Episode: 577 Total reward: -88.0 Training loss: 2.2552 Explore P: 0.0116 RunMean : -99.7800\n",
      "Episode: 578 Total reward: -84.0 Training loss: 1.2780 Explore P: 0.0116 RunMean : -99.9100\n",
      "Episode: 579 Total reward: -82.0 Training loss: 2.4572 Explore P: 0.0116 RunMean : -99.8100\n",
      "Episode: 580 Total reward: -94.0 Training loss: 0.8881 Explore P: 0.0116 RunMean : -99.6200\n",
      "Episode: 581 Total reward: -114.0 Training loss: 2.6433 Explore P: 0.0116 RunMean : -98.8700\n",
      "Episode: 582 Total reward: -90.0 Training loss: 1.4139 Explore P: 0.0116 RunMean : -98.2200\n",
      "Episode: 583 Total reward: -95.0 Training loss: 5.0319 Explore P: 0.0116 RunMean : -98.2900\n",
      "Episode: 584 Total reward: -90.0 Training loss: 2.4564 Explore P: 0.0115 RunMean : -98.2200\n",
      "Episode: 585 Total reward: -116.0 Training loss: 2.9331 Explore P: 0.0115 RunMean : -98.2600\n",
      "Episode: 586 Total reward: -110.0 Training loss: 0.8011 Explore P: 0.0115 RunMean : -98.3000\n",
      "Episode: 587 Total reward: -102.0 Training loss: 2.7248 Explore P: 0.0115 RunMean : -98.3400\n",
      "Episode: 588 Total reward: -117.0 Training loss: 1.2791 Explore P: 0.0115 RunMean : -98.5800\n",
      "Episode: 589 Total reward: -121.0 Training loss: 1.2438 Explore P: 0.0115 RunMean : -98.8800\n",
      "Episode: 590 Total reward: -145.0 Training loss: 1.4454 Explore P: 0.0114 RunMean : -99.1400\n",
      "Episode: 591 Total reward: -124.0 Training loss: 2.0515 Explore P: 0.0114 RunMean : -98.5100\n",
      "Episode: 592 Total reward: -157.0 Training loss: 2.2682 Explore P: 0.0114 RunMean : -99.0500\n",
      "Episode: 593 Total reward: -75.0 Training loss: 1.5712 Explore P: 0.0114 RunMean : -98.8300\n",
      "Episode: 594 Total reward: -84.0 Training loss: 0.7369 Explore P: 0.0114 RunMean : -98.7300\n",
      "Episode: 595 Total reward: -104.0 Training loss: 1.2847 Explore P: 0.0114 RunMean : -98.8800\n",
      "Episode: 596 Total reward: -79.0 Training loss: 1.8339 Explore P: 0.0113 RunMean : -98.3800\n",
      "Episode: 597 Total reward: -83.0 Training loss: 1.0295 Explore P: 0.0113 RunMean : -98.0600\n",
      "Episode: 598 Total reward: -75.0 Training loss: 1.2625 Explore P: 0.0113 RunMean : -97.2800\n",
      "Episode: 599 Total reward: -98.0 Training loss: 1.1586 Explore P: 0.0113 RunMean : -97.0100\n",
      "Episode: 600 Total reward: -102.0 Training loss: 6.1750 Explore P: 0.0113 RunMean : -97.0700\n",
      "Episode: 601 Total reward: -83.0 Training loss: 1.5553 Explore P: 0.0113 RunMean : -96.7300\n",
      "Episode: 602 Total reward: -81.0 Training loss: 3.8356 Explore P: 0.0113 RunMean : -96.8400\n",
      "Episode: 603 Total reward: -131.0 Training loss: 2.0826 Explore P: 0.0113 RunMean : -97.5300\n",
      "Episode: 604 Total reward: -112.0 Training loss: 1.6179 Explore P: 0.0112 RunMean : -97.6300\n",
      "Episode: 605 Total reward: -70.0 Training loss: 1.9686 Explore P: 0.0112 RunMean : -97.5600\n",
      "Episode: 606 Total reward: -115.0 Training loss: 1.9987 Explore P: 0.0112 RunMean : -97.8900\n",
      "Episode: 607 Total reward: -95.0 Training loss: 2.1420 Explore P: 0.0112 RunMean : -98.2100\n",
      "Episode: 608 Total reward: -113.0 Training loss: 2.2022 Explore P: 0.0112 RunMean : -98.4400\n",
      "Episode: 609 Total reward: -85.0 Training loss: 3.1575 Explore P: 0.0112 RunMean : -98.6200\n",
      "Episode: 610 Total reward: -92.0 Training loss: 0.9088 Explore P: 0.0112 RunMean : -98.8000\n",
      "Episode: 611 Total reward: -75.0 Training loss: 2.6691 Explore P: 0.0112 RunMean : -98.5300\n",
      "Episode: 612 Total reward: -91.0 Training loss: 3.9146 Explore P: 0.0112 RunMean : -98.4900\n",
      "Episode: 613 Total reward: -89.0 Training loss: 1.1743 Explore P: 0.0111 RunMean : -98.3400\n",
      "Episode: 614 Total reward: -71.0 Training loss: 1.3832 Explore P: 0.0111 RunMean : -98.3600\n",
      "Episode: 615 Total reward: -81.0 Training loss: 0.8828 Explore P: 0.0111 RunMean : -98.2000\n",
      "Episode: 616 Total reward: -86.0 Training loss: 1.4722 Explore P: 0.0111 RunMean : -98.4300\n",
      "Episode: 617 Total reward: -87.0 Training loss: 1.7209 Explore P: 0.0111 RunMean : -98.4800\n",
      "Episode: 618 Total reward: -103.0 Training loss: 2.4068 Explore P: 0.0111 RunMean : -98.5400\n",
      "Episode: 619 Total reward: -125.0 Training loss: 3.0056 Explore P: 0.0111 RunMean : -98.5700\n",
      "Episode: 620 Total reward: -85.0 Training loss: 0.8056 Explore P: 0.0111 RunMean : -98.5300\n",
      "Episode: 621 Total reward: -123.0 Training loss: 1.2551 Explore P: 0.0111 RunMean : -98.9600\n",
      "Episode: 622 Total reward: -110.0 Training loss: 2.1483 Explore P: 0.0110 RunMean : -98.2600\n",
      "Episode: 623 Total reward: -91.0 Training loss: 1.5091 Explore P: 0.0110 RunMean : -98.0300\n",
      "Episode: 624 Total reward: -63.0 Training loss: 1.1273 Explore P: 0.0110 RunMean : -97.4700\n",
      "Episode: 625 Total reward: -101.0 Training loss: 1.9329 Explore P: 0.0110 RunMean : -97.6200\n",
      "Episode: 626 Total reward: -109.0 Training loss: 1.5086 Explore P: 0.0110 RunMean : -97.6900\n",
      "Episode: 627 Total reward: -177.0 Training loss: 1.3768 Explore P: 0.0110 RunMean : -98.4300\n",
      "Episode: 628 Total reward: -74.0 Training loss: 1.8486 Explore P: 0.0110 RunMean : -98.4300\n",
      "Episode: 629 Total reward: -107.0 Training loss: 2.7907 Explore P: 0.0110 RunMean : -98.4100\n",
      "Episode: 630 Total reward: -111.0 Training loss: 2.8439 Explore P: 0.0110 RunMean : -98.6100\n",
      "Episode: 631 Total reward: -141.0 Training loss: 5.7933 Explore P: 0.0110 RunMean : -98.5900\n",
      "Episode: 632 Total reward: -129.0 Training loss: 2.4742 Explore P: 0.0109 RunMean : -98.7200\n",
      "Episode: 633 Total reward: -62.0 Training loss: 0.9998 Explore P: 0.0109 RunMean : -98.6000\n",
      "Episode: 634 Total reward: -97.0 Training loss: 6.9426 Explore P: 0.0109 RunMean : -98.2600\n",
      "Episode: 635 Total reward: -114.0 Training loss: 1.3457 Explore P: 0.0109 RunMean : -98.5000\n",
      "Episode: 636 Total reward: -183.0 Training loss: 1.0659 Explore P: 0.0109 RunMean : -99.2900\n",
      "Episode: 637 Total reward: -104.0 Training loss: 1.5222 Explore P: 0.0109 RunMean : -99.4900\n",
      "Episode: 638 Total reward: -106.0 Training loss: 0.8999 Explore P: 0.0109 RunMean : -99.3100\n",
      "Episode: 639 Total reward: -80.0 Training loss: 0.8287 Explore P: 0.0109 RunMean : -98.8800\n",
      "Episode: 640 Total reward: -71.0 Training loss: 1.0813 Explore P: 0.0109 RunMean : -98.1900\n",
      "Episode: 641 Total reward: -87.0 Training loss: 1.2412 Explore P: 0.0109 RunMean : -97.9800\n",
      "Episode: 642 Total reward: -109.0 Training loss: 1.4577 Explore P: 0.0108 RunMean : -97.8000\n",
      "Episode: 643 Total reward: -85.0 Training loss: 1.3584 Explore P: 0.0108 RunMean : -97.3900\n",
      "Episode: 644 Total reward: -90.0 Training loss: 1.6465 Explore P: 0.0108 RunMean : -97.1400\n",
      "Episode: 645 Total reward: -82.0 Training loss: 0.9420 Explore P: 0.0108 RunMean : -96.8600\n",
      "Episode: 646 Total reward: -74.0 Training loss: 2.1608 Explore P: 0.0108 RunMean : -96.6500\n",
      "Episode: 647 Total reward: -123.0 Training loss: 3.8216 Explore P: 0.0108 RunMean : -96.7700\n",
      "Episode: 648 Total reward: -91.0 Training loss: 1.4847 Explore P: 0.0108 RunMean : -96.9200\n",
      "Episode: 649 Total reward: -107.0 Training loss: 1.8327 Explore P: 0.0108 RunMean : -97.2300\n",
      "Episode: 650 Total reward: -75.0 Training loss: 2.7392 Explore P: 0.0108 RunMean : -97.1200\n",
      "Episode: 651 Total reward: -109.0 Training loss: 0.9710 Explore P: 0.0108 RunMean : -97.2900\n",
      "Episode: 652 Total reward: -92.0 Training loss: 1.2445 Explore P: 0.0108 RunMean : -97.1900\n",
      "Episode: 653 Total reward: -104.0 Training loss: 5.1327 Explore P: 0.0108 RunMean : -97.1200\n",
      "Episode: 654 Total reward: -86.0 Training loss: 1.3108 Explore P: 0.0108 RunMean : -97.1100\n",
      "Episode: 655 Total reward: -140.0 Training loss: 1.8281 Explore P: 0.0107 RunMean : -97.4400\n",
      "Episode: 656 Total reward: -93.0 Training loss: 1.2392 Explore P: 0.0107 RunMean : -97.3900\n",
      "Episode: 657 Total reward: -90.0 Training loss: 1.2675 Explore P: 0.0107 RunMean : -97.5300\n",
      "Episode: 658 Total reward: -122.0 Training loss: 0.7694 Explore P: 0.0107 RunMean : -97.9100\n",
      "Episode: 659 Total reward: -76.0 Training loss: 1.7973 Explore P: 0.0107 RunMean : -97.7500\n",
      "Episode: 660 Total reward: -87.0 Training loss: 0.6105 Explore P: 0.0107 RunMean : -97.7700\n",
      "Episode: 661 Total reward: -88.0 Training loss: 0.9048 Explore P: 0.0107 RunMean : -97.8300\n",
      "Episode: 662 Total reward: -84.0 Training loss: 1.7607 Explore P: 0.0107 RunMean : -97.8100\n",
      "Episode: 663 Total reward: -78.0 Training loss: 1.2304 Explore P: 0.0107 RunMean : -97.6600\n",
      "Episode: 664 Total reward: -84.0 Training loss: 0.5917 Explore P: 0.0107 RunMean : -97.6400\n",
      "Episode: 665 Total reward: -92.0 Training loss: 1.6689 Explore P: 0.0107 RunMean : -97.4400\n",
      "Episode: 666 Total reward: -87.0 Training loss: 1.0130 Explore P: 0.0107 RunMean : -97.5100\n",
      "Episode: 667 Total reward: -69.0 Training loss: 1.3349 Explore P: 0.0107 RunMean : -97.2600\n",
      "Episode: 668 Total reward: -62.0 Training loss: 1.2945 Explore P: 0.0107 RunMean : -97.0900\n",
      "Episode: 669 Total reward: -94.0 Training loss: 0.9374 Explore P: 0.0107 RunMean : -97.3300\n",
      "Episode: 670 Total reward: -99.0 Training loss: 0.9878 Explore P: 0.0107 RunMean : -97.5800\n",
      "Episode: 671 Total reward: -83.0 Training loss: 0.7915 Explore P: 0.0106 RunMean : -97.5800\n",
      "Episode: 672 Total reward: -69.0 Training loss: 0.9278 Explore P: 0.0106 RunMean : -97.4500\n",
      "Episode: 673 Total reward: -129.0 Training loss: 1.1040 Explore P: 0.0106 RunMean : -97.7700\n",
      "Episode: 674 Total reward: -111.0 Training loss: 0.7987 Explore P: 0.0106 RunMean : -97.6600\n",
      "Episode: 675 Total reward: -81.0 Training loss: 1.0265 Explore P: 0.0106 RunMean : -97.6200\n",
      "Episode: 676 Total reward: -95.0 Training loss: 1.5758 Explore P: 0.0106 RunMean : -97.7900\n",
      "Episode: 677 Total reward: -104.0 Training loss: 1.1053 Explore P: 0.0106 RunMean : -97.9500\n",
      "Episode: 678 Total reward: -131.0 Training loss: 1.8629 Explore P: 0.0106 RunMean : -98.4200\n",
      "Episode: 679 Total reward: -81.0 Training loss: 1.4978 Explore P: 0.0106 RunMean : -98.4100\n",
      "Episode: 680 Total reward: -69.0 Training loss: 0.7589 Explore P: 0.0106 RunMean : -98.1600\n",
      "Episode: 681 Total reward: -121.0 Training loss: 1.7709 Explore P: 0.0106 RunMean : -98.2300\n",
      "Episode: 682 Total reward: -111.0 Training loss: 1.0091 Explore P: 0.0106 RunMean : -98.4400\n",
      "Episode: 683 Total reward: -84.0 Training loss: 1.3026 Explore P: 0.0106 RunMean : -98.3300\n",
      "Episode: 684 Total reward: -90.0 Training loss: 4.8003 Explore P: 0.0106 RunMean : -98.3300\n",
      "Episode: 685 Total reward: -70.0 Training loss: 0.9404 Explore P: 0.0106 RunMean : -97.8700\n",
      "Episode: 686 Total reward: -115.0 Training loss: 1.4774 Explore P: 0.0106 RunMean : -97.9200\n",
      "Episode: 687 Total reward: -139.0 Training loss: 1.5635 Explore P: 0.0106 RunMean : -98.2900\n",
      "Episode: 688 Total reward: -85.0 Training loss: 1.6299 Explore P: 0.0105 RunMean : -97.9700\n",
      "Episode: 689 Total reward: -115.0 Training loss: 0.9302 Explore P: 0.0105 RunMean : -97.9100\n",
      "Episode: 690 Total reward: -74.0 Training loss: 1.3770 Explore P: 0.0105 RunMean : -97.2000\n",
      "Episode: 691 Total reward: -92.0 Training loss: 0.8283 Explore P: 0.0105 RunMean : -96.8800\n",
      "Episode: 692 Total reward: -128.0 Training loss: 2.5217 Explore P: 0.0105 RunMean : -96.5900\n",
      "Episode: 693 Total reward: -100.0 Training loss: 3.0447 Explore P: 0.0105 RunMean : -96.8400\n",
      "Episode: 694 Total reward: -119.0 Training loss: 1.9986 Explore P: 0.0105 RunMean : -97.1900\n",
      "Episode: 695 Total reward: -101.0 Training loss: 4.9312 Explore P: 0.0105 RunMean : -97.1600\n",
      "Episode: 696 Total reward: -98.0 Training loss: 1.5611 Explore P: 0.0105 RunMean : -97.3500\n",
      "Episode: 697 Total reward: -104.0 Training loss: 0.9471 Explore P: 0.0105 RunMean : -97.5600\n",
      "Episode: 698 Total reward: -85.0 Training loss: 1.9878 Explore P: 0.0105 RunMean : -97.6600\n",
      "Episode: 699 Total reward: -85.0 Training loss: 2.0712 Explore P: 0.0105 RunMean : -97.5300\n",
      "Episode: 700 Total reward: -90.0 Training loss: 0.7958 Explore P: 0.0105 RunMean : -97.4100\n",
      "Episode: 701 Total reward: -132.0 Training loss: 1.0259 Explore P: 0.0105 RunMean : -97.9000\n",
      "Episode: 702 Total reward: -76.0 Training loss: 0.8768 Explore P: 0.0105 RunMean : -97.8500\n",
      "Episode: 703 Total reward: -74.0 Training loss: 0.8937 Explore P: 0.0105 RunMean : -97.2800\n",
      "Episode: 704 Total reward: -76.0 Training loss: 1.6504 Explore P: 0.0105 RunMean : -96.9200\n",
      "Episode: 705 Total reward: -117.0 Training loss: 2.2597 Explore P: 0.0105 RunMean : -97.3900\n",
      "Episode: 706 Total reward: -181.0 Training loss: 1.6263 Explore P: 0.0105 RunMean : -98.0500\n",
      "Episode: 707 Total reward: -113.0 Training loss: 0.7181 Explore P: 0.0104 RunMean : -98.2300\n",
      "Episode: 708 Total reward: -85.0 Training loss: 1.3246 Explore P: 0.0104 RunMean : -97.9500\n",
      "Episode: 709 Total reward: -117.0 Training loss: 1.5714 Explore P: 0.0104 RunMean : -98.2700\n",
      "Episode: 710 Total reward: -78.0 Training loss: 5.7492 Explore P: 0.0104 RunMean : -98.1300\n",
      "Episode: 711 Total reward: -85.0 Training loss: 1.3921 Explore P: 0.0104 RunMean : -98.2300\n",
      "Episode: 712 Total reward: -92.0 Training loss: 2.3330 Explore P: 0.0104 RunMean : -98.2400\n",
      "Episode: 713 Total reward: -79.0 Training loss: 2.0079 Explore P: 0.0104 RunMean : -98.1400\n",
      "Episode: 714 Total reward: -105.0 Training loss: 1.6001 Explore P: 0.0104 RunMean : -98.4800\n",
      "Episode: 715 Total reward: -73.0 Training loss: 1.8411 Explore P: 0.0104 RunMean : -98.4000\n",
      "Episode: 716 Total reward: -105.0 Training loss: 1.1988 Explore P: 0.0104 RunMean : -98.5900\n",
      "Episode: 717 Total reward: -89.0 Training loss: 4.8768 Explore P: 0.0104 RunMean : -98.6100\n",
      "Episode: 718 Total reward: -135.0 Training loss: 1.7565 Explore P: 0.0104 RunMean : -98.9300\n",
      "Episode: 719 Total reward: -113.0 Training loss: 1.3971 Explore P: 0.0104 RunMean : -98.8100\n",
      "Episode: 720 Total reward: -112.0 Training loss: 3.0561 Explore P: 0.0104 RunMean : -99.0800\n",
      "Episode: 721 Total reward: -87.0 Training loss: 1.4830 Explore P: 0.0104 RunMean : -98.7200\n",
      "Episode: 722 Total reward: -129.0 Training loss: 1.5632 Explore P: 0.0104 RunMean : -98.9100\n",
      "Episode: 723 Total reward: -72.0 Training loss: 5.1012 Explore P: 0.0104 RunMean : -98.7200\n",
      "Episode: 724 Total reward: -89.0 Training loss: 3.6089 Explore P: 0.0104 RunMean : -98.9800\n",
      "Episode: 725 Total reward: -87.0 Training loss: 3.2770 Explore P: 0.0104 RunMean : -98.8400\n",
      "Episode: 726 Total reward: -142.0 Training loss: 5.2343 Explore P: 0.0104 RunMean : -99.1700\n",
      "Episode: 727 Total reward: -118.0 Training loss: 1.3755 Explore P: 0.0104 RunMean : -98.5800\n",
      "Episode: 728 Total reward: -99.0 Training loss: 3.8706 Explore P: 0.0104 RunMean : -98.8300\n",
      "Episode: 729 Total reward: -104.0 Training loss: 1.1676 Explore P: 0.0104 RunMean : -98.8000\n",
      "Episode: 730 Total reward: -94.0 Training loss: 1.3167 Explore P: 0.0104 RunMean : -98.6300\n",
      "Episode: 731 Total reward: -76.0 Training loss: 0.8419 Explore P: 0.0104 RunMean : -97.9800\n",
      "Episode: 732 Total reward: -117.0 Training loss: 1.0331 Explore P: 0.0103 RunMean : -97.8600\n",
      "Episode: 733 Total reward: -99.0 Training loss: 1.3555 Explore P: 0.0103 RunMean : -98.2300\n",
      "Episode: 734 Total reward: -87.0 Training loss: 3.5562 Explore P: 0.0103 RunMean : -98.1300\n",
      "Episode: 735 Total reward: -93.0 Training loss: 1.6536 Explore P: 0.0103 RunMean : -97.9200\n",
      "Episode: 736 Total reward: -63.0 Training loss: 1.6003 Explore P: 0.0103 RunMean : -96.7200\n",
      "Episode: 737 Total reward: -71.0 Training loss: 1.4423 Explore P: 0.0103 RunMean : -96.3900\n",
      "Episode: 738 Total reward: -85.0 Training loss: 1.9312 Explore P: 0.0103 RunMean : -96.1800\n",
      "Episode: 739 Total reward: -92.0 Training loss: 1.2815 Explore P: 0.0103 RunMean : -96.3000\n",
      "Episode: 740 Total reward: -95.0 Training loss: 2.3835 Explore P: 0.0103 RunMean : -96.5400\n",
      "Episode: 741 Total reward: -89.0 Training loss: 1.6576 Explore P: 0.0103 RunMean : -96.5600\n",
      "Episode: 742 Total reward: -140.0 Training loss: 1.5468 Explore P: 0.0103 RunMean : -96.8700\n",
      "Episode: 743 Total reward: -145.0 Training loss: 1.0035 Explore P: 0.0103 RunMean : -97.4700\n",
      "Episode: 744 Total reward: -108.0 Training loss: 1.6470 Explore P: 0.0103 RunMean : -97.6500\n",
      "Episode: 745 Total reward: -89.0 Training loss: 2.1051 Explore P: 0.0103 RunMean : -97.7200\n",
      "Episode: 746 Total reward: -136.0 Training loss: 3.5526 Explore P: 0.0103 RunMean : -98.3400\n",
      "Episode: 747 Total reward: -106.0 Training loss: 0.9993 Explore P: 0.0103 RunMean : -98.1700\n",
      "Episode: 748 Total reward: -63.0 Training loss: 1.3381 Explore P: 0.0103 RunMean : -97.8900\n",
      "Episode: 749 Total reward: -105.0 Training loss: 0.7839 Explore P: 0.0103 RunMean : -97.8700\n",
      "Episode: 750 Total reward: -94.0 Training loss: 4.6273 Explore P: 0.0103 RunMean : -98.0600\n",
      "Episode: 751 Total reward: -95.0 Training loss: 1.5729 Explore P: 0.0103 RunMean : -97.9200\n",
      "Episode: 752 Total reward: -98.0 Training loss: 2.3232 Explore P: 0.0103 RunMean : -97.9800\n",
      "Episode: 753 Total reward: -128.0 Training loss: 2.4173 Explore P: 0.0103 RunMean : -98.2200\n",
      "Episode: 754 Total reward: -80.0 Training loss: 0.8215 Explore P: 0.0103 RunMean : -98.1600\n",
      "Episode: 755 Total reward: -79.0 Training loss: 0.7028 Explore P: 0.0103 RunMean : -97.5500\n",
      "Episode: 756 Total reward: -75.0 Training loss: 1.2170 Explore P: 0.0103 RunMean : -97.3700\n",
      "Episode: 757 Total reward: -83.0 Training loss: 1.3376 Explore P: 0.0103 RunMean : -97.3000\n",
      "Episode: 758 Total reward: -74.0 Training loss: 2.3420 Explore P: 0.0103 RunMean : -96.8200\n",
      "Episode: 759 Total reward: -87.0 Training loss: 3.6882 Explore P: 0.0103 RunMean : -96.9300\n",
      "Episode: 760 Total reward: -82.0 Training loss: 2.5889 Explore P: 0.0103 RunMean : -96.8800\n",
      "Episode: 761 Total reward: -75.0 Training loss: 1.3747 Explore P: 0.0103 RunMean : -96.7500\n",
      "Episode: 762 Total reward: -115.0 Training loss: 1.9403 Explore P: 0.0103 RunMean : -97.0600\n",
      "Episode: 763 Total reward: -84.0 Training loss: 4.3396 Explore P: 0.0103 RunMean : -97.1200\n",
      "Episode: 764 Total reward: -126.0 Training loss: 2.6275 Explore P: 0.0103 RunMean : -97.5400\n",
      "Episode: 765 Total reward: -126.0 Training loss: 5.9748 Explore P: 0.0103 RunMean : -97.8800\n",
      "Episode: 766 Total reward: -128.0 Training loss: 0.9145 Explore P: 0.0103 RunMean : -98.2900\n",
      "Episode: 767 Total reward: -83.0 Training loss: 1.4699 Explore P: 0.0102 RunMean : -98.4300\n",
      "Episode: 768 Total reward: -116.0 Training loss: 5.9128 Explore P: 0.0102 RunMean : -98.9700\n",
      "Episode: 769 Total reward: -69.0 Training loss: 0.7966 Explore P: 0.0102 RunMean : -98.7200\n",
      "Episode: 770 Total reward: -81.0 Training loss: 2.1418 Explore P: 0.0102 RunMean : -98.5400\n",
      "Episode: 771 Total reward: -75.0 Training loss: 8.8458 Explore P: 0.0102 RunMean : -98.4600\n",
      "Episode: 772 Total reward: -81.0 Training loss: 1.5520 Explore P: 0.0102 RunMean : -98.5800\n",
      "Episode: 773 Total reward: -81.0 Training loss: 1.3048 Explore P: 0.0102 RunMean : -98.1000\n",
      "Episode: 774 Total reward: -84.0 Training loss: 2.4107 Explore P: 0.0102 RunMean : -97.8300\n",
      "Episode: 775 Total reward: -184.0 Training loss: 1.0782 Explore P: 0.0102 RunMean : -98.8600\n",
      "Episode: 776 Total reward: -69.0 Training loss: 2.9300 Explore P: 0.0102 RunMean : -98.6000\n",
      "Episode: 777 Total reward: -119.0 Training loss: 5.7262 Explore P: 0.0102 RunMean : -98.7500\n",
      "Episode: 778 Total reward: -95.0 Training loss: 1.2513 Explore P: 0.0102 RunMean : -98.3900\n",
      "Episode: 779 Total reward: -63.0 Training loss: 2.8241 Explore P: 0.0102 RunMean : -98.2100\n",
      "Episode: 780 Total reward: -90.0 Training loss: 1.4423 Explore P: 0.0102 RunMean : -98.4200\n",
      "Episode: 781 Total reward: -63.0 Training loss: 4.3630 Explore P: 0.0102 RunMean : -97.8400\n",
      "Episode: 782 Total reward: -111.0 Training loss: 1.0080 Explore P: 0.0102 RunMean : -97.8400\n",
      "Episode: 783 Total reward: -102.0 Training loss: 2.7462 Explore P: 0.0102 RunMean : -98.0200\n",
      "Episode: 784 Total reward: -108.0 Training loss: 1.1989 Explore P: 0.0102 RunMean : -98.2000\n",
      "Episode: 785 Total reward: -115.0 Training loss: 1.1494 Explore P: 0.0102 RunMean : -98.6500\n",
      "Episode: 786 Total reward: -107.0 Training loss: 1.6924 Explore P: 0.0102 RunMean : -98.5700\n",
      "Episode: 787 Total reward: -101.0 Training loss: 1.9009 Explore P: 0.0102 RunMean : -98.1900\n",
      "Episode: 788 Total reward: -112.0 Training loss: 0.9457 Explore P: 0.0102 RunMean : -98.4600\n",
      "Episode: 789 Total reward: -114.0 Training loss: 1.4187 Explore P: 0.0102 RunMean : -98.4500\n",
      "Episode: 790 Total reward: -91.0 Training loss: 2.3693 Explore P: 0.0102 RunMean : -98.6200\n",
      "Episode: 791 Total reward: -85.0 Training loss: 1.4732 Explore P: 0.0102 RunMean : -98.5500\n",
      "Episode: 792 Total reward: -101.0 Training loss: 1.1581 Explore P: 0.0102 RunMean : -98.2800\n",
      "Episode: 793 Total reward: -123.0 Training loss: 1.6695 Explore P: 0.0102 RunMean : -98.5100\n",
      "Episode: 794 Total reward: -108.0 Training loss: 1.2402 Explore P: 0.0102 RunMean : -98.4000\n",
      "Episode: 795 Total reward: -121.0 Training loss: 2.0051 Explore P: 0.0102 RunMean : -98.6000\n",
      "Episode: 796 Total reward: -78.0 Training loss: 1.2974 Explore P: 0.0102 RunMean : -98.4000\n",
      "Episode: 797 Total reward: -139.0 Training loss: 0.9937 Explore P: 0.0102 RunMean : -98.7500\n",
      "Episode: 798 Total reward: -102.0 Training loss: 1.0722 Explore P: 0.0102 RunMean : -98.9200\n",
      "Episode: 799 Total reward: -91.0 Training loss: 1.6243 Explore P: 0.0102 RunMean : -98.9800\n",
      "Episode: 800 Total reward: -90.0 Training loss: 3.8635 Explore P: 0.0102 RunMean : -98.9800\n",
      "Episode: 801 Total reward: -95.0 Training loss: 0.5919 Explore P: 0.0102 RunMean : -98.6100\n",
      "Episode: 802 Total reward: -104.0 Training loss: 2.9904 Explore P: 0.0102 RunMean : -98.8900\n",
      "Episode: 803 Total reward: -71.0 Training loss: 1.9215 Explore P: 0.0102 RunMean : -98.8600\n",
      "Episode: 804 Total reward: -74.0 Training loss: 1.1874 Explore P: 0.0102 RunMean : -98.8400\n",
      "Episode: 805 Total reward: -116.0 Training loss: 1.4150 Explore P: 0.0102 RunMean : -98.8300\n",
      "Episode: 806 Total reward: -71.0 Training loss: 2.9878 Explore P: 0.0102 RunMean : -97.7300\n",
      "Episode: 807 Total reward: -89.0 Training loss: 1.1727 Explore P: 0.0102 RunMean : -97.4900\n",
      "Episode: 808 Total reward: -79.0 Training loss: 1.0377 Explore P: 0.0102 RunMean : -97.4300\n",
      "Episode: 809 Total reward: -99.0 Training loss: 1.2086 Explore P: 0.0102 RunMean : -97.2500\n",
      "Episode: 810 Total reward: -91.0 Training loss: 1.3395 Explore P: 0.0102 RunMean : -97.3800\n",
      "Episode: 811 Total reward: -75.0 Training loss: 1.0475 Explore P: 0.0102 RunMean : -97.2800\n",
      "Episode: 812 Total reward: -108.0 Training loss: 1.2289 Explore P: 0.0102 RunMean : -97.4400\n",
      "Episode: 813 Total reward: -95.0 Training loss: 1.4509 Explore P: 0.0102 RunMean : -97.6000\n",
      "Episode: 814 Total reward: -126.0 Training loss: 1.7371 Explore P: 0.0102 RunMean : -97.8100\n",
      "Episode: 815 Total reward: -104.0 Training loss: 1.3122 Explore P: 0.0102 RunMean : -98.1200\n",
      "Episode: 816 Total reward: -86.0 Training loss: 1.4088 Explore P: 0.0102 RunMean : -97.9300\n",
      "Episode: 817 Total reward: -99.0 Training loss: 4.8878 Explore P: 0.0102 RunMean : -98.0300\n",
      "Episode: 818 Total reward: -83.0 Training loss: 1.0461 Explore P: 0.0102 RunMean : -97.5100\n",
      "Episode: 819 Total reward: -94.0 Training loss: 1.2424 Explore P: 0.0101 RunMean : -97.3200\n",
      "Episode: 820 Total reward: -93.0 Training loss: 2.6246 Explore P: 0.0101 RunMean : -97.1300\n",
      "Episode: 821 Total reward: -76.0 Training loss: 3.3403 Explore P: 0.0101 RunMean : -97.0200\n",
      "Episode: 822 Total reward: -136.0 Training loss: 1.4256 Explore P: 0.0101 RunMean : -97.0900\n",
      "Episode: 823 Total reward: -132.0 Training loss: 1.4260 Explore P: 0.0101 RunMean : -97.6900\n",
      "Episode: 824 Total reward: -70.0 Training loss: 1.3769 Explore P: 0.0101 RunMean : -97.5000\n",
      "Episode: 825 Total reward: -63.0 Training loss: 0.9437 Explore P: 0.0101 RunMean : -97.2600\n",
      "Episode: 826 Total reward: -194.0 Training loss: 0.8751 Explore P: 0.0101 RunMean : -97.7800\n",
      "Episode: 827 Total reward: -118.0 Training loss: 2.2727 Explore P: 0.0101 RunMean : -97.7800\n",
      "Episode: 828 Total reward: -89.0 Training loss: 2.3958 Explore P: 0.0101 RunMean : -97.6800\n",
      "Episode: 829 Total reward: -77.0 Training loss: 0.7431 Explore P: 0.0101 RunMean : -97.4100\n",
      "Episode: 830 Total reward: -93.0 Training loss: 1.9816 Explore P: 0.0101 RunMean : -97.4000\n",
      "Episode: 831 Total reward: -74.0 Training loss: 1.3265 Explore P: 0.0101 RunMean : -97.3800\n",
      "Episode: 832 Total reward: -81.0 Training loss: 2.0361 Explore P: 0.0101 RunMean : -97.0200\n",
      "Episode: 833 Total reward: -91.0 Training loss: 1.3350 Explore P: 0.0101 RunMean : -96.9400\n",
      "Episode: 834 Total reward: -96.0 Training loss: 2.0165 Explore P: 0.0101 RunMean : -97.0300\n",
      "Episode: 835 Total reward: -115.0 Training loss: 1.5629 Explore P: 0.0101 RunMean : -97.2500\n",
      "Episode: 836 Total reward: -93.0 Training loss: 1.7992 Explore P: 0.0101 RunMean : -97.5500\n",
      "Episode: 837 Total reward: -107.0 Training loss: 1.6680 Explore P: 0.0101 RunMean : -97.9100\n",
      "Episode: 838 Total reward: -119.0 Training loss: 2.4685 Explore P: 0.0101 RunMean : -98.2500\n",
      "Episode: 839 Total reward: -84.0 Training loss: 1.0987 Explore P: 0.0101 RunMean : -98.1700\n",
      "Episode: 840 Total reward: -104.0 Training loss: 2.0897 Explore P: 0.0101 RunMean : -98.2600\n",
      "Episode: 841 Total reward: -69.0 Training loss: 2.4443 Explore P: 0.0101 RunMean : -98.0600\n",
      "Episode: 842 Total reward: -117.0 Training loss: 1.1635 Explore P: 0.0101 RunMean : -97.8300\n",
      "Episode: 843 Total reward: -76.0 Training loss: 1.2436 Explore P: 0.0101 RunMean : -97.1400\n",
      "Episode: 844 Total reward: -87.0 Training loss: 1.1698 Explore P: 0.0101 RunMean : -96.9300\n",
      "Episode: 845 Total reward: -96.0 Training loss: 2.2235 Explore P: 0.0101 RunMean : -97.0000\n",
      "Episode: 846 Total reward: -83.0 Training loss: 0.9483 Explore P: 0.0101 RunMean : -96.4700\n",
      "Episode: 847 Total reward: -87.0 Training loss: 1.6644 Explore P: 0.0101 RunMean : -96.2800\n",
      "Episode: 848 Total reward: -70.0 Training loss: 1.0155 Explore P: 0.0101 RunMean : -96.3500\n",
      "Episode: 849 Total reward: -125.0 Training loss: 2.0078 Explore P: 0.0101 RunMean : -96.5500\n",
      "Episode: 850 Total reward: -78.0 Training loss: 1.2801 Explore P: 0.0101 RunMean : -96.3900\n",
      "Episode: 851 Total reward: -69.0 Training loss: 1.2640 Explore P: 0.0101 RunMean : -96.1300\n",
      "Episode: 852 Total reward: -90.0 Training loss: 1.7618 Explore P: 0.0101 RunMean : -96.0500\n",
      "Episode: 853 Total reward: -115.0 Training loss: 0.9794 Explore P: 0.0101 RunMean : -95.9200\n",
      "Episode: 854 Total reward: -222.0 Training loss: 1.1992 Explore P: 0.0101 RunMean : -97.3400\n",
      "Episode: 855 Total reward: -71.0 Training loss: 1.2771 Explore P: 0.0101 RunMean : -97.2600\n",
      "Episode: 856 Total reward: -62.0 Training loss: 1.5803 Explore P: 0.0101 RunMean : -97.1300\n",
      "Episode: 857 Total reward: -147.0 Training loss: 4.8665 Explore P: 0.0101 RunMean : -97.7700\n",
      "Episode: 858 Total reward: -99.0 Training loss: 2.6413 Explore P: 0.0101 RunMean : -98.0200\n",
      "Episode: 859 Total reward: -86.0 Training loss: 1.6627 Explore P: 0.0101 RunMean : -98.0100\n",
      "Episode: 860 Total reward: -85.0 Training loss: 1.5511 Explore P: 0.0101 RunMean : -98.0400\n",
      "Episode: 861 Total reward: -68.0 Training loss: 2.4901 Explore P: 0.0101 RunMean : -97.9700\n",
      "Episode: 862 Total reward: -193.0 Training loss: 4.6952 Explore P: 0.0101 RunMean : -98.7500\n",
      "Episode: 863 Total reward: -71.0 Training loss: 1.2790 Explore P: 0.0101 RunMean : -98.6200\n",
      "Episode: 864 Total reward: -115.0 Training loss: 1.9866 Explore P: 0.0101 RunMean : -98.5100\n",
      "Episode: 865 Total reward: -94.0 Training loss: 1.3252 Explore P: 0.0101 RunMean : -98.1900\n",
      "Episode: 866 Total reward: -134.0 Training loss: 1.8314 Explore P: 0.0101 RunMean : -98.2500\n",
      "Episode: 867 Total reward: -124.0 Training loss: 3.2607 Explore P: 0.0101 RunMean : -98.6600\n",
      "Episode: 868 Total reward: -138.0 Training loss: 1.2663 Explore P: 0.0101 RunMean : -98.8800\n",
      "Episode: 869 Total reward: -116.0 Training loss: 2.5516 Explore P: 0.0101 RunMean : -99.3500\n",
      "Episode: 870 Total reward: -96.0 Training loss: 5.2294 Explore P: 0.0101 RunMean : -99.5000\n",
      "Episode: 871 Total reward: -89.0 Training loss: 1.3395 Explore P: 0.0101 RunMean : -99.6400\n",
      "Episode: 872 Total reward: -62.0 Training loss: 0.8774 Explore P: 0.0101 RunMean : -99.4500\n",
      "Episode: 873 Total reward: -79.0 Training loss: 0.8633 Explore P: 0.0101 RunMean : -99.4300\n",
      "Episode: 874 Total reward: -88.0 Training loss: 1.6070 Explore P: 0.0101 RunMean : -99.4700\n",
      "Episode: 875 Total reward: -113.0 Training loss: 1.0418 Explore P: 0.0101 RunMean : -98.7600\n",
      "Episode: 876 Total reward: -86.0 Training loss: 1.3911 Explore P: 0.0101 RunMean : -98.9300\n",
      "Episode: 877 Total reward: -86.0 Training loss: 1.0422 Explore P: 0.0101 RunMean : -98.6000\n",
      "Episode: 878 Total reward: -83.0 Training loss: 1.7075 Explore P: 0.0101 RunMean : -98.4800\n",
      "Episode: 879 Total reward: -92.0 Training loss: 1.8824 Explore P: 0.0101 RunMean : -98.7700\n",
      "Episode: 880 Total reward: -82.0 Training loss: 2.1456 Explore P: 0.0101 RunMean : -98.6900\n",
      "Episode: 881 Total reward: -145.0 Training loss: 2.0431 Explore P: 0.0101 RunMean : -99.5100\n",
      "Episode: 882 Total reward: -142.0 Training loss: 3.3182 Explore P: 0.0101 RunMean : -99.8200\n",
      "Episode: 883 Total reward: -98.0 Training loss: 1.7747 Explore P: 0.0101 RunMean : -99.7800\n",
      "Episode: 884 Total reward: -95.0 Training loss: 0.8898 Explore P: 0.0101 RunMean : -99.6500\n",
      "Episode: 885 Total reward: -106.0 Training loss: 0.8422 Explore P: 0.0101 RunMean : -99.5600\n",
      "Episode: 886 Total reward: -112.0 Training loss: 4.2968 Explore P: 0.0101 RunMean : -99.6100\n",
      "Episode: 887 Total reward: -71.0 Training loss: 4.5500 Explore P: 0.0101 RunMean : -99.3100\n",
      "Episode: 888 Total reward: -133.0 Training loss: 2.5081 Explore P: 0.0101 RunMean : -99.5200\n",
      "Episode: 889 Total reward: -113.0 Training loss: 1.8347 Explore P: 0.0101 RunMean : -99.5100\n",
      "Episode: 890 Total reward: -78.0 Training loss: 1.4142 Explore P: 0.0101 RunMean : -99.3800\n",
      "Episode: 891 Total reward: -112.0 Training loss: 1.1309 Explore P: 0.0101 RunMean : -99.6500\n",
      "Episode: 892 Total reward: -76.0 Training loss: 3.5280 Explore P: 0.0101 RunMean : -99.4000\n",
      "Episode: 893 Total reward: -97.0 Training loss: 2.9949 Explore P: 0.0101 RunMean : -99.1400\n",
      "Episode: 894 Total reward: -83.0 Training loss: 1.6865 Explore P: 0.0101 RunMean : -98.8900\n",
      "Episode: 895 Total reward: -142.0 Training loss: 1.5829 Explore P: 0.0101 RunMean : -99.1000\n",
      "Episode: 896 Total reward: -116.0 Training loss: 1.2753 Explore P: 0.0101 RunMean : -99.4800\n",
      "Episode: 897 Total reward: -84.0 Training loss: 2.6352 Explore P: 0.0101 RunMean : -98.9300\n",
      "Episode: 898 Total reward: -168.0 Training loss: 1.6298 Explore P: 0.0101 RunMean : -99.5900\n",
      "Episode: 899 Total reward: -72.0 Training loss: 2.4208 Explore P: 0.0101 RunMean : -99.4000\n",
      "Episode: 900 Total reward: -85.0 Training loss: 2.0743 Explore P: 0.0101 RunMean : -99.3500\n",
      "Episode: 901 Total reward: -74.0 Training loss: 3.5106 Explore P: 0.0101 RunMean : -99.1400\n",
      "Episode: 902 Total reward: -95.0 Training loss: 2.2476 Explore P: 0.0101 RunMean : -99.0500\n",
      "Episode: 903 Total reward: -74.0 Training loss: 1.8788 Explore P: 0.0101 RunMean : -99.0800\n",
      "Episode: 904 Total reward: -74.0 Training loss: 1.8543 Explore P: 0.0101 RunMean : -99.0800\n",
      "Episode: 905 Total reward: -70.0 Training loss: 0.9626 Explore P: 0.0101 RunMean : -98.6200\n",
      "Episode: 906 Total reward: -74.0 Training loss: 1.5759 Explore P: 0.0101 RunMean : -98.6500\n",
      "Episode: 907 Total reward: -69.0 Training loss: 0.9067 Explore P: 0.0101 RunMean : -98.4500\n",
      "Episode: 908 Total reward: -87.0 Training loss: 1.3553 Explore P: 0.0101 RunMean : -98.5300\n",
      "Episode: 909 Total reward: -79.0 Training loss: 1.2404 Explore P: 0.0101 RunMean : -98.3300\n",
      "Episode: 910 Total reward: -81.0 Training loss: 0.7189 Explore P: 0.0101 RunMean : -98.2300\n",
      "Episode: 911 Total reward: -95.0 Training loss: 1.3432 Explore P: 0.0101 RunMean : -98.4300\n",
      "Episode: 912 Total reward: -70.0 Training loss: 1.7675 Explore P: 0.0101 RunMean : -98.0500\n",
      "Episode: 913 Total reward: -81.0 Training loss: 2.2573 Explore P: 0.0101 RunMean : -97.9100\n",
      "Episode: 914 Total reward: -84.0 Training loss: 0.9021 Explore P: 0.0101 RunMean : -97.4900\n",
      "Episode: 915 Total reward: -87.0 Training loss: 0.7510 Explore P: 0.0101 RunMean : -97.3200\n",
      "Episode: 916 Total reward: -86.0 Training loss: 1.4856 Explore P: 0.0101 RunMean : -97.3200\n",
      "Episode: 917 Total reward: -82.0 Training loss: 4.3581 Explore P: 0.0101 RunMean : -97.1500\n",
      "Episode: 918 Total reward: -98.0 Training loss: 1.9089 Explore P: 0.0101 RunMean : -97.3000\n",
      "Episode: 919 Total reward: -78.0 Training loss: 1.2553 Explore P: 0.0101 RunMean : -97.1400\n",
      "Episode: 920 Total reward: -80.0 Training loss: 3.5436 Explore P: 0.0101 RunMean : -97.0100\n",
      "Episode: 921 Total reward: -80.0 Training loss: 1.2954 Explore P: 0.0101 RunMean : -97.0500\n",
      "Episode: 922 Total reward: -102.0 Training loss: 0.8575 Explore P: 0.0101 RunMean : -96.7100\n",
      "Episode: 923 Total reward: -94.0 Training loss: 3.7672 Explore P: 0.0101 RunMean : -96.3300\n",
      "Episode: 924 Total reward: -114.0 Training loss: 1.2254 Explore P: 0.0101 RunMean : -96.7700\n",
      "Episode: 925 Total reward: -76.0 Training loss: 1.6008 Explore P: 0.0101 RunMean : -96.9000\n",
      "Episode: 926 Total reward: -92.0 Training loss: 1.1962 Explore P: 0.0101 RunMean : -95.8800\n",
      "Episode: 927 Total reward: -89.0 Training loss: 2.1770 Explore P: 0.0101 RunMean : -95.5900\n",
      "Episode: 928 Total reward: -106.0 Training loss: 1.7490 Explore P: 0.0101 RunMean : -95.7600\n",
      "Episode: 929 Total reward: -109.0 Training loss: 1.6301 Explore P: 0.0101 RunMean : -96.0800\n",
      "Episode: 930 Total reward: -72.0 Training loss: 1.1993 Explore P: 0.0101 RunMean : -95.8700\n",
      "Episode: 931 Total reward: -84.0 Training loss: 2.4342 Explore P: 0.0101 RunMean : -95.9700\n",
      "Episode: 932 Total reward: -102.0 Training loss: 4.9875 Explore P: 0.0100 RunMean : -96.1800\n",
      "Episode: 933 Total reward: -106.0 Training loss: 1.6790 Explore P: 0.0100 RunMean : -96.3300\n",
      "Episode: 934 Total reward: -83.0 Training loss: 1.4011 Explore P: 0.0100 RunMean : -96.2000\n",
      "Episode: 935 Total reward: -115.0 Training loss: 2.0793 Explore P: 0.0100 RunMean : -96.2000\n",
      "Episode: 936 Total reward: -89.0 Training loss: 1.3542 Explore P: 0.0100 RunMean : -96.1600\n",
      "Episode: 937 Total reward: -134.0 Training loss: 1.6414 Explore P: 0.0100 RunMean : -96.4300\n",
      "Episode: 938 Total reward: -92.0 Training loss: 2.4302 Explore P: 0.0100 RunMean : -96.1600\n",
      "Episode: 939 Total reward: -83.0 Training loss: 0.8417 Explore P: 0.0100 RunMean : -96.1500\n",
      "Episode: 940 Total reward: -70.0 Training loss: 1.8568 Explore P: 0.0100 RunMean : -95.8100\n",
      "Episode: 941 Total reward: -99.0 Training loss: 0.9573 Explore P: 0.0100 RunMean : -96.1100\n",
      "Episode: 942 Total reward: -82.0 Training loss: 0.5644 Explore P: 0.0100 RunMean : -95.7600\n",
      "Episode: 943 Total reward: -75.0 Training loss: 2.1269 Explore P: 0.0100 RunMean : -95.7500\n",
      "Episode: 944 Total reward: -93.0 Training loss: 0.5815 Explore P: 0.0100 RunMean : -95.8100\n",
      "Episode: 945 Total reward: -108.0 Training loss: 0.9580 Explore P: 0.0100 RunMean : -95.9300\n",
      "Episode: 946 Total reward: -76.0 Training loss: 2.0040 Explore P: 0.0100 RunMean : -95.8600\n",
      "Episode: 947 Total reward: -89.0 Training loss: 1.0577 Explore P: 0.0100 RunMean : -95.8800\n",
      "Episode: 948 Total reward: -77.0 Training loss: 1.4333 Explore P: 0.0100 RunMean : -95.9500\n",
      "Episode: 949 Total reward: -97.0 Training loss: 1.4228 Explore P: 0.0100 RunMean : -95.6700\n",
      "Episode: 950 Total reward: -80.0 Training loss: 1.5229 Explore P: 0.0100 RunMean : -95.6900\n",
      "Episode: 951 Total reward: -110.0 Training loss: 0.9188 Explore P: 0.0100 RunMean : -96.1000\n",
      "Episode: 952 Total reward: -62.0 Training loss: 1.8080 Explore P: 0.0100 RunMean : -95.8200\n",
      "Episode: 953 Total reward: -95.0 Training loss: 2.1179 Explore P: 0.0100 RunMean : -95.6200\n",
      "Episode: 954 Total reward: -81.0 Training loss: 1.9252 Explore P: 0.0100 RunMean : -94.2100\n",
      "Episode: 955 Total reward: -132.0 Training loss: 3.1208 Explore P: 0.0100 RunMean : -94.8200\n",
      "Episode: 956 Total reward: -100.0 Training loss: 3.2178 Explore P: 0.0100 RunMean : -95.2000\n",
      "Episode: 957 Total reward: -131.0 Training loss: 1.2704 Explore P: 0.0100 RunMean : -95.0400\n",
      "Episode: 958 Total reward: -91.0 Training loss: 0.8156 Explore P: 0.0100 RunMean : -94.9600\n",
      "Episode: 959 Total reward: -131.0 Training loss: 1.5528 Explore P: 0.0100 RunMean : -95.4100\n",
      "Episode: 960 Total reward: -94.0 Training loss: 1.2868 Explore P: 0.0100 RunMean : -95.5000\n",
      "Episode: 961 Total reward: -63.0 Training loss: 5.5841 Explore P: 0.0100 RunMean : -95.4500\n",
      "Episode: 962 Total reward: -73.0 Training loss: 2.2498 Explore P: 0.0100 RunMean : -94.2500\n",
      "Episode: 963 Total reward: -78.0 Training loss: 1.4979 Explore P: 0.0100 RunMean : -94.3200\n",
      "Episode: 964 Total reward: -92.0 Training loss: 2.5525 Explore P: 0.0100 RunMean : -94.0900\n",
      "Episode: 965 Total reward: -83.0 Training loss: 1.7103 Explore P: 0.0100 RunMean : -93.9800\n",
      "Episode: 966 Total reward: -87.0 Training loss: 1.2072 Explore P: 0.0100 RunMean : -93.5100\n",
      "Episode: 967 Total reward: -86.0 Training loss: 0.9905 Explore P: 0.0100 RunMean : -93.1300\n",
      "Episode: 968 Total reward: -93.0 Training loss: 1.0809 Explore P: 0.0100 RunMean : -92.6800\n",
      "Episode: 969 Total reward: -113.0 Training loss: 1.9585 Explore P: 0.0100 RunMean : -92.6500\n",
      "Episode: 970 Total reward: -97.0 Training loss: 2.4908 Explore P: 0.0100 RunMean : -92.6600\n",
      "Episode: 971 Total reward: -138.0 Training loss: 2.1099 Explore P: 0.0100 RunMean : -93.1500\n",
      "Episode: 972 Total reward: -177.0 Training loss: 2.7305 Explore P: 0.0100 RunMean : -94.3000\n",
      "Episode: 973 Total reward: -62.0 Training loss: 2.9100 Explore P: 0.0100 RunMean : -94.1300\n",
      "Episode: 974 Total reward: -81.0 Training loss: 1.1741 Explore P: 0.0100 RunMean : -94.0600\n",
      "Episode: 975 Total reward: -68.0 Training loss: 2.4221 Explore P: 0.0100 RunMean : -93.6100\n",
      "Episode: 976 Total reward: -81.0 Training loss: 0.8995 Explore P: 0.0100 RunMean : -93.5600\n",
      "Episode: 977 Total reward: -83.0 Training loss: 1.0114 Explore P: 0.0100 RunMean : -93.5300\n",
      "Episode: 978 Total reward: -82.0 Training loss: 1.1765 Explore P: 0.0100 RunMean : -93.5200\n",
      "Episode: 979 Total reward: -92.0 Training loss: 1.3042 Explore P: 0.0100 RunMean : -93.5200\n",
      "Episode: 980 Total reward: -102.0 Training loss: 1.1996 Explore P: 0.0100 RunMean : -93.7200\n",
      "Episode: 981 Total reward: -110.0 Training loss: 1.0052 Explore P: 0.0100 RunMean : -93.3700\n",
      "Episode: 982 Total reward: -96.0 Training loss: 1.8899 Explore P: 0.0100 RunMean : -92.9100\n",
      "Episode: 983 Total reward: -83.0 Training loss: 0.7219 Explore P: 0.0100 RunMean : -92.7600\n",
      "Episode: 984 Total reward: -69.0 Training loss: 1.7270 Explore P: 0.0100 RunMean : -92.5000\n",
      "Episode: 985 Total reward: -103.0 Training loss: 1.2041 Explore P: 0.0100 RunMean : -92.4700\n",
      "Episode: 986 Total reward: -69.0 Training loss: 1.2464 Explore P: 0.0100 RunMean : -92.0400\n",
      "Episode: 987 Total reward: -79.0 Training loss: 1.2031 Explore P: 0.0100 RunMean : -92.1200\n",
      "Episode: 988 Total reward: -124.0 Training loss: 1.9729 Explore P: 0.0100 RunMean : -92.0300\n",
      "Episode: 989 Total reward: -182.0 Training loss: 3.5007 Explore P: 0.0100 RunMean : -92.7200\n",
      "Episode: 990 Total reward: -121.0 Training loss: 1.8478 Explore P: 0.0100 RunMean : -93.1500\n",
      "Episode: 991 Total reward: -100.0 Training loss: 0.7933 Explore P: 0.0100 RunMean : -93.0300\n",
      "Episode: 992 Total reward: -174.0 Training loss: 1.5207 Explore P: 0.0100 RunMean : -94.0100\n",
      "Episode: 993 Total reward: -108.0 Training loss: 4.4677 Explore P: 0.0100 RunMean : -94.1200\n",
      "Episode: 994 Total reward: -99.0 Training loss: 4.4408 Explore P: 0.0100 RunMean : -94.2800\n",
      "Episode: 995 Total reward: -91.0 Training loss: 1.1470 Explore P: 0.0100 RunMean : -93.7700\n",
      "Episode: 996 Total reward: -70.0 Training loss: 0.8778 Explore P: 0.0100 RunMean : -93.3100\n",
      "Episode: 997 Total reward: -95.0 Training loss: 1.6447 Explore P: 0.0100 RunMean : -93.4200\n",
      "Episode: 998 Total reward: -62.0 Training loss: 2.2572 Explore P: 0.0100 RunMean : -92.3600\n",
      "Episode: 999 Total reward: -86.0 Training loss: 1.1656 Explore P: 0.0100 RunMean : -92.5000\n",
      "Episode: 1000 Total reward: -99.0 Training loss: 1.1357 Explore P: 0.0100 RunMean : -92.6400\n",
      "Episode: 1001 Total reward: -86.0 Training loss: 1.7907 Explore P: 0.0100 RunMean : -92.7600\n",
      "Episode: 1002 Total reward: -104.0 Training loss: 3.6178 Explore P: 0.0100 RunMean : -92.8500\n",
      "Episode: 1003 Total reward: -111.0 Training loss: 2.1344 Explore P: 0.0100 RunMean : -93.2200\n",
      "Episode: 1004 Total reward: -70.0 Training loss: 1.8853 Explore P: 0.0100 RunMean : -93.1800\n",
      "Episode: 1005 Total reward: -88.0 Training loss: 2.4447 Explore P: 0.0100 RunMean : -93.3600\n",
      "Episode: 1006 Total reward: -112.0 Training loss: 2.5540 Explore P: 0.0100 RunMean : -93.7400\n",
      "Episode: 1007 Total reward: -158.0 Training loss: 1.1735 Explore P: 0.0100 RunMean : -94.6300\n",
      "Episode: 1008 Total reward: -66.0 Training loss: 1.2113 Explore P: 0.0100 RunMean : -94.4200\n",
      "Episode: 1009 Total reward: -76.0 Training loss: 2.4064 Explore P: 0.0100 RunMean : -94.3900\n",
      "Episode: 1010 Total reward: -86.0 Training loss: 1.0621 Explore P: 0.0100 RunMean : -94.4400\n",
      "Episode: 1011 Total reward: -120.0 Training loss: 1.3164 Explore P: 0.0100 RunMean : -94.6900\n",
      "Episode: 1012 Total reward: -170.0 Training loss: 1.6133 Explore P: 0.0100 RunMean : -95.6900\n",
      "Episode: 1013 Total reward: -131.0 Training loss: 0.8266 Explore P: 0.0100 RunMean : -96.1900\n",
      "Episode: 1014 Total reward: -104.0 Training loss: 5.6555 Explore P: 0.0100 RunMean : -96.3900\n",
      "Episode: 1015 Total reward: -125.0 Training loss: 2.1968 Explore P: 0.0100 RunMean : -96.7700\n",
      "Episode: 1016 Total reward: -98.0 Training loss: 1.6438 Explore P: 0.0100 RunMean : -96.8900\n",
      "Episode: 1017 Total reward: -76.0 Training loss: 2.3442 Explore P: 0.0100 RunMean : -96.8300\n",
      "Episode: 1018 Total reward: -86.0 Training loss: 1.3190 Explore P: 0.0100 RunMean : -96.7100\n",
      "Episode: 1019 Total reward: -88.0 Training loss: 1.4059 Explore P: 0.0100 RunMean : -96.8100\n",
      "Episode: 1020 Total reward: -62.0 Training loss: 0.8474 Explore P: 0.0100 RunMean : -96.6300\n",
      "Episode: 1021 Total reward: -70.0 Training loss: 4.9454 Explore P: 0.0100 RunMean : -96.5300\n",
      "Episode: 1022 Total reward: -203.0 Training loss: 1.3231 Explore P: 0.0100 RunMean : -97.5400\n",
      "Episode: 1023 Total reward: -95.0 Training loss: 1.3285 Explore P: 0.0100 RunMean : -97.5500\n",
      "Episode: 1024 Total reward: -88.0 Training loss: 1.0562 Explore P: 0.0100 RunMean : -97.2900\n",
      "Episode: 1025 Total reward: -78.0 Training loss: 1.3304 Explore P: 0.0100 RunMean : -97.3100\n",
      "Episode: 1026 Total reward: -84.0 Training loss: 0.7946 Explore P: 0.0100 RunMean : -97.2300\n",
      "Episode: 1027 Total reward: -89.0 Training loss: 1.3911 Explore P: 0.0100 RunMean : -97.2300\n",
      "Episode: 1028 Total reward: -107.0 Training loss: 1.7692 Explore P: 0.0100 RunMean : -97.2400\n",
      "Episode: 1029 Total reward: -100.0 Training loss: 1.5730 Explore P: 0.0100 RunMean : -97.1500\n",
      "Episode: 1030 Total reward: -98.0 Training loss: 3.0021 Explore P: 0.0100 RunMean : -97.4100\n",
      "Episode: 1031 Total reward: -90.0 Training loss: 7.7530 Explore P: 0.0100 RunMean : -97.4700\n",
      "Episode: 1032 Total reward: -61.0 Training loss: 0.5823 Explore P: 0.0100 RunMean : -97.0600\n",
      "Episode: 1033 Total reward: -87.0 Training loss: 3.4905 Explore P: 0.0100 RunMean : -96.8700\n",
      "Episode: 1034 Total reward: -107.0 Training loss: 2.6383 Explore P: 0.0100 RunMean : -97.1100\n",
      "Episode: 1035 Total reward: -118.0 Training loss: 4.9712 Explore P: 0.0100 RunMean : -97.1400\n",
      "Episode: 1036 Total reward: -128.0 Training loss: 1.9457 Explore P: 0.0100 RunMean : -97.5300\n",
      "Episode: 1037 Total reward: -130.0 Training loss: 1.5977 Explore P: 0.0100 RunMean : -97.4900\n",
      "Episode: 1038 Total reward: -109.0 Training loss: 2.0757 Explore P: 0.0100 RunMean : -97.6600\n",
      "Episode: 1039 Total reward: -95.0 Training loss: 7.4878 Explore P: 0.0100 RunMean : -97.7800\n",
      "Episode: 1040 Total reward: -135.0 Training loss: 1.6717 Explore P: 0.0100 RunMean : -98.4300\n",
      "Episode: 1041 Total reward: -108.0 Training loss: 4.0927 Explore P: 0.0100 RunMean : -98.5200\n",
      "Episode: 1042 Total reward: -83.0 Training loss: 1.2946 Explore P: 0.0100 RunMean : -98.5300\n",
      "Episode: 1043 Total reward: -63.0 Training loss: 0.8836 Explore P: 0.0100 RunMean : -98.4100\n",
      "Episode: 1044 Total reward: -69.0 Training loss: 4.2766 Explore P: 0.0100 RunMean : -98.1700\n",
      "Episode: 1045 Total reward: -63.0 Training loss: 1.3328 Explore P: 0.0100 RunMean : -97.7200\n",
      "Episode: 1046 Total reward: -63.0 Training loss: 3.4889 Explore P: 0.0100 RunMean : -97.5900\n",
      "Episode: 1047 Total reward: -87.0 Training loss: 6.3468 Explore P: 0.0100 RunMean : -97.5700\n",
      "Episode: 1048 Total reward: -71.0 Training loss: 1.3532 Explore P: 0.0100 RunMean : -97.5100\n",
      "Episode: 1049 Total reward: -94.0 Training loss: 2.1927 Explore P: 0.0100 RunMean : -97.4800\n",
      "Episode: 1050 Total reward: -70.0 Training loss: 3.5331 Explore P: 0.0100 RunMean : -97.3800\n",
      "Episode: 1051 Total reward: -69.0 Training loss: 3.5751 Explore P: 0.0100 RunMean : -96.9700\n",
      "Episode: 1052 Total reward: -108.0 Training loss: 1.3694 Explore P: 0.0100 RunMean : -97.4300\n",
      "Episode: 1053 Total reward: -86.0 Training loss: 1.5521 Explore P: 0.0100 RunMean : -97.3400\n",
      "Episode: 1054 Total reward: -122.0 Training loss: 2.2528 Explore P: 0.0100 RunMean : -97.7500\n",
      "Episode: 1055 Total reward: -89.0 Training loss: 1.2656 Explore P: 0.0100 RunMean : -97.3200\n",
      "Episode: 1056 Total reward: -70.0 Training loss: 1.7234 Explore P: 0.0100 RunMean : -97.0200\n",
      "Episode: 1057 Total reward: -103.0 Training loss: 0.8988 Explore P: 0.0100 RunMean : -96.7400\n",
      "Episode: 1058 Total reward: -125.0 Training loss: 4.9430 Explore P: 0.0100 RunMean : -97.0800\n",
      "Episode: 1059 Total reward: -132.0 Training loss: 1.8222 Explore P: 0.0100 RunMean : -97.0900\n",
      "Episode: 1060 Total reward: -114.0 Training loss: 2.6691 Explore P: 0.0100 RunMean : -97.2900\n",
      "Episode: 1061 Total reward: -139.0 Training loss: 1.1186 Explore P: 0.0100 RunMean : -98.0500\n",
      "Episode: 1062 Total reward: -86.0 Training loss: 0.9281 Explore P: 0.0100 RunMean : -98.1800\n",
      "Episode: 1063 Total reward: -78.0 Training loss: 0.9031 Explore P: 0.0100 RunMean : -98.1800\n",
      "Episode: 1064 Total reward: -108.0 Training loss: 2.2818 Explore P: 0.0100 RunMean : -98.3400\n",
      "Episode: 1065 Total reward: -86.0 Training loss: 0.9517 Explore P: 0.0100 RunMean : -98.3700\n",
      "Episode: 1066 Total reward: -115.0 Training loss: 1.3073 Explore P: 0.0100 RunMean : -98.6500\n",
      "Episode: 1067 Total reward: -92.0 Training loss: 1.1906 Explore P: 0.0100 RunMean : -98.7100\n",
      "Episode: 1068 Total reward: -74.0 Training loss: 1.2746 Explore P: 0.0100 RunMean : -98.5200\n",
      "Episode: 1069 Total reward: -83.0 Training loss: 1.6286 Explore P: 0.0100 RunMean : -98.2200\n",
      "Episode: 1070 Total reward: -90.0 Training loss: 1.5800 Explore P: 0.0100 RunMean : -98.1500\n",
      "Episode: 1071 Total reward: -117.0 Training loss: 2.2001 Explore P: 0.0100 RunMean : -97.9400\n",
      "Episode: 1072 Total reward: -67.0 Training loss: 2.0864 Explore P: 0.0100 RunMean : -96.8400\n",
      "Episode: 1073 Total reward: -90.0 Training loss: 4.5129 Explore P: 0.0100 RunMean : -97.1200\n",
      "Episode: 1074 Total reward: -63.0 Training loss: 4.5721 Explore P: 0.0100 RunMean : -96.9400\n",
      "Episode: 1075 Total reward: -105.0 Training loss: 1.8833 Explore P: 0.0100 RunMean : -97.3100\n",
      "Episode: 1076 Total reward: -117.0 Training loss: 1.2962 Explore P: 0.0100 RunMean : -97.6700\n",
      "Episode: 1077 Total reward: -98.0 Training loss: 1.9002 Explore P: 0.0100 RunMean : -97.8200\n",
      "Episode: 1078 Total reward: -76.0 Training loss: 1.6578 Explore P: 0.0100 RunMean : -97.7600\n",
      "Episode: 1079 Total reward: -77.0 Training loss: 1.2452 Explore P: 0.0100 RunMean : -97.6100\n",
      "Episode: 1080 Total reward: -119.0 Training loss: 1.2641 Explore P: 0.0100 RunMean : -97.7800\n",
      "Episode: 1081 Total reward: -110.0 Training loss: 0.9175 Explore P: 0.0100 RunMean : -97.7800\n",
      "Episode: 1082 Total reward: -80.0 Training loss: 5.9794 Explore P: 0.0100 RunMean : -97.6200\n",
      "Episode: 1083 Total reward: -91.0 Training loss: 1.5747 Explore P: 0.0100 RunMean : -97.7000\n",
      "Episode: 1084 Total reward: -102.0 Training loss: 2.9977 Explore P: 0.0100 RunMean : -98.0300\n",
      "Episode: 1085 Total reward: -100.0 Training loss: 1.2044 Explore P: 0.0100 RunMean : -98.0000\n",
      "Episode: 1086 Total reward: -69.0 Training loss: 1.0261 Explore P: 0.0100 RunMean : -98.0000\n",
      "Episode: 1087 Total reward: -89.0 Training loss: 0.9872 Explore P: 0.0100 RunMean : -98.1000\n",
      "Episode: 1088 Total reward: -103.0 Training loss: 1.1687 Explore P: 0.0100 RunMean : -97.8900\n",
      "Episode: 1089 Total reward: -117.0 Training loss: 2.7887 Explore P: 0.0100 RunMean : -97.2400\n",
      "Episode: 1090 Total reward: -83.0 Training loss: 0.9460 Explore P: 0.0100 RunMean : -96.8600\n",
      "Episode: 1091 Total reward: -73.0 Training loss: 1.8341 Explore P: 0.0100 RunMean : -96.5900\n",
      "Episode: 1092 Total reward: -81.0 Training loss: 2.2228 Explore P: 0.0100 RunMean : -95.6600\n",
      "Episode: 1093 Total reward: -122.0 Training loss: 1.7257 Explore P: 0.0100 RunMean : -95.8000\n",
      "Episode: 1094 Total reward: -88.0 Training loss: 2.1711 Explore P: 0.0100 RunMean : -95.6900\n",
      "Episode: 1095 Total reward: -138.0 Training loss: 0.9637 Explore P: 0.0100 RunMean : -96.1600\n",
      "Episode: 1096 Total reward: -98.0 Training loss: 0.7245 Explore P: 0.0100 RunMean : -96.4400\n",
      "Episode: 1097 Total reward: -87.0 Training loss: 0.8671 Explore P: 0.0100 RunMean : -96.3600\n",
      "Episode: 1098 Total reward: -71.0 Training loss: 2.9713 Explore P: 0.0100 RunMean : -96.4500\n",
      "Episode: 1099 Total reward: -71.0 Training loss: 1.6395 Explore P: 0.0100 RunMean : -96.3000\n",
      "Episode: 1100 Total reward: -135.0 Training loss: 0.9383 Explore P: 0.0100 RunMean : -96.6600\n",
      "Episode: 1101 Total reward: -104.0 Training loss: 4.9935 Explore P: 0.0100 RunMean : -96.8400\n",
      "Episode: 1102 Total reward: -94.0 Training loss: 1.9337 Explore P: 0.0100 RunMean : -96.7400\n",
      "Episode: 1103 Total reward: -85.0 Training loss: 3.4837 Explore P: 0.0100 RunMean : -96.4800\n",
      "Episode: 1104 Total reward: -96.0 Training loss: 4.6473 Explore P: 0.0100 RunMean : -96.7400\n",
      "Episode: 1105 Total reward: -74.0 Training loss: 2.0637 Explore P: 0.0100 RunMean : -96.6000\n",
      "Episode: 1106 Total reward: -81.0 Training loss: 2.5799 Explore P: 0.0100 RunMean : -96.2900\n",
      "Episode: 1107 Total reward: -83.0 Training loss: 1.4950 Explore P: 0.0100 RunMean : -95.5400\n",
      "Episode: 1108 Total reward: -86.0 Training loss: 4.9752 Explore P: 0.0100 RunMean : -95.7400\n",
      "Episode: 1109 Total reward: -81.0 Training loss: 1.9724 Explore P: 0.0100 RunMean : -95.7900\n",
      "Episode: 1110 Total reward: -69.0 Training loss: 5.2845 Explore P: 0.0100 RunMean : -95.6200\n",
      "Episode: 1111 Total reward: -100.0 Training loss: 1.3058 Explore P: 0.0100 RunMean : -95.4200\n",
      "Episode: 1112 Total reward: -94.0 Training loss: 0.9549 Explore P: 0.0100 RunMean : -94.6600\n",
      "Episode: 1113 Total reward: -108.0 Training loss: 2.1569 Explore P: 0.0100 RunMean : -94.4300\n",
      "Episode: 1114 Total reward: -102.0 Training loss: 1.2297 Explore P: 0.0100 RunMean : -94.4100\n",
      "Episode: 1115 Total reward: -95.0 Training loss: 3.1191 Explore P: 0.0100 RunMean : -94.1100\n",
      "Episode: 1116 Total reward: -90.0 Training loss: 1.6860 Explore P: 0.0100 RunMean : -94.0300\n",
      "Episode: 1117 Total reward: -62.0 Training loss: 1.7239 Explore P: 0.0100 RunMean : -93.8900\n",
      "Episode: 1118 Total reward: -84.0 Training loss: 3.1560 Explore P: 0.0100 RunMean : -93.8700\n",
      "Episode: 1119 Total reward: -83.0 Training loss: 5.7998 Explore P: 0.0100 RunMean : -93.8200\n",
      "Episode: 1120 Total reward: -132.0 Training loss: 2.0369 Explore P: 0.0100 RunMean : -94.5200\n",
      "Episode: 1121 Total reward: -85.0 Training loss: 1.8547 Explore P: 0.0100 RunMean : -94.6700\n",
      "Episode: 1122 Total reward: -107.0 Training loss: 1.6098 Explore P: 0.0100 RunMean : -93.7100\n",
      "Episode: 1123 Total reward: -103.0 Training loss: 2.3306 Explore P: 0.0100 RunMean : -93.7900\n",
      "Episode: 1124 Total reward: -95.0 Training loss: 1.4019 Explore P: 0.0100 RunMean : -93.8600\n",
      "Episode: 1125 Total reward: -87.0 Training loss: 4.9899 Explore P: 0.0100 RunMean : -93.9500\n",
      "Episode: 1126 Total reward: -90.0 Training loss: 1.6309 Explore P: 0.0100 RunMean : -94.0100\n",
      "Episode: 1127 Total reward: -107.0 Training loss: 2.7448 Explore P: 0.0100 RunMean : -94.1900\n",
      "Episode: 1128 Total reward: -86.0 Training loss: 1.3066 Explore P: 0.0100 RunMean : -93.9800\n",
      "Episode: 1129 Total reward: -78.0 Training loss: 2.2924 Explore P: 0.0100 RunMean : -93.7600\n",
      "Episode: 1130 Total reward: -92.0 Training loss: 2.2791 Explore P: 0.0100 RunMean : -93.7000\n",
      "Episode: 1131 Total reward: -91.0 Training loss: 1.5868 Explore P: 0.0100 RunMean : -93.7100\n",
      "Episode: 1132 Total reward: -89.0 Training loss: 1.4549 Explore P: 0.0100 RunMean : -93.9900\n",
      "Episode: 1133 Total reward: -82.0 Training loss: 1.6440 Explore P: 0.0100 RunMean : -93.9400\n",
      "Episode: 1134 Total reward: -84.0 Training loss: 1.2021 Explore P: 0.0100 RunMean : -93.7100\n",
      "Episode: 1135 Total reward: -81.0 Training loss: 2.2787 Explore P: 0.0100 RunMean : -93.3400\n",
      "Episode: 1136 Total reward: -84.0 Training loss: 2.1584 Explore P: 0.0100 RunMean : -92.9000\n",
      "Episode: 1137 Total reward: -106.0 Training loss: 2.0357 Explore P: 0.0100 RunMean : -92.6600\n",
      "Episode: 1138 Total reward: -101.0 Training loss: 1.1106 Explore P: 0.0100 RunMean : -92.5800\n",
      "Episode: 1139 Total reward: -85.0 Training loss: 1.3431 Explore P: 0.0100 RunMean : -92.4800\n",
      "Episode: 1140 Total reward: -78.0 Training loss: 1.8646 Explore P: 0.0100 RunMean : -91.9100\n",
      "Episode: 1141 Total reward: -95.0 Training loss: 0.9226 Explore P: 0.0100 RunMean : -91.7800\n",
      "Episode: 1142 Total reward: -86.0 Training loss: 1.8129 Explore P: 0.0100 RunMean : -91.8100\n",
      "Episode: 1143 Total reward: -111.0 Training loss: 1.9695 Explore P: 0.0100 RunMean : -92.2900\n",
      "Episode: 1144 Total reward: -91.0 Training loss: 1.5252 Explore P: 0.0100 RunMean : -92.5100\n",
      "Episode: 1145 Total reward: -80.0 Training loss: 1.2992 Explore P: 0.0100 RunMean : -92.6800\n",
      "Episode: 1146 Total reward: -83.0 Training loss: 2.8140 Explore P: 0.0100 RunMean : -92.8800\n",
      "Episode: 1147 Total reward: -80.0 Training loss: 1.7377 Explore P: 0.0100 RunMean : -92.8100\n",
      "Episode: 1148 Total reward: -77.0 Training loss: 1.0849 Explore P: 0.0100 RunMean : -92.8700\n",
      "Episode: 1149 Total reward: -75.0 Training loss: 1.8095 Explore P: 0.0100 RunMean : -92.6800\n",
      "Episode: 1150 Total reward: -118.0 Training loss: 1.4075 Explore P: 0.0100 RunMean : -93.1600\n",
      "Episode: 1151 Total reward: -83.0 Training loss: 1.3411 Explore P: 0.0100 RunMean : -93.3000\n",
      "Episode: 1152 Total reward: -152.0 Training loss: 1.0317 Explore P: 0.0100 RunMean : -93.7400\n",
      "Episode: 1153 Total reward: -84.0 Training loss: 5.0546 Explore P: 0.0100 RunMean : -93.7200\n",
      "Episode: 1154 Total reward: -90.0 Training loss: 1.1761 Explore P: 0.0100 RunMean : -93.4000\n",
      "Episode: 1155 Total reward: -95.0 Training loss: 1.2057 Explore P: 0.0100 RunMean : -93.4600\n",
      "Episode: 1156 Total reward: -77.0 Training loss: 2.4273 Explore P: 0.0100 RunMean : -93.5300\n",
      "Episode: 1157 Total reward: -75.0 Training loss: 7.0810 Explore P: 0.0100 RunMean : -93.2500\n",
      "Episode: 1158 Total reward: -62.0 Training loss: 1.2412 Explore P: 0.0100 RunMean : -92.6200\n",
      "Episode: 1159 Total reward: -77.0 Training loss: 4.1008 Explore P: 0.0100 RunMean : -92.0700\n",
      "Episode: 1160 Total reward: -141.0 Training loss: 1.9734 Explore P: 0.0100 RunMean : -92.3400\n",
      "Episode: 1161 Total reward: -108.0 Training loss: 1.0159 Explore P: 0.0100 RunMean : -92.0300\n",
      "Episode: 1162 Total reward: -108.0 Training loss: 0.7387 Explore P: 0.0100 RunMean : -92.2500\n",
      "Episode: 1163 Total reward: -70.0 Training loss: 1.4436 Explore P: 0.0100 RunMean : -92.1700\n",
      "Episode: 1164 Total reward: -91.0 Training loss: 5.1771 Explore P: 0.0100 RunMean : -92.0000\n",
      "Episode: 1165 Total reward: -86.0 Training loss: 1.8047 Explore P: 0.0100 RunMean : -92.0000\n",
      "Episode: 1166 Total reward: -76.0 Training loss: 1.2275 Explore P: 0.0100 RunMean : -91.6100\n",
      "Episode: 1167 Total reward: -86.0 Training loss: 1.6803 Explore P: 0.0100 RunMean : -91.5500\n",
      "Episode: 1168 Total reward: -90.0 Training loss: 1.3624 Explore P: 0.0100 RunMean : -91.7100\n",
      "Episode: 1169 Total reward: -71.0 Training loss: 1.1061 Explore P: 0.0100 RunMean : -91.5900\n",
      "Episode: 1170 Total reward: -85.0 Training loss: 1.5693 Explore P: 0.0100 RunMean : -91.5400\n",
      "Episode: 1171 Total reward: -113.0 Training loss: 0.7875 Explore P: 0.0100 RunMean : -91.5000\n",
      "Episode: 1172 Total reward: -108.0 Training loss: 4.6389 Explore P: 0.0100 RunMean : -91.9100\n",
      "Episode: 1173 Total reward: -500.0 Training loss: 1.2442 Explore P: 0.0100 RunMean : -96.0100\n",
      "Episode: 1174 Total reward: -76.0 Training loss: 1.6648 Explore P: 0.0100 RunMean : -96.1400\n",
      "Episode: 1175 Total reward: -70.0 Training loss: 1.3550 Explore P: 0.0100 RunMean : -95.7900\n",
      "Episode: 1176 Total reward: -75.0 Training loss: 1.8924 Explore P: 0.0100 RunMean : -95.3700\n",
      "Episode: 1177 Total reward: -86.0 Training loss: 1.5407 Explore P: 0.0100 RunMean : -95.2500\n",
      "Episode: 1178 Total reward: -87.0 Training loss: 1.7271 Explore P: 0.0100 RunMean : -95.3600\n",
      "Episode: 1179 Total reward: -87.0 Training loss: 0.7051 Explore P: 0.0100 RunMean : -95.4600\n",
      "Episode: 1180 Total reward: -63.0 Training loss: 1.8847 Explore P: 0.0100 RunMean : -94.9000\n",
      "Episode: 1181 Total reward: -71.0 Training loss: 1.3079 Explore P: 0.0100 RunMean : -94.5100\n",
      "Episode: 1182 Total reward: -82.0 Training loss: 2.6447 Explore P: 0.0100 RunMean : -94.5300\n",
      "Episode: 1183 Total reward: -77.0 Training loss: 1.9679 Explore P: 0.0100 RunMean : -94.3900\n",
      "Episode: 1184 Total reward: -74.0 Training loss: 2.6000 Explore P: 0.0100 RunMean : -94.1100\n",
      "Episode: 1185 Total reward: -108.0 Training loss: 4.9919 Explore P: 0.0100 RunMean : -94.1900\n",
      "Episode: 1186 Total reward: -91.0 Training loss: 2.3277 Explore P: 0.0100 RunMean : -94.4100\n",
      "Episode: 1187 Total reward: -76.0 Training loss: 1.6442 Explore P: 0.0100 RunMean : -94.2800\n",
      "Episode: 1188 Total reward: -99.0 Training loss: 1.1915 Explore P: 0.0100 RunMean : -94.2400\n",
      "Episode: 1189 Total reward: -76.0 Training loss: 1.2077 Explore P: 0.0100 RunMean : -93.8300\n",
      "Episode: 1190 Total reward: -132.0 Training loss: 4.2640 Explore P: 0.0100 RunMean : -94.3200\n",
      "Episode: 1191 Total reward: -142.0 Training loss: 2.2863 Explore P: 0.0100 RunMean : -95.0100\n",
      "Episode: 1192 Total reward: -124.0 Training loss: 2.3450 Explore P: 0.0100 RunMean : -95.4400\n",
      "Episode: 1193 Total reward: -90.0 Training loss: 1.2397 Explore P: 0.0100 RunMean : -95.1200\n",
      "Episode: 1194 Total reward: -94.0 Training loss: 1.9304 Explore P: 0.0100 RunMean : -95.1800\n",
      "Episode: 1195 Total reward: -93.0 Training loss: 2.9770 Explore P: 0.0100 RunMean : -94.7300\n",
      "Episode: 1196 Total reward: -84.0 Training loss: 1.8336 Explore P: 0.0100 RunMean : -94.5900\n",
      "Episode: 1197 Total reward: -95.0 Training loss: 0.9853 Explore P: 0.0100 RunMean : -94.6700\n",
      "Episode: 1198 Total reward: -92.0 Training loss: 1.4100 Explore P: 0.0100 RunMean : -94.8800\n",
      "Episode: 1199 Total reward: -63.0 Training loss: 3.2424 Explore P: 0.0100 RunMean : -94.8000\n",
      "Episode: 1200 Total reward: -72.0 Training loss: 3.2243 Explore P: 0.0100 RunMean : -94.1700\n",
      "Episode: 1201 Total reward: -164.0 Training loss: 4.7910 Explore P: 0.0100 RunMean : -94.7700\n",
      "Episode: 1202 Total reward: -70.0 Training loss: 1.9442 Explore P: 0.0100 RunMean : -94.5300\n",
      "Episode: 1203 Total reward: -101.0 Training loss: 1.9652 Explore P: 0.0100 RunMean : -94.6900\n",
      "Episode: 1204 Total reward: -80.0 Training loss: 2.9967 Explore P: 0.0100 RunMean : -94.5300\n",
      "Episode: 1205 Total reward: -133.0 Training loss: 1.4711 Explore P: 0.0100 RunMean : -95.1200\n",
      "Episode: 1206 Total reward: -111.0 Training loss: 1.5231 Explore P: 0.0100 RunMean : -95.4200\n",
      "Episode: 1207 Total reward: -104.0 Training loss: 1.7288 Explore P: 0.0100 RunMean : -95.6300\n",
      "Episode: 1208 Total reward: -92.0 Training loss: 2.3412 Explore P: 0.0100 RunMean : -95.6900\n",
      "Episode: 1209 Total reward: -82.0 Training loss: 1.1848 Explore P: 0.0100 RunMean : -95.7000\n",
      "Episode: 1210 Total reward: -75.0 Training loss: 1.9158 Explore P: 0.0100 RunMean : -95.7600\n",
      "Episode: 1211 Total reward: -110.0 Training loss: 1.8545 Explore P: 0.0100 RunMean : -95.8600\n",
      "Episode: 1212 Total reward: -112.0 Training loss: 2.1898 Explore P: 0.0100 RunMean : -96.0400\n",
      "Episode: 1213 Total reward: -78.0 Training loss: 4.2980 Explore P: 0.0100 RunMean : -95.7400\n",
      "Episode: 1214 Total reward: -137.0 Training loss: 2.2024 Explore P: 0.0100 RunMean : -96.0900\n",
      "Episode: 1215 Total reward: -116.0 Training loss: 2.2886 Explore P: 0.0100 RunMean : -96.3000\n",
      "Episode: 1216 Total reward: -111.0 Training loss: 2.3600 Explore P: 0.0100 RunMean : -96.5100\n",
      "Episode: 1217 Total reward: -130.0 Training loss: 4.5422 Explore P: 0.0100 RunMean : -97.1900\n",
      "Episode: 1218 Total reward: -105.0 Training loss: 2.6633 Explore P: 0.0100 RunMean : -97.4000\n",
      "Episode: 1219 Total reward: -112.0 Training loss: 1.1956 Explore P: 0.0100 RunMean : -97.6900\n",
      "Episode: 1220 Total reward: -142.0 Training loss: 1.4925 Explore P: 0.0100 RunMean : -97.7900\n",
      "Episode: 1221 Total reward: -89.0 Training loss: 1.8950 Explore P: 0.0100 RunMean : -97.8300\n",
      "Episode: 1222 Total reward: -87.0 Training loss: 1.1479 Explore P: 0.0100 RunMean : -97.6300\n",
      "Episode: 1223 Total reward: -77.0 Training loss: 2.2404 Explore P: 0.0100 RunMean : -97.3700\n",
      "Episode: 1224 Total reward: -139.0 Training loss: 2.0240 Explore P: 0.0100 RunMean : -97.8100\n",
      "Episode: 1225 Total reward: -107.0 Training loss: 2.2592 Explore P: 0.0100 RunMean : -98.0100\n",
      "Episode: 1226 Total reward: -116.0 Training loss: 16.5648 Explore P: 0.0100 RunMean : -98.2700\n",
      "Episode: 1227 Total reward: -138.0 Training loss: 1.9632 Explore P: 0.0100 RunMean : -98.5800\n",
      "Episode: 1228 Total reward: -102.0 Training loss: 2.2958 Explore P: 0.0100 RunMean : -98.7400\n",
      "Episode: 1229 Total reward: -168.0 Training loss: 1.9247 Explore P: 0.0100 RunMean : -99.6400\n",
      "Episode: 1230 Total reward: -73.0 Training loss: 2.8509 Explore P: 0.0100 RunMean : -99.4500\n",
      "Episode: 1231 Total reward: -69.0 Training loss: 2.3552 Explore P: 0.0100 RunMean : -99.2300\n",
      "Episode: 1232 Total reward: -70.0 Training loss: 1.0739 Explore P: 0.0100 RunMean : -99.0400\n",
      "Episode: 1233 Total reward: -102.0 Training loss: 3.0640 Explore P: 0.0100 RunMean : -99.2400\n",
      "Episode: 1234 Total reward: -137.0 Training loss: 1.3137 Explore P: 0.0100 RunMean : -99.7700\n",
      "Episode: 1235 Total reward: -69.0 Training loss: 8.2795 Explore P: 0.0100 RunMean : -99.6500\n",
      "Episode: 1236 Total reward: -63.0 Training loss: 1.2346 Explore P: 0.0100 RunMean : -99.4400\n",
      "Episode: 1237 Total reward: -76.0 Training loss: 2.3698 Explore P: 0.0100 RunMean : -99.1400\n",
      "Episode: 1238 Total reward: -79.0 Training loss: 0.7252 Explore P: 0.0100 RunMean : -98.9200\n",
      "Episode: 1239 Total reward: -86.0 Training loss: 2.3468 Explore P: 0.0100 RunMean : -98.9300\n",
      "Episode: 1240 Total reward: -83.0 Training loss: 3.6538 Explore P: 0.0100 RunMean : -98.9800\n",
      "Episode: 1241 Total reward: -96.0 Training loss: 1.6802 Explore P: 0.0100 RunMean : -98.9900\n",
      "Episode: 1242 Total reward: -101.0 Training loss: 2.0165 Explore P: 0.0100 RunMean : -99.1400\n",
      "Episode: 1243 Total reward: -76.0 Training loss: 1.3938 Explore P: 0.0100 RunMean : -98.7900\n",
      "Episode: 1244 Total reward: -86.0 Training loss: 1.5526 Explore P: 0.0100 RunMean : -98.7400\n",
      "Episode: 1245 Total reward: -99.0 Training loss: 4.1813 Explore P: 0.0100 RunMean : -98.9300\n",
      "Episode: 1246 Total reward: -98.0 Training loss: 3.1167 Explore P: 0.0100 RunMean : -99.0800\n",
      "Episode: 1247 Total reward: -104.0 Training loss: 2.0140 Explore P: 0.0100 RunMean : -99.3200\n",
      "Episode: 1248 Total reward: -86.0 Training loss: 3.9428 Explore P: 0.0100 RunMean : -99.4100\n",
      "Episode: 1249 Total reward: -71.0 Training loss: 1.8023 Explore P: 0.0100 RunMean : -99.3700\n",
      "Episode: 1250 Total reward: -71.0 Training loss: 5.9148 Explore P: 0.0100 RunMean : -98.9000\n",
      "Episode: 1251 Total reward: -107.0 Training loss: 4.1391 Explore P: 0.0100 RunMean : -99.1400\n",
      "Episode: 1252 Total reward: -111.0 Training loss: 1.8821 Explore P: 0.0100 RunMean : -98.7300\n",
      "Episode: 1253 Total reward: -93.0 Training loss: 1.3686 Explore P: 0.0100 RunMean : -98.8200\n",
      "Episode: 1254 Total reward: -97.0 Training loss: 3.4234 Explore P: 0.0100 RunMean : -98.8900\n",
      "Episode: 1255 Total reward: -105.0 Training loss: 3.2208 Explore P: 0.0100 RunMean : -98.9900\n",
      "Episode: 1256 Total reward: -75.0 Training loss: 1.7717 Explore P: 0.0100 RunMean : -98.9700\n",
      "Episode: 1257 Total reward: -68.0 Training loss: 1.4370 Explore P: 0.0100 RunMean : -98.9000\n",
      "Episode: 1258 Total reward: -128.0 Training loss: 1.6236 Explore P: 0.0100 RunMean : -99.5600\n",
      "Episode: 1259 Total reward: -110.0 Training loss: 0.9794 Explore P: 0.0100 RunMean : -99.8900\n",
      "Episode: 1260 Total reward: -209.0 Training loss: 5.6957 Explore P: 0.0100 RunMean : -100.5700\n",
      "Episode: 1261 Total reward: -260.0 Training loss: 1.6909 Explore P: 0.0100 RunMean : -102.0900\n",
      "Episode: 1262 Total reward: -83.0 Training loss: 2.9051 Explore P: 0.0100 RunMean : -101.8400\n",
      "Episode: 1263 Total reward: -86.0 Training loss: 4.8109 Explore P: 0.0100 RunMean : -102.0000\n",
      "Episode: 1264 Total reward: -91.0 Training loss: 4.1090 Explore P: 0.0100 RunMean : -102.0000\n",
      "Episode: 1265 Total reward: -130.0 Training loss: 1.4243 Explore P: 0.0100 RunMean : -102.4400\n",
      "Episode: 1266 Total reward: -70.0 Training loss: 3.9989 Explore P: 0.0100 RunMean : -102.3800\n",
      "Episode: 1267 Total reward: -71.0 Training loss: 3.9648 Explore P: 0.0100 RunMean : -102.2300\n",
      "Episode: 1268 Total reward: -85.0 Training loss: 2.7191 Explore P: 0.0100 RunMean : -102.1800\n",
      "Episode: 1269 Total reward: -111.0 Training loss: 9.1612 Explore P: 0.0100 RunMean : -102.5800\n",
      "Episode: 1270 Total reward: -117.0 Training loss: 2.4479 Explore P: 0.0100 RunMean : -102.9000\n",
      "Episode: 1271 Total reward: -90.0 Training loss: 3.4182 Explore P: 0.0100 RunMean : -102.6700\n",
      "Episode: 1272 Total reward: -113.0 Training loss: 2.0405 Explore P: 0.0100 RunMean : -102.7200\n",
      "Episode: 1273 Total reward: -62.0 Training loss: 0.9111 Explore P: 0.0100 RunMean : -98.3400\n",
      "Episode: 1274 Total reward: -86.0 Training loss: 2.9848 Explore P: 0.0100 RunMean : -98.4400\n",
      "Episode: 1275 Total reward: -110.0 Training loss: 1.6521 Explore P: 0.0100 RunMean : -98.8400\n",
      "Episode: 1276 Total reward: -110.0 Training loss: 3.5413 Explore P: 0.0100 RunMean : -99.1900\n",
      "Episode: 1277 Total reward: -114.0 Training loss: 2.1745 Explore P: 0.0100 RunMean : -99.4700\n",
      "Episode: 1278 Total reward: -98.0 Training loss: 2.3738 Explore P: 0.0100 RunMean : -99.5800\n",
      "Episode: 1279 Total reward: -102.0 Training loss: 1.8604 Explore P: 0.0100 RunMean : -99.7300\n",
      "Episode: 1280 Total reward: -91.0 Training loss: 2.9707 Explore P: 0.0100 RunMean : -100.0100\n",
      "Episode: 1281 Total reward: -105.0 Training loss: 1.5939 Explore P: 0.0100 RunMean : -100.3500\n",
      "Episode: 1282 Total reward: -113.0 Training loss: 2.4384 Explore P: 0.0100 RunMean : -100.6600\n",
      "Episode: 1283 Total reward: -62.0 Training loss: 1.7983 Explore P: 0.0100 RunMean : -100.5100\n",
      "Episode: 1284 Total reward: -77.0 Training loss: 2.8340 Explore P: 0.0100 RunMean : -100.5400\n",
      "Episode: 1285 Total reward: -89.0 Training loss: 1.3402 Explore P: 0.0100 RunMean : -100.3500\n",
      "Episode: 1286 Total reward: -85.0 Training loss: 1.4776 Explore P: 0.0100 RunMean : -100.2900\n",
      "Episode: 1287 Total reward: -97.0 Training loss: 2.0103 Explore P: 0.0100 RunMean : -100.5000\n",
      "Episode: 1288 Total reward: -99.0 Training loss: 2.4554 Explore P: 0.0100 RunMean : -100.5000\n",
      "Episode: 1289 Total reward: -98.0 Training loss: 1.4028 Explore P: 0.0100 RunMean : -100.7200\n",
      "Episode: 1290 Total reward: -71.0 Training loss: 1.6194 Explore P: 0.0100 RunMean : -100.1100\n",
      "Episode: 1291 Total reward: -107.0 Training loss: 1.1077 Explore P: 0.0100 RunMean : -99.7600\n",
      "Episode: 1292 Total reward: -86.0 Training loss: 4.4705 Explore P: 0.0100 RunMean : -99.3800\n",
      "Episode: 1293 Total reward: -69.0 Training loss: 2.9770 Explore P: 0.0100 RunMean : -99.1700\n",
      "Episode: 1294 Total reward: -73.0 Training loss: 4.4331 Explore P: 0.0100 RunMean : -98.9600\n",
      "Episode: 1295 Total reward: -85.0 Training loss: 2.2493 Explore P: 0.0100 RunMean : -98.8800\n",
      "Episode: 1296 Total reward: -122.0 Training loss: 2.2255 Explore P: 0.0100 RunMean : -99.2600\n",
      "Episode: 1297 Total reward: -132.0 Training loss: 1.5169 Explore P: 0.0100 RunMean : -99.6300\n",
      "Episode: 1298 Total reward: -103.0 Training loss: 2.6767 Explore P: 0.0100 RunMean : -99.7400\n",
      "Episode: 1299 Total reward: -108.0 Training loss: 2.8473 Explore P: 0.0100 RunMean : -100.1900\n",
      "Episode: 1300 Total reward: -125.0 Training loss: 1.5591 Explore P: 0.0100 RunMean : -100.7200\n",
      "Episode: 1301 Total reward: -108.0 Training loss: 1.7974 Explore P: 0.0100 RunMean : -100.1600\n",
      "Episode: 1302 Total reward: -91.0 Training loss: 1.9587 Explore P: 0.0100 RunMean : -100.3700\n",
      "Episode: 1303 Total reward: -97.0 Training loss: 1.7752 Explore P: 0.0100 RunMean : -100.3300\n",
      "Episode: 1304 Total reward: -112.0 Training loss: 2.1389 Explore P: 0.0100 RunMean : -100.6500\n",
      "Episode: 1305 Total reward: -137.0 Training loss: 4.1716 Explore P: 0.0100 RunMean : -100.6900\n",
      "Episode: 1306 Total reward: -62.0 Training loss: 3.0674 Explore P: 0.0100 RunMean : -100.2000\n",
      "Episode: 1307 Total reward: -81.0 Training loss: 1.9410 Explore P: 0.0100 RunMean : -99.9700\n",
      "Episode: 1308 Total reward: -84.0 Training loss: 1.9182 Explore P: 0.0100 RunMean : -99.8900\n",
      "Episode: 1309 Total reward: -100.0 Training loss: 1.2326 Explore P: 0.0100 RunMean : -100.0700\n",
      "Episode: 1310 Total reward: -97.0 Training loss: 4.6091 Explore P: 0.0100 RunMean : -100.2900\n",
      "Episode: 1311 Total reward: -86.0 Training loss: 1.6791 Explore P: 0.0100 RunMean : -100.0500\n",
      "Episode: 1312 Total reward: -83.0 Training loss: 6.5489 Explore P: 0.0100 RunMean : -99.7600\n",
      "Episode: 1313 Total reward: -86.0 Training loss: 1.7688 Explore P: 0.0100 RunMean : -99.8400\n",
      "Episode: 1314 Total reward: -90.0 Training loss: 1.5134 Explore P: 0.0100 RunMean : -99.3700\n",
      "Episode: 1315 Total reward: -93.0 Training loss: 1.9023 Explore P: 0.0100 RunMean : -99.1400\n",
      "Episode: 1316 Total reward: -87.0 Training loss: 2.3257 Explore P: 0.0100 RunMean : -98.9000\n",
      "Episode: 1317 Total reward: -69.0 Training loss: 2.7234 Explore P: 0.0100 RunMean : -98.2900\n",
      "Episode: 1318 Total reward: -75.0 Training loss: 5.9030 Explore P: 0.0100 RunMean : -97.9900\n",
      "Episode: 1319 Total reward: -96.0 Training loss: 2.2886 Explore P: 0.0100 RunMean : -97.8300\n",
      "Episode: 1320 Total reward: -90.0 Training loss: 1.2178 Explore P: 0.0100 RunMean : -97.3100\n",
      "Episode: 1321 Total reward: -77.0 Training loss: 1.7801 Explore P: 0.0100 RunMean : -97.1900\n",
      "Episode: 1322 Total reward: -105.0 Training loss: 1.8168 Explore P: 0.0100 RunMean : -97.3700\n",
      "Episode: 1323 Total reward: -79.0 Training loss: 4.2198 Explore P: 0.0100 RunMean : -97.3900\n",
      "Episode: 1324 Total reward: -96.0 Training loss: 1.9901 Explore P: 0.0100 RunMean : -96.9600\n",
      "Episode: 1325 Total reward: -86.0 Training loss: 1.7954 Explore P: 0.0100 RunMean : -96.7500\n",
      "Episode: 1326 Total reward: -97.0 Training loss: 2.1900 Explore P: 0.0100 RunMean : -96.5600\n",
      "Episode: 1327 Total reward: -115.0 Training loss: 1.9210 Explore P: 0.0100 RunMean : -96.3300\n",
      "Episode: 1328 Total reward: -92.0 Training loss: 1.5918 Explore P: 0.0100 RunMean : -96.2300\n",
      "Episode: 1329 Total reward: -86.0 Training loss: 2.3215 Explore P: 0.0100 RunMean : -95.4100\n",
      "Episode: 1330 Total reward: -92.0 Training loss: 1.5833 Explore P: 0.0100 RunMean : -95.6000\n",
      "Episode: 1331 Total reward: -78.0 Training loss: 2.8858 Explore P: 0.0100 RunMean : -95.6900\n",
      "Episode: 1332 Total reward: -167.0 Training loss: 5.1655 Explore P: 0.0100 RunMean : -96.6600\n",
      "Episode: 1333 Total reward: -81.0 Training loss: 1.7527 Explore P: 0.0100 RunMean : -96.4500\n",
      "Episode: 1334 Total reward: -79.0 Training loss: 3.0721 Explore P: 0.0100 RunMean : -95.8700\n",
      "Episode: 1335 Total reward: -82.0 Training loss: 2.4350 Explore P: 0.0100 RunMean : -96.0000\n",
      "Episode: 1336 Total reward: -91.0 Training loss: 3.2091 Explore P: 0.0100 RunMean : -96.2800\n",
      "Episode: 1337 Total reward: -78.0 Training loss: 1.6964 Explore P: 0.0100 RunMean : -96.3000\n",
      "Episode: 1338 Total reward: -79.0 Training loss: 0.8412 Explore P: 0.0100 RunMean : -96.3000\n",
      "Episode: 1339 Total reward: -105.0 Training loss: 2.3052 Explore P: 0.0100 RunMean : -96.4900\n",
      "Episode: 1340 Total reward: -98.0 Training loss: 1.0064 Explore P: 0.0100 RunMean : -96.6400\n",
      "Episode: 1341 Total reward: -84.0 Training loss: 1.1545 Explore P: 0.0100 RunMean : -96.5200\n",
      "Episode: 1342 Total reward: -93.0 Training loss: 1.0738 Explore P: 0.0100 RunMean : -96.4400\n",
      "Episode: 1343 Total reward: -108.0 Training loss: 1.6689 Explore P: 0.0100 RunMean : -96.7600\n",
      "Episode: 1344 Total reward: -84.0 Training loss: 1.7645 Explore P: 0.0100 RunMean : -96.7400\n",
      "Episode: 1345 Total reward: -86.0 Training loss: 1.4490 Explore P: 0.0100 RunMean : -96.6100\n",
      "Episode: 1346 Total reward: -80.0 Training loss: 2.7100 Explore P: 0.0100 RunMean : -96.4300\n",
      "Episode: 1347 Total reward: -68.0 Training loss: 2.5393 Explore P: 0.0100 RunMean : -96.0700\n",
      "Episode: 1348 Total reward: -71.0 Training loss: 1.6388 Explore P: 0.0100 RunMean : -95.9200\n",
      "Episode: 1349 Total reward: -102.0 Training loss: 2.7901 Explore P: 0.0100 RunMean : -96.2300\n",
      "Episode: 1350 Total reward: -127.0 Training loss: 1.6886 Explore P: 0.0100 RunMean : -96.7900\n",
      "Episode: 1351 Total reward: -93.0 Training loss: 2.5457 Explore P: 0.0100 RunMean : -96.6500\n",
      "Episode: 1352 Total reward: -77.0 Training loss: 1.9827 Explore P: 0.0100 RunMean : -96.3100\n",
      "Episode: 1353 Total reward: -99.0 Training loss: 4.1019 Explore P: 0.0100 RunMean : -96.3700\n",
      "Episode: 1354 Total reward: -89.0 Training loss: 3.5232 Explore P: 0.0100 RunMean : -96.2900\n",
      "Episode: 1355 Total reward: -87.0 Training loss: 1.0524 Explore P: 0.0100 RunMean : -96.1100\n",
      "Episode: 1356 Total reward: -62.0 Training loss: 1.7384 Explore P: 0.0100 RunMean : -95.9800\n",
      "Episode: 1357 Total reward: -81.0 Training loss: 1.2212 Explore P: 0.0100 RunMean : -96.1100\n",
      "Episode: 1358 Total reward: -163.0 Training loss: 2.2885 Explore P: 0.0100 RunMean : -96.4600\n",
      "Episode: 1359 Total reward: -107.0 Training loss: 2.6244 Explore P: 0.0100 RunMean : -96.4300\n",
      "Episode: 1360 Total reward: -114.0 Training loss: 1.7863 Explore P: 0.0100 RunMean : -95.4800\n",
      "Episode: 1361 Total reward: -115.0 Training loss: 4.3420 Explore P: 0.0100 RunMean : -94.0300\n",
      "Episode: 1362 Total reward: -100.0 Training loss: 3.2552 Explore P: 0.0100 RunMean : -94.2000\n",
      "Episode: 1363 Total reward: -115.0 Training loss: 2.8125 Explore P: 0.0100 RunMean : -94.4900\n",
      "Episode: 1364 Total reward: -86.0 Training loss: 1.4476 Explore P: 0.0100 RunMean : -94.4400\n",
      "Episode: 1365 Total reward: -95.0 Training loss: 2.3025 Explore P: 0.0100 RunMean : -94.0900\n",
      "Episode: 1366 Total reward: -144.0 Training loss: 3.5262 Explore P: 0.0100 RunMean : -94.8300\n",
      "Episode: 1367 Total reward: -98.0 Training loss: 2.1200 Explore P: 0.0100 RunMean : -95.1000\n",
      "Episode: 1368 Total reward: -86.0 Training loss: 2.1695 Explore P: 0.0100 RunMean : -95.1100\n",
      "Episode: 1369 Total reward: -84.0 Training loss: 3.9934 Explore P: 0.0100 RunMean : -94.8400\n",
      "Episode: 1370 Total reward: -106.0 Training loss: 1.8386 Explore P: 0.0100 RunMean : -94.7300\n",
      "Episode: 1371 Total reward: -120.0 Training loss: 1.2129 Explore P: 0.0100 RunMean : -95.0300\n",
      "Episode: 1372 Total reward: -74.0 Training loss: 1.4824 Explore P: 0.0100 RunMean : -94.6400\n",
      "Episode: 1373 Total reward: -77.0 Training loss: 1.1263 Explore P: 0.0100 RunMean : -94.7900\n",
      "Episode: 1374 Total reward: -87.0 Training loss: 2.5165 Explore P: 0.0100 RunMean : -94.8000\n",
      "Episode: 1375 Total reward: -129.0 Training loss: 1.0678 Explore P: 0.0100 RunMean : -94.9900\n",
      "Episode: 1376 Total reward: -78.0 Training loss: 2.5637 Explore P: 0.0100 RunMean : -94.6700\n",
      "Episode: 1377 Total reward: -86.0 Training loss: 2.8721 Explore P: 0.0100 RunMean : -94.3900\n",
      "Episode: 1378 Total reward: -89.0 Training loss: 1.4521 Explore P: 0.0100 RunMean : -94.3000\n",
      "Episode: 1379 Total reward: -86.0 Training loss: 1.9558 Explore P: 0.0100 RunMean : -94.1400\n",
      "Episode: 1380 Total reward: -95.0 Training loss: 2.3266 Explore P: 0.0100 RunMean : -94.1800\n",
      "Episode: 1381 Total reward: -99.0 Training loss: 0.9703 Explore P: 0.0100 RunMean : -94.1200\n",
      "Episode: 1382 Total reward: -85.0 Training loss: 1.0330 Explore P: 0.0100 RunMean : -93.8400\n",
      "Episode: 1383 Total reward: -97.0 Training loss: 1.4832 Explore P: 0.0100 RunMean : -94.1900\n",
      "Episode: 1384 Total reward: -125.0 Training loss: 1.0200 Explore P: 0.0100 RunMean : -94.6700\n",
      "Episode: 1385 Total reward: -92.0 Training loss: 1.0165 Explore P: 0.0100 RunMean : -94.7000\n",
      "Episode: 1386 Total reward: -129.0 Training loss: 1.5883 Explore P: 0.0100 RunMean : -95.1400\n",
      "Episode: 1387 Total reward: -68.0 Training loss: 1.7011 Explore P: 0.0100 RunMean : -94.8500\n",
      "Episode: 1388 Total reward: -108.0 Training loss: 1.8695 Explore P: 0.0100 RunMean : -94.9400\n",
      "Episode: 1389 Total reward: -73.0 Training loss: 3.4862 Explore P: 0.0100 RunMean : -94.6900\n",
      "Episode: 1390 Total reward: -80.0 Training loss: 2.4452 Explore P: 0.0100 RunMean : -94.7800\n",
      "Episode: 1391 Total reward: -122.0 Training loss: 1.5686 Explore P: 0.0100 RunMean : -94.9300\n",
      "Episode: 1392 Total reward: -129.0 Training loss: 2.3267 Explore P: 0.0100 RunMean : -95.3600\n",
      "Episode: 1393 Total reward: -116.0 Training loss: 1.7525 Explore P: 0.0100 RunMean : -95.8300\n",
      "Episode: 1394 Total reward: -62.0 Training loss: 1.4543 Explore P: 0.0100 RunMean : -95.7200\n",
      "Episode: 1395 Total reward: -103.0 Training loss: 4.0656 Explore P: 0.0100 RunMean : -95.9000\n",
      "Episode: 1396 Total reward: -86.0 Training loss: 3.1841 Explore P: 0.0100 RunMean : -95.5400\n",
      "Episode: 1397 Total reward: -90.0 Training loss: 1.7932 Explore P: 0.0100 RunMean : -95.1200\n",
      "Episode: 1398 Total reward: -85.0 Training loss: 2.0726 Explore P: 0.0100 RunMean : -94.9400\n",
      "Episode: 1399 Total reward: -99.0 Training loss: 1.1901 Explore P: 0.0100 RunMean : -94.8500\n",
      "Episode: 1400 Total reward: -98.0 Training loss: 1.4194 Explore P: 0.0100 RunMean : -94.5800\n",
      "Episode: 1401 Total reward: -74.0 Training loss: 1.1027 Explore P: 0.0100 RunMean : -94.2400\n",
      "Episode: 1402 Total reward: -85.0 Training loss: 2.1490 Explore P: 0.0100 RunMean : -94.1800\n",
      "Episode: 1403 Total reward: -83.0 Training loss: 1.0886 Explore P: 0.0100 RunMean : -94.0400\n",
      "Episode: 1404 Total reward: -71.0 Training loss: 1.4558 Explore P: 0.0100 RunMean : -93.6300\n",
      "Episode: 1405 Total reward: -70.0 Training loss: 1.1699 Explore P: 0.0100 RunMean : -92.9600\n",
      "Episode: 1406 Total reward: -77.0 Training loss: 1.8476 Explore P: 0.0100 RunMean : -93.1100\n",
      "Episode: 1407 Total reward: -76.0 Training loss: 1.8712 Explore P: 0.0100 RunMean : -93.0600\n",
      "Episode: 1408 Total reward: -116.0 Training loss: 2.4100 Explore P: 0.0100 RunMean : -93.3800\n",
      "Episode: 1409 Total reward: -93.0 Training loss: 3.1757 Explore P: 0.0100 RunMean : -93.3100\n",
      "Episode: 1410 Total reward: -84.0 Training loss: 1.9660 Explore P: 0.0100 RunMean : -93.1800\n",
      "Episode: 1411 Total reward: -113.0 Training loss: 1.8561 Explore P: 0.0100 RunMean : -93.4500\n",
      "Episode: 1412 Total reward: -92.0 Training loss: 4.9967 Explore P: 0.0100 RunMean : -93.5400\n",
      "Episode: 1413 Total reward: -92.0 Training loss: 3.7896 Explore P: 0.0100 RunMean : -93.6000\n",
      "Episode: 1414 Total reward: -68.0 Training loss: 2.0725 Explore P: 0.0100 RunMean : -93.3800\n",
      "Episode: 1415 Total reward: -69.0 Training loss: 1.1430 Explore P: 0.0100 RunMean : -93.1400\n",
      "Episode: 1416 Total reward: -95.0 Training loss: 1.8936 Explore P: 0.0100 RunMean : -93.2200\n",
      "Episode: 1417 Total reward: -104.0 Training loss: 3.0394 Explore P: 0.0100 RunMean : -93.5700\n",
      "Episode: 1418 Total reward: -135.0 Training loss: 3.1122 Explore P: 0.0100 RunMean : -94.1700\n",
      "Episode: 1419 Total reward: -116.0 Training loss: 1.8461 Explore P: 0.0100 RunMean : -94.3700\n",
      "Episode: 1420 Total reward: -126.0 Training loss: 1.9744 Explore P: 0.0100 RunMean : -94.7300\n",
      "Episode: 1421 Total reward: -97.0 Training loss: 1.0577 Explore P: 0.0100 RunMean : -94.9300\n",
      "Episode: 1422 Total reward: -69.0 Training loss: 1.3473 Explore P: 0.0100 RunMean : -94.5700\n",
      "Episode: 1423 Total reward: -95.0 Training loss: 2.3373 Explore P: 0.0100 RunMean : -94.7300\n",
      "Episode: 1424 Total reward: -105.0 Training loss: 1.5362 Explore P: 0.0100 RunMean : -94.8200\n",
      "Episode: 1425 Total reward: -93.0 Training loss: 1.1827 Explore P: 0.0100 RunMean : -94.8900\n",
      "Episode: 1426 Total reward: -91.0 Training loss: 1.0890 Explore P: 0.0100 RunMean : -94.8300\n",
      "Episode: 1427 Total reward: -88.0 Training loss: 2.4027 Explore P: 0.0100 RunMean : -94.5600\n",
      "Episode: 1428 Total reward: -100.0 Training loss: 2.5631 Explore P: 0.0100 RunMean : -94.6400\n",
      "Episode: 1429 Total reward: -93.0 Training loss: 1.9209 Explore P: 0.0100 RunMean : -94.7100\n",
      "Episode: 1430 Total reward: -151.0 Training loss: 2.4948 Explore P: 0.0100 RunMean : -95.3000\n",
      "Episode: 1431 Total reward: -118.0 Training loss: 2.1724 Explore P: 0.0100 RunMean : -95.7000\n",
      "Episode: 1432 Total reward: -141.0 Training loss: 1.4571 Explore P: 0.0100 RunMean : -95.4400\n",
      "Episode: 1433 Total reward: -85.0 Training loss: 3.0117 Explore P: 0.0100 RunMean : -95.4800\n",
      "Episode: 1434 Total reward: -77.0 Training loss: 2.3734 Explore P: 0.0100 RunMean : -95.4600\n",
      "Episode: 1435 Total reward: -72.0 Training loss: 0.8301 Explore P: 0.0100 RunMean : -95.3600\n",
      "Episode: 1436 Total reward: -89.0 Training loss: 0.9914 Explore P: 0.0100 RunMean : -95.3400\n",
      "Episode: 1437 Total reward: -63.0 Training loss: 5.4981 Explore P: 0.0100 RunMean : -95.1900\n",
      "Episode: 1438 Total reward: -91.0 Training loss: 1.8780 Explore P: 0.0100 RunMean : -95.3100\n",
      "Episode: 1439 Total reward: -116.0 Training loss: 1.8167 Explore P: 0.0100 RunMean : -95.4200\n",
      "Episode: 1440 Total reward: -83.0 Training loss: 1.5012 Explore P: 0.0100 RunMean : -95.2700\n",
      "Episode: 1441 Total reward: -108.0 Training loss: 1.3118 Explore P: 0.0100 RunMean : -95.5100\n",
      "Episode: 1442 Total reward: -95.0 Training loss: 1.8426 Explore P: 0.0100 RunMean : -95.5300\n",
      "Episode: 1443 Total reward: -94.0 Training loss: 3.2558 Explore P: 0.0100 RunMean : -95.3900\n",
      "Episode: 1444 Total reward: -98.0 Training loss: 3.0925 Explore P: 0.0100 RunMean : -95.5300\n",
      "Episode: 1445 Total reward: -102.0 Training loss: 1.9966 Explore P: 0.0100 RunMean : -95.6900\n",
      "Episode: 1446 Total reward: -126.0 Training loss: 6.1793 Explore P: 0.0100 RunMean : -96.1500\n",
      "Episode: 1447 Total reward: -202.0 Training loss: 0.9239 Explore P: 0.0100 RunMean : -97.4900\n",
      "Episode: 1448 Total reward: -88.0 Training loss: 0.8563 Explore P: 0.0100 RunMean : -97.6600\n",
      "Episode: 1449 Total reward: -91.0 Training loss: 1.8024 Explore P: 0.0100 RunMean : -97.5500\n",
      "Episode: 1450 Total reward: -118.0 Training loss: 1.8462 Explore P: 0.0100 RunMean : -97.4600\n",
      "Episode: 1451 Total reward: -110.0 Training loss: 1.2624 Explore P: 0.0100 RunMean : -97.6300\n",
      "Episode: 1452 Total reward: -122.0 Training loss: 1.3589 Explore P: 0.0100 RunMean : -98.0800\n",
      "Episode: 1453 Total reward: -101.0 Training loss: 1.4585 Explore P: 0.0100 RunMean : -98.1000\n",
      "Episode: 1454 Total reward: -90.0 Training loss: 1.2387 Explore P: 0.0100 RunMean : -98.1100\n",
      "Episode: 1455 Total reward: -71.0 Training loss: 1.3843 Explore P: 0.0100 RunMean : -97.9500\n",
      "Episode: 1456 Total reward: -83.0 Training loss: 2.1742 Explore P: 0.0100 RunMean : -98.1600\n",
      "Episode: 1457 Total reward: -81.0 Training loss: 2.3163 Explore P: 0.0100 RunMean : -98.1600\n",
      "Episode: 1458 Total reward: -83.0 Training loss: 3.1000 Explore P: 0.0100 RunMean : -97.3600\n",
      "Episode: 1459 Total reward: -98.0 Training loss: 0.8457 Explore P: 0.0100 RunMean : -97.2700\n",
      "Episode: 1460 Total reward: -98.0 Training loss: 1.6852 Explore P: 0.0100 RunMean : -97.1100\n",
      "Episode: 1461 Total reward: -89.0 Training loss: 1.2082 Explore P: 0.0100 RunMean : -96.8500\n",
      "Episode: 1462 Total reward: -87.0 Training loss: 5.2272 Explore P: 0.0100 RunMean : -96.7200\n",
      "Episode: 1463 Total reward: -103.0 Training loss: 1.9894 Explore P: 0.0100 RunMean : -96.6000\n",
      "Episode: 1464 Total reward: -97.0 Training loss: 1.5092 Explore P: 0.0100 RunMean : -96.7100\n",
      "Episode: 1465 Total reward: -92.0 Training loss: 1.6594 Explore P: 0.0100 RunMean : -96.6800\n",
      "Episode: 1466 Total reward: -102.0 Training loss: 3.1076 Explore P: 0.0100 RunMean : -96.2600\n",
      "Episode: 1467 Total reward: -84.0 Training loss: 1.5982 Explore P: 0.0100 RunMean : -96.1200\n",
      "Episode: 1468 Total reward: -110.0 Training loss: 1.1553 Explore P: 0.0100 RunMean : -96.3600\n",
      "Episode: 1469 Total reward: -97.0 Training loss: 1.5275 Explore P: 0.0100 RunMean : -96.4900\n",
      "Episode: 1470 Total reward: -79.0 Training loss: 1.4749 Explore P: 0.0100 RunMean : -96.2200\n",
      "Episode: 1471 Total reward: -83.0 Training loss: 2.2687 Explore P: 0.0100 RunMean : -95.8500\n",
      "Episode: 1472 Total reward: -111.0 Training loss: 1.0593 Explore P: 0.0100 RunMean : -96.2200\n",
      "Episode: 1473 Total reward: -126.0 Training loss: 2.0133 Explore P: 0.0100 RunMean : -96.7100\n",
      "Episode: 1474 Total reward: -82.0 Training loss: 1.7202 Explore P: 0.0100 RunMean : -96.6600\n",
      "Episode: 1475 Total reward: -86.0 Training loss: 1.2821 Explore P: 0.0100 RunMean : -96.2300\n",
      "Episode: 1476 Total reward: -111.0 Training loss: 1.0660 Explore P: 0.0100 RunMean : -96.5600\n",
      "Episode: 1477 Total reward: -86.0 Training loss: 2.1898 Explore P: 0.0100 RunMean : -96.5600\n",
      "Episode: 1478 Total reward: -90.0 Training loss: 1.7348 Explore P: 0.0100 RunMean : -96.5700\n",
      "Episode: 1479 Total reward: -99.0 Training loss: 1.3823 Explore P: 0.0100 RunMean : -96.7000\n",
      "Episode: 1480 Total reward: -118.0 Training loss: 1.3165 Explore P: 0.0100 RunMean : -96.9300\n",
      "Episode: 1481 Total reward: -92.0 Training loss: 2.0451 Explore P: 0.0100 RunMean : -96.8600\n",
      "Episode: 1482 Total reward: -82.0 Training loss: 0.5742 Explore P: 0.0100 RunMean : -96.8300\n",
      "Episode: 1483 Total reward: -124.0 Training loss: 1.2478 Explore P: 0.0100 RunMean : -97.1000\n",
      "Episode: 1484 Total reward: -114.0 Training loss: 1.8971 Explore P: 0.0100 RunMean : -96.9900\n",
      "Episode: 1485 Total reward: -96.0 Training loss: 1.0239 Explore P: 0.0100 RunMean : -97.0300\n",
      "Episode: 1486 Total reward: -86.0 Training loss: 0.6501 Explore P: 0.0100 RunMean : -96.6000\n",
      "Episode: 1487 Total reward: -85.0 Training loss: 1.1853 Explore P: 0.0100 RunMean : -96.7700\n",
      "Episode: 1488 Total reward: -94.0 Training loss: 1.0480 Explore P: 0.0100 RunMean : -96.6300\n",
      "Episode: 1489 Total reward: -500.0 Training loss: 1.4621 Explore P: 0.0100 RunMean : -100.9000\n",
      "Episode: 1490 Total reward: -61.0 Training loss: 1.9547 Explore P: 0.0100 RunMean : -100.7100\n",
      "Episode: 1491 Total reward: -103.0 Training loss: 2.6215 Explore P: 0.0100 RunMean : -100.5200\n",
      "Episode: 1492 Total reward: -99.0 Training loss: 1.3440 Explore P: 0.0100 RunMean : -100.2200\n",
      "Episode: 1493 Total reward: -91.0 Training loss: 3.2755 Explore P: 0.0100 RunMean : -99.9700\n",
      "Episode: 1494 Total reward: -116.0 Training loss: 1.2683 Explore P: 0.0100 RunMean : -100.5100\n",
      "Episode: 1495 Total reward: -118.0 Training loss: 3.5478 Explore P: 0.0100 RunMean : -100.6600\n",
      "Episode: 1496 Total reward: -81.0 Training loss: 1.4058 Explore P: 0.0100 RunMean : -100.6100\n",
      "Episode: 1497 Total reward: -105.0 Training loss: 1.5592 Explore P: 0.0100 RunMean : -100.7600\n",
      "Episode: 1498 Total reward: -108.0 Training loss: 1.4890 Explore P: 0.0100 RunMean : -100.9900\n",
      "Episode: 1499 Total reward: -92.0 Training loss: 1.6581 Explore P: 0.0100 RunMean : -100.9200\n",
      "Episode: 1500 Total reward: -85.0 Training loss: 1.9543 Explore P: 0.0100 RunMean : -100.7900\n",
      "Episode: 1501 Total reward: -84.0 Training loss: 2.8668 Explore P: 0.0100 RunMean : -100.8900\n",
      "Episode: 1502 Total reward: -74.0 Training loss: 2.0350 Explore P: 0.0100 RunMean : -100.7800\n",
      "Episode: 1503 Total reward: -78.0 Training loss: 1.6243 Explore P: 0.0100 RunMean : -100.7300\n",
      "Episode: 1504 Total reward: -103.0 Training loss: 2.0760 Explore P: 0.0100 RunMean : -101.0500\n",
      "Episode: 1505 Total reward: -97.0 Training loss: 2.2224 Explore P: 0.0100 RunMean : -101.3200\n",
      "Episode: 1506 Total reward: -62.0 Training loss: 1.8238 Explore P: 0.0100 RunMean : -101.1700\n",
      "Episode: 1507 Total reward: -91.0 Training loss: 3.1782 Explore P: 0.0100 RunMean : -101.3200\n",
      "Episode: 1508 Total reward: -141.0 Training loss: 1.8821 Explore P: 0.0100 RunMean : -101.5700\n",
      "Episode: 1509 Total reward: -89.0 Training loss: 1.3442 Explore P: 0.0100 RunMean : -101.5300\n",
      "Episode: 1510 Total reward: -78.0 Training loss: 1.3267 Explore P: 0.0100 RunMean : -101.4700\n",
      "Episode: 1511 Total reward: -95.0 Training loss: 0.8344 Explore P: 0.0100 RunMean : -101.2900\n",
      "Episode: 1512 Total reward: -91.0 Training loss: 2.0188 Explore P: 0.0100 RunMean : -101.2800\n",
      "Episode: 1513 Total reward: -86.0 Training loss: 1.2710 Explore P: 0.0100 RunMean : -101.2200\n",
      "Episode: 1514 Total reward: -107.0 Training loss: 1.7399 Explore P: 0.0100 RunMean : -101.6100\n",
      "Episode: 1515 Total reward: -69.0 Training loss: 1.6417 Explore P: 0.0100 RunMean : -101.6100\n",
      "Episode: 1516 Total reward: -98.0 Training loss: 1.4562 Explore P: 0.0100 RunMean : -101.6400\n",
      "Episode: 1517 Total reward: -64.0 Training loss: 3.9703 Explore P: 0.0100 RunMean : -101.2400\n",
      "Episode: 1518 Total reward: -85.0 Training loss: 1.0043 Explore P: 0.0100 RunMean : -100.7400\n",
      "Episode: 1519 Total reward: -80.0 Training loss: 4.4202 Explore P: 0.0100 RunMean : -100.3800\n",
      "Episode: 1520 Total reward: -98.0 Training loss: 1.6086 Explore P: 0.0100 RunMean : -100.1000\n",
      "Episode: 1521 Total reward: -75.0 Training loss: 1.8315 Explore P: 0.0100 RunMean : -99.8800\n",
      "Episode: 1522 Total reward: -100.0 Training loss: 1.6014 Explore P: 0.0100 RunMean : -100.1900\n",
      "Episode: 1523 Total reward: -85.0 Training loss: 2.5765 Explore P: 0.0100 RunMean : -100.0900\n",
      "Episode: 1524 Total reward: -102.0 Training loss: 3.2820 Explore P: 0.0100 RunMean : -100.0600\n",
      "Episode: 1525 Total reward: -133.0 Training loss: 2.8568 Explore P: 0.0100 RunMean : -100.4600\n",
      "Episode: 1526 Total reward: -117.0 Training loss: 3.3235 Explore P: 0.0100 RunMean : -100.7200\n",
      "Episode: 1527 Total reward: -122.0 Training loss: 3.3962 Explore P: 0.0100 RunMean : -101.0600\n",
      "Episode: 1528 Total reward: -77.0 Training loss: 1.0196 Explore P: 0.0100 RunMean : -100.8300\n",
      "Episode: 1529 Total reward: -80.0 Training loss: 2.1911 Explore P: 0.0100 RunMean : -100.7000\n",
      "Episode: 1530 Total reward: -78.0 Training loss: 1.3003 Explore P: 0.0100 RunMean : -99.9700\n",
      "Episode: 1531 Total reward: -62.0 Training loss: 0.9633 Explore P: 0.0100 RunMean : -99.4100\n",
      "Episode: 1532 Total reward: -83.0 Training loss: 1.0265 Explore P: 0.0100 RunMean : -98.8300\n",
      "Episode: 1533 Total reward: -77.0 Training loss: 2.1893 Explore P: 0.0100 RunMean : -98.7500\n",
      "Episode: 1534 Total reward: -107.0 Training loss: 2.1121 Explore P: 0.0100 RunMean : -99.0500\n",
      "Episode: 1535 Total reward: -128.0 Training loss: 2.1375 Explore P: 0.0100 RunMean : -99.6100\n",
      "Episode: 1536 Total reward: -102.0 Training loss: 5.6815 Explore P: 0.0100 RunMean : -99.7400\n",
      "Episode: 1537 Total reward: -80.0 Training loss: 1.7328 Explore P: 0.0100 RunMean : -99.9100\n",
      "Episode: 1538 Total reward: -63.0 Training loss: 1.5190 Explore P: 0.0100 RunMean : -99.6300\n",
      "Episode: 1539 Total reward: -147.0 Training loss: 0.8986 Explore P: 0.0100 RunMean : -99.9400\n",
      "Episode: 1540 Total reward: -141.0 Training loss: 1.0832 Explore P: 0.0100 RunMean : -100.5200\n",
      "Episode: 1541 Total reward: -84.0 Training loss: 3.8994 Explore P: 0.0100 RunMean : -100.2800\n",
      "Episode: 1542 Total reward: -78.0 Training loss: 4.5988 Explore P: 0.0100 RunMean : -100.1100\n",
      "Episode: 1543 Total reward: -77.0 Training loss: 1.6103 Explore P: 0.0100 RunMean : -99.9400\n",
      "Episode: 1544 Total reward: -90.0 Training loss: 1.3650 Explore P: 0.0100 RunMean : -99.8600\n",
      "Episode: 1545 Total reward: -90.0 Training loss: 1.8884 Explore P: 0.0100 RunMean : -99.7400\n",
      "Episode: 1546 Total reward: -173.0 Training loss: 1.1040 Explore P: 0.0100 RunMean : -100.2100\n",
      "Episode: 1547 Total reward: -85.0 Training loss: 2.1135 Explore P: 0.0100 RunMean : -99.0400\n",
      "Episode: 1548 Total reward: -105.0 Training loss: 5.6855 Explore P: 0.0100 RunMean : -99.2100\n",
      "Episode: 1549 Total reward: -118.0 Training loss: 2.4343 Explore P: 0.0100 RunMean : -99.4800\n",
      "Episode: 1550 Total reward: -99.0 Training loss: 1.3218 Explore P: 0.0100 RunMean : -99.2900\n",
      "Episode: 1551 Total reward: -139.0 Training loss: 3.0731 Explore P: 0.0100 RunMean : -99.5800\n",
      "Episode: 1552 Total reward: -100.0 Training loss: 1.7170 Explore P: 0.0100 RunMean : -99.3600\n",
      "Episode: 1553 Total reward: -189.0 Training loss: 6.8040 Explore P: 0.0100 RunMean : -100.2400\n",
      "Episode: 1554 Total reward: -93.0 Training loss: 2.5025 Explore P: 0.0100 RunMean : -100.2700\n",
      "Episode: 1555 Total reward: -133.0 Training loss: 1.3414 Explore P: 0.0100 RunMean : -100.8900\n",
      "Episode: 1556 Total reward: -98.0 Training loss: 2.3190 Explore P: 0.0100 RunMean : -101.0400\n",
      "Episode: 1557 Total reward: -71.0 Training loss: 1.0105 Explore P: 0.0100 RunMean : -100.9400\n",
      "Episode: 1558 Total reward: -71.0 Training loss: 1.9062 Explore P: 0.0100 RunMean : -100.8200\n",
      "Episode: 1559 Total reward: -157.0 Training loss: 3.1418 Explore P: 0.0100 RunMean : -101.4100\n",
      "Episode: 1560 Total reward: -186.0 Training loss: 1.6466 Explore P: 0.0100 RunMean : -102.2900\n",
      "Episode: 1561 Total reward: -87.0 Training loss: 3.1494 Explore P: 0.0100 RunMean : -102.2700\n",
      "Episode: 1562 Total reward: -84.0 Training loss: 2.1503 Explore P: 0.0100 RunMean : -102.2400\n",
      "Episode: 1563 Total reward: -122.0 Training loss: 1.5035 Explore P: 0.0100 RunMean : -102.4300\n",
      "Episode: 1564 Total reward: -91.0 Training loss: 2.7441 Explore P: 0.0100 RunMean : -102.3700\n",
      "Episode: 1565 Total reward: -74.0 Training loss: 1.5526 Explore P: 0.0100 RunMean : -102.1900\n",
      "Episode: 1566 Total reward: -77.0 Training loss: 2.5522 Explore P: 0.0100 RunMean : -101.9400\n",
      "Episode: 1567 Total reward: -100.0 Training loss: 1.5786 Explore P: 0.0100 RunMean : -102.1000\n",
      "Episode: 1568 Total reward: -104.0 Training loss: 1.2599 Explore P: 0.0100 RunMean : -102.0400\n",
      "Episode: 1569 Total reward: -82.0 Training loss: 1.4665 Explore P: 0.0100 RunMean : -101.8900\n",
      "Episode: 1570 Total reward: -81.0 Training loss: 2.2546 Explore P: 0.0100 RunMean : -101.9100\n",
      "Episode: 1571 Total reward: -105.0 Training loss: 3.8756 Explore P: 0.0100 RunMean : -102.1300\n",
      "Episode: 1572 Total reward: -81.0 Training loss: 2.3249 Explore P: 0.0100 RunMean : -101.8300\n",
      "Episode: 1573 Total reward: -93.0 Training loss: 2.6371 Explore P: 0.0100 RunMean : -101.5000\n",
      "Episode: 1574 Total reward: -117.0 Training loss: 2.5870 Explore P: 0.0100 RunMean : -101.8500\n",
      "Episode: 1575 Total reward: -77.0 Training loss: 1.1337 Explore P: 0.0100 RunMean : -101.7600\n",
      "Episode: 1576 Total reward: -92.0 Training loss: 1.6521 Explore P: 0.0100 RunMean : -101.5700\n",
      "Episode: 1577 Total reward: -116.0 Training loss: 2.0265 Explore P: 0.0100 RunMean : -101.8700\n",
      "Episode: 1578 Total reward: -64.0 Training loss: 3.3266 Explore P: 0.0100 RunMean : -101.6100\n",
      "Episode: 1579 Total reward: -105.0 Training loss: 2.6629 Explore P: 0.0100 RunMean : -101.6700\n",
      "Episode: 1580 Total reward: -120.0 Training loss: 2.4197 Explore P: 0.0100 RunMean : -101.6900\n",
      "Episode: 1581 Total reward: -118.0 Training loss: 2.3849 Explore P: 0.0100 RunMean : -101.9500\n",
      "Episode: 1582 Total reward: -92.0 Training loss: 2.4736 Explore P: 0.0100 RunMean : -102.0500\n",
      "Episode: 1583 Total reward: -97.0 Training loss: 2.6867 Explore P: 0.0100 RunMean : -101.7800\n",
      "Episode: 1584 Total reward: -63.0 Training loss: 2.0785 Explore P: 0.0100 RunMean : -101.2700\n",
      "Episode: 1585 Total reward: -92.0 Training loss: 2.2446 Explore P: 0.0100 RunMean : -101.2300\n",
      "Episode: 1586 Total reward: -83.0 Training loss: 4.6403 Explore P: 0.0100 RunMean : -101.2000\n",
      "Episode: 1587 Total reward: -72.0 Training loss: 3.0540 Explore P: 0.0100 RunMean : -101.0700\n",
      "Episode: 1588 Total reward: -91.0 Training loss: 3.9743 Explore P: 0.0100 RunMean : -101.0400\n",
      "Episode: 1589 Total reward: -86.0 Training loss: 2.8927 Explore P: 0.0100 RunMean : -96.9000\n",
      "Episode: 1590 Total reward: -94.0 Training loss: 2.0369 Explore P: 0.0100 RunMean : -97.2300\n",
      "Episode: 1591 Total reward: -72.0 Training loss: 1.4064 Explore P: 0.0100 RunMean : -96.9200\n",
      "Episode: 1592 Total reward: -68.0 Training loss: 1.8918 Explore P: 0.0100 RunMean : -96.6100\n",
      "Episode: 1593 Total reward: -97.0 Training loss: 1.6246 Explore P: 0.0100 RunMean : -96.6700\n",
      "Episode: 1594 Total reward: -101.0 Training loss: 2.9234 Explore P: 0.0100 RunMean : -96.5200\n",
      "Episode: 1595 Total reward: -91.0 Training loss: 1.2916 Explore P: 0.0100 RunMean : -96.2500\n",
      "Episode: 1596 Total reward: -80.0 Training loss: 1.9278 Explore P: 0.0100 RunMean : -96.2400\n",
      "Episode: 1597 Total reward: -96.0 Training loss: 1.3423 Explore P: 0.0100 RunMean : -96.1500\n",
      "Episode: 1598 Total reward: -92.0 Training loss: 1.4739 Explore P: 0.0100 RunMean : -95.9900\n",
      "Episode: 1599 Total reward: -117.0 Training loss: 3.5735 Explore P: 0.0100 RunMean : -96.2400\n",
      "Episode: 1600 Total reward: -103.0 Training loss: 2.5079 Explore P: 0.0100 RunMean : -96.4200\n",
      "Episode: 1601 Total reward: -120.0 Training loss: 4.9957 Explore P: 0.0100 RunMean : -96.7800\n",
      "Episode: 1602 Total reward: -189.0 Training loss: 3.4908 Explore P: 0.0100 RunMean : -97.9300\n",
      "Episode: 1603 Total reward: -83.0 Training loss: 2.1966 Explore P: 0.0100 RunMean : -97.9800\n",
      "Episode: 1604 Total reward: -99.0 Training loss: 3.2210 Explore P: 0.0100 RunMean : -97.9400\n",
      "Episode: 1605 Total reward: -116.0 Training loss: 1.8393 Explore P: 0.0100 RunMean : -98.1300\n",
      "Episode: 1606 Total reward: -90.0 Training loss: 1.3050 Explore P: 0.0100 RunMean : -98.4100\n",
      "Episode: 1607 Total reward: -87.0 Training loss: 1.1193 Explore P: 0.0100 RunMean : -98.3700\n",
      "Episode: 1608 Total reward: -120.0 Training loss: 1.4551 Explore P: 0.0100 RunMean : -98.1600\n",
      "Episode: 1609 Total reward: -93.0 Training loss: 1.9471 Explore P: 0.0100 RunMean : -98.2000\n",
      "Episode: 1610 Total reward: -86.0 Training loss: 1.7655 Explore P: 0.0100 RunMean : -98.2800\n",
      "Episode: 1611 Total reward: -137.0 Training loss: 1.6585 Explore P: 0.0100 RunMean : -98.7000\n",
      "Episode: 1612 Total reward: -112.0 Training loss: 2.1267 Explore P: 0.0100 RunMean : -98.9100\n",
      "Episode: 1613 Total reward: -102.0 Training loss: 1.2825 Explore P: 0.0100 RunMean : -99.0700\n",
      "Episode: 1614 Total reward: -122.0 Training loss: 1.1038 Explore P: 0.0100 RunMean : -99.2200\n",
      "Episode: 1615 Total reward: -98.0 Training loss: 1.3232 Explore P: 0.0100 RunMean : -99.5100\n",
      "Episode: 1616 Total reward: -110.0 Training loss: 0.9953 Explore P: 0.0100 RunMean : -99.6300\n",
      "Episode: 1617 Total reward: -128.0 Training loss: 2.6908 Explore P: 0.0100 RunMean : -100.2700\n",
      "Episode: 1618 Total reward: -90.0 Training loss: 1.6133 Explore P: 0.0100 RunMean : -100.3200\n",
      "Episode: 1619 Total reward: -93.0 Training loss: 1.7796 Explore P: 0.0100 RunMean : -100.4500\n",
      "Episode: 1620 Total reward: -77.0 Training loss: 2.2259 Explore P: 0.0100 RunMean : -100.2400\n",
      "Episode: 1621 Total reward: -110.0 Training loss: 2.0345 Explore P: 0.0100 RunMean : -100.5900\n",
      "Episode: 1622 Total reward: -102.0 Training loss: 3.0282 Explore P: 0.0100 RunMean : -100.6100\n",
      "Episode: 1623 Total reward: -72.0 Training loss: 1.3823 Explore P: 0.0100 RunMean : -100.4800\n",
      "Episode: 1624 Total reward: -89.0 Training loss: 1.0649 Explore P: 0.0100 RunMean : -100.3500\n",
      "Episode: 1625 Total reward: -77.0 Training loss: 1.8872 Explore P: 0.0100 RunMean : -99.7900\n",
      "Episode: 1626 Total reward: -102.0 Training loss: 2.0935 Explore P: 0.0100 RunMean : -99.6400\n",
      "Episode: 1627 Total reward: -91.0 Training loss: 1.5829 Explore P: 0.0100 RunMean : -99.3300\n",
      "Episode: 1628 Total reward: -111.0 Training loss: 3.7632 Explore P: 0.0100 RunMean : -99.6700\n",
      "Episode: 1629 Total reward: -109.0 Training loss: 1.8623 Explore P: 0.0100 RunMean : -99.9600\n",
      "Episode: 1630 Total reward: -115.0 Training loss: 1.4946 Explore P: 0.0100 RunMean : -100.3300\n",
      "Episode: 1631 Total reward: -93.0 Training loss: 1.0329 Explore P: 0.0100 RunMean : -100.6400\n",
      "Episode: 1632 Total reward: -100.0 Training loss: 2.8131 Explore P: 0.0100 RunMean : -100.8100\n",
      "Episode: 1633 Total reward: -95.0 Training loss: 1.3144 Explore P: 0.0100 RunMean : -100.9900\n",
      "Episode: 1634 Total reward: -81.0 Training loss: 3.4796 Explore P: 0.0100 RunMean : -100.7300\n",
      "Episode: 1635 Total reward: -102.0 Training loss: 2.2831 Explore P: 0.0100 RunMean : -100.4700\n",
      "Episode: 1636 Total reward: -120.0 Training loss: 1.9299 Explore P: 0.0100 RunMean : -100.6500\n",
      "Episode: 1637 Total reward: -125.0 Training loss: 2.7449 Explore P: 0.0100 RunMean : -101.1000\n",
      "Episode: 1638 Total reward: -109.0 Training loss: 1.4275 Explore P: 0.0100 RunMean : -101.5600\n",
      "Episode: 1639 Total reward: -70.0 Training loss: 1.2228 Explore P: 0.0100 RunMean : -100.7900\n",
      "Episode: 1640 Total reward: -233.0 Training loss: 3.0378 Explore P: 0.0100 RunMean : -101.7100\n",
      "Episode: 1641 Total reward: -125.0 Training loss: 2.9000 Explore P: 0.0100 RunMean : -102.1200\n",
      "Episode: 1642 Total reward: -112.0 Training loss: 1.5541 Explore P: 0.0100 RunMean : -102.4600\n",
      "Episode: 1643 Total reward: -119.0 Training loss: 2.0110 Explore P: 0.0100 RunMean : -102.8800\n",
      "Episode: 1644 Total reward: -79.0 Training loss: 3.8015 Explore P: 0.0100 RunMean : -102.7700\n",
      "Episode: 1645 Total reward: -99.0 Training loss: 1.7890 Explore P: 0.0100 RunMean : -102.8600\n",
      "Episode: 1646 Total reward: -80.0 Training loss: 2.5773 Explore P: 0.0100 RunMean : -101.9300\n",
      "Episode: 1647 Total reward: -132.0 Training loss: 1.0804 Explore P: 0.0100 RunMean : -102.4000\n",
      "Episode: 1648 Total reward: -84.0 Training loss: 2.3954 Explore P: 0.0100 RunMean : -102.1900\n",
      "Episode: 1649 Total reward: -110.0 Training loss: 1.5139 Explore P: 0.0100 RunMean : -102.1100\n",
      "Episode: 1650 Total reward: -84.0 Training loss: 1.5252 Explore P: 0.0100 RunMean : -101.9600\n",
      "Episode: 1651 Total reward: -98.0 Training loss: 1.2579 Explore P: 0.0100 RunMean : -101.5500\n",
      "Episode: 1652 Total reward: -105.0 Training loss: 2.0911 Explore P: 0.0100 RunMean : -101.6000\n",
      "Episode: 1653 Total reward: -152.0 Training loss: 1.9386 Explore P: 0.0100 RunMean : -101.2300\n",
      "Episode: 1654 Total reward: -90.0 Training loss: 1.5752 Explore P: 0.0100 RunMean : -101.2000\n",
      "Episode: 1655 Total reward: -94.0 Training loss: 1.6506 Explore P: 0.0100 RunMean : -100.8100\n",
      "Episode: 1656 Total reward: -125.0 Training loss: 1.9991 Explore P: 0.0100 RunMean : -101.0800\n",
      "Episode: 1657 Total reward: -71.0 Training loss: 2.6261 Explore P: 0.0100 RunMean : -101.0800\n",
      "Episode: 1658 Total reward: -79.0 Training loss: 2.6764 Explore P: 0.0100 RunMean : -101.1600\n",
      "Episode: 1659 Total reward: -133.0 Training loss: 1.4777 Explore P: 0.0100 RunMean : -100.9200\n",
      "Episode: 1660 Total reward: -109.0 Training loss: 1.4843 Explore P: 0.0100 RunMean : -100.1500\n",
      "Episode: 1661 Total reward: -144.0 Training loss: 4.3253 Explore P: 0.0100 RunMean : -100.7200\n",
      "Episode: 1662 Total reward: -84.0 Training loss: 2.4042 Explore P: 0.0100 RunMean : -100.7200\n",
      "Episode: 1663 Total reward: -93.0 Training loss: 1.4487 Explore P: 0.0100 RunMean : -100.4300\n",
      "Episode: 1664 Total reward: -121.0 Training loss: 2.3933 Explore P: 0.0100 RunMean : -100.7300\n",
      "Episode: 1665 Total reward: -112.0 Training loss: 1.6600 Explore P: 0.0100 RunMean : -101.1100\n",
      "Episode: 1666 Total reward: -85.0 Training loss: 3.6996 Explore P: 0.0100 RunMean : -101.1900\n",
      "Episode: 1667 Total reward: -87.0 Training loss: 3.8450 Explore P: 0.0100 RunMean : -101.0600\n",
      "Episode: 1668 Total reward: -95.0 Training loss: 1.7952 Explore P: 0.0100 RunMean : -100.9700\n",
      "Episode: 1669 Total reward: -91.0 Training loss: 1.7272 Explore P: 0.0100 RunMean : -101.0600\n",
      "Episode: 1670 Total reward: -110.0 Training loss: 1.5990 Explore P: 0.0100 RunMean : -101.3500\n",
      "Episode: 1671 Total reward: -94.0 Training loss: 1.9241 Explore P: 0.0100 RunMean : -101.2400\n",
      "Episode: 1672 Total reward: -88.0 Training loss: 1.3545 Explore P: 0.0100 RunMean : -101.3100\n",
      "Episode: 1673 Total reward: -87.0 Training loss: 1.7375 Explore P: 0.0100 RunMean : -101.2500\n",
      "Episode: 1674 Total reward: -153.0 Training loss: 1.6226 Explore P: 0.0100 RunMean : -101.6100\n",
      "Episode: 1675 Total reward: -73.0 Training loss: 1.3270 Explore P: 0.0100 RunMean : -101.5700\n",
      "Episode: 1676 Total reward: -87.0 Training loss: 0.8405 Explore P: 0.0100 RunMean : -101.5200\n",
      "Episode: 1677 Total reward: -79.0 Training loss: 5.7307 Explore P: 0.0100 RunMean : -101.1500\n",
      "Episode: 1678 Total reward: -99.0 Training loss: 3.1040 Explore P: 0.0100 RunMean : -101.5000\n",
      "Episode: 1679 Total reward: -109.0 Training loss: 2.6050 Explore P: 0.0100 RunMean : -101.5400\n",
      "Episode: 1680 Total reward: -126.0 Training loss: 1.2824 Explore P: 0.0100 RunMean : -101.6000\n",
      "Episode: 1681 Total reward: -109.0 Training loss: 3.1707 Explore P: 0.0100 RunMean : -101.5100\n",
      "Episode: 1682 Total reward: -106.0 Training loss: 1.2310 Explore P: 0.0100 RunMean : -101.6500\n",
      "Episode: 1683 Total reward: -92.0 Training loss: 0.7540 Explore P: 0.0100 RunMean : -101.6000\n",
      "Episode: 1684 Total reward: -90.0 Training loss: 2.1468 Explore P: 0.0100 RunMean : -101.8700\n",
      "Episode: 1685 Total reward: -93.0 Training loss: 2.6813 Explore P: 0.0100 RunMean : -101.8800\n",
      "Episode: 1686 Total reward: -139.0 Training loss: 2.1967 Explore P: 0.0100 RunMean : -102.4400\n",
      "Episode: 1687 Total reward: -118.0 Training loss: 3.1057 Explore P: 0.0100 RunMean : -102.9000\n",
      "Episode: 1688 Total reward: -111.0 Training loss: 1.3680 Explore P: 0.0100 RunMean : -103.1000\n",
      "Episode: 1689 Total reward: -71.0 Training loss: 2.0317 Explore P: 0.0100 RunMean : -102.9500\n",
      "Episode: 1690 Total reward: -122.0 Training loss: 1.0643 Explore P: 0.0100 RunMean : -103.2300\n",
      "Episode: 1691 Total reward: -144.0 Training loss: 1.2227 Explore P: 0.0100 RunMean : -103.9500\n",
      "Episode: 1692 Total reward: -96.0 Training loss: 1.3221 Explore P: 0.0100 RunMean : -104.2300\n",
      "Episode: 1693 Total reward: -81.0 Training loss: 1.2201 Explore P: 0.0100 RunMean : -104.0700\n",
      "Episode: 1694 Total reward: -82.0 Training loss: 0.7942 Explore P: 0.0100 RunMean : -103.8800\n",
      "Episode: 1695 Total reward: -116.0 Training loss: 0.5788 Explore P: 0.0100 RunMean : -104.1300\n",
      "Episode: 1696 Total reward: -82.0 Training loss: 1.0219 Explore P: 0.0100 RunMean : -104.1500\n",
      "Episode: 1697 Total reward: -112.0 Training loss: 1.2320 Explore P: 0.0100 RunMean : -104.3100\n",
      "Episode: 1698 Total reward: -111.0 Training loss: 2.4178 Explore P: 0.0100 RunMean : -104.5000\n",
      "Episode: 1699 Total reward: -92.0 Training loss: 1.8593 Explore P: 0.0100 RunMean : -104.2500\n",
      "Episode: 1700 Total reward: -149.0 Training loss: 2.3066 Explore P: 0.0100 RunMean : -104.7100\n",
      "Episode: 1701 Total reward: -96.0 Training loss: 1.7266 Explore P: 0.0100 RunMean : -104.4700\n",
      "Episode: 1702 Total reward: -129.0 Training loss: 2.0099 Explore P: 0.0100 RunMean : -103.8700\n",
      "Episode: 1703 Total reward: -87.0 Training loss: 2.3150 Explore P: 0.0100 RunMean : -103.9100\n",
      "Episode: 1704 Total reward: -118.0 Training loss: 2.3842 Explore P: 0.0100 RunMean : -104.1000\n",
      "Episode: 1705 Total reward: -82.0 Training loss: 2.6729 Explore P: 0.0100 RunMean : -103.7600\n",
      "Episode: 1706 Total reward: -71.0 Training loss: 1.4307 Explore P: 0.0100 RunMean : -103.5700\n",
      "Episode: 1707 Total reward: -95.0 Training loss: 1.6978 Explore P: 0.0100 RunMean : -103.6500\n",
      "Episode: 1708 Total reward: -75.0 Training loss: 1.1853 Explore P: 0.0100 RunMean : -103.2000\n",
      "Episode: 1709 Total reward: -86.0 Training loss: 1.2770 Explore P: 0.0100 RunMean : -103.1300\n",
      "Episode: 1710 Total reward: -106.0 Training loss: 1.6032 Explore P: 0.0100 RunMean : -103.3300\n",
      "Episode: 1711 Total reward: -63.0 Training loss: 1.2211 Explore P: 0.0100 RunMean : -102.5900\n",
      "Episode: 1712 Total reward: -71.0 Training loss: 0.5403 Explore P: 0.0100 RunMean : -102.1800\n",
      "Episode: 1713 Total reward: -63.0 Training loss: 1.4623 Explore P: 0.0100 RunMean : -101.7900\n",
      "Episode: 1714 Total reward: -61.0 Training loss: 3.1075 Explore P: 0.0100 RunMean : -101.1800\n",
      "Episode: 1715 Total reward: -93.0 Training loss: 0.9475 Explore P: 0.0100 RunMean : -101.1300\n",
      "Episode: 1716 Total reward: -63.0 Training loss: 1.0963 Explore P: 0.0100 RunMean : -100.6600\n",
      "Episode: 1717 Total reward: -87.0 Training loss: 1.4950 Explore P: 0.0100 RunMean : -100.2500\n",
      "Episode: 1718 Total reward: -111.0 Training loss: 1.1751 Explore P: 0.0100 RunMean : -100.4600\n",
      "Episode: 1719 Total reward: -94.0 Training loss: 1.8733 Explore P: 0.0100 RunMean : -100.4700\n",
      "Episode: 1720 Total reward: -69.0 Training loss: 1.1794 Explore P: 0.0100 RunMean : -100.3900\n",
      "Episode: 1721 Total reward: -77.0 Training loss: 1.9021 Explore P: 0.0100 RunMean : -100.0600\n",
      "Episode: 1722 Total reward: -99.0 Training loss: 1.7805 Explore P: 0.0100 RunMean : -100.0300\n",
      "Episode: 1723 Total reward: -75.0 Training loss: 1.0036 Explore P: 0.0100 RunMean : -100.0600\n",
      "Episode: 1724 Total reward: -134.0 Training loss: 1.3703 Explore P: 0.0100 RunMean : -100.5100\n",
      "Episode: 1725 Total reward: -86.0 Training loss: 1.1504 Explore P: 0.0100 RunMean : -100.6000\n",
      "Episode: 1726 Total reward: -126.0 Training loss: 2.0602 Explore P: 0.0100 RunMean : -100.8400\n",
      "Episode: 1727 Total reward: -107.0 Training loss: 1.7772 Explore P: 0.0100 RunMean : -101.0000\n",
      "Episode: 1728 Total reward: -131.0 Training loss: 2.0154 Explore P: 0.0100 RunMean : -101.2000\n",
      "Episode: 1729 Total reward: -140.0 Training loss: 2.3179 Explore P: 0.0100 RunMean : -101.5100\n",
      "Episode: 1730 Total reward: -90.0 Training loss: 2.0637 Explore P: 0.0100 RunMean : -101.2600\n",
      "Episode: 1731 Total reward: -85.0 Training loss: 1.3900 Explore P: 0.0100 RunMean : -101.1800\n",
      "Episode: 1732 Total reward: -79.0 Training loss: 1.3259 Explore P: 0.0100 RunMean : -100.9700\n",
      "Episode: 1733 Total reward: -83.0 Training loss: 1.3369 Explore P: 0.0100 RunMean : -100.8500\n",
      "Episode: 1734 Total reward: -75.0 Training loss: 1.4015 Explore P: 0.0100 RunMean : -100.7900\n",
      "Episode: 1735 Total reward: -83.0 Training loss: 1.5914 Explore P: 0.0100 RunMean : -100.6000\n",
      "Episode: 1736 Total reward: -86.0 Training loss: 1.9227 Explore P: 0.0100 RunMean : -100.2600\n",
      "Episode: 1737 Total reward: -75.0 Training loss: 0.6533 Explore P: 0.0100 RunMean : -99.7600\n",
      "Episode: 1738 Total reward: -102.0 Training loss: 2.0467 Explore P: 0.0100 RunMean : -99.6900\n",
      "Episode: 1739 Total reward: -113.0 Training loss: 2.6572 Explore P: 0.0100 RunMean : -100.1200\n",
      "Episode: 1740 Total reward: -94.0 Training loss: 1.0382 Explore P: 0.0100 RunMean : -98.7300\n",
      "Episode: 1741 Total reward: -79.0 Training loss: 1.3471 Explore P: 0.0100 RunMean : -98.2700\n",
      "Episode: 1742 Total reward: -83.0 Training loss: 3.4015 Explore P: 0.0100 RunMean : -97.9800\n",
      "Episode: 1743 Total reward: -122.0 Training loss: 1.5395 Explore P: 0.0100 RunMean : -98.0100\n",
      "Episode: 1744 Total reward: -94.0 Training loss: 1.8723 Explore P: 0.0100 RunMean : -98.1600\n",
      "Episode: 1745 Total reward: -98.0 Training loss: 1.0627 Explore P: 0.0100 RunMean : -98.1500\n",
      "Episode: 1746 Total reward: -80.0 Training loss: 1.2566 Explore P: 0.0100 RunMean : -98.1500\n",
      "Episode: 1747 Total reward: -110.0 Training loss: 1.9782 Explore P: 0.0100 RunMean : -97.9300\n",
      "Episode: 1748 Total reward: -218.0 Training loss: 3.4791 Explore P: 0.0100 RunMean : -99.2700\n",
      "Episode: 1749 Total reward: -116.0 Training loss: 1.1506 Explore P: 0.0100 RunMean : -99.3300\n",
      "Episode: 1750 Total reward: -94.0 Training loss: 2.8868 Explore P: 0.0100 RunMean : -99.4300\n",
      "Episode: 1751 Total reward: -116.0 Training loss: 1.0669 Explore P: 0.0100 RunMean : -99.6100\n",
      "Episode: 1752 Total reward: -82.0 Training loss: 1.5142 Explore P: 0.0100 RunMean : -99.3800\n",
      "Episode: 1753 Total reward: -87.0 Training loss: 1.5099 Explore P: 0.0100 RunMean : -98.7300\n",
      "Episode: 1754 Total reward: -98.0 Training loss: 2.4430 Explore P: 0.0100 RunMean : -98.8100\n",
      "Episode: 1755 Total reward: -102.0 Training loss: 1.2622 Explore P: 0.0100 RunMean : -98.8900\n",
      "Episode: 1756 Total reward: -99.0 Training loss: 1.8070 Explore P: 0.0100 RunMean : -98.6300\n",
      "Episode: 1757 Total reward: -117.0 Training loss: 1.3890 Explore P: 0.0100 RunMean : -99.0900\n",
      "Episode: 1758 Total reward: -87.0 Training loss: 1.3120 Explore P: 0.0100 RunMean : -99.1700\n",
      "Episode: 1759 Total reward: -91.0 Training loss: 2.6585 Explore P: 0.0100 RunMean : -98.7500\n",
      "Episode: 1760 Total reward: -94.0 Training loss: 1.2725 Explore P: 0.0100 RunMean : -98.6000\n",
      "Episode: 1761 Total reward: -80.0 Training loss: 2.9950 Explore P: 0.0100 RunMean : -97.9600\n",
      "Episode: 1762 Total reward: -101.0 Training loss: 1.5024 Explore P: 0.0100 RunMean : -98.1300\n",
      "Episode: 1763 Total reward: -97.0 Training loss: 2.1256 Explore P: 0.0100 RunMean : -98.1700\n",
      "Episode: 1764 Total reward: -115.0 Training loss: 1.6305 Explore P: 0.0100 RunMean : -98.1100\n",
      "Episode: 1765 Total reward: -124.0 Training loss: 1.9145 Explore P: 0.0100 RunMean : -98.2300\n",
      "Episode: 1766 Total reward: -101.0 Training loss: 1.5172 Explore P: 0.0100 RunMean : -98.3900\n",
      "Episode: 1767 Total reward: -87.0 Training loss: 1.3730 Explore P: 0.0100 RunMean : -98.3900\n",
      "Episode: 1768 Total reward: -115.0 Training loss: 3.3744 Explore P: 0.0100 RunMean : -98.5900\n",
      "Episode: 1769 Total reward: -133.0 Training loss: 1.4940 Explore P: 0.0100 RunMean : -99.0100\n",
      "Episode: 1770 Total reward: -105.0 Training loss: 2.0241 Explore P: 0.0100 RunMean : -98.9600\n",
      "Episode: 1771 Total reward: -87.0 Training loss: 2.2779 Explore P: 0.0100 RunMean : -98.8900\n",
      "Episode: 1772 Total reward: -147.0 Training loss: 1.3706 Explore P: 0.0100 RunMean : -99.4800\n",
      "Episode: 1773 Total reward: -154.0 Training loss: 2.0048 Explore P: 0.0100 RunMean : -100.1500\n",
      "Episode: 1774 Total reward: -85.0 Training loss: 1.5760 Explore P: 0.0100 RunMean : -99.4700\n",
      "Episode: 1775 Total reward: -125.0 Training loss: 1.4635 Explore P: 0.0100 RunMean : -99.9900\n",
      "Episode: 1776 Total reward: -89.0 Training loss: 1.4083 Explore P: 0.0100 RunMean : -100.0100\n",
      "Episode: 1777 Total reward: -120.0 Training loss: 1.4574 Explore P: 0.0100 RunMean : -100.4200\n",
      "Episode: 1778 Total reward: -114.0 Training loss: 1.0393 Explore P: 0.0100 RunMean : -100.5700\n",
      "Episode: 1779 Total reward: -115.0 Training loss: 2.0319 Explore P: 0.0100 RunMean : -100.6300\n",
      "Episode: 1780 Total reward: -130.0 Training loss: 3.6221 Explore P: 0.0100 RunMean : -100.6700\n",
      "Episode: 1781 Total reward: -91.0 Training loss: 1.9626 Explore P: 0.0100 RunMean : -100.4900\n",
      "Episode: 1782 Total reward: -91.0 Training loss: 0.9875 Explore P: 0.0100 RunMean : -100.3400\n",
      "Episode: 1783 Total reward: -108.0 Training loss: 1.9664 Explore P: 0.0100 RunMean : -100.5000\n",
      "Episode: 1784 Total reward: -74.0 Training loss: 0.8444 Explore P: 0.0100 RunMean : -100.3400\n",
      "Episode: 1785 Total reward: -95.0 Training loss: 2.7860 Explore P: 0.0100 RunMean : -100.3600\n",
      "Episode: 1786 Total reward: -107.0 Training loss: 1.2680 Explore P: 0.0100 RunMean : -100.0400\n",
      "Episode: 1787 Total reward: -146.0 Training loss: 1.6655 Explore P: 0.0100 RunMean : -100.3200\n",
      "Episode: 1788 Total reward: -113.0 Training loss: 0.8845 Explore P: 0.0100 RunMean : -100.3400\n",
      "Episode: 1789 Total reward: -160.0 Training loss: 0.7611 Explore P: 0.0100 RunMean : -101.2300\n",
      "Episode: 1790 Total reward: -82.0 Training loss: 4.0287 Explore P: 0.0100 RunMean : -100.8300\n",
      "Episode: 1791 Total reward: -97.0 Training loss: 2.7335 Explore P: 0.0100 RunMean : -100.3600\n",
      "Episode: 1792 Total reward: -110.0 Training loss: 3.1841 Explore P: 0.0100 RunMean : -100.5000\n",
      "Episode: 1793 Total reward: -76.0 Training loss: 1.9233 Explore P: 0.0100 RunMean : -100.4500\n",
      "Episode: 1794 Total reward: -84.0 Training loss: 1.2105 Explore P: 0.0100 RunMean : -100.4700\n",
      "Episode: 1795 Total reward: -99.0 Training loss: 1.2197 Explore P: 0.0100 RunMean : -100.3000\n",
      "Episode: 1796 Total reward: -90.0 Training loss: 1.5073 Explore P: 0.0100 RunMean : -100.3800\n",
      "Episode: 1797 Total reward: -94.0 Training loss: 1.3368 Explore P: 0.0100 RunMean : -100.2000\n",
      "Episode: 1798 Total reward: -131.0 Training loss: 2.4720 Explore P: 0.0100 RunMean : -100.4000\n",
      "Episode: 1799 Total reward: -154.0 Training loss: 1.3658 Explore P: 0.0100 RunMean : -101.0200\n",
      "Episode: 1800 Total reward: -109.0 Training loss: 0.9632 Explore P: 0.0100 RunMean : -100.6200\n",
      "Episode: 1801 Total reward: -110.0 Training loss: 4.0728 Explore P: 0.0100 RunMean : -100.7600\n",
      "Episode: 1802 Total reward: -78.0 Training loss: 1.4442 Explore P: 0.0100 RunMean : -100.2500\n",
      "Episode: 1803 Total reward: -138.0 Training loss: 1.9622 Explore P: 0.0100 RunMean : -100.7600\n",
      "Episode: 1804 Total reward: -128.0 Training loss: 1.9336 Explore P: 0.0100 RunMean : -100.8600\n",
      "Episode: 1805 Total reward: -84.0 Training loss: 2.6618 Explore P: 0.0100 RunMean : -100.8800\n",
      "Episode: 1806 Total reward: -109.0 Training loss: 1.3692 Explore P: 0.0100 RunMean : -101.2600\n",
      "Episode: 1807 Total reward: -97.0 Training loss: 1.4372 Explore P: 0.0100 RunMean : -101.2800\n",
      "Episode: 1808 Total reward: -116.0 Training loss: 1.3045 Explore P: 0.0100 RunMean : -101.6900\n",
      "Episode: 1809 Total reward: -88.0 Training loss: 3.7868 Explore P: 0.0100 RunMean : -101.7100\n",
      "Episode: 1810 Total reward: -134.0 Training loss: 1.0724 Explore P: 0.0100 RunMean : -101.9900\n",
      "Episode: 1811 Total reward: -83.0 Training loss: 1.1149 Explore P: 0.0100 RunMean : -102.1900\n",
      "Episode: 1812 Total reward: -95.0 Training loss: 1.3871 Explore P: 0.0100 RunMean : -102.4300\n",
      "Episode: 1813 Total reward: -98.0 Training loss: 1.0006 Explore P: 0.0100 RunMean : -102.7800\n",
      "Episode: 1814 Total reward: -99.0 Training loss: 3.2204 Explore P: 0.0100 RunMean : -103.1600\n",
      "Episode: 1815 Total reward: -83.0 Training loss: 1.1448 Explore P: 0.0100 RunMean : -103.0600\n",
      "Episode: 1816 Total reward: -92.0 Training loss: 1.7327 Explore P: 0.0100 RunMean : -103.3500\n",
      "Episode: 1817 Total reward: -126.0 Training loss: 3.1152 Explore P: 0.0100 RunMean : -103.7400\n",
      "Episode: 1818 Total reward: -128.0 Training loss: 1.0637 Explore P: 0.0100 RunMean : -103.9100\n",
      "Episode: 1819 Total reward: -124.0 Training loss: 1.3019 Explore P: 0.0100 RunMean : -104.2100\n",
      "Episode: 1820 Total reward: -94.0 Training loss: 5.3697 Explore P: 0.0100 RunMean : -104.4600\n",
      "Episode: 1821 Total reward: -98.0 Training loss: 2.9991 Explore P: 0.0100 RunMean : -104.6700\n",
      "Episode: 1822 Total reward: -72.0 Training loss: 0.7940 Explore P: 0.0100 RunMean : -104.4000\n",
      "Episode: 1823 Total reward: -111.0 Training loss: 2.1470 Explore P: 0.0100 RunMean : -104.7600\n",
      "Episode: 1824 Total reward: -74.0 Training loss: 1.8968 Explore P: 0.0100 RunMean : -104.1600\n",
      "Episode: 1825 Total reward: -91.0 Training loss: 1.9980 Explore P: 0.0100 RunMean : -104.2100\n",
      "Episode: 1826 Total reward: -106.0 Training loss: 1.7830 Explore P: 0.0100 RunMean : -104.0100\n",
      "Episode: 1827 Total reward: -100.0 Training loss: 1.8226 Explore P: 0.0100 RunMean : -103.9400\n",
      "Episode: 1828 Total reward: -93.0 Training loss: 1.4542 Explore P: 0.0100 RunMean : -103.5600\n",
      "Episode: 1829 Total reward: -94.0 Training loss: 1.4651 Explore P: 0.0100 RunMean : -103.1000\n",
      "Episode: 1830 Total reward: -121.0 Training loss: 1.6250 Explore P: 0.0100 RunMean : -103.4100\n",
      "Episode: 1831 Total reward: -94.0 Training loss: 0.7305 Explore P: 0.0100 RunMean : -103.5000\n",
      "Episode: 1832 Total reward: -71.0 Training loss: 1.1454 Explore P: 0.0100 RunMean : -103.4200\n",
      "Episode: 1833 Total reward: -100.0 Training loss: 1.5853 Explore P: 0.0100 RunMean : -103.5900\n",
      "Episode: 1834 Total reward: -113.0 Training loss: 6.4896 Explore P: 0.0100 RunMean : -103.9700\n",
      "Episode: 1835 Total reward: -140.0 Training loss: 3.0853 Explore P: 0.0100 RunMean : -104.5400\n",
      "Episode: 1836 Total reward: -78.0 Training loss: 2.3267 Explore P: 0.0100 RunMean : -104.4600\n",
      "Episode: 1837 Total reward: -83.0 Training loss: 0.4519 Explore P: 0.0100 RunMean : -104.5400\n",
      "Episode: 1838 Total reward: -95.0 Training loss: 1.3380 Explore P: 0.0100 RunMean : -104.4700\n",
      "Episode: 1839 Total reward: -94.0 Training loss: 0.9769 Explore P: 0.0100 RunMean : -104.2800\n",
      "Episode: 1840 Total reward: -72.0 Training loss: 1.2785 Explore P: 0.0100 RunMean : -104.0600\n",
      "Episode: 1841 Total reward: -104.0 Training loss: 1.6232 Explore P: 0.0100 RunMean : -104.3100\n",
      "Episode: 1842 Total reward: -91.0 Training loss: 1.9050 Explore P: 0.0100 RunMean : -104.3900\n",
      "Episode: 1843 Total reward: -111.0 Training loss: 3.9178 Explore P: 0.0100 RunMean : -104.2800\n",
      "Episode: 1844 Total reward: -80.0 Training loss: 2.4064 Explore P: 0.0100 RunMean : -104.1400\n",
      "Episode: 1845 Total reward: -152.0 Training loss: 2.1852 Explore P: 0.0100 RunMean : -104.6800\n",
      "Episode: 1846 Total reward: -72.0 Training loss: 2.3961 Explore P: 0.0100 RunMean : -104.6000\n",
      "Episode: 1847 Total reward: -84.0 Training loss: 3.0652 Explore P: 0.0100 RunMean : -104.3400\n",
      "Episode: 1848 Total reward: -85.0 Training loss: 1.9527 Explore P: 0.0100 RunMean : -103.0100\n",
      "Episode: 1849 Total reward: -105.0 Training loss: 5.4513 Explore P: 0.0100 RunMean : -102.9000\n",
      "Episode: 1850 Total reward: -99.0 Training loss: 1.8066 Explore P: 0.0100 RunMean : -102.9500\n",
      "Episode: 1851 Total reward: -74.0 Training loss: 3.0931 Explore P: 0.0100 RunMean : -102.5300\n",
      "Episode: 1852 Total reward: -92.0 Training loss: 1.4073 Explore P: 0.0100 RunMean : -102.6300\n",
      "Episode: 1853 Total reward: -102.0 Training loss: 1.3311 Explore P: 0.0100 RunMean : -102.7800\n",
      "Episode: 1854 Total reward: -75.0 Training loss: 0.9645 Explore P: 0.0100 RunMean : -102.5500\n",
      "Episode: 1855 Total reward: -104.0 Training loss: 1.0105 Explore P: 0.0100 RunMean : -102.5700\n",
      "Episode: 1856 Total reward: -221.0 Training loss: 2.1222 Explore P: 0.0100 RunMean : -103.7900\n",
      "Episode: 1857 Total reward: -112.0 Training loss: 1.0693 Explore P: 0.0100 RunMean : -103.7400\n",
      "Episode: 1858 Total reward: -91.0 Training loss: 0.9551 Explore P: 0.0100 RunMean : -103.7800\n",
      "Episode: 1859 Total reward: -78.0 Training loss: 1.9310 Explore P: 0.0100 RunMean : -103.6500\n",
      "Episode: 1860 Total reward: -123.0 Training loss: 1.5957 Explore P: 0.0100 RunMean : -103.9400\n",
      "Episode: 1861 Total reward: -140.0 Training loss: 1.5993 Explore P: 0.0100 RunMean : -104.5400\n",
      "Episode: 1862 Total reward: -109.0 Training loss: 1.7043 Explore P: 0.0100 RunMean : -104.6200\n",
      "Episode: 1863 Total reward: -115.0 Training loss: 1.3351 Explore P: 0.0100 RunMean : -104.8000\n",
      "Episode: 1864 Total reward: -103.0 Training loss: 1.1005 Explore P: 0.0100 RunMean : -104.6800\n",
      "Episode: 1865 Total reward: -96.0 Training loss: 3.6485 Explore P: 0.0100 RunMean : -104.4000\n",
      "Episode: 1866 Total reward: -123.0 Training loss: 3.2351 Explore P: 0.0100 RunMean : -104.6200\n",
      "Episode: 1867 Total reward: -97.0 Training loss: 1.6804 Explore P: 0.0100 RunMean : -104.7200\n",
      "Episode: 1868 Total reward: -87.0 Training loss: 2.5415 Explore P: 0.0100 RunMean : -104.4400\n",
      "Episode: 1869 Total reward: -106.0 Training loss: 1.2090 Explore P: 0.0100 RunMean : -104.1700\n",
      "Episode: 1870 Total reward: -139.0 Training loss: 1.9038 Explore P: 0.0100 RunMean : -104.5100\n",
      "Episode: 1871 Total reward: -211.0 Training loss: 1.4741 Explore P: 0.0100 RunMean : -105.7500\n",
      "Episode: 1872 Total reward: -113.0 Training loss: 1.2355 Explore P: 0.0100 RunMean : -105.4100\n",
      "Episode: 1873 Total reward: -99.0 Training loss: 1.1765 Explore P: 0.0100 RunMean : -104.8600\n",
      "Episode: 1874 Total reward: -94.0 Training loss: 0.5781 Explore P: 0.0100 RunMean : -104.9500\n",
      "Episode: 1875 Total reward: -170.0 Training loss: 1.3933 Explore P: 0.0100 RunMean : -105.4000\n",
      "Episode: 1876 Total reward: -71.0 Training loss: 2.5887 Explore P: 0.0100 RunMean : -105.2200\n",
      "Episode: 1877 Total reward: -82.0 Training loss: 1.0051 Explore P: 0.0100 RunMean : -104.8400\n",
      "Episode: 1878 Total reward: -93.0 Training loss: 1.7617 Explore P: 0.0100 RunMean : -104.6300\n",
      "Episode: 1879 Total reward: -98.0 Training loss: 2.4587 Explore P: 0.0100 RunMean : -104.4600\n",
      "Episode: 1880 Total reward: -163.0 Training loss: 1.0301 Explore P: 0.0100 RunMean : -104.7900\n",
      "Episode: 1881 Total reward: -97.0 Training loss: 1.6283 Explore P: 0.0100 RunMean : -104.8500\n",
      "Episode: 1882 Total reward: -122.0 Training loss: 1.3726 Explore P: 0.0100 RunMean : -105.1600\n",
      "Episode: 1883 Total reward: -91.0 Training loss: 2.3236 Explore P: 0.0100 RunMean : -104.9900\n",
      "Episode: 1884 Total reward: -94.0 Training loss: 0.9523 Explore P: 0.0100 RunMean : -105.1900\n",
      "Episode: 1885 Total reward: -93.0 Training loss: 3.5241 Explore P: 0.0100 RunMean : -105.1700\n",
      "Episode: 1886 Total reward: -132.0 Training loss: 1.0499 Explore P: 0.0100 RunMean : -105.4200\n",
      "Episode: 1887 Total reward: -83.0 Training loss: 1.2426 Explore P: 0.0100 RunMean : -104.7900\n",
      "Episode: 1888 Total reward: -118.0 Training loss: 0.7665 Explore P: 0.0100 RunMean : -104.8400\n",
      "Episode: 1889 Total reward: -71.0 Training loss: 1.6075 Explore P: 0.0100 RunMean : -103.9500\n",
      "Episode: 1890 Total reward: -70.0 Training loss: 2.1091 Explore P: 0.0100 RunMean : -103.8300\n",
      "Episode: 1891 Total reward: -63.0 Training loss: 0.6077 Explore P: 0.0100 RunMean : -103.4900\n",
      "Episode: 1892 Total reward: -83.0 Training loss: 1.7128 Explore P: 0.0100 RunMean : -103.2200\n",
      "Episode: 1893 Total reward: -131.0 Training loss: 2.2055 Explore P: 0.0100 RunMean : -103.7700\n",
      "Episode: 1894 Total reward: -139.0 Training loss: 1.4928 Explore P: 0.0100 RunMean : -104.3200\n",
      "Episode: 1895 Total reward: -91.0 Training loss: 1.2201 Explore P: 0.0100 RunMean : -104.2400\n",
      "Episode: 1896 Total reward: -117.0 Training loss: 1.2794 Explore P: 0.0100 RunMean : -104.5100\n",
      "Episode: 1897 Total reward: -148.0 Training loss: 0.8462 Explore P: 0.0100 RunMean : -105.0500\n",
      "Episode: 1898 Total reward: -140.0 Training loss: 1.4670 Explore P: 0.0100 RunMean : -105.1400\n",
      "Episode: 1899 Total reward: -87.0 Training loss: 2.1918 Explore P: 0.0100 RunMean : -104.4700\n",
      "Episode: 1900 Total reward: -84.0 Training loss: 1.1108 Explore P: 0.0100 RunMean : -104.2200\n",
      "Episode: 1901 Total reward: -95.0 Training loss: 7.3365 Explore P: 0.0100 RunMean : -104.0700\n",
      "Episode: 1902 Total reward: -104.0 Training loss: 2.3449 Explore P: 0.0100 RunMean : -104.3300\n",
      "Episode: 1903 Total reward: -105.0 Training loss: 1.0951 Explore P: 0.0100 RunMean : -104.0000\n",
      "Episode: 1904 Total reward: -79.0 Training loss: 4.7379 Explore P: 0.0100 RunMean : -103.5100\n",
      "Episode: 1905 Total reward: -106.0 Training loss: 1.4427 Explore P: 0.0100 RunMean : -103.7300\n",
      "Episode: 1906 Total reward: -69.0 Training loss: 2.9952 Explore P: 0.0100 RunMean : -103.3300\n",
      "Episode: 1907 Total reward: -81.0 Training loss: 4.7362 Explore P: 0.0100 RunMean : -103.1700\n",
      "Episode: 1908 Total reward: -116.0 Training loss: 1.9324 Explore P: 0.0100 RunMean : -103.1700\n",
      "Episode: 1909 Total reward: -109.0 Training loss: 3.5804 Explore P: 0.0100 RunMean : -103.3800\n",
      "Episode: 1910 Total reward: -178.0 Training loss: 1.2126 Explore P: 0.0100 RunMean : -103.8200\n",
      "Episode: 1911 Total reward: -63.0 Training loss: 2.2823 Explore P: 0.0100 RunMean : -103.6200\n",
      "Episode: 1912 Total reward: -74.0 Training loss: 1.0115 Explore P: 0.0100 RunMean : -103.4100\n",
      "Episode: 1913 Total reward: -84.0 Training loss: 1.7722 Explore P: 0.0100 RunMean : -103.2700\n",
      "Episode: 1914 Total reward: -94.0 Training loss: 1.9945 Explore P: 0.0100 RunMean : -103.2200\n",
      "Episode: 1915 Total reward: -75.0 Training loss: 1.0973 Explore P: 0.0100 RunMean : -103.1400\n",
      "Episode: 1916 Total reward: -77.0 Training loss: 2.6915 Explore P: 0.0100 RunMean : -102.9900\n",
      "Episode: 1917 Total reward: -85.0 Training loss: 0.5856 Explore P: 0.0100 RunMean : -102.5800\n",
      "Episode: 1918 Total reward: -63.0 Training loss: 3.6361 Explore P: 0.0100 RunMean : -101.9300\n",
      "Episode: 1919 Total reward: -61.0 Training loss: 1.9384 Explore P: 0.0100 RunMean : -101.3000\n",
      "Episode: 1920 Total reward: -98.0 Training loss: 1.8375 Explore P: 0.0100 RunMean : -101.3400\n",
      "Episode: 1921 Total reward: -76.0 Training loss: 0.8452 Explore P: 0.0100 RunMean : -101.1200\n",
      "Episode: 1922 Total reward: -89.0 Training loss: 2.0502 Explore P: 0.0100 RunMean : -101.2900\n",
      "Episode: 1923 Total reward: -85.0 Training loss: 2.1901 Explore P: 0.0100 RunMean : -101.0300\n",
      "Episode: 1924 Total reward: -127.0 Training loss: 1.3147 Explore P: 0.0100 RunMean : -101.5600\n",
      "Episode: 1925 Total reward: -310.0 Training loss: 2.6194 Explore P: 0.0100 RunMean : -103.7500\n",
      "Episode: 1926 Total reward: -136.0 Training loss: 12.7175 Explore P: 0.0100 RunMean : -104.0500\n",
      "Episode: 1927 Total reward: -85.0 Training loss: 3.6640 Explore P: 0.0100 RunMean : -103.9000\n",
      "Episode: 1928 Total reward: -91.0 Training loss: 1.8359 Explore P: 0.0100 RunMean : -103.8800\n",
      "Episode: 1929 Total reward: -73.0 Training loss: 1.0186 Explore P: 0.0100 RunMean : -103.6700\n",
      "Episode: 1930 Total reward: -110.0 Training loss: 1.7229 Explore P: 0.0100 RunMean : -103.5600\n",
      "Episode: 1931 Total reward: -70.0 Training loss: 2.1839 Explore P: 0.0100 RunMean : -103.3200\n",
      "Episode: 1932 Total reward: -62.0 Training loss: 1.8120 Explore P: 0.0100 RunMean : -103.2300\n",
      "Episode: 1933 Total reward: -73.0 Training loss: 1.7144 Explore P: 0.0100 RunMean : -102.9600\n",
      "Episode: 1934 Total reward: -91.0 Training loss: 1.6020 Explore P: 0.0100 RunMean : -102.7400\n",
      "Episode: 1935 Total reward: -91.0 Training loss: 1.1318 Explore P: 0.0100 RunMean : -102.2500\n",
      "Episode: 1936 Total reward: -70.0 Training loss: 3.2796 Explore P: 0.0100 RunMean : -102.1700\n",
      "Episode: 1937 Total reward: -84.0 Training loss: 0.4268 Explore P: 0.0100 RunMean : -102.1800\n",
      "Episode: 1938 Total reward: -83.0 Training loss: 1.5121 Explore P: 0.0100 RunMean : -102.0600\n",
      "Episode: 1939 Total reward: -86.0 Training loss: 2.1163 Explore P: 0.0100 RunMean : -101.9800\n",
      "Episode: 1940 Total reward: -142.0 Training loss: 1.0303 Explore P: 0.0100 RunMean : -102.6800\n",
      "Episode: 1941 Total reward: -98.0 Training loss: 0.6998 Explore P: 0.0100 RunMean : -102.6200\n",
      "Episode: 1942 Total reward: -63.0 Training loss: 0.9203 Explore P: 0.0100 RunMean : -102.3400\n",
      "Episode: 1943 Total reward: -92.0 Training loss: 1.6992 Explore P: 0.0100 RunMean : -102.1500\n",
      "Episode: 1944 Total reward: -85.0 Training loss: 4.3602 Explore P: 0.0100 RunMean : -102.2000\n",
      "Episode: 1945 Total reward: -100.0 Training loss: 1.1883 Explore P: 0.0100 RunMean : -101.6800\n",
      "Episode: 1946 Total reward: -125.0 Training loss: 6.1942 Explore P: 0.0100 RunMean : -102.2100\n",
      "Episode: 1947 Total reward: -118.0 Training loss: 1.3662 Explore P: 0.0100 RunMean : -102.5500\n",
      "Episode: 1948 Total reward: -109.0 Training loss: 1.7538 Explore P: 0.0100 RunMean : -102.7900\n",
      "Episode: 1949 Total reward: -92.0 Training loss: 1.3784 Explore P: 0.0100 RunMean : -102.6600\n",
      "Episode: 1950 Total reward: -78.0 Training loss: 2.5140 Explore P: 0.0100 RunMean : -102.4500\n",
      "Episode: 1951 Total reward: -89.0 Training loss: 1.0115 Explore P: 0.0100 RunMean : -102.6000\n",
      "Episode: 1952 Total reward: -81.0 Training loss: 1.5791 Explore P: 0.0100 RunMean : -102.4900\n",
      "Episode: 1953 Total reward: -95.0 Training loss: 10.5467 Explore P: 0.0100 RunMean : -102.4200\n",
      "Episode: 1954 Total reward: -88.0 Training loss: 1.7313 Explore P: 0.0100 RunMean : -102.5500\n",
      "Episode: 1955 Total reward: -84.0 Training loss: 1.7628 Explore P: 0.0100 RunMean : -102.3500\n",
      "Episode: 1956 Total reward: -93.0 Training loss: 2.3028 Explore P: 0.0100 RunMean : -101.0700\n",
      "Episode: 1957 Total reward: -75.0 Training loss: 1.2202 Explore P: 0.0100 RunMean : -100.7000\n",
      "Episode: 1958 Total reward: -86.0 Training loss: 1.4345 Explore P: 0.0100 RunMean : -100.6500\n",
      "Episode: 1959 Total reward: -74.0 Training loss: 1.4921 Explore P: 0.0100 RunMean : -100.6100\n",
      "Episode: 1960 Total reward: -128.0 Training loss: 1.0915 Explore P: 0.0100 RunMean : -100.6600\n",
      "Episode: 1961 Total reward: -107.0 Training loss: 1.6867 Explore P: 0.0100 RunMean : -100.3300\n",
      "Episode: 1962 Total reward: -176.0 Training loss: 1.5137 Explore P: 0.0100 RunMean : -101.0000\n",
      "Episode: 1963 Total reward: -88.0 Training loss: 2.4980 Explore P: 0.0100 RunMean : -100.7300\n",
      "Episode: 1964 Total reward: -104.0 Training loss: 1.2010 Explore P: 0.0100 RunMean : -100.7400\n",
      "Episode: 1965 Total reward: -90.0 Training loss: 1.9380 Explore P: 0.0100 RunMean : -100.6800\n",
      "Episode: 1966 Total reward: -87.0 Training loss: 1.7789 Explore P: 0.0100 RunMean : -100.3200\n",
      "Episode: 1967 Total reward: -89.0 Training loss: 1.8194 Explore P: 0.0100 RunMean : -100.2400\n",
      "Episode: 1968 Total reward: -63.0 Training loss: 1.1490 Explore P: 0.0100 RunMean : -100.0000\n",
      "Episode: 1969 Total reward: -112.0 Training loss: 1.6693 Explore P: 0.0100 RunMean : -100.0600\n",
      "Episode: 1970 Total reward: -94.0 Training loss: 1.8018 Explore P: 0.0100 RunMean : -99.6100\n",
      "Episode: 1971 Total reward: -82.0 Training loss: 2.0830 Explore P: 0.0100 RunMean : -98.3200\n",
      "Episode: 1972 Total reward: -78.0 Training loss: 2.6284 Explore P: 0.0100 RunMean : -97.9700\n",
      "Episode: 1973 Total reward: -105.0 Training loss: 1.4433 Explore P: 0.0100 RunMean : -98.0300\n",
      "Episode: 1974 Total reward: -97.0 Training loss: 3.0946 Explore P: 0.0100 RunMean : -98.0600\n",
      "Episode: 1975 Total reward: -105.0 Training loss: 2.3722 Explore P: 0.0100 RunMean : -97.4100\n",
      "Episode: 1976 Total reward: -97.0 Training loss: 0.4611 Explore P: 0.0100 RunMean : -97.6700\n",
      "Episode: 1977 Total reward: -87.0 Training loss: 0.9631 Explore P: 0.0100 RunMean : -97.7200\n",
      "Episode: 1978 Total reward: -116.0 Training loss: 1.5790 Explore P: 0.0100 RunMean : -97.9500\n",
      "Episode: 1979 Total reward: -71.0 Training loss: 1.6148 Explore P: 0.0100 RunMean : -97.6800\n",
      "Episode: 1980 Total reward: -73.0 Training loss: 3.3679 Explore P: 0.0100 RunMean : -96.7800\n",
      "Episode: 1981 Total reward: -92.0 Training loss: 1.2243 Explore P: 0.0100 RunMean : -96.7300\n",
      "Episode: 1982 Total reward: -93.0 Training loss: 1.8959 Explore P: 0.0100 RunMean : -96.4400\n",
      "Episode: 1983 Total reward: -71.0 Training loss: 2.6812 Explore P: 0.0100 RunMean : -96.2400\n",
      "Episode: 1984 Total reward: -93.0 Training loss: 1.0335 Explore P: 0.0100 RunMean : -96.2300\n",
      "Episode: 1985 Total reward: -115.0 Training loss: 2.8353 Explore P: 0.0100 RunMean : -96.4500\n",
      "Episode: 1986 Total reward: -70.0 Training loss: 1.8951 Explore P: 0.0100 RunMean : -95.8300\n",
      "Episode: 1987 Total reward: -86.0 Training loss: 1.1770 Explore P: 0.0100 RunMean : -95.8600\n",
      "Episode: 1988 Total reward: -123.0 Training loss: 1.5676 Explore P: 0.0100 RunMean : -95.9100\n",
      "Episode: 1989 Total reward: -95.0 Training loss: 0.8900 Explore P: 0.0100 RunMean : -96.1500\n",
      "Episode: 1990 Total reward: -102.0 Training loss: 1.1828 Explore P: 0.0100 RunMean : -96.4700\n",
      "Episode: 1991 Total reward: -94.0 Training loss: 1.1137 Explore P: 0.0100 RunMean : -96.7800\n",
      "Episode: 1992 Total reward: -62.0 Training loss: 0.9178 Explore P: 0.0100 RunMean : -96.5700\n",
      "Episode: 1993 Total reward: -71.0 Training loss: 1.6010 Explore P: 0.0100 RunMean : -95.9700\n",
      "Episode: 1994 Total reward: -88.0 Training loss: 0.8977 Explore P: 0.0100 RunMean : -95.4600\n",
      "Episode: 1995 Total reward: -96.0 Training loss: 0.8157 Explore P: 0.0100 RunMean : -95.5100\n",
      "Episode: 1996 Total reward: -100.0 Training loss: 3.2775 Explore P: 0.0100 RunMean : -95.3400\n",
      "Episode: 1997 Total reward: -62.0 Training loss: 1.2952 Explore P: 0.0100 RunMean : -94.4800\n",
      "Episode: 1998 Total reward: -96.0 Training loss: 2.9914 Explore P: 0.0100 RunMean : -94.0400\n",
      "Episode: 1999 Total reward: -84.0 Training loss: 1.0871 Explore P: 0.0100 RunMean : -94.0100\n",
      "average training reward =  -101.6105\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-25 16:24:07,054] Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'max_test_rewards' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-980d8748bcb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# test implementation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maverage_rewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_and_train_qnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.99\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0mexplore_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0mexplore_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0mhidden_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0mhidden_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m                                         \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'average test reward = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_rewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-6b3bf3d7a23e>\u001b[0m in \u001b[0;36mtest_and_train_qnetwork\u001b[0;34m(train_episodes, gamma, explore_start, explore_stop, decay_rate, hidden_size, hidden_layers, learning_rate, memory_size, batch_size, test_episodes, render, alpha, verbose)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'average test reward = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_test_rewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mavg_test_rewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunMean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmainQN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrewards_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'max_test_rewards' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAF5CAYAAABjkgsvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDeX/Awk0PH4XwQcbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e0a9886048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test implementation\n",
    "average_rewards = test_and_train_qnetwork(train_episodes=2000, verbose=True,\\\n",
    "                                         gamma=0.99,\\\n",
    "                                         decay_rate=0.0001,\\\n",
    "                                         explore_start=1.0,\\\n",
    "                                         explore_stop=0.01,\\\n",
    "                                         hidden_size=64,\\\n",
    "                                         hidden_layers=2,\\\n",
    "                                         learning_rate=0.0001,\\\n",
    "                                         batch_size=64,\\\n",
    "                                         alpha=0.1)\n",
    "print('average test reward = ', average_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-25 16:28:59,810] Making new env: Acrobot-v1\n"
     ]
    }
   ],
   "source": [
    "train_eps = 2000\n",
    "verb = False\n",
    "gamma = [0.99,0.999]\n",
    "decay_rate = [0.0001,0.00001]\n",
    "exp_start=1.0\n",
    "exp_stop=0.0\n",
    "hidden_size=[32,64]\n",
    "hidden_layers=[2,3]\n",
    "learning_rate=[0.0001]\n",
    "batch_size=[64]\n",
    "num_averages = 1\n",
    "results = []\n",
    "alpha_relu = [0.1,0.05]\n",
    "mem_size = [10000]\n",
    "env = gym.make('Acrobot-v1')\n",
    "env.reset()\n",
    "\n",
    "for gaIndex in range(len(gamma)):\n",
    "    for drIndex in range(len(decay_rate)):\n",
    "        for hs in hidden_size:\n",
    "            for hl in hidden_layers:\n",
    "                for lr in learning_rate:\n",
    "                    for bs in batch_size:\n",
    "                        for alu in alpha_relu:\n",
    "                            for mems in mem_size:\n",
    "                                ga = gamma[gaIndex]\n",
    "                                dr = decay_rate[drIndex]\n",
    "                                train_params_name = 'dr='+str(dr)+'_ga='+str(ga)+'_hs='+str(hs)+'_hl'+str(hl)+'_lr'+str(lr)+'_bs'+str(bs)+'_alu='+str(alu)+'_mm='+str(mems)\n",
    "                                average_test_rewards = 0.\n",
    "                                average_train_rewards = 0.\n",
    "                                for i in range(num_averages):\n",
    "                                    test,train, mainQN, saver, num_episodes = test_and_train_qnetwork(memory_size=mems,\\\n",
    "                                                           train_episodes=train_eps,\\\n",
    "                                                           gamma=ga,\\\n",
    "                                                           explore_start=exp_start,\\\n",
    "                                                           explore_stop=exp_stop,\\\n",
    "                                                           decay_rate=dr,\\\n",
    "                                                           hidden_layers=hl,\\\n",
    "                                                           hidden_size=hs,\\\n",
    "                                                           learning_rate=lr,\\\n",
    "                                                           batch_size=bs,\\\n",
    "                                                           alpha = alu,\\\n",
    "                                                           verbose=verb)\n",
    "                                    average_test_rewards += test\n",
    "                                    average_train_rewards += train\n",
    "\n",
    "                                average_test_rewards = average_test_rewards / num_averages\n",
    "                                average_train_rewards = average_train_rewards / num_averages\n",
    "                                results.append([train_params_name+' test='+str(average_test_rewards)+'  train='+str(average_train_rewards)])\n",
    "                                clear_output()\n",
    "                                for each in results:\n",
    "                                    print(each)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-23 00:16:21,269] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Total reward: 17.0 Training loss: 1.1656 Explore P: 0.9997 RunMean : 17.0000\n",
      "Episode: 1 Total reward: 13.0 Training loss: 1.1657 Explore P: 0.9994 RunMean : 15.0000\n",
      "Episode: 2 Total reward: 21.0 Training loss: 1.1492 Explore P: 0.9990 RunMean : 17.0000\n",
      "Episode: 3 Total reward: 12.0 Training loss: 1.1934 Explore P: 0.9987 RunMean : 15.7500\n",
      "Episode: 4 Total reward: 11.0 Training loss: 1.1641 Explore P: 0.9985 RunMean : 14.8000\n",
      "Episode: 5 Total reward: 59.0 Training loss: 1.6975 Explore P: 0.9973 RunMean : 22.1667\n",
      "Episode: 6 Total reward: 21.0 Training loss: 1.7549 Explore P: 0.9969 RunMean : 22.0000\n",
      "Episode: 7 Total reward: 17.0 Training loss: 2.0484 Explore P: 0.9966 RunMean : 21.3750\n",
      "Episode: 8 Total reward: 43.0 Training loss: 2.1694 Explore P: 0.9957 RunMean : 23.7778\n",
      "Episode: 9 Total reward: 17.0 Training loss: 2.8160 Explore P: 0.9954 RunMean : 23.1000\n",
      "Episode: 10 Total reward: 73.0 Training loss: 2.2687 Explore P: 0.9939 RunMean : 27.6364\n",
      "Episode: 11 Total reward: 16.0 Training loss: 2.7256 Explore P: 0.9936 RunMean : 26.6667\n",
      "Episode: 12 Total reward: 12.0 Training loss: 8.4308 Explore P: 0.9934 RunMean : 25.5385\n",
      "Episode: 13 Total reward: 14.0 Training loss: 6.7139 Explore P: 0.9931 RunMean : 24.7143\n",
      "Episode: 14 Total reward: 18.0 Training loss: 13.0625 Explore P: 0.9927 RunMean : 24.2667\n",
      "Episode: 15 Total reward: 16.0 Training loss: 10.7731 Explore P: 0.9924 RunMean : 23.7500\n",
      "Episode: 16 Total reward: 19.0 Training loss: 2.8467 Explore P: 0.9921 RunMean : 23.4706\n",
      "Episode: 17 Total reward: 26.0 Training loss: 11.2651 Explore P: 0.9915 RunMean : 23.6111\n",
      "Episode: 18 Total reward: 21.0 Training loss: 24.8415 Explore P: 0.9911 RunMean : 23.4737\n",
      "Episode: 19 Total reward: 12.0 Training loss: 9.1614 Explore P: 0.9909 RunMean : 22.9000\n",
      "Episode: 20 Total reward: 15.0 Training loss: 9.1509 Explore P: 0.9906 RunMean : 22.5238\n",
      "Episode: 21 Total reward: 10.0 Training loss: 16.3554 Explore P: 0.9904 RunMean : 21.9545\n",
      "Episode: 22 Total reward: 10.0 Training loss: 18.6006 Explore P: 0.9902 RunMean : 21.4348\n",
      "Episode: 23 Total reward: 41.0 Training loss: 12.0395 Explore P: 0.9894 RunMean : 22.2500\n",
      "Episode: 24 Total reward: 10.0 Training loss: 12.8364 Explore P: 0.9892 RunMean : 21.7600\n",
      "Episode: 25 Total reward: 41.0 Training loss: 14.7631 Explore P: 0.9884 RunMean : 22.5000\n",
      "Episode: 26 Total reward: 30.0 Training loss: 46.0448 Explore P: 0.9878 RunMean : 22.7778\n",
      "Episode: 27 Total reward: 74.0 Training loss: 21.1415 Explore P: 0.9863 RunMean : 24.6071\n",
      "Episode: 28 Total reward: 17.0 Training loss: 9.7505 Explore P: 0.9860 RunMean : 24.3448\n",
      "Episode: 29 Total reward: 23.0 Training loss: 6.6060 Explore P: 0.9855 RunMean : 24.3000\n",
      "Episode: 30 Total reward: 21.0 Training loss: 7.4892 Explore P: 0.9851 RunMean : 24.1935\n",
      "Episode: 31 Total reward: 17.0 Training loss: 16.9831 Explore P: 0.9848 RunMean : 23.9688\n",
      "Episode: 32 Total reward: 14.0 Training loss: 31.6762 Explore P: 0.9845 RunMean : 23.6667\n",
      "Episode: 33 Total reward: 12.0 Training loss: 27.9460 Explore P: 0.9843 RunMean : 23.3235\n",
      "Episode: 34 Total reward: 17.0 Training loss: 14.2116 Explore P: 0.9839 RunMean : 23.1429\n",
      "Episode: 35 Total reward: 28.0 Training loss: 24.1913 Explore P: 0.9834 RunMean : 23.2778\n",
      "Episode: 36 Total reward: 10.0 Training loss: 19.2155 Explore P: 0.9832 RunMean : 22.9189\n",
      "Episode: 37 Total reward: 10.0 Training loss: 62.6675 Explore P: 0.9830 RunMean : 22.5789\n",
      "Episode: 38 Total reward: 32.0 Training loss: 18.2114 Explore P: 0.9824 RunMean : 22.8205\n",
      "Episode: 39 Total reward: 10.0 Training loss: 7.4697 Explore P: 0.9822 RunMean : 22.5000\n",
      "Episode: 40 Total reward: 25.0 Training loss: 24.5470 Explore P: 0.9817 RunMean : 22.5610\n",
      "Episode: 41 Total reward: 17.0 Training loss: 7.6535 Explore P: 0.9813 RunMean : 22.4286\n",
      "Episode: 42 Total reward: 17.0 Training loss: 28.2176 Explore P: 0.9810 RunMean : 22.3023\n",
      "Episode: 43 Total reward: 36.0 Training loss: 5.8869 Explore P: 0.9803 RunMean : 22.6136\n",
      "Episode: 44 Total reward: 15.0 Training loss: 21.5618 Explore P: 0.9800 RunMean : 22.4444\n",
      "Episode: 45 Total reward: 17.0 Training loss: 22.1815 Explore P: 0.9797 RunMean : 22.3261\n",
      "Episode: 46 Total reward: 13.0 Training loss: 29.5247 Explore P: 0.9794 RunMean : 22.1277\n",
      "Episode: 47 Total reward: 26.0 Training loss: 11.9424 Explore P: 0.9789 RunMean : 22.2083\n",
      "Episode: 48 Total reward: 19.0 Training loss: 12.4713 Explore P: 0.9785 RunMean : 22.1429\n",
      "Episode: 49 Total reward: 20.0 Training loss: 28.8654 Explore P: 0.9781 RunMean : 22.1000\n",
      "Episode: 50 Total reward: 15.0 Training loss: 16.3238 Explore P: 0.9778 RunMean : 21.9608\n",
      "Episode: 51 Total reward: 40.0 Training loss: 24.3776 Explore P: 0.9771 RunMean : 22.3077\n",
      "Episode: 52 Total reward: 36.0 Training loss: 3.0555 Explore P: 0.9764 RunMean : 22.5660\n",
      "Episode: 53 Total reward: 23.0 Training loss: 14.6104 Explore P: 0.9759 RunMean : 22.5741\n",
      "Episode: 54 Total reward: 75.0 Training loss: 13.0764 Explore P: 0.9745 RunMean : 23.5273\n",
      "Episode: 55 Total reward: 27.0 Training loss: 8.0931 Explore P: 0.9739 RunMean : 23.5893\n",
      "Episode: 56 Total reward: 19.0 Training loss: 66.0316 Explore P: 0.9736 RunMean : 23.5088\n",
      "Episode: 57 Total reward: 24.0 Training loss: 96.0158 Explore P: 0.9731 RunMean : 23.5172\n",
      "Episode: 58 Total reward: 26.0 Training loss: 20.0276 Explore P: 0.9726 RunMean : 23.5593\n",
      "Episode: 59 Total reward: 14.0 Training loss: 17.4774 Explore P: 0.9723 RunMean : 23.4000\n",
      "Episode: 60 Total reward: 58.0 Training loss: 34.1643 Explore P: 0.9712 RunMean : 23.9672\n",
      "Episode: 61 Total reward: 22.0 Training loss: 21.1117 Explore P: 0.9708 RunMean : 23.9355\n",
      "Episode: 62 Total reward: 9.0 Training loss: 22.5490 Explore P: 0.9706 RunMean : 23.6984\n",
      "Episode: 63 Total reward: 21.0 Training loss: 81.6318 Explore P: 0.9702 RunMean : 23.6562\n",
      "Episode: 64 Total reward: 20.0 Training loss: 19.1401 Explore P: 0.9698 RunMean : 23.6000\n",
      "Episode: 65 Total reward: 44.0 Training loss: 37.5020 Explore P: 0.9689 RunMean : 23.9091\n",
      "Episode: 66 Total reward: 11.0 Training loss: 24.6112 Explore P: 0.9687 RunMean : 23.7164\n",
      "Episode: 67 Total reward: 18.0 Training loss: 35.2874 Explore P: 0.9684 RunMean : 23.6324\n",
      "Episode: 68 Total reward: 12.0 Training loss: 5.0415 Explore P: 0.9681 RunMean : 23.4638\n",
      "Episode: 69 Total reward: 21.0 Training loss: 18.8306 Explore P: 0.9677 RunMean : 23.4286\n",
      "Episode: 70 Total reward: 12.0 Training loss: 18.2271 Explore P: 0.9675 RunMean : 23.2676\n",
      "Episode: 71 Total reward: 24.0 Training loss: 52.6413 Explore P: 0.9670 RunMean : 23.2778\n",
      "Episode: 72 Total reward: 19.0 Training loss: 31.0983 Explore P: 0.9667 RunMean : 23.2192\n",
      "Episode: 73 Total reward: 32.0 Training loss: 60.7617 Explore P: 0.9660 RunMean : 23.3378\n",
      "Episode: 74 Total reward: 39.0 Training loss: 71.1984 Explore P: 0.9653 RunMean : 23.5467\n",
      "Episode: 75 Total reward: 26.0 Training loss: 70.7509 Explore P: 0.9648 RunMean : 23.5789\n",
      "Episode: 76 Total reward: 33.0 Training loss: 30.0379 Explore P: 0.9642 RunMean : 23.7013\n",
      "Episode: 77 Total reward: 16.0 Training loss: 49.1351 Explore P: 0.9638 RunMean : 23.6026\n",
      "Episode: 78 Total reward: 39.0 Training loss: 77.7881 Explore P: 0.9631 RunMean : 23.7975\n",
      "Episode: 79 Total reward: 20.0 Training loss: 26.4486 Explore P: 0.9627 RunMean : 23.7500\n",
      "Episode: 80 Total reward: 30.0 Training loss: 8.1680 Explore P: 0.9621 RunMean : 23.8272\n",
      "Episode: 81 Total reward: 29.0 Training loss: 78.6502 Explore P: 0.9616 RunMean : 23.8902\n",
      "Episode: 82 Total reward: 21.0 Training loss: 97.5038 Explore P: 0.9612 RunMean : 23.8554\n",
      "Episode: 83 Total reward: 12.0 Training loss: 41.7298 Explore P: 0.9609 RunMean : 23.7143\n",
      "Episode: 84 Total reward: 42.0 Training loss: 28.8246 Explore P: 0.9601 RunMean : 23.9294\n",
      "Episode: 85 Total reward: 15.0 Training loss: 63.5781 Explore P: 0.9598 RunMean : 23.8256\n",
      "Episode: 86 Total reward: 21.0 Training loss: 103.6328 Explore P: 0.9594 RunMean : 23.7931\n",
      "Episode: 87 Total reward: 44.0 Training loss: 39.1499 Explore P: 0.9586 RunMean : 24.0227\n",
      "Episode: 88 Total reward: 25.0 Training loss: 63.4166 Explore P: 0.9581 RunMean : 24.0337\n",
      "Episode: 89 Total reward: 41.0 Training loss: 95.0590 Explore P: 0.9573 RunMean : 24.2222\n",
      "Episode: 90 Total reward: 22.0 Training loss: 135.7745 Explore P: 0.9569 RunMean : 24.1978\n",
      "Episode: 91 Total reward: 14.0 Training loss: 143.2859 Explore P: 0.9566 RunMean : 24.0870\n",
      "Episode: 92 Total reward: 11.0 Training loss: 46.0329 Explore P: 0.9564 RunMean : 23.9462\n",
      "Episode: 93 Total reward: 63.0 Training loss: 78.1899 Explore P: 0.9552 RunMean : 24.3617\n",
      "Episode: 94 Total reward: 20.0 Training loss: 90.8581 Explore P: 0.9549 RunMean : 24.3158\n",
      "Episode: 95 Total reward: 20.0 Training loss: 11.7560 Explore P: 0.9545 RunMean : 24.2708\n",
      "Episode: 96 Total reward: 21.0 Training loss: 88.2380 Explore P: 0.9541 RunMean : 24.2371\n",
      "Episode: 97 Total reward: 66.0 Training loss: 41.8349 Explore P: 0.9528 RunMean : 24.6633\n",
      "Episode: 98 Total reward: 41.0 Training loss: 140.9594 Explore P: 0.9520 RunMean : 24.8283\n",
      "Episode: 99 Total reward: 13.0 Training loss: 116.9515 Explore P: 0.9518 RunMean : 24.7100\n",
      "Episode: 100 Total reward: 14.0 Training loss: 59.0135 Explore P: 0.9515 RunMean : 24.6800\n",
      "Episode: 101 Total reward: 56.0 Training loss: 41.6394 Explore P: 0.9504 RunMean : 25.1100\n",
      "Episode: 102 Total reward: 17.0 Training loss: 114.4426 Explore P: 0.9501 RunMean : 25.0700\n",
      "Episode: 103 Total reward: 34.0 Training loss: 13.2757 Explore P: 0.9495 RunMean : 25.2900\n",
      "Episode: 104 Total reward: 32.0 Training loss: 49.1476 Explore P: 0.9489 RunMean : 25.5000\n",
      "Episode: 105 Total reward: 15.0 Training loss: 102.3701 Explore P: 0.9486 RunMean : 25.0600\n",
      "Episode: 106 Total reward: 19.0 Training loss: 56.9884 Explore P: 0.9482 RunMean : 25.0400\n",
      "Episode: 107 Total reward: 44.0 Training loss: 83.8496 Explore P: 0.9474 RunMean : 25.3100\n",
      "Episode: 108 Total reward: 14.0 Training loss: 24.1513 Explore P: 0.9471 RunMean : 25.0200\n",
      "Episode: 109 Total reward: 29.0 Training loss: 83.8473 Explore P: 0.9466 RunMean : 25.1400\n",
      "Episode: 110 Total reward: 13.0 Training loss: 81.0411 Explore P: 0.9463 RunMean : 24.5400\n",
      "Episode: 111 Total reward: 16.0 Training loss: 27.9198 Explore P: 0.9460 RunMean : 24.5400\n",
      "Episode: 112 Total reward: 17.0 Training loss: 96.1663 Explore P: 0.9457 RunMean : 24.5900\n",
      "Episode: 113 Total reward: 13.0 Training loss: 64.8013 Explore P: 0.9455 RunMean : 24.5800\n",
      "Episode: 114 Total reward: 23.0 Training loss: 66.9520 Explore P: 0.9450 RunMean : 24.6300\n",
      "Episode: 115 Total reward: 15.0 Training loss: 50.5344 Explore P: 0.9447 RunMean : 24.6200\n",
      "Episode: 116 Total reward: 20.0 Training loss: 30.8566 Explore P: 0.9444 RunMean : 24.6300\n",
      "Episode: 117 Total reward: 18.0 Training loss: 157.0943 Explore P: 0.9440 RunMean : 24.5500\n",
      "Episode: 118 Total reward: 44.0 Training loss: 51.4343 Explore P: 0.9432 RunMean : 24.7800\n",
      "Episode: 119 Total reward: 14.0 Training loss: 84.4393 Explore P: 0.9429 RunMean : 24.8000\n",
      "Episode: 120 Total reward: 15.0 Training loss: 127.5017 Explore P: 0.9427 RunMean : 24.8000\n",
      "Episode: 121 Total reward: 16.0 Training loss: 27.9675 Explore P: 0.9423 RunMean : 24.8600\n",
      "Episode: 122 Total reward: 12.0 Training loss: 93.4124 Explore P: 0.9421 RunMean : 24.8800\n",
      "Episode: 123 Total reward: 14.0 Training loss: 83.1597 Explore P: 0.9419 RunMean : 24.6100\n",
      "Episode: 124 Total reward: 11.0 Training loss: 101.6295 Explore P: 0.9417 RunMean : 24.6200\n",
      "Episode: 125 Total reward: 16.0 Training loss: 175.2880 Explore P: 0.9414 RunMean : 24.3700\n",
      "Episode: 126 Total reward: 22.0 Training loss: 32.9655 Explore P: 0.9409 RunMean : 24.2900\n",
      "Episode: 127 Total reward: 15.0 Training loss: 22.7646 Explore P: 0.9407 RunMean : 23.7000\n",
      "Episode: 128 Total reward: 19.0 Training loss: 115.9381 Explore P: 0.9403 RunMean : 23.7200\n",
      "Episode: 129 Total reward: 33.0 Training loss: 85.5923 Explore P: 0.9397 RunMean : 23.8200\n",
      "Episode: 130 Total reward: 33.0 Training loss: 109.0901 Explore P: 0.9391 RunMean : 23.9400\n",
      "Episode: 131 Total reward: 13.0 Training loss: 19.0375 Explore P: 0.9388 RunMean : 23.9000\n",
      "Episode: 132 Total reward: 31.0 Training loss: 135.6039 Explore P: 0.9382 RunMean : 24.0700\n",
      "Episode: 133 Total reward: 22.0 Training loss: 82.8699 Explore P: 0.9378 RunMean : 24.1700\n",
      "Episode: 134 Total reward: 39.0 Training loss: 124.3636 Explore P: 0.9371 RunMean : 24.3900\n",
      "Episode: 135 Total reward: 35.0 Training loss: 79.8154 Explore P: 0.9364 RunMean : 24.4600\n",
      "Episode: 136 Total reward: 29.0 Training loss: 36.5054 Explore P: 0.9359 RunMean : 24.6500\n",
      "Episode: 137 Total reward: 18.0 Training loss: 88.6074 Explore P: 0.9356 RunMean : 24.7300\n",
      "Episode: 138 Total reward: 11.0 Training loss: 85.2581 Explore P: 0.9353 RunMean : 24.5200\n",
      "Episode: 139 Total reward: 41.0 Training loss: 192.0361 Explore P: 0.9346 RunMean : 24.8300\n",
      "Episode: 140 Total reward: 13.0 Training loss: 107.5896 Explore P: 0.9343 RunMean : 24.7100\n",
      "Episode: 141 Total reward: 19.0 Training loss: 122.6996 Explore P: 0.9340 RunMean : 24.7300\n",
      "Episode: 142 Total reward: 55.0 Training loss: 206.7387 Explore P: 0.9330 RunMean : 25.1100\n",
      "Episode: 143 Total reward: 27.0 Training loss: 35.9314 Explore P: 0.9324 RunMean : 25.0200\n",
      "Episode: 144 Total reward: 35.0 Training loss: 48.4697 Explore P: 0.9318 RunMean : 25.2200\n",
      "Episode: 145 Total reward: 9.0 Training loss: 13.6518 Explore P: 0.9316 RunMean : 25.1400\n",
      "Episode: 146 Total reward: 17.0 Training loss: 162.0551 Explore P: 0.9313 RunMean : 25.1800\n",
      "Episode: 147 Total reward: 18.0 Training loss: 118.3616 Explore P: 0.9310 RunMean : 25.1000\n",
      "Episode: 148 Total reward: 15.0 Training loss: 45.1864 Explore P: 0.9307 RunMean : 25.0600\n",
      "Episode: 149 Total reward: 44.0 Training loss: 16.6377 Explore P: 0.9299 RunMean : 25.3000\n",
      "Episode: 150 Total reward: 17.0 Training loss: 119.7445 Explore P: 0.9296 RunMean : 25.3200\n",
      "Episode: 151 Total reward: 25.0 Training loss: 74.7105 Explore P: 0.9291 RunMean : 25.1700\n",
      "Episode: 152 Total reward: 17.0 Training loss: 20.7756 Explore P: 0.9288 RunMean : 24.9800\n",
      "Episode: 153 Total reward: 17.0 Training loss: 88.2626 Explore P: 0.9285 RunMean : 24.9200\n",
      "Episode: 154 Total reward: 13.0 Training loss: 90.2290 Explore P: 0.9282 RunMean : 24.3000\n",
      "Episode: 155 Total reward: 31.0 Training loss: 220.2811 Explore P: 0.9277 RunMean : 24.3400\n",
      "Episode: 156 Total reward: 22.0 Training loss: 105.4856 Explore P: 0.9272 RunMean : 24.3700\n",
      "Episode: 157 Total reward: 15.0 Training loss: 114.5777 Explore P: 0.9270 RunMean : 24.2800\n",
      "Episode: 158 Total reward: 22.0 Training loss: 193.7681 Explore P: 0.9266 RunMean : 24.2400\n",
      "Episode: 159 Total reward: 24.0 Training loss: 149.7752 Explore P: 0.9261 RunMean : 24.3400\n",
      "Episode: 160 Total reward: 20.0 Training loss: 77.2901 Explore P: 0.9257 RunMean : 23.9600\n",
      "Episode: 161 Total reward: 25.0 Training loss: 312.8281 Explore P: 0.9253 RunMean : 23.9900\n",
      "Episode: 162 Total reward: 17.0 Training loss: 195.4706 Explore P: 0.9250 RunMean : 24.0700\n",
      "Episode: 163 Total reward: 32.0 Training loss: 56.6134 Explore P: 0.9244 RunMean : 24.1800\n",
      "Episode: 164 Total reward: 13.0 Training loss: 193.9928 Explore P: 0.9241 RunMean : 24.1100\n",
      "Episode: 165 Total reward: 14.0 Training loss: 47.6140 Explore P: 0.9239 RunMean : 23.8100\n",
      "Episode: 166 Total reward: 24.0 Training loss: 96.3819 Explore P: 0.9234 RunMean : 23.9400\n",
      "Episode: 167 Total reward: 38.0 Training loss: 81.0337 Explore P: 0.9227 RunMean : 24.1400\n",
      "Episode: 168 Total reward: 25.0 Training loss: 33.2407 Explore P: 0.9223 RunMean : 24.2700\n",
      "Episode: 169 Total reward: 22.0 Training loss: 94.6202 Explore P: 0.9219 RunMean : 24.2800\n",
      "Episode: 170 Total reward: 19.0 Training loss: 31.6684 Explore P: 0.9215 RunMean : 24.3500\n",
      "Episode: 171 Total reward: 17.0 Training loss: 126.4461 Explore P: 0.9212 RunMean : 24.2800\n",
      "Episode: 172 Total reward: 65.0 Training loss: 121.7669 Explore P: 0.9200 RunMean : 24.7400\n",
      "Episode: 173 Total reward: 16.0 Training loss: 18.9331 Explore P: 0.9197 RunMean : 24.5800\n",
      "Episode: 174 Total reward: 36.0 Training loss: 80.5996 Explore P: 0.9190 RunMean : 24.5500\n",
      "Episode: 175 Total reward: 19.0 Training loss: 137.2823 Explore P: 0.9187 RunMean : 24.4800\n",
      "Episode: 176 Total reward: 11.0 Training loss: 172.9449 Explore P: 0.9185 RunMean : 24.2600\n",
      "Episode: 177 Total reward: 20.0 Training loss: 112.5595 Explore P: 0.9181 RunMean : 24.3000\n",
      "Episode: 178 Total reward: 15.0 Training loss: 95.2467 Explore P: 0.9179 RunMean : 24.0600\n",
      "Episode: 179 Total reward: 29.0 Training loss: 211.7570 Explore P: 0.9173 RunMean : 24.1500\n",
      "Episode: 180 Total reward: 72.0 Training loss: 32.4999 Explore P: 0.9160 RunMean : 24.5700\n",
      "Episode: 181 Total reward: 18.0 Training loss: 47.4928 Explore P: 0.9157 RunMean : 24.4600\n",
      "Episode: 182 Total reward: 11.0 Training loss: 107.2894 Explore P: 0.9155 RunMean : 24.3600\n",
      "Episode: 183 Total reward: 70.0 Training loss: 168.5672 Explore P: 0.9142 RunMean : 24.9400\n",
      "Episode: 184 Total reward: 16.0 Training loss: 200.4568 Explore P: 0.9139 RunMean : 24.6800\n",
      "Episode: 185 Total reward: 16.0 Training loss: 27.8273 Explore P: 0.9136 RunMean : 24.6900\n",
      "Episode: 186 Total reward: 19.0 Training loss: 23.7237 Explore P: 0.9133 RunMean : 24.6700\n",
      "Episode: 187 Total reward: 17.0 Training loss: 84.3282 Explore P: 0.9129 RunMean : 24.4000\n",
      "Episode: 188 Total reward: 20.0 Training loss: 92.7456 Explore P: 0.9126 RunMean : 24.3500\n",
      "Episode: 189 Total reward: 14.0 Training loss: 25.0014 Explore P: 0.9123 RunMean : 24.0800\n",
      "Episode: 190 Total reward: 16.0 Training loss: 107.7568 Explore P: 0.9120 RunMean : 24.0200\n",
      "Episode: 191 Total reward: 11.0 Training loss: 16.6047 Explore P: 0.9118 RunMean : 23.9900\n",
      "Episode: 192 Total reward: 40.0 Training loss: 224.0645 Explore P: 0.9111 RunMean : 24.2800\n",
      "Episode: 193 Total reward: 19.0 Training loss: 64.3599 Explore P: 0.9108 RunMean : 23.8400\n",
      "Episode: 194 Total reward: 12.0 Training loss: 13.1501 Explore P: 0.9105 RunMean : 23.7600\n",
      "Episode: 195 Total reward: 15.0 Training loss: 143.1540 Explore P: 0.9103 RunMean : 23.7100\n",
      "Episode: 196 Total reward: 17.0 Training loss: 70.1461 Explore P: 0.9100 RunMean : 23.6700\n",
      "Episode: 197 Total reward: 18.0 Training loss: 126.5494 Explore P: 0.9096 RunMean : 23.1900\n",
      "Episode: 198 Total reward: 36.0 Training loss: 19.2377 Explore P: 0.9090 RunMean : 23.1400\n",
      "Episode: 199 Total reward: 17.0 Training loss: 140.5316 Explore P: 0.9087 RunMean : 23.1800\n",
      "Episode: 200 Total reward: 18.0 Training loss: 102.1609 Explore P: 0.9083 RunMean : 23.2200\n",
      "Episode: 201 Total reward: 12.0 Training loss: 149.9764 Explore P: 0.9081 RunMean : 22.7800\n",
      "Episode: 202 Total reward: 22.0 Training loss: 112.7277 Explore P: 0.9077 RunMean : 22.8300\n",
      "Episode: 203 Total reward: 12.0 Training loss: 41.2099 Explore P: 0.9075 RunMean : 22.6100\n",
      "Episode: 204 Total reward: 37.0 Training loss: 82.2716 Explore P: 0.9068 RunMean : 22.6600\n",
      "Episode: 205 Total reward: 18.0 Training loss: 138.2508 Explore P: 0.9065 RunMean : 22.6900\n",
      "Episode: 206 Total reward: 80.0 Training loss: 94.4056 Explore P: 0.9051 RunMean : 23.3000\n",
      "Episode: 207 Total reward: 12.0 Training loss: 76.6419 Explore P: 0.9048 RunMean : 22.9800\n",
      "Episode: 208 Total reward: 9.0 Training loss: 125.3177 Explore P: 0.9047 RunMean : 22.9300\n",
      "Episode: 209 Total reward: 20.0 Training loss: 93.1192 Explore P: 0.9043 RunMean : 22.8400\n",
      "Episode: 210 Total reward: 12.0 Training loss: 64.4576 Explore P: 0.9041 RunMean : 22.8300\n",
      "Episode: 211 Total reward: 53.0 Training loss: 145.9480 Explore P: 0.9031 RunMean : 23.2000\n",
      "Episode: 212 Total reward: 33.0 Training loss: 20.1558 Explore P: 0.9025 RunMean : 23.3600\n",
      "Episode: 213 Total reward: 21.0 Training loss: 133.0162 Explore P: 0.9022 RunMean : 23.4400\n",
      "Episode: 214 Total reward: 21.0 Training loss: 163.9800 Explore P: 0.9018 RunMean : 23.4200\n",
      "Episode: 215 Total reward: 44.0 Training loss: 84.5976 Explore P: 0.9010 RunMean : 23.7100\n",
      "Episode: 216 Total reward: 16.0 Training loss: 106.9781 Explore P: 0.9007 RunMean : 23.6700\n",
      "Episode: 217 Total reward: 18.0 Training loss: 132.6360 Explore P: 0.9004 RunMean : 23.6700\n",
      "Episode: 218 Total reward: 20.0 Training loss: 142.1452 Explore P: 0.9000 RunMean : 23.4300\n",
      "Episode: 219 Total reward: 53.0 Training loss: 82.3290 Explore P: 0.8991 RunMean : 23.8200\n",
      "Episode: 220 Total reward: 35.0 Training loss: 97.6266 Explore P: 0.8984 RunMean : 24.0200\n",
      "Episode: 221 Total reward: 12.0 Training loss: 123.0450 Explore P: 0.8982 RunMean : 23.9800\n",
      "Episode: 222 Total reward: 20.0 Training loss: 185.3528 Explore P: 0.8979 RunMean : 24.0600\n",
      "Episode: 223 Total reward: 24.0 Training loss: 249.1241 Explore P: 0.8974 RunMean : 24.1600\n",
      "Episode: 224 Total reward: 18.0 Training loss: 20.1509 Explore P: 0.8971 RunMean : 24.2300\n",
      "Episode: 225 Total reward: 33.0 Training loss: 175.3532 Explore P: 0.8965 RunMean : 24.4000\n",
      "Episode: 226 Total reward: 28.0 Training loss: 73.8539 Explore P: 0.8960 RunMean : 24.4600\n",
      "Episode: 227 Total reward: 16.0 Training loss: 14.5552 Explore P: 0.8957 RunMean : 24.4700\n",
      "Episode: 228 Total reward: 60.0 Training loss: 220.9644 Explore P: 0.8947 RunMean : 24.8800\n",
      "Episode: 229 Total reward: 17.0 Training loss: 73.0940 Explore P: 0.8943 RunMean : 24.7200\n",
      "Episode: 230 Total reward: 9.0 Training loss: 295.7286 Explore P: 0.8942 RunMean : 24.4800\n",
      "Episode: 231 Total reward: 25.0 Training loss: 129.9730 Explore P: 0.8937 RunMean : 24.6000\n",
      "Episode: 232 Total reward: 38.0 Training loss: 118.9467 Explore P: 0.8931 RunMean : 24.6700\n",
      "Episode: 233 Total reward: 21.0 Training loss: 285.5303 Explore P: 0.8927 RunMean : 24.6600\n",
      "Episode: 234 Total reward: 36.0 Training loss: 16.1128 Explore P: 0.8920 RunMean : 24.6300\n",
      "Episode: 235 Total reward: 15.0 Training loss: 78.9693 Explore P: 0.8918 RunMean : 24.4300\n",
      "Episode: 236 Total reward: 40.0 Training loss: 168.1378 Explore P: 0.8911 RunMean : 24.5400\n",
      "Episode: 237 Total reward: 70.0 Training loss: 89.5975 Explore P: 0.8898 RunMean : 25.0600\n",
      "Episode: 238 Total reward: 32.0 Training loss: 93.1696 Explore P: 0.8892 RunMean : 25.2700\n",
      "Episode: 239 Total reward: 52.0 Training loss: 123.3093 Explore P: 0.8883 RunMean : 25.3800\n",
      "Episode: 240 Total reward: 37.0 Training loss: 298.9714 Explore P: 0.8877 RunMean : 25.6200\n",
      "Episode: 241 Total reward: 66.0 Training loss: 154.9689 Explore P: 0.8865 RunMean : 26.0900\n",
      "Episode: 242 Total reward: 34.0 Training loss: 132.6678 Explore P: 0.8859 RunMean : 25.8800\n",
      "Episode: 243 Total reward: 11.0 Training loss: 58.4780 Explore P: 0.8857 RunMean : 25.7200\n",
      "Episode: 244 Total reward: 12.0 Training loss: 16.9050 Explore P: 0.8855 RunMean : 25.4900\n",
      "Episode: 245 Total reward: 25.0 Training loss: 86.4067 Explore P: 0.8850 RunMean : 25.6500\n",
      "Episode: 246 Total reward: 26.0 Training loss: 177.4487 Explore P: 0.8846 RunMean : 25.7400\n",
      "Episode: 247 Total reward: 35.0 Training loss: 117.2148 Explore P: 0.8840 RunMean : 25.9100\n",
      "Episode: 248 Total reward: 10.0 Training loss: 182.1439 Explore P: 0.8838 RunMean : 25.8600\n",
      "Episode: 249 Total reward: 31.0 Training loss: 174.6484 Explore P: 0.8832 RunMean : 25.7300\n",
      "Episode: 250 Total reward: 20.0 Training loss: 128.0020 Explore P: 0.8829 RunMean : 25.7600\n",
      "Episode: 251 Total reward: 34.0 Training loss: 72.6714 Explore P: 0.8823 RunMean : 25.8500\n",
      "Episode: 252 Total reward: 26.0 Training loss: 237.6183 Explore P: 0.8818 RunMean : 25.9400\n",
      "Episode: 253 Total reward: 31.0 Training loss: 66.5147 Explore P: 0.8813 RunMean : 26.0800\n",
      "Episode: 254 Total reward: 16.0 Training loss: 134.4581 Explore P: 0.8810 RunMean : 26.1100\n",
      "Episode: 255 Total reward: 37.0 Training loss: 95.5316 Explore P: 0.8803 RunMean : 26.1700\n",
      "Episode: 256 Total reward: 34.0 Training loss: 20.3844 Explore P: 0.8797 RunMean : 26.2900\n",
      "Episode: 257 Total reward: 32.0 Training loss: 188.7671 Explore P: 0.8792 RunMean : 26.4600\n",
      "Episode: 258 Total reward: 53.0 Training loss: 20.3255 Explore P: 0.8783 RunMean : 26.7700\n",
      "Episode: 259 Total reward: 30.0 Training loss: 105.9328 Explore P: 0.8777 RunMean : 26.8300\n",
      "Episode: 260 Total reward: 13.0 Training loss: 207.8138 Explore P: 0.8775 RunMean : 26.7600\n",
      "Episode: 261 Total reward: 15.0 Training loss: 115.1792 Explore P: 0.8772 RunMean : 26.6600\n",
      "Episode: 262 Total reward: 53.0 Training loss: 32.7771 Explore P: 0.8763 RunMean : 27.0200\n",
      "Episode: 263 Total reward: 18.0 Training loss: 133.2558 Explore P: 0.8760 RunMean : 26.8800\n",
      "Episode: 264 Total reward: 29.0 Training loss: 249.3378 Explore P: 0.8755 RunMean : 27.0400\n",
      "Episode: 265 Total reward: 28.0 Training loss: 134.8640 Explore P: 0.8750 RunMean : 27.1800\n",
      "Episode: 266 Total reward: 16.0 Training loss: 174.2843 Explore P: 0.8747 RunMean : 27.1000\n",
      "Episode: 267 Total reward: 43.0 Training loss: 194.6828 Explore P: 0.8740 RunMean : 27.1500\n",
      "Episode: 268 Total reward: 98.0 Training loss: 70.0088 Explore P: 0.8722 RunMean : 27.8800\n",
      "Episode: 269 Total reward: 22.0 Training loss: 99.1201 Explore P: 0.8719 RunMean : 27.8800\n",
      "Episode: 270 Total reward: 28.0 Training loss: 354.1528 Explore P: 0.8714 RunMean : 27.9700\n",
      "Episode: 271 Total reward: 25.0 Training loss: 398.7106 Explore P: 0.8709 RunMean : 28.0500\n",
      "Episode: 272 Total reward: 29.0 Training loss: 30.7924 Explore P: 0.8704 RunMean : 27.6900\n",
      "Episode: 273 Total reward: 29.0 Training loss: 99.2074 Explore P: 0.8699 RunMean : 27.8200\n",
      "Episode: 274 Total reward: 53.0 Training loss: 144.8717 Explore P: 0.8690 RunMean : 27.9900\n",
      "Episode: 275 Total reward: 46.0 Training loss: 64.9637 Explore P: 0.8682 RunMean : 28.2600\n",
      "Episode: 276 Total reward: 11.0 Training loss: 99.2693 Explore P: 0.8680 RunMean : 28.2600\n",
      "Episode: 277 Total reward: 34.0 Training loss: 229.0451 Explore P: 0.8674 RunMean : 28.4000\n",
      "Episode: 278 Total reward: 11.0 Training loss: 184.1963 Explore P: 0.8672 RunMean : 28.3600\n",
      "Episode: 279 Total reward: 20.0 Training loss: 166.1586 Explore P: 0.8669 RunMean : 28.2700\n",
      "Episode: 280 Total reward: 78.0 Training loss: 178.3463 Explore P: 0.8655 RunMean : 28.3300\n",
      "Episode: 281 Total reward: 22.0 Training loss: 41.9726 Explore P: 0.8652 RunMean : 28.3700\n",
      "Episode: 282 Total reward: 32.0 Training loss: 93.4403 Explore P: 0.8646 RunMean : 28.5800\n",
      "Episode: 283 Total reward: 28.0 Training loss: 192.1346 Explore P: 0.8641 RunMean : 28.1600\n",
      "Episode: 284 Total reward: 15.0 Training loss: 276.3983 Explore P: 0.8639 RunMean : 28.1500\n",
      "Episode: 285 Total reward: 27.0 Training loss: 183.0822 Explore P: 0.8634 RunMean : 28.2600\n",
      "Episode: 286 Total reward: 74.0 Training loss: 149.0130 Explore P: 0.8621 RunMean : 28.8100\n",
      "Episode: 287 Total reward: 15.0 Training loss: 442.2310 Explore P: 0.8619 RunMean : 28.7900\n",
      "Episode: 288 Total reward: 13.0 Training loss: 20.6186 Explore P: 0.8616 RunMean : 28.7200\n",
      "Episode: 289 Total reward: 11.0 Training loss: 118.3294 Explore P: 0.8614 RunMean : 28.6900\n",
      "Episode: 290 Total reward: 54.0 Training loss: 270.1999 Explore P: 0.8605 RunMean : 29.0700\n",
      "Episode: 291 Total reward: 43.0 Training loss: 376.0733 Explore P: 0.8598 RunMean : 29.3900\n",
      "Episode: 292 Total reward: 59.0 Training loss: 244.1227 Explore P: 0.8588 RunMean : 29.5800\n",
      "Episode: 293 Total reward: 46.0 Training loss: 541.9722 Explore P: 0.8580 RunMean : 29.8500\n",
      "Episode: 294 Total reward: 21.0 Training loss: 28.3375 Explore P: 0.8576 RunMean : 29.9400\n",
      "Episode: 295 Total reward: 37.0 Training loss: 120.5026 Explore P: 0.8570 RunMean : 30.1600\n",
      "Episode: 296 Total reward: 59.0 Training loss: 150.4201 Explore P: 0.8560 RunMean : 30.5800\n",
      "Episode: 297 Total reward: 38.0 Training loss: 114.6372 Explore P: 0.8553 RunMean : 30.7800\n",
      "Episode: 298 Total reward: 23.0 Training loss: 20.9039 Explore P: 0.8549 RunMean : 30.6500\n",
      "Episode: 299 Total reward: 15.0 Training loss: 116.0944 Explore P: 0.8547 RunMean : 30.6300\n",
      "Episode: 300 Total reward: 16.0 Training loss: 324.2987 Explore P: 0.8544 RunMean : 30.6100\n",
      "Episode: 301 Total reward: 19.0 Training loss: 411.7443 Explore P: 0.8541 RunMean : 30.6800\n",
      "Episode: 302 Total reward: 35.0 Training loss: 188.3374 Explore P: 0.8535 RunMean : 30.8100\n",
      "Episode: 303 Total reward: 47.0 Training loss: 101.6326 Explore P: 0.8527 RunMean : 31.1600\n",
      "Episode: 304 Total reward: 28.0 Training loss: 150.8865 Explore P: 0.8522 RunMean : 31.0700\n",
      "Episode: 305 Total reward: 28.0 Training loss: 45.2599 Explore P: 0.8517 RunMean : 31.1700\n",
      "Episode: 306 Total reward: 37.0 Training loss: 212.6143 Explore P: 0.8511 RunMean : 30.7400\n",
      "Episode: 307 Total reward: 26.0 Training loss: 179.2021 Explore P: 0.8506 RunMean : 30.8800\n",
      "Episode: 308 Total reward: 15.0 Training loss: 402.7444 Explore P: 0.8504 RunMean : 30.9400\n",
      "Episode: 309 Total reward: 14.0 Training loss: 24.5618 Explore P: 0.8502 RunMean : 30.8800\n",
      "Episode: 310 Total reward: 29.0 Training loss: 153.6459 Explore P: 0.8497 RunMean : 31.0500\n",
      "Episode: 311 Total reward: 28.0 Training loss: 103.9765 Explore P: 0.8492 RunMean : 30.8000\n",
      "Episode: 312 Total reward: 54.0 Training loss: 367.3305 Explore P: 0.8483 RunMean : 31.0100\n",
      "Episode: 313 Total reward: 65.0 Training loss: 379.6005 Explore P: 0.8472 RunMean : 31.4500\n",
      "Episode: 314 Total reward: 16.0 Training loss: 41.7177 Explore P: 0.8469 RunMean : 31.4000\n",
      "Episode: 315 Total reward: 25.0 Training loss: 120.9002 Explore P: 0.8465 RunMean : 31.2100\n",
      "Episode: 316 Total reward: 13.0 Training loss: 257.4013 Explore P: 0.8463 RunMean : 31.1800\n",
      "Episode: 317 Total reward: 25.0 Training loss: 412.1755 Explore P: 0.8458 RunMean : 31.2500\n",
      "Episode: 318 Total reward: 11.0 Training loss: 142.1869 Explore P: 0.8456 RunMean : 31.1600\n",
      "Episode: 319 Total reward: 23.0 Training loss: 289.8732 Explore P: 0.8453 RunMean : 30.8600\n",
      "Episode: 320 Total reward: 18.0 Training loss: 260.8398 Explore P: 0.8449 RunMean : 30.6900\n",
      "Episode: 321 Total reward: 18.0 Training loss: 324.5741 Explore P: 0.8446 RunMean : 30.7500\n",
      "Episode: 322 Total reward: 33.0 Training loss: 828.7430 Explore P: 0.8441 RunMean : 30.8800\n",
      "Episode: 323 Total reward: 70.0 Training loss: 184.3914 Explore P: 0.8429 RunMean : 31.3400\n",
      "Episode: 324 Total reward: 78.0 Training loss: 322.4012 Explore P: 0.8416 RunMean : 31.9400\n",
      "Episode: 325 Total reward: 33.0 Training loss: 28.2323 Explore P: 0.8410 RunMean : 31.9400\n",
      "Episode: 326 Total reward: 12.0 Training loss: 34.5035 Explore P: 0.8408 RunMean : 31.7800\n",
      "Episode: 327 Total reward: 48.0 Training loss: 43.7572 Explore P: 0.8400 RunMean : 32.1000\n",
      "Episode: 328 Total reward: 27.0 Training loss: 35.6412 Explore P: 0.8396 RunMean : 31.7700\n",
      "Episode: 329 Total reward: 41.0 Training loss: 418.6916 Explore P: 0.8389 RunMean : 32.0100\n",
      "Episode: 330 Total reward: 36.0 Training loss: 361.5101 Explore P: 0.8383 RunMean : 32.2800\n",
      "Episode: 331 Total reward: 18.0 Training loss: 40.3723 Explore P: 0.8380 RunMean : 32.2100\n",
      "Episode: 332 Total reward: 20.0 Training loss: 34.6132 Explore P: 0.8376 RunMean : 32.0300\n",
      "Episode: 333 Total reward: 18.0 Training loss: 144.1471 Explore P: 0.8373 RunMean : 32.0000\n",
      "Episode: 334 Total reward: 15.0 Training loss: 245.0061 Explore P: 0.8371 RunMean : 31.7900\n",
      "Episode: 335 Total reward: 19.0 Training loss: 88.9734 Explore P: 0.8368 RunMean : 31.8300\n",
      "Episode: 336 Total reward: 31.0 Training loss: 457.9503 Explore P: 0.8363 RunMean : 31.7400\n",
      "Episode: 337 Total reward: 41.0 Training loss: 348.9373 Explore P: 0.8356 RunMean : 31.4500\n",
      "Episode: 338 Total reward: 54.0 Training loss: 335.6392 Explore P: 0.8347 RunMean : 31.6700\n",
      "Episode: 339 Total reward: 14.0 Training loss: 226.4177 Explore P: 0.8344 RunMean : 31.2900\n",
      "Episode: 340 Total reward: 18.0 Training loss: 565.7655 Explore P: 0.8341 RunMean : 31.1000\n",
      "Episode: 341 Total reward: 11.0 Training loss: 42.0089 Explore P: 0.8340 RunMean : 30.5500\n",
      "Episode: 342 Total reward: 27.0 Training loss: 223.8116 Explore P: 0.8335 RunMean : 30.4800\n",
      "Episode: 343 Total reward: 13.0 Training loss: 282.8461 Explore P: 0.8333 RunMean : 30.5000\n",
      "Episode: 344 Total reward: 27.0 Training loss: 200.1774 Explore P: 0.8328 RunMean : 30.6500\n",
      "Episode: 345 Total reward: 20.0 Training loss: 382.6174 Explore P: 0.8325 RunMean : 30.6000\n",
      "Episode: 346 Total reward: 21.0 Training loss: 179.1819 Explore P: 0.8322 RunMean : 30.5500\n",
      "Episode: 347 Total reward: 30.0 Training loss: 33.3938 Explore P: 0.8317 RunMean : 30.5000\n",
      "Episode: 348 Total reward: 35.0 Training loss: 469.4245 Explore P: 0.8311 RunMean : 30.7500\n",
      "Episode: 349 Total reward: 27.0 Training loss: 331.2292 Explore P: 0.8306 RunMean : 30.7100\n",
      "Episode: 350 Total reward: 53.0 Training loss: 163.2943 Explore P: 0.8297 RunMean : 31.0400\n",
      "Episode: 351 Total reward: 22.0 Training loss: 218.3674 Explore P: 0.8294 RunMean : 30.9200\n",
      "Episode: 352 Total reward: 110.0 Training loss: 553.9531 Explore P: 0.8276 RunMean : 31.7600\n",
      "Episode: 353 Total reward: 28.0 Training loss: 173.3902 Explore P: 0.8271 RunMean : 31.7300\n",
      "Episode: 354 Total reward: 22.0 Training loss: 178.5198 Explore P: 0.8267 RunMean : 31.7900\n",
      "Episode: 355 Total reward: 34.0 Training loss: 42.7903 Explore P: 0.8262 RunMean : 31.7600\n",
      "Episode: 356 Total reward: 25.0 Training loss: 276.4302 Explore P: 0.8258 RunMean : 31.6700\n",
      "Episode: 357 Total reward: 26.0 Training loss: 265.8350 Explore P: 0.8253 RunMean : 31.6100\n",
      "Episode: 358 Total reward: 22.0 Training loss: 680.5073 Explore P: 0.8250 RunMean : 31.3000\n",
      "Episode: 359 Total reward: 46.0 Training loss: 122.5116 Explore P: 0.8242 RunMean : 31.4600\n",
      "Episode: 360 Total reward: 43.0 Training loss: 384.8596 Explore P: 0.8235 RunMean : 31.7600\n",
      "Episode: 361 Total reward: 32.0 Training loss: 230.8220 Explore P: 0.8230 RunMean : 31.9300\n",
      "Episode: 362 Total reward: 25.0 Training loss: 491.7935 Explore P: 0.8226 RunMean : 31.6500\n",
      "Episode: 363 Total reward: 91.0 Training loss: 156.9548 Explore P: 0.8211 RunMean : 32.3800\n",
      "Episode: 364 Total reward: 28.0 Training loss: 40.3023 Explore P: 0.8206 RunMean : 32.3700\n",
      "Episode: 365 Total reward: 17.0 Training loss: 252.4118 Explore P: 0.8203 RunMean : 32.2600\n",
      "Episode: 366 Total reward: 87.0 Training loss: 880.5630 Explore P: 0.8189 RunMean : 32.9700\n",
      "Episode: 367 Total reward: 19.0 Training loss: 243.2866 Explore P: 0.8186 RunMean : 32.7300\n",
      "Episode: 368 Total reward: 33.0 Training loss: 151.5079 Explore P: 0.8180 RunMean : 32.0800\n",
      "Episode: 369 Total reward: 13.0 Training loss: 204.2729 Explore P: 0.8178 RunMean : 31.9900\n",
      "Episode: 370 Total reward: 22.0 Training loss: 375.9681 Explore P: 0.8175 RunMean : 31.9300\n",
      "Episode: 371 Total reward: 28.0 Training loss: 237.4130 Explore P: 0.8170 RunMean : 31.9600\n",
      "Episode: 372 Total reward: 16.0 Training loss: 80.8085 Explore P: 0.8168 RunMean : 31.8300\n",
      "Episode: 373 Total reward: 94.0 Training loss: 568.3343 Explore P: 0.8152 RunMean : 32.4800\n",
      "Episode: 374 Total reward: 80.0 Training loss: 535.9055 Explore P: 0.8139 RunMean : 32.7500\n",
      "Episode: 375 Total reward: 32.0 Training loss: 40.6086 Explore P: 0.8134 RunMean : 32.6100\n",
      "Episode: 376 Total reward: 48.0 Training loss: 288.8875 Explore P: 0.8126 RunMean : 32.9800\n",
      "Episode: 377 Total reward: 18.0 Training loss: 383.5699 Explore P: 0.8123 RunMean : 32.8200\n",
      "Episode: 378 Total reward: 33.0 Training loss: 265.7330 Explore P: 0.8118 RunMean : 33.0400\n",
      "Episode: 379 Total reward: 40.0 Training loss: 130.1112 Explore P: 0.8111 RunMean : 33.2400\n",
      "Episode: 380 Total reward: 23.0 Training loss: 343.0541 Explore P: 0.8108 RunMean : 32.6900\n",
      "Episode: 381 Total reward: 22.0 Training loss: 275.2760 Explore P: 0.8104 RunMean : 32.6900\n",
      "Episode: 382 Total reward: 23.0 Training loss: 376.0316 Explore P: 0.8100 RunMean : 32.6000\n",
      "Episode: 383 Total reward: 23.0 Training loss: 223.5729 Explore P: 0.8097 RunMean : 32.5500\n",
      "Episode: 384 Total reward: 18.0 Training loss: 491.1066 Explore P: 0.8094 RunMean : 32.5800\n",
      "Episode: 385 Total reward: 19.0 Training loss: 704.7206 Explore P: 0.8091 RunMean : 32.5000\n",
      "Episode: 386 Total reward: 14.0 Training loss: 712.3558 Explore P: 0.8088 RunMean : 31.9000\n",
      "Episode: 387 Total reward: 29.0 Training loss: 188.7359 Explore P: 0.8084 RunMean : 32.0400\n",
      "Episode: 388 Total reward: 55.0 Training loss: 685.8025 Explore P: 0.8075 RunMean : 32.4600\n",
      "Episode: 389 Total reward: 22.0 Training loss: 822.8644 Explore P: 0.8071 RunMean : 32.5700\n",
      "Episode: 390 Total reward: 22.0 Training loss: 778.1589 Explore P: 0.8068 RunMean : 32.2500\n",
      "Episode: 391 Total reward: 21.0 Training loss: 562.5607 Explore P: 0.8064 RunMean : 32.0300\n",
      "Episode: 392 Total reward: 96.0 Training loss: 352.0296 Explore P: 0.8049 RunMean : 32.4000\n",
      "Episode: 393 Total reward: 44.0 Training loss: 470.5098 Explore P: 0.8042 RunMean : 32.3800\n",
      "Episode: 394 Total reward: 30.0 Training loss: 51.4842 Explore P: 0.8037 RunMean : 32.4700\n",
      "Episode: 395 Total reward: 21.0 Training loss: 58.0106 Explore P: 0.8034 RunMean : 32.3100\n",
      "Episode: 396 Total reward: 19.0 Training loss: 359.6736 Explore P: 0.8030 RunMean : 31.9100\n",
      "Episode: 397 Total reward: 14.0 Training loss: 184.1162 Explore P: 0.8028 RunMean : 31.6700\n",
      "Episode: 398 Total reward: 142.0 Training loss: 887.4337 Explore P: 0.8005 RunMean : 32.8600\n",
      "Episode: 399 Total reward: 36.0 Training loss: 638.1575 Explore P: 0.8000 RunMean : 33.0700\n",
      "Episode: 400 Total reward: 14.0 Training loss: 52.4952 Explore P: 0.7997 RunMean : 33.0500\n",
      "Episode: 401 Total reward: 15.0 Training loss: 1083.1620 Explore P: 0.7995 RunMean : 33.0100\n",
      "Episode: 402 Total reward: 36.0 Training loss: 595.2642 Explore P: 0.7989 RunMean : 33.0200\n",
      "Episode: 403 Total reward: 20.0 Training loss: 47.9054 Explore P: 0.7986 RunMean : 32.7500\n",
      "Episode: 404 Total reward: 30.0 Training loss: 407.2055 Explore P: 0.7981 RunMean : 32.7700\n",
      "Episode: 405 Total reward: 24.0 Training loss: 604.3216 Explore P: 0.7978 RunMean : 32.7300\n",
      "Episode: 406 Total reward: 129.0 Training loss: 445.7142 Explore P: 0.7957 RunMean : 33.6500\n",
      "Episode: 407 Total reward: 102.0 Training loss: 637.6218 Explore P: 0.7941 RunMean : 34.4100\n",
      "Episode: 408 Total reward: 38.0 Training loss: 476.3418 Explore P: 0.7935 RunMean : 34.6400\n",
      "Episode: 409 Total reward: 37.0 Training loss: 360.8085 Explore P: 0.7929 RunMean : 34.8700\n",
      "Episode: 410 Total reward: 14.0 Training loss: 232.3315 Explore P: 0.7927 RunMean : 34.7200\n",
      "Episode: 411 Total reward: 38.0 Training loss: 617.6332 Explore P: 0.7921 RunMean : 34.8200\n",
      "Episode: 412 Total reward: 64.0 Training loss: 505.7341 Explore P: 0.7910 RunMean : 34.9200\n",
      "Episode: 413 Total reward: 22.0 Training loss: 604.7310 Explore P: 0.7907 RunMean : 34.4900\n",
      "Episode: 414 Total reward: 44.0 Training loss: 920.5857 Explore P: 0.7900 RunMean : 34.7700\n",
      "Episode: 415 Total reward: 57.0 Training loss: 78.3729 Explore P: 0.7891 RunMean : 35.0900\n",
      "Episode: 416 Total reward: 23.0 Training loss: 629.9489 Explore P: 0.7887 RunMean : 35.1900\n",
      "Episode: 417 Total reward: 30.0 Training loss: 81.9290 Explore P: 0.7883 RunMean : 35.2400\n",
      "Episode: 418 Total reward: 58.0 Training loss: 57.6494 Explore P: 0.7874 RunMean : 35.7100\n",
      "Episode: 419 Total reward: 13.0 Training loss: 462.2305 Explore P: 0.7871 RunMean : 35.6100\n",
      "Episode: 420 Total reward: 79.0 Training loss: 1056.2192 Explore P: 0.7859 RunMean : 36.2200\n",
      "Episode: 421 Total reward: 19.0 Training loss: 336.0733 Explore P: 0.7856 RunMean : 36.2300\n",
      "Episode: 422 Total reward: 17.0 Training loss: 1006.8411 Explore P: 0.7853 RunMean : 36.0700\n",
      "Episode: 423 Total reward: 34.0 Training loss: 72.7678 Explore P: 0.7848 RunMean : 35.7100\n",
      "Episode: 424 Total reward: 23.0 Training loss: 566.1194 Explore P: 0.7844 RunMean : 35.1600\n",
      "Episode: 425 Total reward: 58.0 Training loss: 1397.9774 Explore P: 0.7835 RunMean : 35.4100\n",
      "Episode: 426 Total reward: 68.0 Training loss: 230.6816 Explore P: 0.7825 RunMean : 35.9700\n",
      "Episode: 427 Total reward: 16.0 Training loss: 818.6042 Explore P: 0.7822 RunMean : 35.6500\n",
      "Episode: 428 Total reward: 17.0 Training loss: 759.4417 Explore P: 0.7820 RunMean : 35.5500\n",
      "Episode: 429 Total reward: 10.0 Training loss: 1455.4692 Explore P: 0.7818 RunMean : 35.2400\n",
      "Episode: 430 Total reward: 21.0 Training loss: 121.5687 Explore P: 0.7815 RunMean : 35.0900\n",
      "Episode: 431 Total reward: 16.0 Training loss: 1079.3942 Explore P: 0.7812 RunMean : 35.0700\n",
      "Episode: 432 Total reward: 55.0 Training loss: 74.1079 Explore P: 0.7804 RunMean : 35.4200\n",
      "Episode: 433 Total reward: 27.0 Training loss: 64.8056 Explore P: 0.7799 RunMean : 35.5100\n",
      "Episode: 434 Total reward: 29.0 Training loss: 236.8794 Explore P: 0.7795 RunMean : 35.6500\n",
      "Episode: 435 Total reward: 40.0 Training loss: 1461.3198 Explore P: 0.7789 RunMean : 35.8600\n",
      "Episode: 436 Total reward: 16.0 Training loss: 361.7951 Explore P: 0.7786 RunMean : 35.7100\n",
      "Episode: 437 Total reward: 124.0 Training loss: 1116.4294 Explore P: 0.7767 RunMean : 36.5400\n",
      "Episode: 438 Total reward: 20.0 Training loss: 865.9596 Explore P: 0.7764 RunMean : 36.2000\n",
      "Episode: 439 Total reward: 37.0 Training loss: 381.6505 Explore P: 0.7758 RunMean : 36.4300\n",
      "Episode: 440 Total reward: 37.0 Training loss: 980.4623 Explore P: 0.7752 RunMean : 36.6200\n",
      "Episode: 441 Total reward: 169.0 Training loss: 2389.0056 Explore P: 0.7726 RunMean : 38.2000\n",
      "Episode: 442 Total reward: 42.0 Training loss: 1036.4098 Explore P: 0.7720 RunMean : 38.3500\n",
      "Episode: 443 Total reward: 85.0 Training loss: 206.8243 Explore P: 0.7707 RunMean : 39.0700\n",
      "Episode: 444 Total reward: 30.0 Training loss: 1191.7885 Explore P: 0.7702 RunMean : 39.1000\n",
      "Episode: 445 Total reward: 24.0 Training loss: 854.3271 Explore P: 0.7698 RunMean : 39.1400\n",
      "Episode: 446 Total reward: 50.0 Training loss: 2083.4050 Explore P: 0.7690 RunMean : 39.4300\n",
      "Episode: 447 Total reward: 26.0 Training loss: 1235.7723 Explore P: 0.7686 RunMean : 39.3900\n",
      "Episode: 448 Total reward: 39.0 Training loss: 1859.4999 Explore P: 0.7681 RunMean : 39.4300\n",
      "Episode: 449 Total reward: 104.0 Training loss: 334.6611 Explore P: 0.7665 RunMean : 40.2000\n",
      "Episode: 450 Total reward: 16.0 Training loss: 169.3765 Explore P: 0.7662 RunMean : 39.8300\n",
      "Episode: 451 Total reward: 15.0 Training loss: 656.3914 Explore P: 0.7660 RunMean : 39.7600\n",
      "Episode: 452 Total reward: 35.0 Training loss: 475.5118 Explore P: 0.7654 RunMean : 39.0100\n",
      "Episode: 453 Total reward: 19.0 Training loss: 604.9578 Explore P: 0.7652 RunMean : 38.9200\n",
      "Episode: 454 Total reward: 22.0 Training loss: 796.6943 Explore P: 0.7648 RunMean : 38.9200\n",
      "Episode: 455 Total reward: 20.0 Training loss: 421.7720 Explore P: 0.7645 RunMean : 38.7800\n",
      "Episode: 456 Total reward: 25.0 Training loss: 879.0942 Explore P: 0.7641 RunMean : 38.7800\n",
      "Episode: 457 Total reward: 42.0 Training loss: 2052.2856 Explore P: 0.7635 RunMean : 38.9400\n",
      "Episode: 458 Total reward: 13.0 Training loss: 653.8631 Explore P: 0.7633 RunMean : 38.8500\n",
      "Episode: 459 Total reward: 103.0 Training loss: 1119.8168 Explore P: 0.7617 RunMean : 39.4200\n",
      "Episode: 460 Total reward: 61.0 Training loss: 390.0334 Explore P: 0.7608 RunMean : 39.6000\n",
      "Episode: 461 Total reward: 21.0 Training loss: 720.6793 Explore P: 0.7605 RunMean : 39.4900\n",
      "Episode: 462 Total reward: 26.0 Training loss: 356.0959 Explore P: 0.7601 RunMean : 39.5000\n",
      "Episode: 463 Total reward: 15.0 Training loss: 662.4566 Explore P: 0.7598 RunMean : 38.7400\n",
      "Episode: 464 Total reward: 36.0 Training loss: 1095.5358 Explore P: 0.7593 RunMean : 38.8200\n",
      "Episode: 465 Total reward: 61.0 Training loss: 2429.9998 Explore P: 0.7584 RunMean : 39.2600\n",
      "Episode: 466 Total reward: 64.0 Training loss: 1834.3408 Explore P: 0.7574 RunMean : 39.0300\n",
      "Episode: 467 Total reward: 26.0 Training loss: 813.4962 Explore P: 0.7570 RunMean : 39.1000\n",
      "Episode: 468 Total reward: 11.0 Training loss: 832.5422 Explore P: 0.7568 RunMean : 38.8800\n",
      "Episode: 469 Total reward: 51.0 Training loss: 221.1366 Explore P: 0.7561 RunMean : 39.2600\n",
      "Episode: 470 Total reward: 50.0 Training loss: 602.5627 Explore P: 0.7553 RunMean : 39.5400\n",
      "Episode: 471 Total reward: 41.0 Training loss: 414.2193 Explore P: 0.7547 RunMean : 39.6700\n",
      "Episode: 472 Total reward: 14.0 Training loss: 1151.0052 Explore P: 0.7545 RunMean : 39.6500\n",
      "Episode: 473 Total reward: 62.0 Training loss: 1282.7114 Explore P: 0.7535 RunMean : 39.3300\n",
      "Episode: 474 Total reward: 14.0 Training loss: 1372.0818 Explore P: 0.7533 RunMean : 38.6700\n",
      "Episode: 475 Total reward: 15.0 Training loss: 101.7886 Explore P: 0.7531 RunMean : 38.5000\n",
      "Episode: 476 Total reward: 31.0 Training loss: 1852.4604 Explore P: 0.7526 RunMean : 38.3300\n",
      "Episode: 477 Total reward: 34.0 Training loss: 1790.6522 Explore P: 0.7521 RunMean : 38.4900\n",
      "Episode: 478 Total reward: 49.0 Training loss: 1017.8834 Explore P: 0.7514 RunMean : 38.6500\n",
      "Episode: 479 Total reward: 66.0 Training loss: 1580.6672 Explore P: 0.7504 RunMean : 38.9100\n",
      "Episode: 480 Total reward: 78.0 Training loss: 2560.1414 Explore P: 0.7492 RunMean : 39.4600\n",
      "Episode: 481 Total reward: 28.0 Training loss: 1790.2913 Explore P: 0.7488 RunMean : 39.5200\n",
      "Episode: 482 Total reward: 16.0 Training loss: 2177.9058 Explore P: 0.7486 RunMean : 39.4500\n",
      "Episode: 483 Total reward: 46.0 Training loss: 902.7173 Explore P: 0.7479 RunMean : 39.6800\n",
      "Episode: 484 Total reward: 22.0 Training loss: 336.2140 Explore P: 0.7476 RunMean : 39.7200\n",
      "Episode: 485 Total reward: 56.0 Training loss: 952.0493 Explore P: 0.7467 RunMean : 40.0900\n",
      "Episode: 486 Total reward: 28.0 Training loss: 350.3792 Explore P: 0.7463 RunMean : 40.2300\n",
      "Episode: 487 Total reward: 27.0 Training loss: 1114.1998 Explore P: 0.7459 RunMean : 40.2100\n",
      "Episode: 488 Total reward: 105.0 Training loss: 425.5065 Explore P: 0.7443 RunMean : 40.7100\n",
      "Episode: 489 Total reward: 14.0 Training loss: 427.6640 Explore P: 0.7441 RunMean : 40.6300\n",
      "Episode: 490 Total reward: 15.0 Training loss: 1231.0042 Explore P: 0.7439 RunMean : 40.5600\n",
      "Episode: 491 Total reward: 22.0 Training loss: 2756.2109 Explore P: 0.7436 RunMean : 40.5700\n",
      "Episode: 492 Total reward: 35.0 Training loss: 1187.8322 Explore P: 0.7431 RunMean : 39.9600\n",
      "Episode: 493 Total reward: 46.0 Training loss: 2685.7739 Explore P: 0.7424 RunMean : 39.9800\n",
      "Episode: 494 Total reward: 32.0 Training loss: 852.9197 Explore P: 0.7419 RunMean : 40.0000\n",
      "Episode: 495 Total reward: 110.0 Training loss: 546.1600 Explore P: 0.7403 RunMean : 40.8900\n",
      "Episode: 496 Total reward: 16.0 Training loss: 1167.2587 Explore P: 0.7400 RunMean : 40.8600\n",
      "Episode: 497 Total reward: 50.0 Training loss: 1761.6180 Explore P: 0.7393 RunMean : 41.2200\n",
      "Episode: 498 Total reward: 54.0 Training loss: 2119.4307 Explore P: 0.7385 RunMean : 40.3400\n",
      "Episode: 499 Total reward: 56.0 Training loss: 192.4792 Explore P: 0.7377 RunMean : 40.5400\n",
      "Episode: 500 Total reward: 112.0 Training loss: 980.5767 Explore P: 0.7360 RunMean : 41.5200\n",
      "Episode: 501 Total reward: 44.0 Training loss: 2020.2649 Explore P: 0.7354 RunMean : 41.8100\n",
      "Episode: 502 Total reward: 150.0 Training loss: 139.3766 Explore P: 0.7332 RunMean : 42.9500\n",
      "Episode: 503 Total reward: 28.0 Training loss: 2082.0781 Explore P: 0.7328 RunMean : 43.0300\n",
      "Episode: 504 Total reward: 77.0 Training loss: 4342.1172 Explore P: 0.7316 RunMean : 43.5000\n",
      "Episode: 505 Total reward: 25.0 Training loss: 461.1412 Explore P: 0.7313 RunMean : 43.5100\n",
      "Episode: 506 Total reward: 63.0 Training loss: 172.2436 Explore P: 0.7303 RunMean : 42.8500\n",
      "Episode: 507 Total reward: 27.0 Training loss: 676.3478 Explore P: 0.7299 RunMean : 42.1000\n",
      "Episode: 508 Total reward: 47.0 Training loss: 2906.2041 Explore P: 0.7293 RunMean : 42.1900\n",
      "Episode: 509 Total reward: 68.0 Training loss: 2090.3875 Explore P: 0.7283 RunMean : 42.5000\n",
      "Episode: 510 Total reward: 75.0 Training loss: 355.5062 Explore P: 0.7272 RunMean : 43.1100\n",
      "Episode: 511 Total reward: 19.0 Training loss: 1275.4147 Explore P: 0.7269 RunMean : 42.9200\n",
      "Episode: 512 Total reward: 32.0 Training loss: 105.4588 Explore P: 0.7264 RunMean : 42.6000\n",
      "Episode: 513 Total reward: 14.0 Training loss: 3099.3440 Explore P: 0.7262 RunMean : 42.5200\n",
      "Episode: 514 Total reward: 12.0 Training loss: 2688.1704 Explore P: 0.7261 RunMean : 42.2000\n",
      "Episode: 515 Total reward: 16.0 Training loss: 2356.5010 Explore P: 0.7258 RunMean : 41.7900\n",
      "Episode: 516 Total reward: 27.0 Training loss: 4334.1265 Explore P: 0.7254 RunMean : 41.8300\n",
      "Episode: 517 Total reward: 43.0 Training loss: 495.0286 Explore P: 0.7248 RunMean : 41.9600\n",
      "Episode: 518 Total reward: 27.0 Training loss: 1693.3752 Explore P: 0.7244 RunMean : 41.6500\n",
      "Episode: 519 Total reward: 72.0 Training loss: 132.4622 Explore P: 0.7234 RunMean : 42.2400\n",
      "Episode: 520 Total reward: 39.0 Training loss: 629.8784 Explore P: 0.7228 RunMean : 41.8400\n",
      "Episode: 521 Total reward: 80.0 Training loss: 1568.8618 Explore P: 0.7217 RunMean : 42.4500\n",
      "Episode: 522 Total reward: 84.0 Training loss: 769.3390 Explore P: 0.7204 RunMean : 43.1200\n",
      "Episode: 523 Total reward: 62.0 Training loss: 199.1646 Explore P: 0.7196 RunMean : 43.4000\n",
      "Episode: 524 Total reward: 32.0 Training loss: 2302.9016 Explore P: 0.7191 RunMean : 43.4900\n",
      "Episode: 525 Total reward: 103.0 Training loss: 2648.1526 Explore P: 0.7176 RunMean : 43.9400\n",
      "Episode: 526 Total reward: 13.0 Training loss: 1032.2245 Explore P: 0.7174 RunMean : 43.3900\n",
      "Episode: 527 Total reward: 16.0 Training loss: 2850.7068 Explore P: 0.7172 RunMean : 43.3900\n",
      "Episode: 528 Total reward: 96.0 Training loss: 1259.5620 Explore P: 0.7158 RunMean : 44.1800\n",
      "Episode: 529 Total reward: 13.0 Training loss: 3521.3560 Explore P: 0.7156 RunMean : 44.2100\n",
      "Episode: 530 Total reward: 105.0 Training loss: 1998.7059 Explore P: 0.7141 RunMean : 45.0500\n",
      "Episode: 531 Total reward: 22.0 Training loss: 3496.3303 Explore P: 0.7138 RunMean : 45.1100\n",
      "Episode: 532 Total reward: 34.0 Training loss: 1707.0680 Explore P: 0.7133 RunMean : 44.9000\n",
      "Episode: 533 Total reward: 58.0 Training loss: 161.4082 Explore P: 0.7125 RunMean : 45.2100\n",
      "Episode: 534 Total reward: 27.0 Training loss: 1636.6342 Explore P: 0.7121 RunMean : 45.1900\n",
      "Episode: 535 Total reward: 99.0 Training loss: 192.1257 Explore P: 0.7107 RunMean : 45.7800\n",
      "Episode: 536 Total reward: 41.0 Training loss: 1712.9246 Explore P: 0.7101 RunMean : 46.0300\n",
      "Episode: 537 Total reward: 36.0 Training loss: 189.4227 Explore P: 0.7096 RunMean : 45.1500\n",
      "Episode: 538 Total reward: 59.0 Training loss: 4644.3447 Explore P: 0.7088 RunMean : 45.5400\n",
      "Episode: 539 Total reward: 77.0 Training loss: 5094.9497 Explore P: 0.7077 RunMean : 45.9400\n",
      "Episode: 540 Total reward: 122.0 Training loss: 3987.5979 Explore P: 0.7060 RunMean : 46.7900\n",
      "Episode: 541 Total reward: 143.0 Training loss: 4278.8926 Explore P: 0.7040 RunMean : 46.5300\n",
      "Episode: 542 Total reward: 167.0 Training loss: 1894.3535 Explore P: 0.7016 RunMean : 47.7800\n",
      "Episode: 543 Total reward: 83.0 Training loss: 1071.6835 Explore P: 0.7004 RunMean : 47.7600\n",
      "Episode: 544 Total reward: 33.0 Training loss: 293.0034 Explore P: 0.7000 RunMean : 47.7900\n",
      "Episode: 545 Total reward: 21.0 Training loss: 131.1011 Explore P: 0.6997 RunMean : 47.7600\n",
      "Episode: 546 Total reward: 14.0 Training loss: 1622.7263 Explore P: 0.6995 RunMean : 47.4000\n",
      "Episode: 547 Total reward: 9.0 Training loss: 4502.2769 Explore P: 0.6994 RunMean : 47.2300\n",
      "Episode: 548 Total reward: 31.0 Training loss: 2987.0752 Explore P: 0.6989 RunMean : 47.1500\n",
      "Episode: 549 Total reward: 12.0 Training loss: 1645.1372 Explore P: 0.6988 RunMean : 46.2300\n",
      "Episode: 550 Total reward: 32.0 Training loss: 3292.3940 Explore P: 0.6983 RunMean : 46.3900\n",
      "Episode: 551 Total reward: 30.0 Training loss: 164.4582 Explore P: 0.6979 RunMean : 46.5400\n",
      "Episode: 552 Total reward: 20.0 Training loss: 3734.3838 Explore P: 0.6976 RunMean : 46.3900\n",
      "Episode: 553 Total reward: 20.0 Training loss: 4352.7554 Explore P: 0.6973 RunMean : 46.4000\n",
      "Episode: 554 Total reward: 59.0 Training loss: 1950.6156 Explore P: 0.6965 RunMean : 46.7700\n",
      "Episode: 555 Total reward: 137.0 Training loss: 3505.7671 Explore P: 0.6946 RunMean : 47.9400\n",
      "Episode: 556 Total reward: 112.0 Training loss: 171.4818 Explore P: 0.6931 RunMean : 48.8100\n",
      "Episode: 557 Total reward: 136.0 Training loss: 489.3474 Explore P: 0.6912 RunMean : 49.7500\n",
      "Episode: 558 Total reward: 9.0 Training loss: 197.7561 Explore P: 0.6911 RunMean : 49.7100\n",
      "Episode: 559 Total reward: 73.0 Training loss: 1033.3064 Explore P: 0.6900 RunMean : 49.4100\n",
      "Episode: 560 Total reward: 34.0 Training loss: 1327.1390 Explore P: 0.6896 RunMean : 49.1400\n",
      "Episode: 561 Total reward: 37.0 Training loss: 2710.3010 Explore P: 0.6891 RunMean : 49.3000\n",
      "Episode: 562 Total reward: 18.0 Training loss: 5653.4023 Explore P: 0.6888 RunMean : 49.2200\n",
      "Episode: 563 Total reward: 22.0 Training loss: 213.4427 Explore P: 0.6885 RunMean : 49.2900\n",
      "Episode: 564 Total reward: 16.0 Training loss: 2942.8618 Explore P: 0.6883 RunMean : 49.0900\n",
      "Episode: 565 Total reward: 27.0 Training loss: 3567.7720 Explore P: 0.6879 RunMean : 48.7500\n",
      "Episode: 566 Total reward: 26.0 Training loss: 2288.3728 Explore P: 0.6876 RunMean : 48.3700\n",
      "Episode: 567 Total reward: 68.0 Training loss: 1330.5282 Explore P: 0.6866 RunMean : 48.7900\n",
      "Episode: 568 Total reward: 64.0 Training loss: 6696.3418 Explore P: 0.6858 RunMean : 49.3200\n",
      "Episode: 569 Total reward: 52.0 Training loss: 180.9552 Explore P: 0.6850 RunMean : 49.3300\n",
      "Episode: 570 Total reward: 40.0 Training loss: 199.2569 Explore P: 0.6845 RunMean : 49.2300\n",
      "Episode: 571 Total reward: 47.0 Training loss: 2642.7642 Explore P: 0.6838 RunMean : 49.2900\n",
      "Episode: 572 Total reward: 85.0 Training loss: 3515.5647 Explore P: 0.6827 RunMean : 50.0000\n",
      "Episode: 573 Total reward: 115.0 Training loss: 5322.6035 Explore P: 0.6811 RunMean : 50.5300\n",
      "Episode: 574 Total reward: 130.0 Training loss: 311.0465 Explore P: 0.6793 RunMean : 51.6900\n",
      "Episode: 575 Total reward: 44.0 Training loss: 2315.6382 Explore P: 0.6788 RunMean : 51.9800\n",
      "Episode: 576 Total reward: 68.0 Training loss: 2970.1060 Explore P: 0.6778 RunMean : 52.3500\n",
      "Episode: 577 Total reward: 18.0 Training loss: 257.3268 Explore P: 0.6776 RunMean : 52.1900\n",
      "Episode: 578 Total reward: 188.0 Training loss: 161.9194 Explore P: 0.6750 RunMean : 53.5800\n",
      "Episode: 579 Total reward: 15.0 Training loss: 3235.6348 Explore P: 0.6748 RunMean : 53.0700\n",
      "Episode: 580 Total reward: 126.0 Training loss: 295.3263 Explore P: 0.6731 RunMean : 53.5500\n",
      "Episode: 581 Total reward: 149.0 Training loss: 191.2287 Explore P: 0.6711 RunMean : 54.7600\n",
      "Episode: 582 Total reward: 24.0 Training loss: 704.2246 Explore P: 0.6708 RunMean : 54.8400\n",
      "Episode: 583 Total reward: 151.0 Training loss: 5580.7383 Explore P: 0.6688 RunMean : 55.8900\n",
      "Episode: 584 Total reward: 66.0 Training loss: 2200.6167 Explore P: 0.6679 RunMean : 56.3300\n",
      "Episode: 585 Total reward: 79.0 Training loss: 223.9169 Explore P: 0.6669 RunMean : 56.5600\n",
      "Episode: 586 Total reward: 69.0 Training loss: 3322.2166 Explore P: 0.6659 RunMean : 56.9700\n",
      "Episode: 587 Total reward: 56.0 Training loss: 6916.6689 Explore P: 0.6652 RunMean : 57.2600\n",
      "Episode: 588 Total reward: 61.0 Training loss: 2904.4583 Explore P: 0.6644 RunMean : 56.8200\n",
      "Episode: 589 Total reward: 34.0 Training loss: 10393.0059 Explore P: 0.6639 RunMean : 57.0200\n",
      "Episode: 590 Total reward: 57.0 Training loss: 3379.5972 Explore P: 0.6632 RunMean : 57.4400\n",
      "Episode: 591 Total reward: 142.0 Training loss: 1377.0107 Explore P: 0.6613 RunMean : 58.6400\n",
      "Episode: 592 Total reward: 47.0 Training loss: 1564.4634 Explore P: 0.6607 RunMean : 58.7600\n",
      "Episode: 593 Total reward: 187.0 Training loss: 2997.6233 Explore P: 0.6582 RunMean : 60.1700\n",
      "Episode: 594 Total reward: 88.0 Training loss: 211.0029 Explore P: 0.6570 RunMean : 60.7300\n",
      "Episode: 595 Total reward: 21.0 Training loss: 9681.0156 Explore P: 0.6568 RunMean : 59.8400\n",
      "Episode: 596 Total reward: 35.0 Training loss: 1994.2097 Explore P: 0.6563 RunMean : 60.0300\n",
      "Episode: 597 Total reward: 134.0 Training loss: 2879.6768 Explore P: 0.6546 RunMean : 60.8700\n",
      "Episode: 598 Total reward: 134.0 Training loss: 6324.5815 Explore P: 0.6528 RunMean : 61.6700\n",
      "Episode: 599 Total reward: 55.0 Training loss: 4518.9883 Explore P: 0.6521 RunMean : 61.6600\n",
      "Episode: 600 Total reward: 198.0 Training loss: 276.4431 Explore P: 0.6495 RunMean : 62.5200\n",
      "Episode: 601 Total reward: 63.0 Training loss: 7826.9272 Explore P: 0.6487 RunMean : 62.7100\n",
      "Episode: 602 Total reward: 88.0 Training loss: 3088.8694 Explore P: 0.6475 RunMean : 62.0900\n",
      "Episode: 603 Total reward: 88.0 Training loss: 9319.0215 Explore P: 0.6464 RunMean : 62.6900\n",
      "Episode: 604 Total reward: 10.0 Training loss: 2390.7590 Explore P: 0.6463 RunMean : 62.0200\n",
      "Episode: 605 Total reward: 18.0 Training loss: 7032.6392 Explore P: 0.6460 RunMean : 61.9500\n",
      "Episode: 606 Total reward: 14.0 Training loss: 1334.6741 Explore P: 0.6459 RunMean : 61.4600\n",
      "Episode: 607 Total reward: 53.0 Training loss: 286.6241 Explore P: 0.6452 RunMean : 61.7200\n",
      "Episode: 608 Total reward: 54.0 Training loss: 7103.9248 Explore P: 0.6445 RunMean : 61.7900\n",
      "Episode: 609 Total reward: 157.0 Training loss: 7515.8984 Explore P: 0.6425 RunMean : 62.6800\n",
      "Episode: 610 Total reward: 112.0 Training loss: 4748.1265 Explore P: 0.6410 RunMean : 63.0500\n",
      "Episode: 611 Total reward: 96.0 Training loss: 4929.0410 Explore P: 0.6398 RunMean : 63.8200\n",
      "Episode: 612 Total reward: 114.0 Training loss: 18924.1777 Explore P: 0.6383 RunMean : 64.6400\n",
      "Episode: 613 Total reward: 12.0 Training loss: 231.4443 Explore P: 0.6382 RunMean : 64.6200\n",
      "Episode: 614 Total reward: 75.0 Training loss: 999.6309 Explore P: 0.6372 RunMean : 65.2500\n",
      "Episode: 615 Total reward: 44.0 Training loss: 267.7329 Explore P: 0.6367 RunMean : 65.5300\n",
      "Episode: 616 Total reward: 157.0 Training loss: 5504.2900 Explore P: 0.6347 RunMean : 66.8300\n",
      "Episode: 617 Total reward: 56.0 Training loss: 1954.7598 Explore P: 0.6340 RunMean : 66.9600\n",
      "Episode: 618 Total reward: 102.0 Training loss: 5029.7979 Explore P: 0.6327 RunMean : 67.7100\n",
      "Episode: 619 Total reward: 13.0 Training loss: 1163.3685 Explore P: 0.6325 RunMean : 67.1200\n",
      "Episode: 620 Total reward: 43.0 Training loss: 4343.1753 Explore P: 0.6320 RunMean : 67.1600\n",
      "Episode: 621 Total reward: 48.0 Training loss: 3574.3828 Explore P: 0.6314 RunMean : 66.8400\n",
      "Episode: 622 Total reward: 200.0 Training loss: 2939.7031 Explore P: 0.6288 RunMean : 68.0000\n",
      "Episode: 623 Total reward: 111.0 Training loss: 363.7228 Explore P: 0.6274 RunMean : 68.4900\n",
      "Episode: 624 Total reward: 137.0 Training loss: 255.1120 Explore P: 0.6257 RunMean : 69.5400\n",
      "Episode: 625 Total reward: 62.0 Training loss: 8590.6865 Explore P: 0.6250 RunMean : 69.1300\n",
      "Episode: 626 Total reward: 71.0 Training loss: 3509.3965 Explore P: 0.6241 RunMean : 69.7100\n",
      "Episode: 627 Total reward: 51.0 Training loss: 3436.1067 Explore P: 0.6234 RunMean : 70.0600\n",
      "Episode: 628 Total reward: 31.0 Training loss: 225.8002 Explore P: 0.6230 RunMean : 69.4100\n",
      "Episode: 629 Total reward: 15.0 Training loss: 312.5990 Explore P: 0.6229 RunMean : 69.4300\n",
      "Episode: 630 Total reward: 21.0 Training loss: 6039.8096 Explore P: 0.6226 RunMean : 68.5900\n",
      "Episode: 631 Total reward: 76.0 Training loss: 3957.3679 Explore P: 0.6216 RunMean : 69.1300\n",
      "Episode: 632 Total reward: 146.0 Training loss: 6230.6099 Explore P: 0.6198 RunMean : 70.2500\n",
      "Episode: 633 Total reward: 66.0 Training loss: 422.7186 Explore P: 0.6190 RunMean : 70.3300\n",
      "Episode: 634 Total reward: 25.0 Training loss: 3172.5801 Explore P: 0.6187 RunMean : 70.3100\n",
      "Episode: 635 Total reward: 205.0 Training loss: 6047.5952 Explore P: 0.6162 RunMean : 71.3700\n",
      "Episode: 636 Total reward: 146.0 Training loss: 455.4297 Explore P: 0.6144 RunMean : 72.4200\n",
      "Episode: 637 Total reward: 165.0 Training loss: 9492.3809 Explore P: 0.6124 RunMean : 73.7100\n",
      "Episode: 638 Total reward: 70.0 Training loss: 12714.0381 Explore P: 0.6115 RunMean : 73.8200\n",
      "Episode: 639 Total reward: 85.0 Training loss: 8118.5054 Explore P: 0.6105 RunMean : 73.9000\n",
      "Episode: 640 Total reward: 17.0 Training loss: 18551.5547 Explore P: 0.6103 RunMean : 72.8500\n",
      "Episode: 641 Total reward: 73.0 Training loss: 3590.3125 Explore P: 0.6094 RunMean : 72.1500\n",
      "Episode: 642 Total reward: 29.0 Training loss: 6569.5332 Explore P: 0.6090 RunMean : 70.7700\n",
      "Episode: 643 Total reward: 13.0 Training loss: 10690.5225 Explore P: 0.6089 RunMean : 70.0700\n",
      "Episode: 644 Total reward: 63.0 Training loss: 392.6444 Explore P: 0.6081 RunMean : 70.3700\n",
      "Episode: 645 Total reward: 125.0 Training loss: 273.4455 Explore P: 0.6066 RunMean : 71.4100\n",
      "Episode: 646 Total reward: 175.0 Training loss: 493.5878 Explore P: 0.6044 RunMean : 73.0200\n",
      "Episode: 647 Total reward: 45.0 Training loss: 5128.2900 Explore P: 0.6039 RunMean : 73.3800\n",
      "Episode: 648 Total reward: 32.0 Training loss: 17026.6094 Explore P: 0.6035 RunMean : 73.3900\n",
      "Episode: 649 Total reward: 86.0 Training loss: 4860.6582 Explore P: 0.6025 RunMean : 74.1300\n",
      "Episode: 650 Total reward: 150.0 Training loss: 392.4688 Explore P: 0.6007 RunMean : 75.3100\n",
      "Episode: 651 Total reward: 48.0 Training loss: 343.0405 Explore P: 0.6001 RunMean : 75.4900\n",
      "Episode: 652 Total reward: 132.0 Training loss: 4694.6885 Explore P: 0.5985 RunMean : 76.6100\n",
      "Episode: 653 Total reward: 176.0 Training loss: 5342.4004 Explore P: 0.5964 RunMean : 78.1700\n",
      "Episode: 654 Total reward: 103.0 Training loss: 427.5483 Explore P: 0.5952 RunMean : 78.6100\n",
      "Episode: 655 Total reward: 129.0 Training loss: 8235.5947 Explore P: 0.5937 RunMean : 78.5300\n",
      "Episode: 656 Total reward: 149.0 Training loss: 22168.9883 Explore P: 0.5919 RunMean : 78.9000\n",
      "Episode: 657 Total reward: 66.0 Training loss: 3704.5366 Explore P: 0.5911 RunMean : 78.2000\n",
      "Episode: 658 Total reward: 48.0 Training loss: 435.9729 Explore P: 0.5905 RunMean : 78.5900\n",
      "Episode: 659 Total reward: 38.0 Training loss: 226.8962 Explore P: 0.5901 RunMean : 78.2400\n",
      "Episode: 660 Total reward: 101.0 Training loss: 6534.3530 Explore P: 0.5889 RunMean : 78.9100\n",
      "Episode: 661 Total reward: 192.0 Training loss: 11988.5205 Explore P: 0.5866 RunMean : 80.4600\n",
      "Episode: 662 Total reward: 181.0 Training loss: 3954.3467 Explore P: 0.5845 RunMean : 82.0900\n",
      "Episode: 663 Total reward: 153.0 Training loss: 5552.7051 Explore P: 0.5827 RunMean : 83.4000\n",
      "Episode: 664 Total reward: 23.0 Training loss: 5268.7744 Explore P: 0.5825 RunMean : 83.4700\n",
      "Episode: 665 Total reward: 84.0 Training loss: 516.1276 Explore P: 0.5815 RunMean : 84.0400\n",
      "Episode: 666 Total reward: 122.0 Training loss: 4784.7695 Explore P: 0.5801 RunMean : 85.0000\n",
      "Episode: 667 Total reward: 78.0 Training loss: 253.2376 Explore P: 0.5792 RunMean : 85.1000\n",
      "Episode: 668 Total reward: 45.0 Training loss: 6977.7261 Explore P: 0.5786 RunMean : 84.9100\n",
      "Episode: 669 Total reward: 74.0 Training loss: 575.0853 Explore P: 0.5778 RunMean : 85.1300\n",
      "Episode: 670 Total reward: 19.0 Training loss: 311.6778 Explore P: 0.5776 RunMean : 84.9200\n",
      "Episode: 671 Total reward: 89.0 Training loss: 5120.6235 Explore P: 0.5765 RunMean : 85.3400\n",
      "Episode: 672 Total reward: 143.0 Training loss: 380.8262 Explore P: 0.5749 RunMean : 85.9200\n",
      "Episode: 673 Total reward: 158.0 Training loss: 453.2401 Explore P: 0.5731 RunMean : 86.3500\n",
      "Episode: 674 Total reward: 123.0 Training loss: 423.4803 Explore P: 0.5717 RunMean : 86.2800\n",
      "Episode: 675 Total reward: 81.0 Training loss: 10576.1045 Explore P: 0.5708 RunMean : 86.6500\n",
      "Episode: 676 Total reward: 14.0 Training loss: 488.3044 Explore P: 0.5706 RunMean : 86.1100\n",
      "Episode: 677 Total reward: 175.0 Training loss: 9686.1357 Explore P: 0.5686 RunMean : 87.6800\n",
      "Episode: 678 Total reward: 164.0 Training loss: 643.9609 Explore P: 0.5667 RunMean : 87.4400\n",
      "Episode: 679 Total reward: 116.0 Training loss: 517.4737 Explore P: 0.5654 RunMean : 88.4500\n",
      "Episode: 680 Total reward: 65.0 Training loss: 351.8174 Explore P: 0.5647 RunMean : 87.8400\n",
      "Episode: 681 Total reward: 56.0 Training loss: 317.3273 Explore P: 0.5641 RunMean : 86.9100\n",
      "Episode: 682 Total reward: 160.0 Training loss: 350.7668 Explore P: 0.5623 RunMean : 88.2700\n",
      "Episode: 683 Total reward: 255.0 Training loss: 341.4752 Explore P: 0.5594 RunMean : 89.3100\n",
      "Episode: 684 Total reward: 221.0 Training loss: 2803.3174 Explore P: 0.5569 RunMean : 90.8600\n",
      "Episode: 685 Total reward: 70.0 Training loss: 411.9817 Explore P: 0.5561 RunMean : 90.7700\n",
      "Episode: 686 Total reward: 141.0 Training loss: 7118.4478 Explore P: 0.5546 RunMean : 91.4900\n",
      "Episode: 687 Total reward: 46.0 Training loss: 495.0687 Explore P: 0.5541 RunMean : 91.3900\n",
      "Episode: 688 Total reward: 131.0 Training loss: 546.6940 Explore P: 0.5526 RunMean : 92.0900\n",
      "Episode: 689 Total reward: 80.0 Training loss: 409.7448 Explore P: 0.5517 RunMean : 92.5500\n",
      "Episode: 690 Total reward: 258.0 Training loss: 14916.9756 Explore P: 0.5489 RunMean : 94.5600\n",
      "Episode: 691 Total reward: 54.0 Training loss: 6903.7783 Explore P: 0.5483 RunMean : 93.6800\n",
      "Episode: 692 Total reward: 43.0 Training loss: 21660.1250 Explore P: 0.5478 RunMean : 93.6400\n",
      "Episode: 693 Total reward: 29.0 Training loss: 486.9900 Explore P: 0.5475 RunMean : 92.0600\n",
      "Episode: 694 Total reward: 157.0 Training loss: 41089.4688 Explore P: 0.5458 RunMean : 92.7500\n",
      "Episode: 695 Total reward: 72.0 Training loss: 6286.0439 Explore P: 0.5450 RunMean : 93.2600\n",
      "Episode: 696 Total reward: 186.0 Training loss: 652.5293 Explore P: 0.5430 RunMean : 94.7700\n",
      "Episode: 697 Total reward: 216.0 Training loss: 3987.9097 Explore P: 0.5407 RunMean : 95.5900\n",
      "Episode: 698 Total reward: 21.0 Training loss: 402.2307 Explore P: 0.5404 RunMean : 94.4600\n",
      "Episode: 699 Total reward: 157.0 Training loss: 7746.7163 Explore P: 0.5387 RunMean : 95.4800\n",
      "Episode: 700 Total reward: 25.0 Training loss: 17874.8477 Explore P: 0.5385 RunMean : 93.7500\n",
      "Episode: 701 Total reward: 197.0 Training loss: 31395.1250 Explore P: 0.5363 RunMean : 95.0900\n",
      "Episode: 702 Total reward: 160.0 Training loss: 14566.1289 Explore P: 0.5346 RunMean : 95.8100\n",
      "Episode: 703 Total reward: 187.0 Training loss: 20584.0117 Explore P: 0.5326 RunMean : 96.8000\n",
      "Episode: 704 Total reward: 101.0 Training loss: 503.0134 Explore P: 0.5316 RunMean : 97.7100\n",
      "Episode: 705 Total reward: 500.0 Training loss: 15123.4287 Explore P: 0.5263 RunMean : 102.5300\n",
      "Episode: 706 Total reward: 48.0 Training loss: 12344.1025 Explore P: 0.5258 RunMean : 102.8700\n",
      "Episode: 707 Total reward: 265.0 Training loss: 10758.5371 Explore P: 0.5230 RunMean : 104.9900\n",
      "Episode: 708 Total reward: 121.0 Training loss: 16370.4492 Explore P: 0.5217 RunMean : 105.6600\n",
      "Episode: 709 Total reward: 172.0 Training loss: 430.7067 Explore P: 0.5199 RunMean : 105.8100\n",
      "Episode: 710 Total reward: 24.0 Training loss: 14696.0068 Explore P: 0.5197 RunMean : 104.9300\n",
      "Episode: 711 Total reward: 169.0 Training loss: 8575.4824 Explore P: 0.5179 RunMean : 105.6600\n",
      "Episode: 712 Total reward: 301.0 Training loss: 635.0621 Explore P: 0.5148 RunMean : 107.5300\n",
      "Episode: 713 Total reward: 180.0 Training loss: 13336.6621 Explore P: 0.5130 RunMean : 109.2100\n",
      "Episode: 714 Total reward: 122.0 Training loss: 480.6241 Explore P: 0.5117 RunMean : 109.6800\n",
      "Episode: 715 Total reward: 103.0 Training loss: 46982.4453 Explore P: 0.5107 RunMean : 110.2700\n",
      "Episode: 716 Total reward: 63.0 Training loss: 371.5463 Explore P: 0.5100 RunMean : 109.3300\n",
      "Episode: 717 Total reward: 169.0 Training loss: 472.9754 Explore P: 0.5083 RunMean : 110.4600\n",
      "Episode: 718 Total reward: 124.0 Training loss: 19011.3340 Explore P: 0.5070 RunMean : 110.6800\n",
      "Episode: 719 Total reward: 176.0 Training loss: 18168.1152 Explore P: 0.5053 RunMean : 112.3100\n",
      "Episode: 720 Total reward: 168.0 Training loss: 322.9540 Explore P: 0.5036 RunMean : 113.5600\n",
      "Episode: 721 Total reward: 172.0 Training loss: 8865.5127 Explore P: 0.5018 RunMean : 114.8000\n",
      "Episode: 722 Total reward: 34.0 Training loss: 16547.8770 Explore P: 0.5015 RunMean : 113.1400\n",
      "Episode: 723 Total reward: 485.0 Training loss: 551.1204 Explore P: 0.4967 RunMean : 116.8800\n",
      "Episode: 724 Total reward: 38.0 Training loss: 41804.8672 Explore P: 0.4963 RunMean : 115.8900\n",
      "Episode: 725 Total reward: 154.0 Training loss: 15744.2490 Explore P: 0.4948 RunMean : 116.8100\n",
      "Episode: 726 Total reward: 220.0 Training loss: 312.3685 Explore P: 0.4926 RunMean : 118.3000\n",
      "Episode: 727 Total reward: 192.0 Training loss: 526.1876 Explore P: 0.4907 RunMean : 119.7100\n",
      "Episode: 728 Total reward: 225.0 Training loss: 560.4623 Explore P: 0.4885 RunMean : 121.6500\n",
      "Episode: 729 Total reward: 172.0 Training loss: 491.9014 Explore P: 0.4868 RunMean : 123.2200\n",
      "Episode: 730 Total reward: 38.0 Training loss: 316.8405 Explore P: 0.4864 RunMean : 123.3900\n",
      "Episode: 731 Total reward: 242.0 Training loss: 405.0280 Explore P: 0.4841 RunMean : 125.0500\n",
      "Episode: 732 Total reward: 180.0 Training loss: 331.5982 Explore P: 0.4824 RunMean : 125.3900\n",
      "Episode: 733 Total reward: 40.0 Training loss: 592.7314 Explore P: 0.4820 RunMean : 125.1300\n",
      "Episode: 734 Total reward: 319.0 Training loss: 754.9821 Explore P: 0.4789 RunMean : 128.0700\n",
      "Episode: 735 Total reward: 186.0 Training loss: 27730.0898 Explore P: 0.4771 RunMean : 127.8800\n",
      "Episode: 736 Total reward: 63.0 Training loss: 10363.5479 Explore P: 0.4765 RunMean : 127.0500\n",
      "Episode: 737 Total reward: 243.0 Training loss: 264.9283 Explore P: 0.4742 RunMean : 127.8300\n",
      "Episode: 738 Total reward: 197.0 Training loss: 515.6577 Explore P: 0.4723 RunMean : 129.1000\n",
      "Episode: 739 Total reward: 151.0 Training loss: 70046.6484 Explore P: 0.4709 RunMean : 129.7600\n",
      "Episode: 740 Total reward: 204.0 Training loss: 378.4393 Explore P: 0.4690 RunMean : 131.6300\n",
      "Episode: 741 Total reward: 213.0 Training loss: 71097.2578 Explore P: 0.4670 RunMean : 133.0300\n",
      "Episode: 742 Total reward: 273.0 Training loss: 401.9485 Explore P: 0.4645 RunMean : 135.4700\n",
      "Episode: 743 Total reward: 302.0 Training loss: 421.0185 Explore P: 0.4617 RunMean : 138.3600\n",
      "Episode: 744 Total reward: 191.0 Training loss: 509.6223 Explore P: 0.4599 RunMean : 139.6400\n",
      "Episode: 745 Total reward: 44.0 Training loss: 20907.4707 Explore P: 0.4595 RunMean : 138.8300\n",
      "Episode: 746 Total reward: 185.0 Training loss: 4615.4111 Explore P: 0.4578 RunMean : 138.9300\n",
      "Episode: 747 Total reward: 236.0 Training loss: 121345.1641 Explore P: 0.4557 RunMean : 140.8400\n",
      "Episode: 748 Total reward: 139.0 Training loss: 445.8239 Explore P: 0.4544 RunMean : 141.9100\n",
      "Episode: 749 Total reward: 270.0 Training loss: 446.8178 Explore P: 0.4519 RunMean : 143.7500\n",
      "Episode: 750 Total reward: 376.0 Training loss: 2405.4429 Explore P: 0.4486 RunMean : 146.0100\n",
      "Episode: 751 Total reward: 37.0 Training loss: 667.1532 Explore P: 0.4482 RunMean : 145.9000\n",
      "Episode: 752 Total reward: 318.0 Training loss: 244.3235 Explore P: 0.4454 RunMean : 147.7600\n",
      "Episode: 753 Total reward: 201.0 Training loss: 2879.2263 Explore P: 0.4436 RunMean : 148.0100\n",
      "Episode: 754 Total reward: 100.0 Training loss: 5060.2275 Explore P: 0.4427 RunMean : 147.9800\n",
      "Episode: 755 Total reward: 204.0 Training loss: 7241.8057 Explore P: 0.4409 RunMean : 148.7300\n",
      "Episode: 756 Total reward: 281.0 Training loss: 575.9996 Explore P: 0.4384 RunMean : 150.0500\n",
      "Episode: 757 Total reward: 285.0 Training loss: 338.1815 Explore P: 0.4359 RunMean : 152.2400\n",
      "Episode: 758 Total reward: 300.0 Training loss: 353.7735 Explore P: 0.4333 RunMean : 154.7600\n",
      "Episode: 759 Total reward: 254.0 Training loss: 4152.5283 Explore P: 0.4311 RunMean : 156.9200\n",
      "Episode: 760 Total reward: 169.0 Training loss: 328.0398 Explore P: 0.4297 RunMean : 157.6000\n",
      "Episode: 761 Total reward: 260.0 Training loss: 498.6396 Explore P: 0.4275 RunMean : 158.2800\n",
      "Episode: 762 Total reward: 405.0 Training loss: 281.3975 Explore P: 0.4240 RunMean : 160.5200\n",
      "Episode: 763 Total reward: 294.0 Training loss: 359.9561 Explore P: 0.4215 RunMean : 161.9300\n",
      "Episode: 764 Total reward: 101.0 Training loss: 263.9489 Explore P: 0.4207 RunMean : 162.7100\n",
      "Episode: 765 Total reward: 357.0 Training loss: 380.8476 Explore P: 0.4177 RunMean : 165.4400\n",
      "Episode: 766 Total reward: 215.0 Training loss: 263.0158 Explore P: 0.4159 RunMean : 166.3700\n",
      "Episode: 767 Total reward: 286.0 Training loss: 278.8635 Explore P: 0.4135 RunMean : 168.4500\n",
      "Episode: 768 Total reward: 369.0 Training loss: 359.4016 Explore P: 0.4105 RunMean : 171.6900\n",
      "Episode: 769 Total reward: 500.0 Training loss: 1752.5208 Explore P: 0.4064 RunMean : 175.9500\n",
      "Episode: 770 Total reward: 287.0 Training loss: 387.5225 Explore P: 0.4041 RunMean : 178.6300\n",
      "Episode: 771 Total reward: 340.0 Training loss: 347.2417 Explore P: 0.4013 RunMean : 181.1400\n",
      "Episode: 772 Total reward: 270.0 Training loss: 1628.4996 Explore P: 0.3992 RunMean : 182.4100\n",
      "Episode: 773 Total reward: 75.0 Training loss: 286.1414 Explore P: 0.3986 RunMean : 181.5800\n",
      "Episode: 774 Total reward: 321.0 Training loss: 22303.0879 Explore P: 0.3960 RunMean : 183.5600\n",
      "Episode: 775 Total reward: 20.0 Training loss: 450.4030 Explore P: 0.3959 RunMean : 182.9500\n",
      "Episode: 776 Total reward: 176.0 Training loss: 486.1095 Explore P: 0.3945 RunMean : 184.5700\n",
      "Episode: 777 Total reward: 26.0 Training loss: 1475.8979 Explore P: 0.3943 RunMean : 183.0800\n",
      "Episode: 778 Total reward: 197.0 Training loss: 555.2354 Explore P: 0.3927 RunMean : 183.4100\n",
      "Episode: 779 Total reward: 125.0 Training loss: 4210.4248 Explore P: 0.3917 RunMean : 183.5000\n",
      "Episode: 780 Total reward: 130.0 Training loss: 339.7869 Explore P: 0.3907 RunMean : 184.1500\n",
      "Episode: 781 Total reward: 411.0 Training loss: 294.1770 Explore P: 0.3875 RunMean : 187.7000\n",
      "Episode: 782 Total reward: 397.0 Training loss: 329.4250 Explore P: 0.3845 RunMean : 190.0700\n",
      "Episode: 783 Total reward: 394.0 Training loss: 423.9573 Explore P: 0.3814 RunMean : 191.4600\n",
      "Episode: 784 Total reward: 500.0 Training loss: 90175.3047 Explore P: 0.3776 RunMean : 194.2500\n",
      "Episode: 785 Total reward: 339.0 Training loss: 533.6581 Explore P: 0.3751 RunMean : 196.9400\n",
      "Episode: 786 Total reward: 275.0 Training loss: 258.2036 Explore P: 0.3730 RunMean : 198.2800\n",
      "Episode: 787 Total reward: 330.0 Training loss: 461.9298 Explore P: 0.3706 RunMean : 201.1200\n",
      "Episode: 788 Total reward: 474.0 Training loss: 405.1732 Explore P: 0.3671 RunMean : 204.5500\n",
      "Episode: 789 Total reward: 395.0 Training loss: 383.7903 Explore P: 0.3642 RunMean : 207.7000\n",
      "Episode: 790 Total reward: 352.0 Training loss: 179.5084 Explore P: 0.3616 RunMean : 208.6400\n",
      "Episode: 791 Total reward: 469.0 Training loss: 236.7010 Explore P: 0.3583 RunMean : 212.7900\n",
      "Episode: 792 Total reward: 317.0 Training loss: 358.7320 Explore P: 0.3560 RunMean : 215.5300\n",
      "Episode: 793 Total reward: 289.0 Training loss: 267.4758 Explore P: 0.3539 RunMean : 218.1300\n",
      "Episode: 794 Total reward: 185.0 Training loss: 6397.8135 Explore P: 0.3526 RunMean : 218.4100\n",
      "Episode: 795 Total reward: 371.0 Training loss: 315.6790 Explore P: 0.3500 RunMean : 221.4000\n",
      "Episode: 796 Total reward: 381.0 Training loss: 195.4288 Explore P: 0.3474 RunMean : 223.3500\n",
      "Episode: 797 Total reward: 500.0 Training loss: 208.2234 Explore P: 0.3439 RunMean : 226.1900\n",
      "Episode: 798 Total reward: 367.0 Training loss: 2772.9741 Explore P: 0.3414 RunMean : 229.6500\n",
      "Episode: 799 Total reward: 477.0 Training loss: 49163.2773 Explore P: 0.3382 RunMean : 232.8500\n",
      "Episode: 800 Total reward: 360.0 Training loss: 247.2257 Explore P: 0.3357 RunMean : 236.2000\n",
      "Episode: 801 Total reward: 315.0 Training loss: 184.1133 Explore P: 0.3336 RunMean : 237.3800\n",
      "Episode: 802 Total reward: 292.0 Training loss: 273.9033 Explore P: 0.3317 RunMean : 238.7000\n",
      "Episode: 803 Total reward: 476.0 Training loss: 253.6061 Explore P: 0.3285 RunMean : 241.5900\n",
      "Episode: 804 Total reward: 395.0 Training loss: 253.2893 Explore P: 0.3260 RunMean : 244.5300\n",
      "Episode: 805 Total reward: 350.0 Training loss: 555.6541 Explore P: 0.3237 RunMean : 243.0300\n",
      "Episode: 806 Total reward: 409.0 Training loss: 305.9293 Explore P: 0.3210 RunMean : 246.6400\n",
      "Episode: 807 Total reward: 208.0 Training loss: 203.0592 Explore P: 0.3197 RunMean : 246.0700\n",
      "Episode: 808 Total reward: 246.0 Training loss: 149.9857 Explore P: 0.3181 RunMean : 247.3200\n",
      "Episode: 809 Total reward: 193.0 Training loss: 145.1019 Explore P: 0.3169 RunMean : 247.5300\n",
      "Episode: 810 Total reward: 16.0 Training loss: 539.4089 Explore P: 0.3168 RunMean : 247.4500\n",
      "Episode: 811 Total reward: 341.0 Training loss: 198.0964 Explore P: 0.3147 RunMean : 249.1700\n",
      "Episode: 812 Total reward: 446.0 Training loss: 116.9358 Explore P: 0.3119 RunMean : 250.6200\n",
      "Episode: 813 Total reward: 500.0 Training loss: 193.1676 Explore P: 0.3088 RunMean : 253.8200\n",
      "Episode: 814 Total reward: 500.0 Training loss: 107.8605 Explore P: 0.3057 RunMean : 257.6000\n",
      "Episode: 815 Total reward: 357.0 Training loss: 93.7340 Explore P: 0.3035 RunMean : 260.1400\n",
      "Episode: 816 Total reward: 423.0 Training loss: 89.3919 Explore P: 0.3010 RunMean : 263.7400\n",
      "Episode: 817 Total reward: 500.0 Training loss: 122.9284 Explore P: 0.2980 RunMean : 267.0500\n",
      "Episode: 818 Total reward: 500.0 Training loss: 155.0013 Explore P: 0.2950 RunMean : 270.8100\n",
      "Episode: 819 Total reward: 495.0 Training loss: 135.4264 Explore P: 0.2921 RunMean : 274.0000\n",
      "Episode: 820 Total reward: 500.0 Training loss: 139.5670 Explore P: 0.2892 RunMean : 277.3200\n",
      "Episode: 821 Total reward: 349.0 Training loss: 112.9676 Explore P: 0.2872 RunMean : 279.0900\n",
      "Episode: 822 Total reward: 330.0 Training loss: 103.9518 Explore P: 0.2853 RunMean : 282.0500\n",
      "Episode: 823 Total reward: 500.0 Training loss: 48.3575 Explore P: 0.2824 RunMean : 282.2000\n",
      "Episode: 824 Total reward: 500.0 Training loss: 45.4476 Explore P: 0.2796 RunMean : 286.8200\n",
      "Episode: 825 Total reward: 500.0 Training loss: 179.3857 Explore P: 0.2769 RunMean : 290.2800\n",
      "Episode: 826 Total reward: 500.0 Training loss: 49.1409 Explore P: 0.2741 RunMean : 293.0800\n",
      "Episode: 827 Total reward: 500.0 Training loss: 167.4285 Explore P: 0.2714 RunMean : 296.1600\n",
      "Episode: 828 Total reward: 500.0 Training loss: 121.2405 Explore P: 0.2687 RunMean : 298.9100\n",
      "Episode: 829 Total reward: 488.0 Training loss: 85.9106 Explore P: 0.2661 RunMean : 302.0700\n",
      "Episode: 830 Total reward: 500.0 Training loss: 83.8763 Explore P: 0.2634 RunMean : 306.6900\n",
      "Episode: 831 Total reward: 500.0 Training loss: 87.1576 Explore P: 0.2608 RunMean : 309.2700\n",
      "Episode: 832 Total reward: 500.0 Training loss: 102.6114 Explore P: 0.2582 RunMean : 312.4700\n",
      "Episode: 833 Total reward: 500.0 Training loss: 66.1856 Explore P: 0.2556 RunMean : 317.0700\n",
      "Episode: 834 Total reward: 500.0 Training loss: 76.0015 Explore P: 0.2531 RunMean : 318.8800\n",
      "Episode: 835 Total reward: 500.0 Training loss: 78.4931 Explore P: 0.2506 RunMean : 322.0200\n",
      "Episode: 836 Total reward: 493.0 Training loss: 78.8297 Explore P: 0.2481 RunMean : 326.3200\n",
      "Episode: 837 Total reward: 481.0 Training loss: 69.0843 Explore P: 0.2457 RunMean : 328.7000\n",
      "Episode: 838 Total reward: 500.0 Training loss: 45.6753 Explore P: 0.2433 RunMean : 331.7300\n",
      "Episode: 839 Total reward: 481.0 Training loss: 29418.7734 Explore P: 0.2410 RunMean : 335.0300\n",
      "Episode: 840 Total reward: 475.0 Training loss: 37.5439 Explore P: 0.2387 RunMean : 337.7400\n",
      "Episode: 841 Total reward: 420.0 Training loss: 53.4651 Explore P: 0.2367 RunMean : 339.8100\n",
      "Episode: 842 Total reward: 500.0 Training loss: 41.2299 Explore P: 0.2343 RunMean : 342.0800\n",
      "Episode: 843 Total reward: 443.0 Training loss: 52.8039 Explore P: 0.2323 RunMean : 343.4900\n",
      "Episode: 844 Total reward: 453.0 Training loss: 35.1147 Explore P: 0.2302 RunMean : 346.1100\n",
      "Episode: 845 Total reward: 500.0 Training loss: 58.3931 Explore P: 0.2279 RunMean : 350.6700\n",
      "Episode: 846 Total reward: 500.0 Training loss: 23180.0332 Explore P: 0.2256 RunMean : 353.8200\n",
      "Episode: 847 Total reward: 322.0 Training loss: 39.4031 Explore P: 0.2242 RunMean : 354.6800\n",
      "Episode: 848 Total reward: 500.0 Training loss: 25.5759 Explore P: 0.2219 RunMean : 358.2900\n",
      "Episode: 849 Total reward: 449.0 Training loss: 28.0440 Explore P: 0.2199 RunMean : 360.0800\n",
      "Episode: 850 Total reward: 500.0 Training loss: 43.5163 Explore P: 0.2178 RunMean : 361.3200\n",
      "Episode: 851 Total reward: 500.0 Training loss: 30.4177 Explore P: 0.2156 RunMean : 365.9500\n",
      "Episode: 852 Total reward: 362.0 Training loss: 13077.8076 Explore P: 0.2140 RunMean : 366.3900\n",
      "Episode: 853 Total reward: 329.0 Training loss: 40.2014 Explore P: 0.2126 RunMean : 367.6700\n",
      "Episode: 854 Total reward: 352.0 Training loss: 34.8917 Explore P: 0.2111 RunMean : 370.1900\n",
      "Episode: 855 Total reward: 367.0 Training loss: 10690.5137 Explore P: 0.2096 RunMean : 371.8200\n",
      "Episode: 856 Total reward: 273.0 Training loss: 1416.2489 Explore P: 0.2085 RunMean : 371.7400\n",
      "Episode: 857 Total reward: 500.0 Training loss: 31.0769 Explore P: 0.2064 RunMean : 373.8900\n",
      "Episode: 858 Total reward: 321.0 Training loss: 41.3256 Explore P: 0.2051 RunMean : 374.1000\n",
      "Episode: 859 Total reward: 393.0 Training loss: 56.6624 Explore P: 0.2035 RunMean : 375.4900\n",
      "Episode: 860 Total reward: 500.0 Training loss: 39.1866 Explore P: 0.2014 RunMean : 378.8000\n",
      "Episode: 861 Total reward: 500.0 Training loss: 32.6709 Explore P: 0.1994 RunMean : 381.2000\n",
      "Episode: 862 Total reward: 242.0 Training loss: 47.3897 Explore P: 0.1985 RunMean : 379.5700\n",
      "Episode: 863 Total reward: 500.0 Training loss: 21.9501 Explore P: 0.1965 RunMean : 381.6300\n",
      "Episode: 864 Total reward: 500.0 Training loss: 25.7035 Explore P: 0.1945 RunMean : 385.6200\n",
      "Episode: 865 Total reward: 500.0 Training loss: 23.8728 Explore P: 0.1926 RunMean : 387.0500\n",
      "Episode: 866 Total reward: 500.0 Training loss: 22.5865 Explore P: 0.1907 RunMean : 389.9000\n",
      "Episode: 867 Total reward: 500.0 Training loss: 25.2763 Explore P: 0.1888 RunMean : 392.0400\n",
      "Episode: 868 Total reward: 500.0 Training loss: 31.4738 Explore P: 0.1869 RunMean : 393.3500\n",
      "Episode: 869 Total reward: 500.0 Training loss: 20.5085 Explore P: 0.1850 RunMean : 393.3500\n",
      "Episode: 870 Total reward: 433.0 Training loss: 68.9968 Explore P: 0.1835 RunMean : 394.8100\n",
      "Episode: 871 Total reward: 500.0 Training loss: 25.9310 Explore P: 0.1816 RunMean : 396.4100\n",
      "Episode: 872 Total reward: 369.0 Training loss: 23.4090 Explore P: 0.1803 RunMean : 397.4000\n",
      "Episode: 873 Total reward: 308.0 Training loss: 26.5706 Explore P: 0.1792 RunMean : 399.7300\n",
      "Episode: 874 Total reward: 426.0 Training loss: 1694.4658 Explore P: 0.1777 RunMean : 400.7800\n",
      "Episode: 875 Total reward: 445.0 Training loss: 36.3301 Explore P: 0.1761 RunMean : 405.0300\n",
      "Episode: 876 Total reward: 373.0 Training loss: 20.2068 Explore P: 0.1748 RunMean : 407.0000\n",
      "Episode: 877 Total reward: 500.0 Training loss: 18.1465 Explore P: 0.1730 RunMean : 411.7400\n",
      "Episode: 878 Total reward: 500.0 Training loss: 27.2588 Explore P: 0.1713 RunMean : 414.7700\n",
      "Episode: 879 Total reward: 500.0 Training loss: 28.5456 Explore P: 0.1696 RunMean : 418.5200\n",
      "Episode: 880 Total reward: 500.0 Training loss: 18.9434 Explore P: 0.1679 RunMean : 422.2200\n",
      "Episode: 881 Total reward: 461.0 Training loss: 23.8900 Explore P: 0.1664 RunMean : 422.7200\n",
      "Episode: 882 Total reward: 500.0 Training loss: 28.2730 Explore P: 0.1647 RunMean : 423.7500\n",
      "Episode: 883 Total reward: 500.0 Training loss: 33.4819 Explore P: 0.1631 RunMean : 424.8100\n",
      "Episode: 884 Total reward: 500.0 Training loss: 30.9015 Explore P: 0.1615 RunMean : 424.8100\n",
      "Episode: 885 Total reward: 491.0 Training loss: 26.8398 Explore P: 0.1599 RunMean : 426.3300\n",
      "Episode: 886 Total reward: 500.0 Training loss: 22.6839 Explore P: 0.1583 RunMean : 428.5800\n",
      "Episode: 887 Total reward: 500.0 Training loss: 121.0985 Explore P: 0.1567 RunMean : 430.2800\n",
      "Episode: 888 Total reward: 500.0 Training loss: 13.6115 Explore P: 0.1552 RunMean : 430.5400\n",
      "Episode: 889 Total reward: 500.0 Training loss: 13.5419 Explore P: 0.1536 RunMean : 431.5900\n",
      "Episode: 890 Total reward: 500.0 Training loss: 12.0019 Explore P: 0.1521 RunMean : 433.0700\n",
      "Episode: 891 Total reward: 500.0 Training loss: 30.3796 Explore P: 0.1506 RunMean : 433.3800\n",
      "Episode: 892 Total reward: 500.0 Training loss: 18.6437 Explore P: 0.1491 RunMean : 435.2100\n",
      "Episode: 893 Total reward: 500.0 Training loss: 21.0875 Explore P: 0.1476 RunMean : 437.3200\n",
      "Episode: 894 Total reward: 500.0 Training loss: 13743.8809 Explore P: 0.1461 RunMean : 440.4700\n",
      "Episode: 895 Total reward: 500.0 Training loss: 14.0302 Explore P: 0.1447 RunMean : 441.7600\n",
      "Episode: 896 Total reward: 500.0 Training loss: 9.8842 Explore P: 0.1432 RunMean : 442.9500\n",
      "Episode: 897 Total reward: 500.0 Training loss: 18.7277 Explore P: 0.1418 RunMean : 442.9500\n",
      "Episode: 898 Total reward: 500.0 Training loss: 11.9635 Explore P: 0.1404 RunMean : 444.2800\n",
      "Episode: 899 Total reward: 500.0 Training loss: 8.5853 Explore P: 0.1390 RunMean : 444.5100\n",
      "Episode: 900 Total reward: 500.0 Training loss: 10.0672 Explore P: 0.1376 RunMean : 445.9100\n",
      "Episode: 901 Total reward: 500.0 Training loss: 7.9557 Explore P: 0.1363 RunMean : 447.7600\n",
      "Episode: 902 Total reward: 323.0 Training loss: 21663.5000 Explore P: 0.1354 RunMean : 448.0700\n",
      "Episode: 903 Total reward: 500.0 Training loss: 9694.4609 Explore P: 0.1340 RunMean : 448.3100\n",
      "Episode: 904 Total reward: 500.0 Training loss: 13.8722 Explore P: 0.1327 RunMean : 449.3600\n",
      "Episode: 905 Total reward: 500.0 Training loss: 9777.8633 Explore P: 0.1314 RunMean : 450.8600\n",
      "Episode: 906 Total reward: 500.0 Training loss: 4.0889 Explore P: 0.1301 RunMean : 451.7700\n",
      "Episode: 907 Total reward: 500.0 Training loss: 8332.6318 Explore P: 0.1288 RunMean : 454.6900\n",
      "Episode: 908 Total reward: 500.0 Training loss: 5.0310 Explore P: 0.1275 RunMean : 457.2300\n",
      "Episode: 909 Total reward: 500.0 Training loss: 15433.6621 Explore P: 0.1262 RunMean : 460.3000\n",
      "Episode: 910 Total reward: 500.0 Training loss: 2.9869 Explore P: 0.1250 RunMean : 465.1400\n",
      "Episode: 911 Total reward: 500.0 Training loss: 6735.2144 Explore P: 0.1237 RunMean : 466.7300\n",
      "Episode: 912 Total reward: 500.0 Training loss: 24.6128 Explore P: 0.1225 RunMean : 467.2700\n",
      "Episode: 913 Total reward: 500.0 Training loss: 6264.0972 Explore P: 0.1213 RunMean : 467.2700\n",
      "Episode: 914 Total reward: 500.0 Training loss: 10.7936 Explore P: 0.1201 RunMean : 467.2700\n",
      "Episode: 915 Total reward: 500.0 Training loss: 6.5593 Explore P: 0.1189 RunMean : 468.7000\n",
      "Episode: 916 Total reward: 500.0 Training loss: 10.2554 Explore P: 0.1177 RunMean : 469.4700\n",
      "Episode: 917 Total reward: 500.0 Training loss: 6.9978 Explore P: 0.1165 RunMean : 469.4700\n",
      "Episode: 918 Total reward: 500.0 Training loss: 9.0094 Explore P: 0.1154 RunMean : 469.4700\n",
      "Episode: 919 Total reward: 500.0 Training loss: 9.9225 Explore P: 0.1142 RunMean : 469.5200\n",
      "Episode: 920 Total reward: 500.0 Training loss: 8.0980 Explore P: 0.1131 RunMean : 469.5200\n",
      "Episode: 921 Total reward: 462.0 Training loss: 4469.6006 Explore P: 0.1120 RunMean : 470.6500\n",
      "Episode: 922 Total reward: 500.0 Training loss: 11.1872 Explore P: 0.1109 RunMean : 472.3500\n",
      "Episode: 923 Total reward: 500.0 Training loss: 4572.3408 Explore P: 0.1098 RunMean : 472.3500\n",
      "Episode: 924 Total reward: 500.0 Training loss: 9.1435 Explore P: 0.1087 RunMean : 472.3500\n",
      "Episode: 925 Total reward: 500.0 Training loss: 6.4619 Explore P: 0.1076 RunMean : 472.3500\n",
      "Episode: 926 Total reward: 500.0 Training loss: 6840.6841 Explore P: 0.1066 RunMean : 472.3500\n",
      "Episode: 927 Total reward: 500.0 Training loss: 9.9927 Explore P: 0.1055 RunMean : 472.3500\n",
      "Episode: 928 Total reward: 95.0 Training loss: 6.5358 Explore P: 0.1053 RunMean : 468.3000\n",
      "Episode: 929 Total reward: 500.0 Training loss: 350.8738 Explore P: 0.1043 RunMean : 468.4200\n",
      "Episode: 930 Total reward: 500.0 Training loss: 6377.9409 Explore P: 0.1032 RunMean : 468.4200\n",
      "Episode: 931 Total reward: 489.0 Training loss: 7.1215 Explore P: 0.1022 RunMean : 468.3100\n",
      "Episode: 932 Total reward: 500.0 Training loss: 17.1602 Explore P: 0.1012 RunMean : 468.3100\n",
      "Episode: 933 Total reward: 500.0 Training loss: 29.8809 Explore P: 0.1002 RunMean : 468.3100\n",
      "Episode: 934 Total reward: 500.0 Training loss: 62.7283 Explore P: 0.0992 RunMean : 468.3100\n",
      "Episode: 935 Total reward: 198.0 Training loss: 146.1781 Explore P: 0.0988 RunMean : 465.2900\n",
      "Episode: 936 Total reward: 138.0 Training loss: 225.6694 Explore P: 0.0985 RunMean : 461.7400\n",
      "Episode: 937 Total reward: 107.0 Training loss: 415.3438 Explore P: 0.0983 RunMean : 458.0000\n",
      "Episode: 938 Total reward: 107.0 Training loss: 432.4462 Explore P: 0.0981 RunMean : 454.0700\n",
      "Episode: 939 Total reward: 92.0 Training loss: 577.6641 Explore P: 0.0979 RunMean : 450.1800\n",
      "Episode: 940 Total reward: 96.0 Training loss: 11023.6416 Explore P: 0.0977 RunMean : 446.3900\n",
      "Episode: 941 Total reward: 15.0 Training loss: 642.3060 Explore P: 0.0977 RunMean : 442.3400\n",
      "Episode: 942 Total reward: 84.0 Training loss: 892.3158 Explore P: 0.0976 RunMean : 438.1800\n",
      "Episode: 943 Total reward: 13.0 Training loss: 718.4109 Explore P: 0.0975 RunMean : 433.8800\n",
      "Episode: 944 Total reward: 13.0 Training loss: 984.6996 Explore P: 0.0975 RunMean : 429.4800\n",
      "Episode: 945 Total reward: 9.0 Training loss: 52057.0664 Explore P: 0.0975 RunMean : 424.5700\n",
      "Episode: 946 Total reward: 10.0 Training loss: 831.3071 Explore P: 0.0975 RunMean : 419.6700\n",
      "Episode: 947 Total reward: 11.0 Training loss: 1001.6387 Explore P: 0.0974 RunMean : 416.5600\n",
      "Episode: 948 Total reward: 11.0 Training loss: 828.4213 Explore P: 0.0974 RunMean : 411.6700\n",
      "Episode: 949 Total reward: 9.0 Training loss: 980.8236 Explore P: 0.0974 RunMean : 407.2700\n",
      "Episode: 950 Total reward: 15.0 Training loss: 53231.3086 Explore P: 0.0974 RunMean : 402.4200\n",
      "Episode: 951 Total reward: 13.0 Training loss: 610.9263 Explore P: 0.0973 RunMean : 397.5500\n",
      "Episode: 952 Total reward: 12.0 Training loss: 959.3634 Explore P: 0.0973 RunMean : 394.0500\n",
      "Episode: 953 Total reward: 11.0 Training loss: 761.4685 Explore P: 0.0973 RunMean : 390.8700\n",
      "Episode: 954 Total reward: 87.0 Training loss: 988.1312 Explore P: 0.0971 RunMean : 388.2200\n",
      "Episode: 955 Total reward: 90.0 Training loss: 864.4000 Explore P: 0.0970 RunMean : 385.4500\n",
      "Episode: 956 Total reward: 90.0 Training loss: 73146.1172 Explore P: 0.0968 RunMean : 383.6200\n",
      "Episode: 957 Total reward: 109.0 Training loss: 13028.2217 Explore P: 0.0966 RunMean : 379.7100\n",
      "Episode: 958 Total reward: 115.0 Training loss: 491.2636 Explore P: 0.0964 RunMean : 377.6500\n",
      "Episode: 959 Total reward: 126.0 Training loss: 445.8252 Explore P: 0.0961 RunMean : 374.9800\n",
      "Episode: 960 Total reward: 143.0 Training loss: 329.0327 Explore P: 0.0958 RunMean : 371.4100\n",
      "Episode: 961 Total reward: 234.0 Training loss: 320.5156 Explore P: 0.0954 RunMean : 368.7500\n",
      "Episode: 962 Total reward: 500.0 Training loss: 279.3481 Explore P: 0.0944 RunMean : 371.3300\n",
      "Episode: 963 Total reward: 365.0 Training loss: 152.0020 Explore P: 0.0938 RunMean : 369.9800\n",
      "Episode: 964 Total reward: 246.0 Training loss: 176.5657 Explore P: 0.0933 RunMean : 367.4400\n",
      "Episode: 965 Total reward: 194.0 Training loss: 489.5676 Explore P: 0.0929 RunMean : 364.3800\n",
      "Episode: 966 Total reward: 156.0 Training loss: 170.3805 Explore P: 0.0926 RunMean : 360.9400\n",
      "Episode: 967 Total reward: 148.0 Training loss: 190.3795 Explore P: 0.0924 RunMean : 357.4200\n",
      "Episode: 968 Total reward: 119.0 Training loss: 274.7590 Explore P: 0.0921 RunMean : 353.6100\n",
      "Episode: 969 Total reward: 121.0 Training loss: 380.9852 Explore P: 0.0919 RunMean : 349.8200\n",
      "Episode: 970 Total reward: 111.0 Training loss: 338.3985 Explore P: 0.0917 RunMean : 346.6000\n",
      "Episode: 971 Total reward: 36.0 Training loss: 400.5019 Explore P: 0.0917 RunMean : 341.9600\n",
      "Episode: 972 Total reward: 14.0 Training loss: 361.8903 Explore P: 0.0916 RunMean : 338.4100\n",
      "Episode: 973 Total reward: 10.0 Training loss: 22129.3086 Explore P: 0.0916 RunMean : 335.4300\n",
      "Episode: 974 Total reward: 104.0 Training loss: 342.5943 Explore P: 0.0914 RunMean : 332.2100\n",
      "Episode: 975 Total reward: 95.0 Training loss: 48313.3555 Explore P: 0.0912 RunMean : 328.7100\n",
      "Episode: 976 Total reward: 12.0 Training loss: 54442.0039 Explore P: 0.0912 RunMean : 325.1000\n",
      "Episode: 977 Total reward: 98.0 Training loss: 336.8083 Explore P: 0.0910 RunMean : 321.0800\n",
      "Episode: 978 Total reward: 99.0 Training loss: 641.9440 Explore P: 0.0909 RunMean : 317.0700\n",
      "Episode: 979 Total reward: 17.0 Training loss: 667.3403 Explore P: 0.0908 RunMean : 312.2400\n",
      "Episode: 980 Total reward: 9.0 Training loss: 21119.5566 Explore P: 0.0908 RunMean : 307.3300\n",
      "Episode: 981 Total reward: 11.0 Training loss: 490.0320 Explore P: 0.0908 RunMean : 302.8300\n",
      "Episode: 982 Total reward: 10.0 Training loss: 530.4960 Explore P: 0.0908 RunMean : 297.9300\n",
      "Episode: 983 Total reward: 9.0 Training loss: 44304.1250 Explore P: 0.0908 RunMean : 293.0200\n",
      "Episode: 984 Total reward: 9.0 Training loss: 1146.2080 Explore P: 0.0907 RunMean : 288.1100\n",
      "Episode: 985 Total reward: 10.0 Training loss: 608.8430 Explore P: 0.0907 RunMean : 283.3000\n",
      "Episode: 986 Total reward: 8.0 Training loss: 930.5112 Explore P: 0.0907 RunMean : 278.3800\n",
      "Episode: 987 Total reward: 10.0 Training loss: 607.9709 Explore P: 0.0907 RunMean : 273.4800\n",
      "Episode: 988 Total reward: 10.0 Training loss: 1027.9556 Explore P: 0.0907 RunMean : 268.5800\n",
      "Episode: 989 Total reward: 8.0 Training loss: 644.3625 Explore P: 0.0907 RunMean : 263.6600\n",
      "Episode: 990 Total reward: 10.0 Training loss: 952.9373 Explore P: 0.0906 RunMean : 258.7600\n",
      "Episode: 991 Total reward: 11.0 Training loss: 23062.6562 Explore P: 0.0906 RunMean : 253.8700\n",
      "Episode: 992 Total reward: 9.0 Training loss: 28715.3438 Explore P: 0.0906 RunMean : 248.9600\n",
      "Episode: 993 Total reward: 12.0 Training loss: 49875.9141 Explore P: 0.0906 RunMean : 244.0800\n",
      "Episode: 994 Total reward: 10.0 Training loss: 68059.0078 Explore P: 0.0906 RunMean : 239.1800\n",
      "Episode: 995 Total reward: 10.0 Training loss: 43707.0898 Explore P: 0.0906 RunMean : 234.2800\n",
      "Episode: 996 Total reward: 10.0 Training loss: 975.1256 Explore P: 0.0905 RunMean : 229.3800\n",
      "Episode: 997 Total reward: 9.0 Training loss: 986.9359 Explore P: 0.0905 RunMean : 224.4700\n",
      "Episode: 998 Total reward: 117.0 Training loss: 86558.5938 Explore P: 0.0903 RunMean : 220.6400\n",
      "Episode: 999 Total reward: 211.0 Training loss: 51619.5625 Explore P: 0.0899 RunMean : 217.7500\n",
      "Episode: 1000 Total reward: 500.0 Training loss: 3271.4973 Explore P: 0.0890 RunMean : 217.7500\n",
      "Episode: 1001 Total reward: 199.0 Training loss: 24167.6523 Explore P: 0.0887 RunMean : 214.7400\n",
      "Episode: 1002 Total reward: 165.0 Training loss: 18418.8926 Explore P: 0.0884 RunMean : 213.1600\n",
      "Episode: 1003 Total reward: 199.0 Training loss: 868.5342 Explore P: 0.0880 RunMean : 210.1500\n",
      "Episode: 1004 Total reward: 170.0 Training loss: 25104.0781 Explore P: 0.0877 RunMean : 206.8500\n",
      "Episode: 1005 Total reward: 199.0 Training loss: 16138.1748 Explore P: 0.0874 RunMean : 203.8400\n",
      "Episode: 1006 Total reward: 272.0 Training loss: 22637.7207 Explore P: 0.0869 RunMean : 201.5600\n",
      "Episode: 1007 Total reward: 200.0 Training loss: 26144.7031 Explore P: 0.0866 RunMean : 198.5600\n",
      "Episode: 1008 Total reward: 500.0 Training loss: 365.1210 Explore P: 0.0857 RunMean : 198.5600\n",
      "Episode: 1009 Total reward: 268.0 Training loss: 8950.4502 Explore P: 0.0852 RunMean : 196.2400\n",
      "Episode: 1010 Total reward: 233.0 Training loss: 618.6809 Explore P: 0.0849 RunMean : 193.5700\n",
      "Episode: 1011 Total reward: 216.0 Training loss: 355.0129 Explore P: 0.0845 RunMean : 190.7300\n",
      "Episode: 1012 Total reward: 228.0 Training loss: 340.3591 Explore P: 0.0841 RunMean : 188.0100\n",
      "Episode: 1013 Total reward: 186.0 Training loss: 601.6702 Explore P: 0.0838 RunMean : 184.8700\n",
      "Episode: 1014 Total reward: 183.0 Training loss: 22449.0723 Explore P: 0.0835 RunMean : 181.7000\n",
      "Episode: 1015 Total reward: 147.0 Training loss: 388.7097 Explore P: 0.0832 RunMean : 178.1700\n",
      "Episode: 1016 Total reward: 169.0 Training loss: 430.7647 Explore P: 0.0830 RunMean : 174.8600\n",
      "Episode: 1017 Total reward: 175.0 Training loss: 426.6786 Explore P: 0.0827 RunMean : 171.6100\n",
      "Episode: 1018 Total reward: 165.0 Training loss: 538.4442 Explore P: 0.0824 RunMean : 168.2600\n",
      "Episode: 1019 Total reward: 134.0 Training loss: 451.5880 Explore P: 0.0822 RunMean : 164.6000\n",
      "Episode: 1020 Total reward: 144.0 Training loss: 4133.6514 Explore P: 0.0819 RunMean : 161.0400\n",
      "Episode: 1021 Total reward: 131.0 Training loss: 9024.2109 Explore P: 0.0817 RunMean : 157.7300\n",
      "Episode: 1022 Total reward: 152.0 Training loss: 7735.6914 Explore P: 0.0815 RunMean : 154.2500\n",
      "Episode: 1023 Total reward: 139.0 Training loss: 12940.6162 Explore P: 0.0812 RunMean : 150.6400\n",
      "Episode: 1024 Total reward: 133.0 Training loss: 604.4568 Explore P: 0.0810 RunMean : 146.9700\n",
      "Episode: 1025 Total reward: 138.0 Training loss: 14397.2607 Explore P: 0.0808 RunMean : 143.3500\n",
      "Episode: 1026 Total reward: 127.0 Training loss: 508.7368 Explore P: 0.0806 RunMean : 139.6200\n",
      "Episode: 1027 Total reward: 128.0 Training loss: 721.9573 Explore P: 0.0804 RunMean : 135.9000\n",
      "Episode: 1028 Total reward: 161.0 Training loss: 24403.8672 Explore P: 0.0801 RunMean : 136.5600\n",
      "Episode: 1029 Total reward: 139.0 Training loss: 441.8113 Explore P: 0.0799 RunMean : 132.9500\n",
      "Episode: 1030 Total reward: 116.0 Training loss: 17969.6445 Explore P: 0.0797 RunMean : 129.1100\n",
      "Episode: 1031 Total reward: 122.0 Training loss: 1473.6223 Explore P: 0.0795 RunMean : 125.4400\n",
      "Episode: 1032 Total reward: 129.0 Training loss: 731.6409 Explore P: 0.0793 RunMean : 121.7300\n",
      "Episode: 1033 Total reward: 133.0 Training loss: 606.8485 Explore P: 0.0791 RunMean : 118.0600\n",
      "Episode: 1034 Total reward: 123.0 Training loss: 481.9460 Explore P: 0.0789 RunMean : 114.2900\n",
      "Episode: 1035 Total reward: 145.0 Training loss: 578.8406 Explore P: 0.0787 RunMean : 113.7600\n",
      "Episode: 1036 Total reward: 160.0 Training loss: 596.3364 Explore P: 0.0784 RunMean : 113.9800\n",
      "Episode: 1037 Total reward: 130.0 Training loss: 647.7010 Explore P: 0.0782 RunMean : 114.2100\n",
      "Episode: 1038 Total reward: 141.0 Training loss: 19010.8750 Explore P: 0.0780 RunMean : 114.5500\n",
      "Episode: 1039 Total reward: 123.0 Training loss: 22876.7168 Explore P: 0.0778 RunMean : 114.8600\n",
      "Episode: 1040 Total reward: 126.0 Training loss: 16692.5176 Explore P: 0.0776 RunMean : 115.1600\n",
      "Episode: 1041 Total reward: 136.0 Training loss: 8802.4580 Explore P: 0.0774 RunMean : 116.3700\n",
      "Episode: 1042 Total reward: 182.0 Training loss: 433.1342 Explore P: 0.0771 RunMean : 117.3500\n",
      "Episode: 1043 Total reward: 183.0 Training loss: 668.7861 Explore P: 0.0769 RunMean : 119.0500\n",
      "Episode: 1044 Total reward: 158.0 Training loss: 364.7557 Explore P: 0.0766 RunMean : 120.5000\n",
      "Episode: 1045 Total reward: 221.0 Training loss: 578.8748 Explore P: 0.0763 RunMean : 122.6200\n",
      "Episode: 1046 Total reward: 123.0 Training loss: 540.9409 Explore P: 0.0761 RunMean : 123.7500\n",
      "Episode: 1047 Total reward: 147.0 Training loss: 23978.7676 Explore P: 0.0759 RunMean : 125.1100\n",
      "Episode: 1048 Total reward: 165.0 Training loss: 16375.4336 Explore P: 0.0756 RunMean : 126.6500\n",
      "Episode: 1049 Total reward: 159.0 Training loss: 13858.1895 Explore P: 0.0754 RunMean : 128.1500\n",
      "Episode: 1050 Total reward: 120.0 Training loss: 563.8181 Explore P: 0.0752 RunMean : 129.2000\n",
      "Episode: 1051 Total reward: 126.0 Training loss: 497.4686 Explore P: 0.0750 RunMean : 130.3300\n",
      "Episode: 1052 Total reward: 170.0 Training loss: 330.8086 Explore P: 0.0748 RunMean : 131.9100\n",
      "Episode: 1053 Total reward: 130.0 Training loss: 459.8315 Explore P: 0.0746 RunMean : 133.1000\n",
      "Episode: 1054 Total reward: 133.0 Training loss: 273.7304 Explore P: 0.0744 RunMean : 133.5600\n",
      "Episode: 1055 Total reward: 177.0 Training loss: 292.9857 Explore P: 0.0741 RunMean : 134.4300\n",
      "Episode: 1056 Total reward: 227.0 Training loss: 408.8471 Explore P: 0.0738 RunMean : 135.8000\n",
      "Episode: 1057 Total reward: 165.0 Training loss: 501.8867 Explore P: 0.0735 RunMean : 136.3600\n",
      "Episode: 1058 Total reward: 164.0 Training loss: 23144.4668 Explore P: 0.0733 RunMean : 136.8500\n",
      "Episode: 1059 Total reward: 135.0 Training loss: 21595.6855 Explore P: 0.0731 RunMean : 136.9400\n",
      "Episode: 1060 Total reward: 135.0 Training loss: 432.3002 Explore P: 0.0729 RunMean : 136.8600\n",
      "Episode: 1061 Total reward: 214.0 Training loss: 423.0868 Explore P: 0.0726 RunMean : 136.6600\n",
      "Episode: 1062 Total reward: 167.0 Training loss: 404.7791 Explore P: 0.0723 RunMean : 133.3300\n",
      "Episode: 1063 Total reward: 213.0 Training loss: 9307.6396 Explore P: 0.0720 RunMean : 131.8100\n",
      "Episode: 1064 Total reward: 355.0 Training loss: 302.6126 Explore P: 0.0715 RunMean : 132.9000\n",
      "Episode: 1065 Total reward: 343.0 Training loss: 310.1136 Explore P: 0.0710 RunMean : 134.3900\n",
      "Episode: 1066 Total reward: 158.0 Training loss: 180.3607 Explore P: 0.0708 RunMean : 134.4100\n",
      "Episode: 1067 Total reward: 307.0 Training loss: 338.9521 Explore P: 0.0704 RunMean : 136.0000\n",
      "Episode: 1068 Total reward: 370.0 Training loss: 292.2325 Explore P: 0.0699 RunMean : 138.5100\n",
      "Episode: 1069 Total reward: 261.0 Training loss: 315.0302 Explore P: 0.0695 RunMean : 139.9100\n",
      "Episode: 1070 Total reward: 500.0 Training loss: 306.4421 Explore P: 0.0688 RunMean : 143.8000\n",
      "Episode: 1071 Total reward: 500.0 Training loss: 239.1775 Explore P: 0.0681 RunMean : 148.4400\n",
      "Episode: 1072 Total reward: 155.0 Training loss: 219.1469 Explore P: 0.0679 RunMean : 149.8500\n",
      "Episode: 1073 Total reward: 170.0 Training loss: 262.7741 Explore P: 0.0677 RunMean : 151.4500\n",
      "Episode: 1074 Total reward: 245.0 Training loss: 172.7011 Explore P: 0.0673 RunMean : 152.8600\n",
      "Episode: 1075 Total reward: 172.0 Training loss: 14868.6934 Explore P: 0.0671 RunMean : 153.6300\n",
      "Episode: 1076 Total reward: 184.0 Training loss: 10713.5361 Explore P: 0.0669 RunMean : 155.3500\n",
      "Episode: 1077 Total reward: 432.0 Training loss: 4150.7778 Explore P: 0.0663 RunMean : 158.6900\n",
      "Episode: 1078 Total reward: 194.0 Training loss: 183.5193 Explore P: 0.0660 RunMean : 159.6400\n",
      "Episode: 1079 Total reward: 168.0 Training loss: 17401.3184 Explore P: 0.0658 RunMean : 161.1500\n",
      "Episode: 1080 Total reward: 153.0 Training loss: 140.1334 Explore P: 0.0656 RunMean : 162.5900\n",
      "Episode: 1081 Total reward: 272.0 Training loss: 140.8940 Explore P: 0.0653 RunMean : 165.2000\n",
      "Episode: 1082 Total reward: 316.0 Training loss: 7825.1978 Explore P: 0.0648 RunMean : 168.2600\n",
      "Episode: 1083 Total reward: 500.0 Training loss: 69.0229 Explore P: 0.0642 RunMean : 173.1700\n",
      "Episode: 1084 Total reward: 334.0 Training loss: 142.7620 Explore P: 0.0638 RunMean : 176.4200\n",
      "Episode: 1085 Total reward: 173.0 Training loss: 94.2209 Explore P: 0.0635 RunMean : 178.0500\n",
      "Episode: 1086 Total reward: 231.0 Training loss: 89.8077 Explore P: 0.0633 RunMean : 180.2800\n",
      "Episode: 1087 Total reward: 500.0 Training loss: 81.8128 Explore P: 0.0626 RunMean : 185.1800\n",
      "Episode: 1088 Total reward: 482.0 Training loss: 105.5539 Explore P: 0.0620 RunMean : 189.9000\n",
      "Episode: 1089 Total reward: 218.0 Training loss: 4861.8560 Explore P: 0.0618 RunMean : 192.0000\n",
      "Episode: 1090 Total reward: 260.0 Training loss: 7452.1074 Explore P: 0.0614 RunMean : 194.5000\n",
      "Episode: 1091 Total reward: 459.0 Training loss: 87.0786 Explore P: 0.0609 RunMean : 198.9800\n",
      "Episode: 1092 Total reward: 204.0 Training loss: 100.9434 Explore P: 0.0606 RunMean : 200.9300\n",
      "Episode: 1093 Total reward: 194.0 Training loss: 5110.1982 Explore P: 0.0604 RunMean : 202.7500\n",
      "Episode: 1094 Total reward: 366.0 Training loss: 6301.2993 Explore P: 0.0600 RunMean : 206.3100\n",
      "Episode: 1095 Total reward: 359.0 Training loss: 78.3480 Explore P: 0.0595 RunMean : 209.8000\n",
      "Episode: 1096 Total reward: 406.0 Training loss: 3301.8994 Explore P: 0.0590 RunMean : 213.7600\n",
      "Episode: 1097 Total reward: 472.0 Training loss: 50.6359 Explore P: 0.0585 RunMean : 218.3900\n",
      "Episode: 1098 Total reward: 500.0 Training loss: 63.0066 Explore P: 0.0579 RunMean : 222.2200\n",
      "Episode: 1099 Total reward: 500.0 Training loss: 48.1489 Explore P: 0.0573 RunMean : 225.1100\n",
      "Episode: 1100 Total reward: 500.0 Training loss: 29.5287 Explore P: 0.0568 RunMean : 225.1100\n",
      "Episode: 1101 Total reward: 477.0 Training loss: 52.7846 Explore P: 0.0562 RunMean : 227.8900\n",
      "Episode: 1102 Total reward: 500.0 Training loss: 18.8883 Explore P: 0.0557 RunMean : 231.2400\n",
      "Episode: 1103 Total reward: 500.0 Training loss: 21.9039 Explore P: 0.0551 RunMean : 234.2500\n",
      "Episode: 1104 Total reward: 500.0 Training loss: 2092.3828 Explore P: 0.0546 RunMean : 237.5500\n",
      "Episode: 1105 Total reward: 424.0 Training loss: 62.5439 Explore P: 0.0541 RunMean : 239.8000\n",
      "Episode: 1106 Total reward: 500.0 Training loss: 2991.8081 Explore P: 0.0536 RunMean : 242.0800\n",
      "Episode: 1107 Total reward: 426.0 Training loss: 65.1157 Explore P: 0.0531 RunMean : 244.3400\n",
      "Episode: 1108 Total reward: 378.0 Training loss: 23.8337 Explore P: 0.0527 RunMean : 243.1200\n",
      "Episode: 1109 Total reward: 500.0 Training loss: 49.9336 Explore P: 0.0522 RunMean : 245.4400\n",
      "Episode: 1110 Total reward: 500.0 Training loss: 16.0764 Explore P: 0.0517 RunMean : 248.1100\n",
      "Episode: 1111 Total reward: 500.0 Training loss: 58.6607 Explore P: 0.0511 RunMean : 250.9500\n",
      "Episode: 1112 Total reward: 500.0 Training loss: 27.7882 Explore P: 0.0506 RunMean : 253.6700\n",
      "Episode: 1113 Total reward: 500.0 Training loss: 23.9521 Explore P: 0.0501 RunMean : 256.8100\n",
      "Episode: 1114 Total reward: 428.0 Training loss: 15.7460 Explore P: 0.0497 RunMean : 259.2600\n",
      "Episode: 1115 Total reward: 500.0 Training loss: 19.1346 Explore P: 0.0492 RunMean : 262.7900\n",
      "Episode: 1116 Total reward: 500.0 Training loss: 20.1460 Explore P: 0.0487 RunMean : 266.1000\n",
      "Episode: 1117 Total reward: 500.0 Training loss: 12.3651 Explore P: 0.0482 RunMean : 269.3500\n",
      "Episode: 1118 Total reward: 494.0 Training loss: 26.8756 Explore P: 0.0478 RunMean : 272.6400\n",
      "Episode: 1119 Total reward: 500.0 Training loss: 23.5543 Explore P: 0.0473 RunMean : 276.3000\n",
      "Episode: 1120 Total reward: 500.0 Training loss: 15.9245 Explore P: 0.0468 RunMean : 279.8600\n",
      "Episode: 1121 Total reward: 500.0 Training loss: 17.3846 Explore P: 0.0464 RunMean : 283.5500\n",
      "Episode: 1122 Total reward: 500.0 Training loss: 855.4840 Explore P: 0.0459 RunMean : 287.0300\n",
      "Episode: 1123 Total reward: 500.0 Training loss: 24.6003 Explore P: 0.0454 RunMean : 290.6400\n",
      "Episode: 1124 Total reward: 500.0 Training loss: 10.9013 Explore P: 0.0450 RunMean : 294.3100\n",
      "Episode: 1125 Total reward: 500.0 Training loss: 15.7143 Explore P: 0.0445 RunMean : 297.9300\n",
      "Episode: 1126 Total reward: 500.0 Training loss: 22.6950 Explore P: 0.0441 RunMean : 301.6600\n",
      "Episode: 1127 Total reward: 500.0 Training loss: 19.1606 Explore P: 0.0437 RunMean : 305.3800\n",
      "Episode: 1128 Total reward: 500.0 Training loss: 11.9067 Explore P: 0.0432 RunMean : 308.7700\n",
      "Episode: 1129 Total reward: 500.0 Training loss: 14.9852 Explore P: 0.0428 RunMean : 312.3800\n",
      "Episode: 1130 Total reward: 500.0 Training loss: 15.0415 Explore P: 0.0424 RunMean : 316.2200\n",
      "Episode: 1131 Total reward: 500.0 Training loss: 13.3505 Explore P: 0.0419 RunMean : 320.0000\n",
      "Episode: 1132 Total reward: 500.0 Training loss: 13.1100 Explore P: 0.0415 RunMean : 323.7100\n",
      "Episode: 1133 Total reward: 500.0 Training loss: 10.7460 Explore P: 0.0411 RunMean : 327.3800\n",
      "Episode: 1134 Total reward: 500.0 Training loss: 5107.3647 Explore P: 0.0407 RunMean : 331.1500\n",
      "Episode: 1135 Total reward: 500.0 Training loss: 11.8727 Explore P: 0.0403 RunMean : 334.7000\n",
      "Episode: 1136 Total reward: 500.0 Training loss: 10.3314 Explore P: 0.0399 RunMean : 338.1000\n",
      "Episode: 1137 Total reward: 500.0 Training loss: 9.8719 Explore P: 0.0395 RunMean : 341.8000\n",
      "Episode: 1138 Total reward: 500.0 Training loss: 10.7597 Explore P: 0.0391 RunMean : 345.3900\n",
      "Episode: 1139 Total reward: 500.0 Training loss: 7.6209 Explore P: 0.0387 RunMean : 349.1600\n",
      "Episode: 1140 Total reward: 500.0 Training loss: 3527.7615 Explore P: 0.0383 RunMean : 352.9000\n",
      "Episode: 1141 Total reward: 500.0 Training loss: 6.6908 Explore P: 0.0379 RunMean : 356.5400\n",
      "Episode: 1142 Total reward: 500.0 Training loss: 6.4895 Explore P: 0.0376 RunMean : 359.7200\n",
      "Episode: 1143 Total reward: 500.0 Training loss: 6.0571 Explore P: 0.0372 RunMean : 362.8900\n",
      "Episode: 1144 Total reward: 500.0 Training loss: 3.2595 Explore P: 0.0368 RunMean : 366.3100\n",
      "Episode: 1145 Total reward: 500.0 Training loss: 1761.2198 Explore P: 0.0365 RunMean : 369.1000\n",
      "Episode: 1146 Total reward: 500.0 Training loss: 4.3457 Explore P: 0.0361 RunMean : 372.8700\n",
      "Episode: 1147 Total reward: 500.0 Training loss: 3.1867 Explore P: 0.0357 RunMean : 376.4000\n",
      "Episode: 1148 Total reward: 500.0 Training loss: 3.9926 Explore P: 0.0354 RunMean : 379.7500\n",
      "Episode: 1149 Total reward: 500.0 Training loss: 2289.3242 Explore P: 0.0350 RunMean : 383.1600\n",
      "Episode: 1150 Total reward: 500.0 Training loss: 1.7961 Explore P: 0.0347 RunMean : 386.9600\n",
      "Episode: 1151 Total reward: 500.0 Training loss: 346.3125 Explore P: 0.0343 RunMean : 390.7000\n",
      "Episode: 1152 Total reward: 500.0 Training loss: 3.9556 Explore P: 0.0340 RunMean : 394.0000\n",
      "Episode: 1153 Total reward: 500.0 Training loss: 4.3371 Explore P: 0.0337 RunMean : 397.7000\n",
      "Episode: 1154 Total reward: 396.0 Training loss: 2.6345 Explore P: 0.0334 RunMean : 400.3300\n",
      "Episode: 1155 Total reward: 500.0 Training loss: 6.7436 Explore P: 0.0331 RunMean : 403.5600\n",
      "Episode: 1156 Total reward: 500.0 Training loss: 3.2957 Explore P: 0.0327 RunMean : 406.2900\n",
      "Episode: 1157 Total reward: 500.0 Training loss: 3.7272 Explore P: 0.0324 RunMean : 409.6400\n",
      "Episode: 1158 Total reward: 304.0 Training loss: 47.7170 Explore P: 0.0322 RunMean : 411.0400\n",
      "Episode: 1159 Total reward: 500.0 Training loss: 3.9804 Explore P: 0.0319 RunMean : 414.6900\n",
      "Episode: 1160 Total reward: 500.0 Training loss: 3.3907 Explore P: 0.0316 RunMean : 418.3400\n",
      "Episode: 1161 Total reward: 500.0 Training loss: 73.8503 Explore P: 0.0313 RunMean : 421.2000\n",
      "Episode: 1162 Total reward: 500.0 Training loss: 16.2689 Explore P: 0.0309 RunMean : 424.5300\n",
      "Episode: 1163 Total reward: 500.0 Training loss: 9.5107 Explore P: 0.0306 RunMean : 427.4000\n",
      "Episode: 1164 Total reward: 500.0 Training loss: 520.0219 Explore P: 0.0303 RunMean : 428.8500\n",
      "Episode: 1165 Total reward: 500.0 Training loss: 295.5256 Explore P: 0.0300 RunMean : 430.4200\n",
      "Episode: 1166 Total reward: 500.0 Training loss: 4.6269 Explore P: 0.0297 RunMean : 433.8400\n",
      "Episode: 1167 Total reward: 500.0 Training loss: 6.8201 Explore P: 0.0294 RunMean : 435.7700\n",
      "Episode: 1168 Total reward: 444.0 Training loss: 10.5484 Explore P: 0.0292 RunMean : 436.5100\n",
      "Episode: 1169 Total reward: 500.0 Training loss: 10.1030 Explore P: 0.0289 RunMean : 438.9000\n",
      "Episode: 1170 Total reward: 443.0 Training loss: 7.8204 Explore P: 0.0286 RunMean : 438.3300\n",
      "Episode: 1171 Total reward: 500.0 Training loss: 8.1313 Explore P: 0.0283 RunMean : 438.3300\n",
      "Episode: 1172 Total reward: 151.0 Training loss: 4511.9478 Explore P: 0.0283 RunMean : 438.2900\n",
      "Episode: 1173 Total reward: 222.0 Training loss: 14.5032 Explore P: 0.0281 RunMean : 438.8100\n",
      "Episode: 1174 Total reward: 269.0 Training loss: 15.0809 Explore P: 0.0280 RunMean : 439.0500\n",
      "Episode: 1175 Total reward: 500.0 Training loss: 7.0495 Explore P: 0.0277 RunMean : 442.3300\n",
      "Episode: 1176 Total reward: 500.0 Training loss: 29.5183 Explore P: 0.0274 RunMean : 445.4900\n",
      "Episode: 1177 Total reward: 500.0 Training loss: 9.9568 Explore P: 0.0272 RunMean : 446.1700\n",
      "Episode: 1178 Total reward: 500.0 Training loss: 5.1264 Explore P: 0.0269 RunMean : 449.2300\n",
      "Episode: 1179 Total reward: 341.0 Training loss: 3.6448 Explore P: 0.0267 RunMean : 450.9600\n",
      "Episode: 1180 Total reward: 500.0 Training loss: 10.4107 Explore P: 0.0264 RunMean : 454.4300\n",
      "Episode: 1181 Total reward: 365.0 Training loss: 9.0139 Explore P: 0.0262 RunMean : 455.3600\n",
      "Episode: 1182 Total reward: 500.0 Training loss: 5.8671 Explore P: 0.0260 RunMean : 457.2000\n",
      "Episode: 1183 Total reward: 470.0 Training loss: 8.9330 Explore P: 0.0257 RunMean : 456.9000\n",
      "Episode: 1184 Total reward: 193.0 Training loss: 25.6756 Explore P: 0.0256 RunMean : 455.4900\n",
      "Episode: 1185 Total reward: 500.0 Training loss: 12.5445 Explore P: 0.0254 RunMean : 458.7600\n",
      "Episode: 1186 Total reward: 500.0 Training loss: 553.2048 Explore P: 0.0251 RunMean : 461.4500\n",
      "Episode: 1187 Total reward: 500.0 Training loss: 25.5221 Explore P: 0.0249 RunMean : 461.4500\n",
      "Episode: 1188 Total reward: 500.0 Training loss: 8.2976 Explore P: 0.0246 RunMean : 461.6300\n",
      "Episode: 1189 Total reward: 500.0 Training loss: 13.6986 Explore P: 0.0244 RunMean : 464.4500\n",
      "Episode: 1190 Total reward: 500.0 Training loss: 16.3942 Explore P: 0.0241 RunMean : 466.8500\n",
      "Episode: 1191 Total reward: 500.0 Training loss: 10.2473 Explore P: 0.0239 RunMean : 467.2600\n",
      "Episode: 1192 Total reward: 500.0 Training loss: 10.3293 Explore P: 0.0237 RunMean : 470.2200\n",
      "Episode: 1193 Total reward: 500.0 Training loss: 7.8827 Explore P: 0.0234 RunMean : 473.2800\n",
      "Episode: 1194 Total reward: 500.0 Training loss: 4705.4727 Explore P: 0.0232 RunMean : 474.6200\n",
      "Episode: 1195 Total reward: 500.0 Training loss: 13.5264 Explore P: 0.0230 RunMean : 476.0300\n",
      "Episode: 1196 Total reward: 34.0 Training loss: 15.9388 Explore P: 0.0230 RunMean : 472.3100\n",
      "Episode: 1197 Total reward: 500.0 Training loss: 9.2298 Explore P: 0.0227 RunMean : 472.5900\n",
      "Episode: 1198 Total reward: 155.0 Training loss: 20.9224 Explore P: 0.0227 RunMean : 469.1400\n",
      "Episode: 1199 Total reward: 200.0 Training loss: 30.0157 Explore P: 0.0226 RunMean : 466.1400\n",
      "Episode: 1200 Total reward: 168.0 Training loss: 35.7747 Explore P: 0.0225 RunMean : 462.8200\n",
      "Episode: 1201 Total reward: 198.0 Training loss: 5588.7441 Explore P: 0.0224 RunMean : 460.0300\n",
      "Episode: 1202 Total reward: 500.0 Training loss: 608.8953 Explore P: 0.0222 RunMean : 460.0300\n",
      "Episode: 1203 Total reward: 500.0 Training loss: 8.3314 Explore P: 0.0220 RunMean : 460.0300\n",
      "Episode: 1204 Total reward: 500.0 Training loss: 6.7431 Explore P: 0.0217 RunMean : 460.0300\n",
      "Episode: 1205 Total reward: 500.0 Training loss: 7.6513 Explore P: 0.0215 RunMean : 460.7900\n",
      "Episode: 1206 Total reward: 500.0 Training loss: 8.5812 Explore P: 0.0213 RunMean : 460.7900\n",
      "Episode: 1207 Total reward: 500.0 Training loss: 7.3992 Explore P: 0.0211 RunMean : 461.5300\n",
      "Episode: 1208 Total reward: 500.0 Training loss: 340.3524 Explore P: 0.0209 RunMean : 462.7500\n",
      "Episode: 1209 Total reward: 500.0 Training loss: 10.9189 Explore P: 0.0207 RunMean : 462.7500\n",
      "Episode: 1210 Total reward: 500.0 Training loss: 7.3912 Explore P: 0.0205 RunMean : 462.7500\n",
      "Episode: 1211 Total reward: 483.0 Training loss: 10.0110 Explore P: 0.0203 RunMean : 462.5800\n",
      "Episode: 1212 Total reward: 500.0 Training loss: 10.1310 Explore P: 0.0201 RunMean : 462.5800\n",
      "Episode: 1213 Total reward: 500.0 Training loss: 13.1714 Explore P: 0.0199 RunMean : 462.5800\n",
      "Episode: 1214 Total reward: 500.0 Training loss: 29.6920 Explore P: 0.0197 RunMean : 463.3000\n",
      "Episode: 1215 Total reward: 391.0 Training loss: 13.2807 Explore P: 0.0195 RunMean : 462.2100\n",
      "Episode: 1216 Total reward: 500.0 Training loss: 11.8066 Explore P: 0.0193 RunMean : 462.2100\n",
      "Episode: 1217 Total reward: 500.0 Training loss: 12.1894 Explore P: 0.0191 RunMean : 462.2100\n",
      "Episode: 1218 Total reward: 485.0 Training loss: 16.0579 Explore P: 0.0190 RunMean : 462.1200\n",
      "Episode: 1219 Total reward: 500.0 Training loss: 21.5808 Explore P: 0.0188 RunMean : 462.1200\n",
      "Episode: 1220 Total reward: 500.0 Training loss: 5.4275 Explore P: 0.0186 RunMean : 462.1200\n",
      "Episode: 1221 Total reward: 500.0 Training loss: 12.5550 Explore P: 0.0184 RunMean : 462.1200\n",
      "Episode: 1222 Total reward: 500.0 Training loss: 8.9973 Explore P: 0.0182 RunMean : 462.1200\n",
      "Episode: 1223 Total reward: 500.0 Training loss: 9.7828 Explore P: 0.0180 RunMean : 462.1200\n",
      "Episode: 1224 Total reward: 500.0 Training loss: 6.8750 Explore P: 0.0178 RunMean : 462.1200\n",
      "Episode: 1225 Total reward: 500.0 Training loss: 6.9898 Explore P: 0.0177 RunMean : 462.1200\n",
      "Episode: 1226 Total reward: 500.0 Training loss: 3.4908 Explore P: 0.0175 RunMean : 462.1200\n",
      "Episode: 1227 Total reward: 500.0 Training loss: 3.1449 Explore P: 0.0173 RunMean : 462.1200\n",
      "Episode: 1228 Total reward: 500.0 Training loss: 6.2782 Explore P: 0.0171 RunMean : 462.1200\n",
      "Episode: 1229 Total reward: 500.0 Training loss: 4.7510 Explore P: 0.0170 RunMean : 462.1200\n",
      "Episode: 1230 Total reward: 500.0 Training loss: 4842.1226 Explore P: 0.0168 RunMean : 462.1200\n",
      "Episode: 1231 Total reward: 500.0 Training loss: 5726.2896 Explore P: 0.0166 RunMean : 462.1200\n",
      "Episode: 1232 Total reward: 500.0 Training loss: 6.2184 Explore P: 0.0165 RunMean : 462.1200\n",
      "Episode: 1233 Total reward: 500.0 Training loss: 3.6293 Explore P: 0.0163 RunMean : 462.1200\n",
      "Episode: 1234 Total reward: 500.0 Training loss: 4261.2236 Explore P: 0.0162 RunMean : 462.1200\n",
      "Episode: 1235 Total reward: 500.0 Training loss: 4.3990 Explore P: 0.0160 RunMean : 462.1200\n",
      "Episode: 1236 Total reward: 500.0 Training loss: 5.6884 Explore P: 0.0158 RunMean : 462.1200\n",
      "Episode: 1237 Total reward: 500.0 Training loss: 4.3193 Explore P: 0.0157 RunMean : 462.1200\n",
      "Episode: 1238 Total reward: 500.0 Training loss: 5.8030 Explore P: 0.0155 RunMean : 462.1200\n",
      "Episode: 1239 Total reward: 500.0 Training loss: 4.5010 Explore P: 0.0154 RunMean : 462.1200\n",
      "Episode: 1240 Total reward: 500.0 Training loss: 3.3859 Explore P: 0.0152 RunMean : 462.1200\n",
      "Episode: 1241 Total reward: 500.0 Training loss: 2.8790 Explore P: 0.0151 RunMean : 462.1200\n",
      "Episode: 1242 Total reward: 500.0 Training loss: 3.5204 Explore P: 0.0149 RunMean : 462.1200\n",
      "Episode: 1243 Total reward: 500.0 Training loss: 3.2274 Explore P: 0.0148 RunMean : 462.1200\n",
      "Episode: 1244 Total reward: 500.0 Training loss: 4.3605 Explore P: 0.0146 RunMean : 462.1200\n",
      "Episode: 1245 Total reward: 500.0 Training loss: 3.5075 Explore P: 0.0145 RunMean : 462.1200\n",
      "Episode: 1246 Total reward: 500.0 Training loss: 3.6125 Explore P: 0.0143 RunMean : 462.1200\n",
      "Episode: 1247 Total reward: 500.0 Training loss: 2.6113 Explore P: 0.0142 RunMean : 462.1200\n",
      "Episode: 1248 Total reward: 500.0 Training loss: 3.2972 Explore P: 0.0140 RunMean : 462.1200\n",
      "Episode: 1249 Total reward: 500.0 Training loss: 3.7786 Explore P: 0.0139 RunMean : 462.1200\n",
      "Episode: 1250 Total reward: 500.0 Training loss: 1.8021 Explore P: 0.0138 RunMean : 462.1200\n",
      "Episode: 1251 Total reward: 500.0 Training loss: 1.7062 Explore P: 0.0136 RunMean : 462.1200\n",
      "Episode: 1252 Total reward: 500.0 Training loss: 3.8330 Explore P: 0.0135 RunMean : 462.1200\n",
      "Episode: 1253 Total reward: 500.0 Training loss: 2.0415 Explore P: 0.0134 RunMean : 462.1200\n",
      "Episode: 1254 Total reward: 500.0 Training loss: 2.9250 Explore P: 0.0132 RunMean : 463.1600\n",
      "Episode: 1255 Total reward: 500.0 Training loss: 5154.9375 Explore P: 0.0131 RunMean : 463.1600\n",
      "Episode: 1256 Total reward: 500.0 Training loss: 1.8346 Explore P: 0.0130 RunMean : 463.1600\n",
      "Episode: 1257 Total reward: 500.0 Training loss: 2647.6577 Explore P: 0.0128 RunMean : 463.1600\n",
      "Episode: 1258 Total reward: 500.0 Training loss: 3.0464 Explore P: 0.0127 RunMean : 465.1200\n",
      "Episode: 1259 Total reward: 500.0 Training loss: 1.9205 Explore P: 0.0126 RunMean : 465.1200\n",
      "Episode: 1260 Total reward: 500.0 Training loss: 3.7347 Explore P: 0.0125 RunMean : 465.1200\n",
      "Episode: 1261 Total reward: 500.0 Training loss: 1.9957 Explore P: 0.0123 RunMean : 465.1200\n",
      "Episode: 1262 Total reward: 500.0 Training loss: 2.3961 Explore P: 0.0122 RunMean : 465.1200\n",
      "Episode: 1263 Total reward: 500.0 Training loss: 2349.3696 Explore P: 0.0121 RunMean : 465.1200\n",
      "Episode: 1264 Total reward: 500.0 Training loss: 1.3399 Explore P: 0.0120 RunMean : 465.1200\n",
      "Episode: 1265 Total reward: 500.0 Training loss: 7.1046 Explore P: 0.0118 RunMean : 465.1200\n",
      "Episode: 1266 Total reward: 500.0 Training loss: 2.7225 Explore P: 0.0117 RunMean : 465.1200\n",
      "Episode: 1267 Total reward: 500.0 Training loss: 2.4335 Explore P: 0.0116 RunMean : 465.1200\n",
      "Episode: 1268 Total reward: 500.0 Training loss: 1.9405 Explore P: 0.0115 RunMean : 465.6800\n",
      "Episode: 1269 Total reward: 500.0 Training loss: 1.6077 Explore P: 0.0114 RunMean : 465.6800\n",
      "Episode: 1270 Total reward: 500.0 Training loss: 3.6529 Explore P: 0.0113 RunMean : 466.2500\n",
      "Episode: 1271 Total reward: 500.0 Training loss: 6.1804 Explore P: 0.0112 RunMean : 466.2500\n",
      "Episode: 1272 Total reward: 500.0 Training loss: 2.5011 Explore P: 0.0110 RunMean : 469.7400\n",
      "Episode: 1273 Total reward: 500.0 Training loss: 2.1266 Explore P: 0.0109 RunMean : 472.5200\n",
      "Episode: 1274 Total reward: 500.0 Training loss: 2.9668 Explore P: 0.0108 RunMean : 474.8300\n",
      "Episode: 1275 Total reward: 500.0 Training loss: 2.0203 Explore P: 0.0107 RunMean : 474.8300\n",
      "Episode: 1276 Total reward: 500.0 Training loss: 1.8871 Explore P: 0.0106 RunMean : 474.8300\n",
      "Episode: 1277 Total reward: 500.0 Training loss: 1.9066 Explore P: 0.0105 RunMean : 474.8300\n",
      "Episode: 1278 Total reward: 500.0 Training loss: 2762.7888 Explore P: 0.0104 RunMean : 474.8300\n",
      "Episode: 1279 Total reward: 500.0 Training loss: 1.8935 Explore P: 0.0103 RunMean : 476.4200\n",
      "Episode: 1280 Total reward: 500.0 Training loss: 3.6544 Explore P: 0.0102 RunMean : 476.4200\n",
      "Episode: 1281 Total reward: 500.0 Training loss: 6.5073 Explore P: 0.0101 RunMean : 477.7700\n",
      "Episode: 1282 Total reward: 500.0 Training loss: 2.6560 Explore P: 0.0100 RunMean : 477.7700\n",
      "Episode: 1283 Total reward: 500.0 Training loss: 2.1077 Explore P: 0.0099 RunMean : 478.0700\n",
      "Episode: 1284 Total reward: 500.0 Training loss: 1.6063 Explore P: 0.0098 RunMean : 481.1400\n",
      "Episode: 1285 Total reward: 500.0 Training loss: 1.6792 Explore P: 0.0097 RunMean : 481.1400\n",
      "Episode: 1286 Total reward: 500.0 Training loss: 1.7711 Explore P: 0.0096 RunMean : 481.1400\n",
      "Episode: 1287 Total reward: 500.0 Training loss: 3.7865 Explore P: 0.0095 RunMean : 481.1400\n",
      "Episode: 1288 Total reward: 500.0 Training loss: 2.3066 Explore P: 0.0094 RunMean : 481.1400\n",
      "Episode: 1289 Total reward: 500.0 Training loss: 1.8047 Explore P: 0.0093 RunMean : 481.1400\n",
      "Episode: 1290 Total reward: 500.0 Training loss: 4.0448 Explore P: 0.0092 RunMean : 481.1400\n",
      "Episode: 1291 Total reward: 500.0 Training loss: 1.4714 Explore P: 0.0091 RunMean : 481.1400\n",
      "Episode: 1292 Total reward: 500.0 Training loss: 2.4251 Explore P: 0.0090 RunMean : 481.1400\n",
      "Episode: 1293 Total reward: 500.0 Training loss: 3.8276 Explore P: 0.0090 RunMean : 481.1400\n",
      "Episode: 1294 Total reward: 500.0 Training loss: 2.1279 Explore P: 0.0089 RunMean : 481.1400\n",
      "Episode: 1295 Total reward: 500.0 Training loss: 2.8712 Explore P: 0.0088 RunMean : 481.1400\n",
      "Episode: 1296 Total reward: 500.0 Training loss: 1.5609 Explore P: 0.0087 RunMean : 485.8000\n",
      "Episode: 1297 Total reward: 500.0 Training loss: 1.4464 Explore P: 0.0086 RunMean : 485.8000\n",
      "Episode: 1298 Total reward: 500.0 Training loss: 1.4813 Explore P: 0.0085 RunMean : 489.2500\n",
      "Episode: 1299 Total reward: 500.0 Training loss: 5.0250 Explore P: 0.0084 RunMean : 492.2500\n",
      "Episode: 1300 Total reward: 500.0 Training loss: 2.2195 Explore P: 0.0083 RunMean : 495.5700\n",
      "average training reward =  183.926210607\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-23 00:28:11,926] Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test reward =  500.0000000000452\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e1576820b7cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmainQN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_and_train_qnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m                                     \u001b[0mtrain_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.999\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mexplore_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mexplore_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00002\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mhidden_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mhidden_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAF5CAYAAABeAGpJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh8PhcDimNP8fbIvRLU9KcTUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22229823240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gym import wrappers\n",
    "    \n",
    "env = gym.make('CartPole-v1')\n",
    "#env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\n",
    "\n",
    "test,train, mainQN, saver, num_episodes = test_and_train_qnetwork(memory_size=10000,\\\n",
    "                                     train_episodes=4000,\\\n",
    "                                           gamma=0.999,\\\n",
    "                                           explore_start=1.,\\\n",
    "                                           explore_stop=0.0,\\\n",
    "                                           decay_rate=0.00002,\\\n",
    "                                           hidden_layers=1,\\\n",
    "                                           hidden_size=64,\\\n",
    "                                           learning_rate=0.001,\\\n",
    "                                           batch_size=64,\\\n",
    "                                           alpha=0.1,\\\n",
    "                                           verbose=True)\n",
    "print('test=',str(test))\n",
    "print(train)\n",
    "print('number of episodes=',str(num_episodes))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 23:50:18,379] Making new env: CartPole-v0\n",
      "[2017-05-22 23:50:18,382] Clearing 4 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 23:50:18,392] Restoring parameters from checkpoints\\cartpole.ckpt\n",
      "[2017-05-22 23:50:18,484] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000000.mp4\n",
      "[2017-05-22 23:50:21,927] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000001.mp4\n",
      "[2017-05-22 23:50:25,823] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000008.mp4\n",
      "[2017-05-22 23:50:30,765] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000027.mp4\n",
      "[2017-05-22 23:50:37,157] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000064.mp4\n",
      "[2017-05-22 23:50:45,686] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.9999999998906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Monitor.close of <Monitor<TimeLimit<CartPoleEnv<CartPole-v0>>>>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\n",
    "avg_test_rewards = test_q_network(mainQN, saver, test_episodes=200, render=False)\n",
    "print(avg_test_rewards)\n",
    "env.close\n",
    "#     if verbose:\n",
    "#         print('average test reward = ', avg_test_rewards)\n",
    "    \n",
    "#     return avg_test_rewards, avg_train_rewards, mainQN, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 23:52:13,462] Finished writing results. You can upload them to the scoreboard via gym.upload('D:\\\\tmp\\\\cartpole-experiment-1')\n",
      "[2017-05-22 23:52:13,463] [CartPole-v0] Uploading 200 episodes of training data\n",
      "[2017-05-22 23:52:14,715] [CartPole-v0] Uploading videos of 6 training episodes (79922 bytes)\n",
      "[2017-05-22 23:52:15,216] [CartPole-v0] Creating evaluation object from /tmp/cartpole-experiment-1 with learning curve and training video\n",
      "[2017-05-22 23:52:15,550] \n",
      "****************************************************\n",
      "You successfully uploaded your evaluation on CartPole-v0 to\n",
      "OpenAI Gym! You can find it at:\n",
      "\n",
      "    https://gym.openai.com/evaluations/eval_XidnJOdDQlK8HQV5xk1QRA\n",
      "\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "gym.upload('/tmp/cartpole-experiment-1', api_key='sk_2nAEHbARwKPuKcao8nWRw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 21:43:41,579] Making new env: CartPole-v0\n",
      "[2017-05-22 21:43:41,580] Clearing 3 monitor files from previous run (because force=True was provided)\n",
      "[2017-05-22 21:43:41,585] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-2\\openaigym.video.0.2340.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03158918  0.01501189 -0.04439814  0.02392597]\n",
      "[-0.03128894 -0.17944616 -0.04391962  0.30227684]\n",
      "[-0.03487786  0.01627333 -0.03787408 -0.00392752]\n",
      "[-0.0345524   0.21191741 -0.03795263 -0.3083155 ]\n",
      "[-0.03031405  0.0173562  -0.04411894 -0.02783925]\n",
      "[-0.02996692  0.21308217 -0.04467573 -0.33410928]\n",
      "[-0.02570528  0.40881056 -0.05135791 -0.64053921]\n",
      "[-0.01752907  0.60460946 -0.0641687  -0.9489429 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 21:43:43,488] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-2\\openaigym.video.0.2340.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00543688  0.80053387 -0.08314756 -1.26107733]\n",
      "[ 0.0105738   0.99661498 -0.1083691  -1.57860008]\n",
      "[ 0.0305061   1.19284804 -0.1399411  -1.90302116]\n",
      "[ 0.05436306  1.38917853 -0.17800153 -2.2356465 ]\n",
      "Episode finished after 12 timesteps\n",
      "[ 0.01721082 -0.01583853 -0.02459659  0.00499927]\n",
      "[ 0.01689405 -0.21059925 -0.02449661  0.28982131]\n",
      "[ 0.01268206 -0.01513671 -0.01870018 -0.01048581]\n",
      "[ 0.01237933 -0.20998555 -0.0189099   0.27623882]\n",
      "[ 0.00817962 -0.40483268 -0.01338512  0.56289808]\n",
      "[  8.29628614e-05  -5.99764277e-01  -2.12716057e-03   8.51334169e-01]\n",
      "[-0.01191232 -0.79485716  0.01489952  1.14334745]\n",
      "[-0.02780947 -0.99017059  0.03776647  1.44066537]\n",
      "[-0.04761288 -0.7955336   0.06657978  1.16001877]\n",
      "[-0.06352355 -0.99145678  0.08978015  1.47281241]\n",
      "[-0.08335269 -0.79753982  0.1192364   1.2094684 ]\n",
      "[-0.09930348 -0.60414221  0.14342577  0.95640423]\n",
      "[-0.11138633 -0.80087136  0.16255386  1.29049072]\n",
      "[-0.12740375 -0.99764366  0.18836367  1.6293388 ]\n",
      "Episode finished after 14 timesteps\n",
      "[ 0.00567666 -0.00429267 -0.02422598 -0.0220614 ]\n",
      "[ 0.0055908   0.19116817 -0.02466721 -0.32228838]\n",
      "[ 0.00941417  0.38663254 -0.03111298 -0.62264717]\n",
      "[ 0.01714682  0.5821748  -0.04356592 -0.92496434]\n",
      "[ 0.02879031  0.3876675  -0.06206521 -0.64628455]\n",
      "[ 0.03654366  0.58359685 -0.0749909  -0.95784816]\n",
      "[ 0.0482156   0.38955898 -0.09414786 -0.68963604]\n",
      "[ 0.05600678  0.58585263 -0.10794058 -1.01041114]\n",
      "[ 0.06772383  0.39232375 -0.12814881 -0.75348026]\n",
      "[ 0.07557031  0.58895772 -0.14321841 -1.08358537]\n",
      "[ 0.08734946  0.78564897 -0.16489012 -1.41756401]\n",
      "[ 0.10306244  0.59290733 -0.1932414  -1.18063128]\n",
      "Episode finished after 12 timesteps\n",
      "[ 0.046459   -0.00798891 -0.0432039  -0.03734576]\n",
      "[ 0.04629922  0.1877251  -0.04395081 -0.34334084]\n",
      "[ 0.05005372 -0.00674493 -0.05081763 -0.06483487]\n",
      "[ 0.04991882 -0.20110285 -0.05211433  0.2113917 ]\n",
      "[ 0.04589677 -0.005276   -0.04788649 -0.09726445]\n",
      "[ 0.04579125 -0.19968009 -0.04983178  0.17993415]\n",
      "[ 0.04179764 -0.00388178 -0.0462331  -0.12804321]\n",
      "[ 0.04172001  0.19187094 -0.04879396 -0.43494623]\n",
      "[ 0.04555743  0.38764848 -0.05749289 -0.74260275]\n",
      "[ 0.0533104   0.58351491 -0.07234494 -1.05281056]\n",
      "[ 0.06498069  0.77951769 -0.09340115 -1.36729654]\n",
      "[ 0.08057105  0.58568073 -0.12074709 -1.10522846]\n",
      "[ 0.09228466  0.78216544 -0.14285165 -1.43322304]\n",
      "[ 0.10792797  0.5890655  -0.17151612 -1.18837919]\n",
      "[ 0.11970928  0.78594449 -0.1952837  -1.52954336]\n",
      "Episode finished after 15 timesteps\n",
      "[ 0.01739391 -0.02319332 -0.02043269 -0.02869286]\n",
      "[ 0.01693004  0.1722156  -0.02100654 -0.32775184]\n",
      "[ 0.02037435  0.36763022 -0.02756158 -0.62698457]\n",
      "[ 0.02772696  0.17290359 -0.04010127 -0.34310764]\n",
      "[ 0.03118503  0.36857242 -0.04696343 -0.64816154]\n",
      "[ 0.03855648  0.17413512 -0.05992666 -0.37062933]\n",
      "[ 0.04203918 -0.02008651 -0.06733924 -0.09742775]\n",
      "[ 0.04163745  0.17593271 -0.0692878  -0.41057295]\n",
      "[ 0.0451561   0.37196503 -0.07749926 -0.72427021]\n",
      "[ 0.05259541  0.17799554 -0.09198466 -0.45695127]\n",
      "[ 0.05615532  0.37428936 -0.10112369 -0.77715259]\n",
      "[ 0.0636411   0.18069269 -0.11666674 -0.51792082]\n",
      "[ 0.06725496  0.37724734 -0.12702516 -0.84497083]\n",
      "[ 0.0747999   0.18406619 -0.14392457 -0.59477881]\n",
      "[ 0.07848123 -0.00877928 -0.15582015 -0.35066932]\n",
      "[ 0.07830564 -0.20138175 -0.16283353 -0.11089178]\n",
      "[ 0.07427801 -0.39384133 -0.16505137  0.126317  ]\n",
      "[ 0.06640118 -0.58626143 -0.16252503  0.36271956]\n",
      "[ 0.05467595 -0.38924767 -0.15527064  0.02352106]\n",
      "[ 0.046891   -0.1922793  -0.15480022 -0.31384349]\n",
      "[ 0.04304541 -0.38489626 -0.16107709 -0.07370263]\n",
      "[ 0.03534749 -0.57738644 -0.16255114  0.16414285]\n",
      "[ 0.02379976 -0.76985343 -0.15926828  0.40145772]\n",
      "[ 0.00840269 -0.57287323 -0.15123913  0.06309986]\n",
      "[-0.00305478 -0.37594289 -0.14997713 -0.27321875]\n",
      "[-0.01057363 -0.56864216 -0.15544151 -0.03134273]\n",
      "[-0.02194648 -0.37167227 -0.15606836 -0.36875134]\n",
      "[-0.02937992 -0.56427228 -0.16344339 -0.12906066]\n",
      "[-0.04066537 -0.75672154 -0.1660246   0.10792733]\n",
      "[-0.0557998  -0.55965776 -0.16386605 -0.23219106]\n",
      "[-0.06699295 -0.75210532 -0.16850988  0.00465192]\n",
      "[-0.08203506 -0.55501781 -0.16841684 -0.33609973]\n",
      "[-0.09313542 -0.35794955 -0.17513883 -0.67680055]\n",
      "[-0.10029441 -0.16088257 -0.18867484 -1.01910703]\n",
      "[-0.10351206  0.03618421 -0.20905698 -1.36460325]\n",
      "Episode finished after 35 timesteps\n",
      "[ 0.02298201 -0.00600255 -0.0044421  -0.04751785]\n",
      "[ 0.02286196  0.18918281 -0.00539245 -0.34159898]\n",
      "[ 0.02664562 -0.005862   -0.01222443 -0.05062139]\n",
      "[ 0.02652838  0.18943308 -0.01323686 -0.34713602]\n",
      "[ 0.03031704  0.38474078 -0.02017958 -0.64396343]\n",
      "[ 0.03801186  0.1899058  -0.03305885 -0.35770285]\n",
      "[ 0.04180997 -0.00473095 -0.04021291 -0.07562478]\n",
      "[ 0.04171535  0.19094373 -0.0417254  -0.38071892]\n",
      "[ 0.04553423 -0.00356165 -0.04933978 -0.10147851]\n",
      "[ 0.04546299 -0.19794304 -0.05136935  0.17523874]\n",
      "[ 0.04150413 -0.00212499 -0.04786458 -0.13319683]\n",
      "[ 0.04146163  0.19364874 -0.05052851 -0.44058791]\n",
      "[ 0.04533461 -0.00072308 -0.05934027 -0.16425136]\n",
      "[ 0.04532015  0.19519592 -0.0626253  -0.4750484 ]\n",
      "[ 0.04922407  0.00101164 -0.07212627 -0.20274278]\n",
      "[ 0.0492443  -0.19300867 -0.07618112  0.06634427]\n",
      "[ 0.04538413  0.00311816 -0.07485424 -0.2493683 ]\n",
      "[ 0.04544649 -0.19085943 -0.0798416   0.01879671]\n",
      "[ 0.0416293  -0.38475098 -0.07946567  0.28525902]\n",
      "[ 0.03393428 -0.57865496 -0.07376049  0.55185881]\n",
      "[ 0.02236118 -0.38257882 -0.06272331  0.23687839]\n",
      "[ 0.0147096  -0.18661945 -0.05798574 -0.07491121]\n",
      "[ 0.01097722 -0.38086425 -0.05948397  0.19892802]\n",
      "[ 0.00335993 -0.18494418 -0.05550541 -0.11191028]\n",
      "[ -3.38953218e-04  -3.79228664e-01  -5.77436144e-02   1.62757421e-01]\n",
      "[-0.00792353 -0.57347848 -0.05448847  0.43667932]\n",
      "[-0.0193931  -0.76778849 -0.04575488  0.71170008]\n",
      "[-0.03474887 -0.962248   -0.03152088  0.98963683]\n",
      "[-0.05399383 -1.15693416 -0.01172814  1.27225541]\n",
      "[-0.07713251 -0.96166451  0.01371697  0.97592308]\n",
      "[-0.0963658  -1.15696773  0.03323543  1.27288301]\n",
      "[-0.11950515 -0.96228527  0.05869309  0.99079001]\n",
      "[-0.13875086 -1.15814155  0.07850889  1.3013144 ]\n",
      "[-0.16191369 -0.96409867  0.10453518  1.03420454]\n",
      "[-0.18119566 -0.77051035  0.12521927  0.77608461]\n",
      "[-0.19660587 -0.57731262  0.14074096  0.52527537]\n",
      "[-0.20815212 -0.38442252  0.15124647  0.28004245]\n",
      "[-0.21584057 -0.19174526  0.15684732  0.03862308]\n",
      "[-0.21967548 -0.38872801  0.15761978  0.37639442]\n",
      "[-0.22745004 -0.19615479  0.16514767  0.13726396]\n",
      "[-0.23137313 -0.00373597  0.16789295 -0.09910422]\n",
      "[-0.23144785  0.1886317   0.16591086 -0.33446945]\n",
      "[-0.22767522  0.38105168  0.15922147 -0.57058173]\n",
      "[-0.22005419  0.18409729  0.14780984 -0.23227348]\n",
      "[-0.21637224  0.37683205  0.14316437 -0.47492522]\n",
      "[-0.2088356   0.56967292  0.13366586 -0.71928053]\n",
      "[-0.19744214  0.37297963  0.11928025 -0.38769151]\n",
      "[-0.18998255  0.17638435  0.11152642 -0.05990865]\n",
      "[-0.18645486  0.36974522  0.11032825 -0.31542719]\n",
      "[-0.17905996  0.17323881  0.10401971  0.00991103]\n",
      "[-0.17559518 -0.02320922  0.10421793  0.33351699]\n",
      "[-0.17605937 -0.21964817  0.11088827  0.6571613 ]\n",
      "[-0.18045233 -0.41612474  0.12403149  0.98260046]\n",
      "[-0.18877482 -0.22286329  0.1436835   0.73130709]\n",
      "[-0.19323209 -0.02998838  0.15830964  0.48707374]\n",
      "[-0.19383186 -0.22694831  0.16805112  0.82516809]\n",
      "[-0.19837082 -0.42392091  0.18455448  1.16563956]\n",
      "[-0.20684924 -0.23161665  0.20786727  0.93603322]\n",
      "Episode finished after 58 timesteps\n",
      "[-0.03783027 -0.01103463  0.01544723 -0.04519796]\n",
      "[-0.03805097  0.18386244  0.01454327 -0.3329674 ]\n",
      "[-0.03437372  0.37877441  0.00788392 -0.62102886]\n",
      "[-0.02679823  0.57378538 -0.00453665 -0.91121837]\n",
      "[-0.01532252  0.76896842 -0.02276102 -1.2053237 ]\n",
      "[  5.68478771e-05   5.74147910e-01  -4.68674957e-02  -9.19859785e-01]\n",
      "[ 0.01153981  0.37968968 -0.06526469 -0.64226673]\n",
      "[ 0.0191336   0.18553524 -0.07811003 -0.37082931]\n",
      "[ 0.0228443   0.381675   -0.08552661 -0.68708289]\n",
      "[ 0.0304778   0.18783781 -0.09926827 -0.42250404]\n",
      "[ 0.03423456  0.38421569 -0.10771835 -0.74475766]\n",
      "[ 0.04191887  0.58064625 -0.1226135  -1.06930371]\n",
      "[ 0.0535318   0.77715756 -0.14399958 -1.39781579]\n",
      "[ 0.06907495  0.5840897  -0.17195589 -1.15340112]\n",
      "[ 0.08075674  0.78098553 -0.19502392 -1.49469538]\n",
      "Episode finished after 15 timesteps\n",
      "[-0.04240573 -0.01728493  0.0278611  -0.00057409]\n",
      "[-0.04275143 -0.21279514  0.02784961  0.30076751]\n",
      "[-0.04700734 -0.01808098  0.03386497  0.01699625]\n",
      "[-0.04736895 -0.21367181  0.03420489  0.32016869]\n",
      "[-0.05164239 -0.01905326  0.04060826  0.0384659 ]\n",
      "[-0.05202346  0.17546355  0.04137758 -0.24113323]\n",
      "[-0.04851419 -0.02022429  0.03655492  0.06430883]\n",
      "[-0.04891867 -0.21585076  0.03784109  0.36829725]\n",
      "[-0.05323569 -0.02128636  0.04520704  0.0877822 ]\n",
      "[-0.05366141 -0.21702617  0.04696268  0.39437829]\n",
      "[-0.05800194 -0.02260098  0.05485025  0.11686399]\n",
      "[-0.05845396 -0.21846418  0.05718753  0.42633485]\n",
      "[-0.06282324 -0.02419689  0.06571423  0.15221427]\n",
      "[-0.06330718 -0.22019525  0.06875851  0.46488331]\n",
      "[-0.06771108 -0.02610884  0.07805618  0.19464069]\n",
      "[-0.06823326 -0.22225554  0.08194899  0.51089011]\n",
      "[-0.07267837 -0.02837781  0.09216679  0.24511553]\n",
      "[-0.07324593 -0.22468703  0.0970691   0.56538824]\n",
      "[-0.07773967 -0.4210272   0.10837687  0.8870056 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 21:43:46,601] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-2\\openaigym.video.0.2340.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08616021 -0.61744012  0.12611698  1.21169691]\n",
      "[-0.09850901 -0.42415134  0.15035092  0.96104664]\n",
      "[-0.10699204 -0.62093918  0.16957185  1.29693513]\n",
      "[-0.11941082 -0.42832723  0.19551055  1.06177668]\n",
      "Episode finished after 23 timesteps\n",
      "[ 0.01929627 -0.04759821  0.01128067 -0.03405203]\n",
      "[ 0.0183443   0.14736017  0.01059963 -0.32315455]\n",
      "[ 0.02129151 -0.0479111   0.00413654 -0.02714787]\n",
      "[ 0.02033328 -0.24309212  0.00359359  0.26683731]\n",
      "[ 0.01547144 -0.43826518  0.00893033  0.56065151]\n",
      "[ 0.00670614 -0.63351132  0.02014336  0.85613453]\n",
      "[-0.00596409 -0.82890187  0.03726605  1.15508265]\n",
      "[-0.02254213 -0.63428515  0.06036771  0.87431393]\n",
      "[-0.03522783 -0.83017359  0.07785398  1.18534868]\n",
      "[-0.0518313  -1.0262142   0.10156096  1.50138481]\n",
      "[-0.07235558 -0.83246154  0.13158865  1.24206102]\n",
      "[-0.08900482 -1.02900389  0.15642987  1.57290131]\n",
      "[-0.10958489 -1.22560767  0.1878879   1.91000915]\n",
      "Episode finished after 13 timesteps\n",
      "[-0.02936307  0.04969574  0.03889237  0.02069656]\n",
      "[-0.02836916  0.24423898  0.0393063  -0.25946615]\n",
      "[-0.02348438  0.04857858  0.03411698  0.04535083]\n",
      "[-0.02251281 -0.14701555  0.03502399  0.34859975]\n",
      "[-0.02545312  0.0475912   0.04199599  0.06716358]\n",
      "[-0.02450129 -0.1481069   0.04333926  0.37279511]\n",
      "[-0.02746343  0.04637344  0.05079516  0.09408627]\n",
      "[-0.02653596 -0.14943836  0.05267689  0.40235249]\n",
      "[-0.02952473 -0.34526634  0.06072394  0.71116685]\n",
      "[-0.03643006 -0.15103551  0.07494727  0.43819947]\n",
      "[-0.03945077  0.04295005  0.08371126  0.17005185]\n",
      "[-0.03859177 -0.15326411  0.0871123   0.48792483]\n",
      "[-0.04165705 -0.34950017  0.0968708   0.8067414 ]\n",
      "[-0.04864705 -0.54580693  0.11300562  1.12825652]\n",
      "[-0.05956319 -0.35233186  0.13557076  0.87304797]\n",
      "[-0.06660983 -0.15928798  0.15303171  0.62587492]\n",
      "[-0.06979559 -0.35617751  0.16554921  0.96257371]\n",
      "[-0.07691914 -0.55309028  0.18480069  1.30235404]\n",
      "Episode finished after 18 timesteps\n",
      "[ 0.0288528  -0.01424239  0.03316189 -0.01845229]\n",
      "[ 0.02856796 -0.20982384  0.03279284  0.28450639]\n",
      "[ 0.02437148 -0.40539778  0.03848297  0.58734895]\n",
      "[ 0.01626352 -0.21083531  0.05022995  0.30703252]\n",
      "[ 0.01204682 -0.40663569  0.0563706   0.61512405]\n",
      "[ 0.0039141  -0.21234479  0.06867308  0.3407148 ]\n",
      "[ -3.32792617e-04  -4.08373210e-01   7.54873785e-02   6.54238373e-01]\n",
      "[-0.00850026 -0.60446056  0.08857215  0.96970398]\n",
      "[-0.02058947 -0.80065265  0.10796623  1.28884471]\n",
      "[-0.03660252 -0.60705694  0.13374312  1.03182245]\n",
      "[-0.04874366 -0.41394302  0.15437957  0.78394177]\n",
      "[-0.05702252 -0.22124128  0.1700584   0.54353435]\n",
      "[-0.06144735 -0.41829361  0.18092909  0.88460562]\n",
      "[-0.06981322 -0.61534984  0.1986212   1.22826854]\n",
      "Episode finished after 14 timesteps\n",
      "[ 0.02402884  0.03851564 -0.01227161 -0.01467831]\n",
      "[ 0.02479915  0.23381141 -0.01256518 -0.31120768]\n",
      "[ 0.02947538  0.4291101  -0.01878933 -0.60782666]\n",
      "[ 0.03805758  0.62448964 -0.03094587 -0.90636797]\n",
      "[ 0.05054737  0.42980005 -0.04907323 -0.62357004]\n",
      "[ 0.05914337  0.23539637 -0.06154463 -0.34673731]\n",
      "[ 0.0638513   0.04120137 -0.06847937 -0.07407901]\n",
      "[ 0.06467533  0.23723483 -0.06996095 -0.3875572 ]\n",
      "[ 0.06942002  0.43327651 -0.0777121  -0.70145211]\n",
      "[ 0.07808555  0.23931285 -0.09174114 -0.43420909]\n",
      "[ 0.08287181  0.43560574 -0.10042532 -0.7543443 ]\n",
      "[ 0.09158393  0.2420011  -0.11551221 -0.49487597]\n",
      "[ 0.09642395  0.04868144 -0.12540973 -0.24071404]\n",
      "[ 0.09739758  0.24535093 -0.13022401 -0.57017536]\n",
      "[ 0.10230459  0.05227259 -0.14162751 -0.32118782]\n",
      "[ 0.10335005  0.24909747 -0.14805127 -0.65496854]\n",
      "[ 0.108332    0.44593667 -0.16115064 -0.99036556]\n",
      "[ 0.11725073  0.64280555 -0.18095795 -1.32901621]\n",
      "[ 0.13010684  0.83968967 -0.20753828 -1.67243199]\n",
      "Episode finished after 19 timesteps\n",
      "[  4.65557646e-02  -8.98761061e-05   4.96372319e-02   4.58966789e-02]\n",
      "[ 0.04655397 -0.19588716  0.05055517  0.35381822]\n",
      "[ 0.04263622 -0.39169015  0.05763153  0.66200435]\n",
      "[ 0.03480242 -0.19741543  0.07087162  0.38801036]\n",
      "[ 0.03085411 -0.00336727  0.07863182  0.11848764]\n",
      "[ 0.03078677  0.19054515  0.08100158 -0.1483883 ]\n",
      "[ 0.03459767 -0.00563769  0.07803381  0.16870951]\n",
      "[ 0.03448492  0.18828562  0.081408   -0.09837159]\n",
      "[ 0.03825063  0.38215218  0.07944057 -0.36430083]\n",
      "[ 0.04589367  0.57606054  0.07215455 -0.63091511]\n",
      "[ 0.05741488  0.77010549  0.05953625 -0.90003013]\n",
      "[ 0.07281699  0.57422948  0.04153565 -0.58924336]\n",
      "[ 0.08430158  0.37855128  0.02975078 -0.28377126]\n",
      "[ 0.09187261  0.57323655  0.02407536 -0.56692449]\n",
      "[ 0.10333734  0.76801265  0.01273687 -0.85192649]\n",
      "[ 0.11869759  0.57271939 -0.00430166 -0.55526583]\n",
      "[ 0.13015198  0.3776581  -0.01540698 -0.26394128]\n",
      "[ 0.13770514  0.18275941 -0.02068581  0.02384258]\n",
      "[ 0.14136033  0.37817181 -0.02020895 -0.27529451]\n",
      "[ 0.14892377  0.57357618 -0.02571484 -0.57428223]\n",
      "[ 0.16039529  0.378824   -0.03720049 -0.28980988]\n",
      "[ 0.16797177  0.57445612 -0.04299669 -0.59398946]\n",
      "[ 0.17946089  0.77015269 -0.05487648 -0.89990015]\n",
      "[ 0.19486395  0.96597364 -0.07287448 -1.20931499]\n",
      "[ 0.21418342  1.16195711 -0.09706078 -1.52391608]\n",
      "[ 0.23742256  1.35810798 -0.1275391  -1.84524863]\n",
      "[ 0.26458472  1.1646019  -0.16444407 -1.59474194]\n",
      "[ 0.28787676  0.97176798 -0.19633891 -1.35752216]\n",
      "Episode finished after 28 timesteps\n",
      "[ 0.04812963  0.03402094 -0.04908267  0.04699764]\n",
      "[ 0.04881005  0.22981108 -0.04814272 -0.26075841]\n",
      "[ 0.05340627  0.03540825 -0.05335789  0.01635948]\n",
      "[ 0.05411444  0.23125321 -0.0530307  -0.29266964]\n",
      "[ 0.0587395   0.03692589 -0.05888409 -0.01717216]\n",
      "[ 0.05947802  0.23284071 -0.05922753 -0.32783698]\n",
      "[ 0.06413483  0.42875365 -0.06578427 -0.63859382]\n",
      "[ 0.07270991  0.23460766 -0.07855615 -0.36733137]\n",
      "[ 0.07740206  0.04068474 -0.08590278 -0.10041583]\n",
      "[ 0.07821575 -0.15310775 -0.08791109  0.16397667]\n",
      "[ 0.0751536   0.04315549 -0.08463156 -0.15509391]\n",
      "[ 0.07601671 -0.15065916 -0.08773344  0.10973555]\n",
      "[ 0.07300353 -0.34442152 -0.08553873  0.37350068]\n",
      "[ 0.0661151  -0.14819522 -0.07806871  0.05511967]\n",
      "[ 0.06315119  0.04795428 -0.07696632 -0.26113732]\n",
      "[ 0.06411028  0.24408573 -0.08218907 -0.5770693 ]\n",
      "[ 0.06899199  0.44025767 -0.09373045 -0.89447031]\n",
      "[ 0.07779715  0.24652322 -0.11161986 -0.63266063]\n",
      "[ 0.08272761  0.44301082 -0.12427307 -0.95830605]\n",
      "[ 0.09158783  0.24975903 -0.14343919 -0.70710621]\n",
      "[ 0.09658301  0.05688476 -0.15758132 -0.46279262]\n",
      "[ 0.0977207  -0.13570023 -0.16683717 -0.22363181]\n",
      "[ 0.0950067  -0.32809353 -0.1713098   0.01212814]\n",
      "[ 0.08844483 -0.13098169 -0.17106724 -0.32933081]\n",
      "[ 0.08582519  0.06611009 -0.17765386 -0.67070209]\n",
      "[ 0.08714739  0.26319865 -0.1910679  -1.0136379 ]\n",
      "Episode finished after 26 timesteps\n",
      "[ 0.03257094 -0.04544678 -0.03526248  0.02116087]\n",
      "[ 0.031662    0.15016266 -0.03483926 -0.28243591]\n",
      "[ 0.03466526 -0.04444548 -0.04048798 -0.00094151]\n",
      "[ 0.03377635 -0.23896409 -0.04050681  0.27869707]\n",
      "[ 0.02899707 -0.0432884  -0.03493287 -0.02648145]\n",
      "[ 0.0281313   0.15231665 -0.0354625  -0.3299782 ]\n",
      "[ 0.03117763  0.347925   -0.04206206 -0.63363004]\n",
      "[ 0.03813613  0.54360769 -0.05473467 -0.93925705]\n",
      "[ 0.04900829  0.73942308 -0.07351981 -1.24862422]\n",
      "[ 0.06379675  0.93540652 -0.09849229 -1.56340061]\n",
      "[ 0.08250488  0.74159062 -0.1297603  -1.30299567]\n",
      "[ 0.09733669  0.54833124 -0.15582022 -1.05358628]\n",
      "[ 0.10830331  0.74513699 -0.17689194 -1.39084432]\n",
      "[ 0.12320605  0.94196517 -0.20470883 -1.73321487]\n",
      "Episode finished after 14 timesteps\n",
      "[ 0.02952904 -0.04796749 -0.03110508 -0.0454169 ]\n",
      "[ 0.02856969  0.14758636 -0.03201342 -0.34774921]\n",
      "[ 0.03152141  0.34314868 -0.0389684  -0.65035272]\n",
      "[ 0.03838439  0.53879113 -0.05197546 -0.95504741]\n",
      "[ 0.04916021  0.73457225 -0.07107641 -1.26359642]\n",
      "[ 0.06385165  0.93052717 -0.09634834 -1.57766554]\n",
      "[ 0.0824622   1.12665595 -0.12790165 -1.89877687]\n",
      "[ 0.10499532  1.32290997 -0.16587718 -2.22825396]\n",
      "Episode finished after 8 timesteps\n",
      "[ 0.04305961  0.0322213   0.03516371 -0.04491327]\n",
      "[ 0.04370403 -0.16338678  0.03426544  0.25865346]\n",
      "[ 0.0404363  -0.35898073  0.03943851  0.56194423]\n",
      "[ 0.03325668 -0.5546333   0.0506774   0.86678679]\n",
      "[ 0.02216402 -0.36023626  0.06801313  0.59045837]\n",
      "[ 0.01495929 -0.16612919  0.0798223   0.31995138]\n",
      "[ 0.01163671  0.0277706   0.08622133  0.05347063]\n",
      "[ 0.01219212 -0.16847505  0.08729074  0.37206326]\n",
      "[ 0.00882262  0.02530539  0.094732    0.10813022]\n",
      "[ 0.00932873  0.21895116  0.09689461 -0.15322649]\n",
      "[ 0.01370775  0.41256181  0.09383008 -0.41383777]\n",
      "[ 0.02195899  0.60623724  0.08555332 -0.67552742]\n",
      "[ 0.03408373  0.80007269  0.07204278 -0.94009518]\n",
      "[ 0.05008519  0.9941535   0.05324087 -1.20929898]\n",
      "[ 0.06996826  1.18854898  0.02905489 -1.48483361]\n",
      "[  9.37392350e-02   9.93085136e-01  -6.41779686e-04  -1.18322064e+00]\n",
      "[ 0.11360094  0.79797152 -0.02430619 -0.89073896]\n",
      "[ 0.12956037  0.60318762 -0.04212097 -0.60579474]\n",
      "[ 0.14162412  0.40867919 -0.05423687 -0.32667078]\n",
      "[ 0.1497977   0.6045297  -0.06077028 -0.63595237]\n",
      "[ 0.1618883   0.8004442  -0.07348933 -0.94713712]\n",
      "[ 0.17789718  0.60638469 -0.09243207 -0.67841997]\n",
      "[ 0.19002488  0.80266092 -0.10600047 -0.99871386]\n",
      "[ 0.20607809  0.60910339 -0.12597475 -0.74111298]\n",
      "[ 0.21826016  0.41592486 -0.14079701 -0.49058008]\n",
      "[ 0.22657866  0.61272293 -0.15060861 -0.82411376]\n",
      "[ 0.23883312  0.41994654 -0.16709088 -0.58233426]\n",
      "[ 0.24723205  0.61696669 -0.17873757 -0.92264501]\n",
      "[ 0.25957138  0.42465098 -0.19719047 -0.69103664]\n",
      "Episode finished after 29 timesteps\n",
      "[ 0.00869642 -0.0317159   0.03414911 -0.00617802]\n",
      "[ 0.0080621  -0.22731054  0.03402555  0.29708076]\n",
      "[ 0.00351589 -0.4229006   0.03996717  0.60029762]\n",
      "[-0.00494212 -0.61855822  0.05197312  0.9052969 ]\n",
      "[-0.01731328 -0.814344    0.07007906  1.21385224]\n",
      "[-0.03360016 -0.6201928   0.0943561   0.94392664]\n",
      "[-0.04600402 -0.42645997  0.11323464  0.6823196 ]\n",
      "[-0.05453322 -0.23307745  0.12688103  0.42732341]\n",
      "[-0.05919477 -0.42974663  0.1354275   0.75715876]\n",
      "[-0.0677897  -0.23672518  0.15057067  0.50997173]\n",
      "[-0.0725242  -0.43361184  0.16077011  0.84606093]\n",
      "[-0.08119644 -0.24100538  0.17769133  0.60794001]\n",
      "[-0.08601655 -0.43810806  0.18985013  0.95090553]\n",
      "[-0.09477871 -0.63520771  0.20886824  1.29672419]\n",
      "Episode finished after 14 timesteps\n",
      "[-0.00869149  0.01991773  0.00031862 -0.0106579 ]\n",
      "[ -8.29313096e-03  -1.75208792e-01   1.05461338e-04   2.82125536e-01]\n",
      "[-0.01179731  0.01991165  0.00574797 -0.01052413]\n",
      "[-0.01139907  0.2149507   0.00553749 -0.30138797]\n",
      "[ -7.10005966e-03   4.09993293e-01  -4.90269881e-04  -5.92319357e-01]\n",
      "[ 0.00109981  0.21487821 -0.01233666 -0.2997909 ]\n",
      "[ 0.00539737  0.41017381 -0.01833248 -0.5963389 ]\n",
      "[ 0.01360085  0.21531315 -0.03025925 -0.30948647]\n",
      "[ 0.01790711  0.0206351  -0.03644898 -0.02649794]\n",
      "[ 0.01831981  0.21626029 -0.03697894 -0.33045445]\n",
      "[ 0.02264502  0.41188859 -0.04358803 -0.63456562]\n",
      "[ 0.03088279  0.60759056 -0.05627934 -0.94065058]\n",
      "[ 0.0430346   0.41327046 -0.07509235 -0.66616932]\n",
      "[ 0.05130001  0.60935207 -0.08841574 -0.98151927]\n",
      "[ 0.06348705  0.80554051 -0.10804613 -1.30061281]\n",
      "[ 0.07959786  0.61194283 -0.13405838 -1.04361347]\n",
      "[ 0.09183672  0.80856539 -0.15493065 -1.37519627]\n",
      "[ 0.10800803  0.61568135 -0.18243458 -1.13470329]\n",
      "[ 0.12032165  0.81265971 -0.20512864 -1.47860626]\n",
      "Episode finished after 19 timesteps\n",
      "[-0.0225129   0.04749441 -0.0175406   0.033015  ]\n",
      "[-0.02156301 -0.14737166 -0.0168803   0.32011248]\n",
      "[-0.02451044 -0.3422492  -0.01047805  0.60742456]\n",
      "[-0.03135542 -0.14698233  0.00167044  0.31145985]\n",
      "[-0.03429507  0.04811579  0.00789964  0.01930419]\n",
      "[-0.03333276 -0.14711856  0.00828572  0.31446904]\n",
      "[-0.03627513  0.04788439  0.0145751   0.02441064]\n",
      "[-0.03531744  0.24279432  0.01506332 -0.26363828]\n",
      "[-0.03046155  0.43769806  0.00979055 -0.55153227]\n",
      "[-0.02170759  0.63268115 -0.0012401  -0.84111451]\n",
      "[-0.00905397  0.82782001 -0.01806239 -1.13418716]\n",
      "[ 0.00750243  1.02317361 -0.04074613 -1.43247982]\n",
      "[ 0.0279659   0.82857745 -0.06939573 -1.1528039 ]\n",
      "[ 0.04453745  0.63442595 -0.0924518  -0.88266358]\n",
      "[ 0.05722597  0.83067369 -0.11010508 -1.20292017]\n",
      "[ 0.07383945  0.63713394 -0.13416348 -0.94667402]\n",
      "[ 0.08658213  0.83378258 -0.15309696 -1.27832208]\n",
      "[ 0.10325778  0.64090721 -0.1786634  -1.03722783]\n",
      "[ 0.11607592  0.44855136 -0.19940796 -0.80553495]\n",
      "Episode finished after 19 timesteps\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "env = gym.make('CartPole-v1')\n",
    "env = wrappers.Monitor(env, '/tmp/cartpolev1-experiment-1',force=True)\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
