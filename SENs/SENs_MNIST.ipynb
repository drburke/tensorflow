{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x225244276d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWEAAAFfCAYAAACfj30KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhJAWoYQJIaRF/j8MrDWJxou2WgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x225243719e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the model inputs\n",
    "def model_inputs(image_width, image_height, image_channels, embedded_dim):\n",
    "    \"\"\"\n",
    "    Create the model inputs\n",
    "    :param image_width: The input image width\n",
    "    :param image_height: The input image height\n",
    "    :param image_channels: The number of image channels\n",
    "    :param z_dim: The dimension of Z\n",
    "    :return: Tuple of (tensor of real input images, tensor of z data, learning rate)\n",
    "    \"\"\"\n",
    "\n",
    "    real_input_images = tf.placeholder(tf.float32, \\\n",
    "                                       shape=(None,image_width,\\\n",
    "                                              image_height,\\\n",
    "                                              image_channels))\n",
    "    \n",
    "    embedded_data = tf.placeholder(tf.float32, \\\n",
    "                           shape=(None,embedded_dim))\n",
    "    \n",
    "    learning_rate = tf.placeholder(tf.float32, \\\n",
    "                                  shape=None)\n",
    "\n",
    "    target_input_images = tf.placeholder(tf.float32, \\\n",
    "                                        shape=(None,image_width,\\\n",
    "                                              image_height,\\\n",
    "                                              image_channels))\n",
    "    return real_input_images, embedded_data, learning_rate, target_input_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, alpha=0.1, name='leaky_relu'):\n",
    "            return tf.maximum(x, alpha * x, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoding network\n",
    "def encoder(images, reuse=False):\n",
    "    \"\"\"\n",
    "    Create the discriminator network\n",
    "    :param image: Tensor of input image(s)\n",
    "    :param reuse: Boolean if the weights should be reused\n",
    "    :return: Tuple of (tensor output of the discriminator, tensor logits of the discriminator)\n",
    "    \"\"\"\n",
    "\n",
    "    #TODO Batch Normalization\n",
    "    \n",
    "    with tf.variable_scope('encoder', reuse=reuse):\n",
    "        # Input layer is 28x28x1\n",
    "        conv1 = tf.layers.conv2d(images, 64, 5, strides=2, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        relu1 = leaky_relu(conv1)\n",
    "        # 14x14x64\n",
    "        \n",
    "        conv2 = tf.layers.conv2d(relu1, 128, 5, strides=2, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        bn2 = tf.layers.batch_normalization(conv2, training=True)\n",
    "        relu2 = leaky_relu(bn2)\n",
    "        # 7x7x128\n",
    "        \n",
    "        conv3 = tf.layers.conv2d(relu2, 256, 5, strides=1, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        bn3 = tf.layers.batch_normalization(conv3, training=True)\n",
    "        relu3 = leaky_relu(bn3)\n",
    "        #7x7x256\n",
    "        \n",
    "        # Flatten it\n",
    "        flat = tf.reshape(relu2, (-1, 7*7*256))\n",
    "        \n",
    "        # Dropout\n",
    "        dropout = tf.nn.dropout(flat,0.8)\n",
    "        \n",
    "        # Logits\n",
    "        logits = tf.layers.dense(dropout, 1,\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        out = tf.sigmoid(logits)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "def generator(z, out_channel_dim, is_train=True):\n",
    "    \"\"\"\n",
    "    Create the generator network\n",
    "    :param z: Input z\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param is_train: Boolean if generator is being used for training\n",
    "    :return: The tensor output of the generator\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=not is_train):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(z, 7*7*512,\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        # Reshape it to start the convolutional stack\n",
    "        x1 = tf.reshape(x1, (-1, 7, 7, 512))\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = leaky_relu(x1)\n",
    "        x1 = tf.nn.dropout(x1,0.5)\n",
    "        # 7x7x512 now\n",
    "        \n",
    "        x2 = tf.layers.conv2d_transpose(x1, 256, 5, strides=2, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        x2 = tf.layers.batch_normalization(x2, training=is_train)\n",
    "        x2 = leaky_relu(x2)\n",
    "        x2 = tf.nn.dropout(x2,0.5)\n",
    "        # 14x14x256 now\n",
    "        \n",
    "        x3 = tf.layers.conv2d_transpose(x2, 128, 5, strides=2, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        x3 = tf.layers.batch_normalization(x3, training=is_train)\n",
    "        x3 = leaky_relu(x3)\n",
    "        x3 = tf.nn.dropout(x3,0.5)\n",
    "        # 28x28x256 now\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.conv2d_transpose(x3, out_channel_dim, 5, strides=1, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        # 28x28x3 now\n",
    "        \n",
    "        out = tf.tanh(logits)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Descriminator\n",
    "def descriminator(z, out_channel_dim, is_train=True):\n",
    "    \"\"\"\n",
    "    Create the generator network\n",
    "    :param z: Input z\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param is_train: Boolean if generator is being used for training\n",
    "    :return: The tensor output of the generator\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=not is_train):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(z, 7*7*512,\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        # Reshape it to start the convolutional stack\n",
    "        x1 = tf.reshape(x1, (-1, 7, 7, 512))\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = leaky_relu(x1)\n",
    "        x1 = tf.nn.dropout(x1,0.5)\n",
    "        # 7x7x512 now\n",
    "        \n",
    "        x2 = tf.layers.conv2d_transpose(x1, 256, 5, strides=2, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        x2 = tf.layers.batch_normalization(x2, training=is_train)\n",
    "        x2 = leaky_relu(x2)\n",
    "        x2 = tf.nn.dropout(x2,0.5)\n",
    "        # 14x14x256 now\n",
    "        \n",
    "        x3 = tf.layers.conv2d_transpose(x2, 128, 5, strides=2, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        x3 = tf.layers.batch_normalization(x3, training=is_train)\n",
    "        x3 = leaky_relu(x3)\n",
    "        x3 = tf.nn.dropout(x3,0.5)\n",
    "        # 28x28x256 now\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.conv2d_transpose(x3, out_channel_dim, 5, strides=1, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        # 28x28x3 now\n",
    "        \n",
    "        out = tf.tanh(logits)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifier\n",
    "def classifier(z, out_channel_dim, is_train=True):\n",
    "    \"\"\"\n",
    "    Create the generator network\n",
    "    :param z: Input z\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param is_train: Boolean if generator is being used for training\n",
    "    :return: The tensor output of the generator\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.variable_scope('generator', reuse=not is_train):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(z, 7*7*512,\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        # Reshape it to start the convolutional stack\n",
    "        x1 = tf.reshape(x1, (-1, 7, 7, 512))\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = leaky_relu(x1)\n",
    "        x1 = tf.nn.dropout(x1,0.5)\n",
    "        # 7x7x512 now\n",
    "        \n",
    "        x2 = tf.layers.conv2d_transpose(x1, 256, 5, strides=2, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        x2 = tf.layers.batch_normalization(x2, training=is_train)\n",
    "        x2 = leaky_relu(x2)\n",
    "        x2 = tf.nn.dropout(x2,0.5)\n",
    "        # 14x14x256 now\n",
    "        \n",
    "        x3 = tf.layers.conv2d_transpose(x2, 128, 5, strides=2, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        x3 = tf.layers.batch_normalization(x3, training=is_train)\n",
    "        x3 = leaky_relu(x3)\n",
    "        x3 = tf.nn.dropout(x3,0.5)\n",
    "        # 28x28x256 now\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.conv2d_transpose(x3, out_channel_dim, 5, strides=1, padding='same',\\\n",
    "                                kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        # 28x28x3 now\n",
    "        \n",
    "        out = tf.tanh(logits)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_loss(input_real, input_z, out_channel_dim, target_real):\n",
    "    \"\"\"\n",
    "    Get the loss for the discriminator and generator\n",
    "    :param input_real: Images from the real dataset\n",
    "    :param input_z: Z input\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :return: A tuple of (discriminator loss, generator loss)\n",
    "    \"\"\"\n",
    "    smooth = 0.1\n",
    "    \n",
    "    # generator for fake images\n",
    "    g_logits = generator(input_z, out_channel_dim, is_train=True, reuse=True)\n",
    "    \n",
    "    # encoder for real and faked images\n",
    "    e_model_real, e_logits_real = encoder(input_real, reuse=False)\n",
    "    e_model_fake, e_logits_fake = encoder(g_logits, reuse=True)\n",
    "    \n",
    "    # descriminator for real and faked images\n",
    "    d_model_real, d_logits_real = discriminator(e_model_encoder_real, reuse=False)\n",
    "    d_model_fake, d_logits_fake = discriminator(e_model_encoder_fake, reuse=True)\n",
    "    \n",
    "    # classifier\n",
    "    c_model_real, c_logits_real = classifier(e_model_encoder_real, reuse=False)\n",
    "    c_model_fake, c_logits_fake = classifier(e_model_encoder_fake, reuse=True)\n",
    "    \n",
    "    # autoencoder\n",
    "    a_model_real, a_logits_real = generator(e_logits_real, reuse=True)\n",
    "    \n",
    "    # descriminator loss\n",
    "    d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, \\\n",
    "                                                labels=tf.ones_like(d_model_real) * (1-smooth)))\n",
    "    d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, \\\n",
    "                                                labels=tf.zeros_like(d_model_fake)))\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "    # generator loss\n",
    "    # fake comparing descriminator with '1'\n",
    "    g_loss_fake = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_model_fake)))\n",
    "    # real comparing input_real with autoencoder image\n",
    "    g_loss_real = tf.nn.cross_entropy_with_logits(labels=target_real, logits=a_logits_real)\n",
    "    g_cost_real = tf.reduce_mean(g_loss_real)\n",
    "    \n",
    "    g_loss = g_loss_fake + g_loss_real\n",
    "    \n",
    "    #TODO Classifier loss\n",
    "    \n",
    "    return d_loss, g_loss_fake, g_loss_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_opt(d_loss, g_loss, e_loss, c_loss, learning_rate, beta1):\n",
    "    \"\"\"\n",
    "    Get optimization operations\n",
    "    :param d_loss: Discriminator loss Tensor\n",
    "    :param g_loss: Generator loss Tensor\n",
    "    :param learning_rate: Learning Rate Placeholder\n",
    "    :param beta1: The exponential decay rate for the 1st moment in the optimizer\n",
    "    :return: A tuple of (discriminator training operation, generator training operation)\n",
    "    \"\"\"\n",
    "    # Get weights and bias to update\n",
    "    t_vars = tf.trainable_variables()\n",
    "    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "    e_vars = [var for var in t_vars if var.name.startswith('encoder')]\n",
    "    c_vars = [var for var in t_vars if var.name.startswith('classifier')]\n",
    "    \n",
    "    # Optimize\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n",
    "        e_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(e_loss, var_list=d_vars)\n",
    "        c_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(c_loss, var_list=g_vars)\n",
    "\n",
    "    return d_train_opt, g_train_opt, e_train_opt, c_train_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_generator_output(sess, n_images, input_z, out_channel_dim, image_mode):\n",
    "    \"\"\"\n",
    "    Show example output for the generator\n",
    "    :param sess: TensorFlow session\n",
    "    :param n_images: Number of Images to display\n",
    "    :param input_z: Input Z Tensor\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param image_mode: The mode to use for images (\"RGB\" or \"L\")\n",
    "    \"\"\"\n",
    "    clear_output()\n",
    "    cmap = None if image_mode == 'RGB' else 'gray'\n",
    "    z_dim = input_z.get_shape().as_list()[-1]\n",
    "#     example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n",
    "    example_z = np.random.normal(0.,1.,size=[n_images, z_dim])\n",
    "    samples = sess.run(\n",
    "        generator(input_z, out_channel_dim, False),\n",
    "        feed_dict={input_z: example_z})\n",
    "\n",
    "    images_grid = helper.images_square_grid(samples, image_mode)\n",
    "    pyplot.imshow(images_grid, cmap=cmap)\n",
    "    pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
