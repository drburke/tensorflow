{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "# base code from udacity-deep-learning/reinforcement/Q-learning-cart.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 23:55:00,617] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00093697 -0.01747059  0.01530989  0.02381758]\n"
     ]
    }
   ],
   "source": [
    "# Create new cart pole environment\n",
    "env = gym.make('CartPole-v1')\n",
    "state = env.reset()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create class QNetwork\n",
    "class QNetwork:\n",
    "    def __init__(self, \\\n",
    "                 learning_rate=0.01, \\\n",
    "                 state_size=4, \n",
    "                 action_size=2, \\\n",
    "                 hidden_size=10, \\\n",
    "                 hidden_layers=2, \\\n",
    "                 alpha=0., \\\n",
    "                 name='QNetwork'):\n",
    "        \n",
    "        # create Q Network\n",
    "        with tf.variable_scope(name):\n",
    "            self.inputs_ = tf.placeholder(tf.float32, \\\n",
    "                                          [None, state_size], \\\n",
    "                                          name='inputs')\n",
    "            \n",
    "            # placeholder for actions, to be one-hot encoded next\n",
    "            self.actions_ = tf.placeholder(tf.int32, \\\n",
    "                                           [None], \\\n",
    "                                           name='actions')\n",
    "            \n",
    "            # one hot encode actions\n",
    "            one_hot_actions = tf.one_hot(self.actions_, \\\n",
    "                                         action_size)\n",
    "            \n",
    "            # placeholder for target Qs\n",
    "            self.targetQs_ = tf.placeholder(tf.float32, \\\n",
    "                                            [None], \\\n",
    "                                            name='target')\n",
    "            \n",
    "                \n",
    "            # ReLU hidden layers\n",
    "            self.fc1 = tf.layers.dense(self.inputs_, \\\n",
    "                                        hidden_size,\\\n",
    "                                        activation=None,\\\n",
    "                                        kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            self.fc1 = tf.maximum(alpha*self.fc1,self.fc1)\n",
    "            \n",
    "            if hidden_layers == 1:\n",
    "                out_layer = self.fc1\n",
    "            else:\n",
    "                \n",
    "                self.fc2 = tf.layers.dense(self.fc1, hidden_size,\\\n",
    "                                            activation=None,\\\n",
    "                                            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                self.fc2 = tf.maximum(alpha*self.fc2,self.fc2)\n",
    "                \n",
    "                if hidden_layers == 2:\n",
    "                    out_layer = self.fc2\n",
    "                else:\n",
    "                    self.fc3 = tf.layers.dense(self.fc2, hidden_size,\\\n",
    "                                            activation=None,\\\n",
    "                                            kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "                    self.fc3 = tf.maximum(alpha*self.fc3,self.fc3)\n",
    "                    out_layer = self.fc3\n",
    "\n",
    "            # Linear output layer\n",
    "            self.output = tf.layers.dense(out_layer, action_size, \\\n",
    "                                          activation=None,\\\n",
    "                                          kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "            \n",
    "            ### Train with loss (targetQ - Q)^2\n",
    "            # output has length 2, for two actions. This next line chooses\n",
    "            # one value from output (per row) according to the one-hot encoded actions.\n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create memory class for storing previous experiences\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_memory_rand_states(memory_size=10000,pretrain_length=20):\n",
    "    # Initialize the simulation\n",
    "    state = env.reset()\n",
    "    \n",
    "    memory = Memory(max_size=memory_size)\n",
    "\n",
    "    # Make a bunch of random actions and store the experiences\n",
    "    for ii in range(pretrain_length):\n",
    "\n",
    "        # Make a random action\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            # The simulation fails so no next state\n",
    "            next_state = np.zeros(state.shape)\n",
    "            # Add experience to memory\n",
    "            memory.add((state, action, reward, next_state))\n",
    "\n",
    "            # Start new episode\n",
    "            state = env.reset()\n",
    "\n",
    "        else:\n",
    "            # Add experience to memory\n",
    "            memory.add((state, action, reward, next_state))\n",
    "            state = next_state\n",
    "            \n",
    "    return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_q_network(train_episodes=500,\\\n",
    "                   gamma=0.99,\\\n",
    "                   explore_start=1.0,\\\n",
    "                   explore_stop=0.01,\\\n",
    "                   decay_rate=0.0001,\\\n",
    "                   hidden_size=64,\\\n",
    "                   hidden_layers=2,\\\n",
    "                   learning_rate=0.0001,\\\n",
    "                   memory_size=10000,\\\n",
    "                   batch_size=20,\\\n",
    "                   max_steps=500,\\\n",
    "                   alpha=0.,\\\n",
    "                   verbose=True):\n",
    "    \n",
    "    \n",
    "    mainQN = QNetwork(name='main', hidden_size=hidden_size, hidden_layers=hidden_layers, learning_rate=learning_rate, alpha=alpha)\n",
    "    \n",
    "    memory = initialize_memory_rand_states(memory_size=memory_size,pretrain_length=batch_size)\n",
    "\n",
    "    state = env.reset()\n",
    "    \n",
    "    # Now train with experiences\n",
    "    saver = tf.train.Saver()\n",
    "    rewards_list = []\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        steps_list = []\n",
    "        \n",
    "        for ep in range(train_episodes):\n",
    "            total_reward = 0\n",
    "            t = 0\n",
    "            \n",
    "            while t < max_steps:\n",
    "                step += 1\n",
    "                # Uncomment this next line to watch the training\n",
    "                # env.render() \n",
    "\n",
    "                # Explore or Exploit\n",
    "                explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "                if explore_p > np.random.rand():\n",
    "                    # Make a random action\n",
    "                    action = env.action_space.sample()\n",
    "                else:\n",
    "                    # Get action from Q-network\n",
    "                    feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                    Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                    action = np.argmax(Qs)\n",
    "\n",
    "                # Take action, get new state and reward\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "                total_reward += reward\n",
    "\n",
    "                if done:\n",
    "                    t = t+1\n",
    "                    # the episode ends so no next state\n",
    "                    next_state = np.zeros(state.shape)\n",
    "                    steps_list.append(t)\n",
    "                    t = max_steps\n",
    "\n",
    "                    # Add experience to memory\n",
    "                    memory.add((state, action, reward, next_state))\n",
    "                    state = env.reset()\n",
    "                else:\n",
    "                    # Add experience to memory\n",
    "                    memory.add((state, action, reward, next_state))\n",
    "                    state = next_state\n",
    "                    t += 1\n",
    "\n",
    "                # Sample mini-batch from memory\n",
    "                batch = memory.sample(batch_size)\n",
    "                states = np.array([each[0] for each in batch])\n",
    "                actions = np.array([each[1] for each in batch])\n",
    "                rewards = np.array([each[2] for each in batch])\n",
    "                next_states = np.array([each[3] for each in batch])\n",
    "\n",
    "                # Train network\n",
    "                target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "\n",
    "                # Set target_Qs to 0 for states where episode ends\n",
    "                episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "                target_Qs[episode_ends] = (0, 0)\n",
    "\n",
    "                targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "                loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                    feed_dict={mainQN.inputs_: states,\n",
    "                                               mainQN.targetQs_: targets,\n",
    "                                               mainQN.actions_: actions})\n",
    "            \n",
    "            rewards_list.append((ep, total_reward))   \n",
    "            runningMean = np.mean(steps_list[-100:])\n",
    "            if verbose:\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p),\n",
    "                      'RunMean : {:.4f}'.format(runningMean))\n",
    "               \n",
    "            \n",
    "            \n",
    "            if runningMean > 495.:\n",
    "                saver.save(sess, \"checkpoints/cartpole.ckpt\")\n",
    "                return rewards_list, mainQN, saver\n",
    "            \n",
    "        saver.save(sess, \"checkpoints/cartpole.ckpt\")\n",
    "        return rewards_list, mainQN, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_rewards(rewards_list):\n",
    "    eps, rews = np.array(rewards_list).T\n",
    "    smoothed_rews = running_mean(rews, 10)\n",
    "    plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "    plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_q_network(mainQN, saver, test_episodes=100, test_max_steps=500, render=True):\n",
    "\n",
    "\n",
    "    avg_rewards = 0.\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "   \n",
    "        state = env.reset()\n",
    "        for ep in range(test_episodes):\n",
    "            t = 0\n",
    "            while t < test_max_steps:\n",
    "                if render:\n",
    "                    env.render() \n",
    "\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "\n",
    "                # Take action, get new state and reward\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                \n",
    "                avg_rewards = avg_rewards + reward / test_episodes\n",
    "                if done:\n",
    "                    t = test_max_steps\n",
    "                    state = env.reset()\n",
    "                    # Take one random step to get the pole and cart moving\n",
    "                    #state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "                else:\n",
    "                    state = next_state\n",
    "                    t += 1\n",
    "              \n",
    "    return avg_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_and_train_qnetwork(train_episodes=1000,\\\n",
    "                   gamma=0.99,\\\n",
    "                   explore_start=1.0,\\\n",
    "                   explore_stop=0.01,\\\n",
    "                   decay_rate=0.0001,\\\n",
    "                   hidden_size=64,\\\n",
    "                   hidden_layers=2,\\\n",
    "                   learning_rate=0.0001,\\\n",
    "                   memory_size=10000,\\\n",
    "                   batch_size=20,\\\n",
    "                   test_episodes=10,\\\n",
    "                   render=False,\\\n",
    "                   alpha=0.,\\\n",
    "                   verbose=True):\n",
    "    \n",
    "    # reset graph\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    # train q-network\n",
    "    rewards_list, mainQN, saver = train_q_network(train_episodes = train_episodes, \\\n",
    "                                                  gamma=gamma,\\\n",
    "                                                  explore_start=explore_start,\\\n",
    "                                                  explore_stop=explore_stop,\\\n",
    "                                                  decay_rate=decay_rate,\\\n",
    "                                                  hidden_size=hidden_size,\\\n",
    "                                                  hidden_layers=hidden_layers,\\\n",
    "                                                  learning_rate=learning_rate,\\\n",
    "                                                  memory_size=memory_size,\\\n",
    "                                                  batch_size=batch_size,\\\n",
    "                                                  alpha=alpha,\\\n",
    "                                                  verbose=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        # plot training\n",
    "        plot_rewards(rewards_list)\n",
    "    \n",
    "    avg_train_rewards = np.sum([each[1] for each in rewards_list]) / len(rewards_list)\n",
    "    if verbose:\n",
    "        print('average training reward = ',avg_train_rewards)\n",
    "\n",
    "    # test q-network\n",
    "    avg_test_rewards = test_q_network(mainQN, saver, test_episodes=test_episodes, render=verbose)\n",
    "    if verbose:\n",
    "        print('average test reward = ', avg_test_rewards)\n",
    "    \n",
    "    return avg_test_rewards, avg_train_rewards, mainQN, saver, len(rewards_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 15:54:17,537] Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test reward =  9.249999999999996\n"
     ]
    }
   ],
   "source": [
    "# test implementation\n",
    "average_rewards = test_and_train_qnetwork(train_episodes=100, verbose=False)\n",
    "print('average test reward = ', average_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dr=0.0001_ga=0.99_hs=64_hl2_lr0.0001_bs32_alu=0.1 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl2_lr0.0001_bs32_alu=0.2 test=423.6000000000278  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl2_lr0.0001_bs64_alu=0.1 test=9.699999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl2_lr0.0001_bs64_alu=0.2 test=500.0000000000452  numEps=704']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl2_lr1e-05_bs32_alu=0.1 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl2_lr1e-05_bs32_alu=0.2 test=9.499999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl2_lr1e-05_bs64_alu=0.1 test=8.899999999999984  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl2_lr1e-05_bs64_alu=0.2 test=9.499999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl3_lr0.0001_bs32_alu=0.1 test=383.6000000000187  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl3_lr0.0001_bs32_alu=0.2 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl3_lr0.0001_bs64_alu=0.1 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl3_lr0.0001_bs64_alu=0.2 test=188.59999999999357  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl3_lr1e-05_bs32_alu=0.1 test=9.599999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl3_lr1e-05_bs32_alu=0.2 test=9.099999999999984  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl3_lr1e-05_bs64_alu=0.1 test=9.699999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=64_hl3_lr1e-05_bs64_alu=0.2 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl2_lr0.0001_bs32_alu=0.1 test=217.19999999999195  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl2_lr0.0001_bs32_alu=0.2 test=499.00000000004496  numEps=1008']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl2_lr0.0001_bs64_alu=0.1 test=9.599999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl2_lr0.0001_bs64_alu=0.2 test=500.0000000000452  numEps=885']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl2_lr1e-05_bs32_alu=0.1 test=9.499999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl2_lr1e-05_bs32_alu=0.2 test=9.499999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl2_lr1e-05_bs64_alu=0.1 test=9.699999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl2_lr1e-05_bs64_alu=0.2 test=9.099999999999984  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl3_lr0.0001_bs32_alu=0.1 test=9.599999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl3_lr0.0001_bs32_alu=0.2 test=8.699999999999985  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl3_lr0.0001_bs64_alu=0.1 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl3_lr0.0001_bs64_alu=0.2 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl3_lr1e-05_bs32_alu=0.1 test=10.899999999999977  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl3_lr1e-05_bs32_alu=0.2 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl3_lr1e-05_bs64_alu=0.1 test=89.09999999999921  numEps=1200']\n",
      "['dr=0.0001_ga=0.99_hs=128_hl3_lr1e-05_bs64_alu=0.2 test=61.0000000000006  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl2_lr0.0001_bs32_alu=0.1 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl2_lr0.0001_bs32_alu=0.2 test=9.499999999999982  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl2_lr0.0001_bs64_alu=0.1 test=358.500000000013  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl2_lr0.0001_bs64_alu=0.2 test=364.9000000000145  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl2_lr1e-05_bs32_alu=0.1 test=9.099999999999984  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl2_lr1e-05_bs32_alu=0.2 test=9.099999999999984  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl2_lr1e-05_bs64_alu=0.1 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl2_lr1e-05_bs64_alu=0.2 test=9.099999999999984  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl3_lr0.0001_bs32_alu=0.1 test=9.399999999999983  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl3_lr0.0001_bs32_alu=0.2 test=417.7000000000265  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl3_lr0.0001_bs64_alu=0.1 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl3_lr0.0001_bs64_alu=0.2 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl3_lr1e-05_bs32_alu=0.1 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl3_lr1e-05_bs32_alu=0.2 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl3_lr1e-05_bs64_alu=0.1 test=11.899999999999974  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=64_hl3_lr1e-05_bs64_alu=0.2 test=17.399999999999977  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl2_lr0.0001_bs32_alu=0.1 test=500.0000000000452  numEps=534']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl2_lr0.0001_bs32_alu=0.2 test=489.9000000000429  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl2_lr0.0001_bs64_alu=0.1 test=478.70000000004035  numEps=498']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl2_lr0.0001_bs64_alu=0.2 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl2_lr1e-05_bs32_alu=0.1 test=9.499999999999982  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl2_lr1e-05_bs32_alu=0.2 test=9.399999999999983  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl2_lr1e-05_bs64_alu=0.1 test=8.699999999999985  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl2_lr1e-05_bs64_alu=0.2 test=23.90000000000007  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl3_lr0.0001_bs32_alu=0.1 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl3_lr0.0001_bs32_alu=0.2 test=500.0000000000452  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl3_lr0.0001_bs64_alu=0.1 test=9.599999999999982  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl3_lr0.0001_bs64_alu=0.2 test=176.99999999999423  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl3_lr1e-05_bs32_alu=0.1 test=15.59999999999996  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl3_lr1e-05_bs32_alu=0.2 test=15.199999999999962  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl3_lr1e-05_bs64_alu=0.1 test=190.49999999999346  numEps=1200']\n",
      "['dr=0.0002_ga=0.99_hs=128_hl3_lr1e-05_bs64_alu=0.2 test=15.99999999999996  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl2_lr0.0001_bs32_alu=0.1 test=138.7999999999964  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl2_lr0.0001_bs32_alu=0.2 test=333.10000000000724  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl2_lr0.0001_bs64_alu=0.1 test=76.09999999999995  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl2_lr0.0001_bs64_alu=0.2 test=191.4999999999934  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl2_lr1e-05_bs32_alu=0.1 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl2_lr1e-05_bs32_alu=0.2 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl2_lr1e-05_bs64_alu=0.1 test=9.199999999999983  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl2_lr1e-05_bs64_alu=0.2 test=9.499999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl3_lr0.0001_bs32_alu=0.1 test=128.399999999997  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl3_lr0.0001_bs32_alu=0.2 test=152.9999999999956  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl3_lr0.0001_bs64_alu=0.1 test=325.8000000000056  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl3_lr0.0001_bs64_alu=0.2 test=124.09999999999722  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl3_lr1e-05_bs32_alu=0.1 test=11.399999999999975  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl3_lr1e-05_bs32_alu=0.2 test=9.499999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl3_lr1e-05_bs64_alu=0.1 test=15.099999999999962  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=64_hl3_lr1e-05_bs64_alu=0.2 test=69.20000000000034  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl2_lr0.0001_bs32_alu=0.1 test=304.60000000000076  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl2_lr0.0001_bs32_alu=0.2 test=280.4999999999953  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl2_lr0.0001_bs64_alu=0.1 test=164.79999999999492  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl2_lr0.0001_bs64_alu=0.2 test=296.4999999999989  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl2_lr1e-05_bs32_alu=0.1 test=12.299999999999972  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl2_lr1e-05_bs32_alu=0.2 test=11.099999999999977  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl2_lr1e-05_bs64_alu=0.1 test=38.70000000000028  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl2_lr1e-05_bs64_alu=0.2 test=9.499999999999982  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl3_lr0.0001_bs32_alu=0.1 test=133.7999999999967  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl3_lr0.0001_bs32_alu=0.2 test=351.3000000000114  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl3_lr0.0001_bs64_alu=0.1 test=270.7999999999931  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl3_lr0.0001_bs64_alu=0.2 test=131.09999999999684  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl3_lr1e-05_bs32_alu=0.1 test=221.5999999999917  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl3_lr1e-05_bs32_alu=0.2 test=107.59999999999816  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl3_lr1e-05_bs64_alu=0.1 test=140.99999999999628  numEps=1200']\n",
      "['dr=0.0001_ga=0.9_hs=128_hl3_lr1e-05_bs64_alu=0.2 test=213.49999999999216  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl2_lr0.0001_bs32_alu=0.1 test=279.99999999999517  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl2_lr0.0001_bs32_alu=0.2 test=107.99999999999814  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl2_lr0.0001_bs64_alu=0.1 test=482.70000000004126  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl2_lr0.0001_bs64_alu=0.2 test=10.699999999999978  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl2_lr1e-05_bs32_alu=0.1 test=9.199999999999983  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl2_lr1e-05_bs32_alu=0.2 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl2_lr1e-05_bs64_alu=0.1 test=9.599999999999982  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl2_lr1e-05_bs64_alu=0.2 test=10.399999999999979  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl3_lr0.0001_bs32_alu=0.1 test=155.59999999999545  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl3_lr0.0001_bs32_alu=0.2 test=192.09999999999337  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl3_lr0.0001_bs64_alu=0.1 test=182.9999999999939  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl3_lr0.0001_bs64_alu=0.2 test=194.29999999999325  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl3_lr1e-05_bs32_alu=0.1 test=9.89999999999998  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl3_lr1e-05_bs32_alu=0.2 test=9.399999999999983  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl3_lr1e-05_bs64_alu=0.1 test=10.599999999999978  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=64_hl3_lr1e-05_bs64_alu=0.2 test=12.099999999999973  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl2_lr0.0001_bs32_alu=0.1 test=174.69999999999436  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl2_lr0.0001_bs32_alu=0.2 test=393.00000000002086  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl2_lr0.0001_bs64_alu=0.1 test=194.69999999999322  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl2_lr0.0001_bs64_alu=0.2 test=175.6999999999943  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl2_lr1e-05_bs32_alu=0.1 test=9.99999999999998  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl2_lr1e-05_bs32_alu=0.2 test=14.499999999999964  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl2_lr1e-05_bs64_alu=0.1 test=9.299999999999983  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl2_lr1e-05_bs64_alu=0.2 test=25.700000000000095  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl3_lr0.0001_bs32_alu=0.1 test=138.09999999999644  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl3_lr0.0001_bs32_alu=0.2 test=125.19999999999716  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl3_lr0.0001_bs64_alu=0.1 test=124.3999999999972  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl3_lr0.0001_bs64_alu=0.2 test=196.49999999999312  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl3_lr1e-05_bs32_alu=0.1 test=139.39999999999637  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl3_lr1e-05_bs32_alu=0.2 test=59.500000000000576  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl3_lr1e-05_bs64_alu=0.1 test=355.4000000000123  numEps=1200']\n",
      "['dr=0.0002_ga=0.9_hs=128_hl3_lr1e-05_bs64_alu=0.2 test=211.1999999999923  numEps=1200']\n"
     ]
    }
   ],
   "source": [
    "train_eps = 1200\n",
    "verb = False\n",
    "gamma = [0.99,0.9]\n",
    "decay_rate = [0.0001,0.0002]\n",
    "exp_start=1.0\n",
    "exp_stop=0.1\n",
    "hidden_size=[64,128]\n",
    "hidden_layers=[2,3]\n",
    "learning_rate=[0.0001,0.00001]\n",
    "batch_size=[32,64]\n",
    "num_averages = 1\n",
    "results = []\n",
    "alpha_relu = [0.1,0.2]\n",
    "env = gym.make('CartPole-v1')\n",
    "env.reset()\n",
    "\n",
    "for gaIndex in range(len(gamma)):\n",
    "    for drIndex in range(len(decay_rate)):\n",
    "        for hs in hidden_size:\n",
    "            for hl in hidden_layers:\n",
    "                for lr in learning_rate:\n",
    "                    for bs in batch_size:\n",
    "                        for alu in alpha_relu:\n",
    "                            \n",
    "                            ga = gamma[gaIndex]\n",
    "                            dr = decay_rate[drIndex]\n",
    "                            train_params_name = 'dr='+str(dr)+'_ga='+str(ga)+'_hs='+str(hs)+'_hl'+str(hl)+'_lr'+str(lr)+'_bs'+str(bs)+'_alu='+str(alu)\n",
    "                            average_test_rewards = 0.\n",
    "                            average_train_rewards = 0.\n",
    "                            for i in range(num_averages):\n",
    "                                test,train, mainQN, saver, num_episodes = test_and_train_qnetwork(memory_size=10000,\\\n",
    "                                                       train_episodes=train_eps,\\\n",
    "                                                       gamma=ga,\\\n",
    "                                                       explore_start=exp_start,\\\n",
    "                                                       explore_stop=exp_stop,\\\n",
    "                                                       decay_rate=dr,\\\n",
    "                                                       hidden_layers=hl,\\\n",
    "                                                       hidden_size=hs,\\\n",
    "                                                       learning_rate=lr,\\\n",
    "                                                       batch_size=bs,\\\n",
    "                                                       alpha = alu,\\\n",
    "                                                       verbose=verb)\n",
    "                                average_test_rewards += test\n",
    "                                average_train_rewards += train\n",
    "\n",
    "                            average_test_rewards = average_test_rewards / num_averages\n",
    "                            average_train_rewards = average_train_rewards / num_averages\n",
    "                            results.append([train_params_name+' test='+str(average_test_rewards)+'  numEps='+str(num_episodes)])\n",
    "                            clear_output()\n",
    "                            for each in results:\n",
    "                                print(each)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-23 00:16:21,269] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Total reward: 17.0 Training loss: 1.1656 Explore P: 0.9997 RunMean : 17.0000\n",
      "Episode: 1 Total reward: 13.0 Training loss: 1.1657 Explore P: 0.9994 RunMean : 15.0000\n",
      "Episode: 2 Total reward: 21.0 Training loss: 1.1492 Explore P: 0.9990 RunMean : 17.0000\n",
      "Episode: 3 Total reward: 12.0 Training loss: 1.1934 Explore P: 0.9987 RunMean : 15.7500\n",
      "Episode: 4 Total reward: 11.0 Training loss: 1.1641 Explore P: 0.9985 RunMean : 14.8000\n",
      "Episode: 5 Total reward: 59.0 Training loss: 1.6975 Explore P: 0.9973 RunMean : 22.1667\n",
      "Episode: 6 Total reward: 21.0 Training loss: 1.7549 Explore P: 0.9969 RunMean : 22.0000\n",
      "Episode: 7 Total reward: 17.0 Training loss: 2.0484 Explore P: 0.9966 RunMean : 21.3750\n",
      "Episode: 8 Total reward: 43.0 Training loss: 2.1694 Explore P: 0.9957 RunMean : 23.7778\n",
      "Episode: 9 Total reward: 17.0 Training loss: 2.8160 Explore P: 0.9954 RunMean : 23.1000\n",
      "Episode: 10 Total reward: 73.0 Training loss: 2.2687 Explore P: 0.9939 RunMean : 27.6364\n",
      "Episode: 11 Total reward: 16.0 Training loss: 2.7256 Explore P: 0.9936 RunMean : 26.6667\n",
      "Episode: 12 Total reward: 12.0 Training loss: 8.4308 Explore P: 0.9934 RunMean : 25.5385\n",
      "Episode: 13 Total reward: 14.0 Training loss: 6.7139 Explore P: 0.9931 RunMean : 24.7143\n",
      "Episode: 14 Total reward: 18.0 Training loss: 13.0625 Explore P: 0.9927 RunMean : 24.2667\n",
      "Episode: 15 Total reward: 16.0 Training loss: 10.7731 Explore P: 0.9924 RunMean : 23.7500\n",
      "Episode: 16 Total reward: 19.0 Training loss: 2.8467 Explore P: 0.9921 RunMean : 23.4706\n",
      "Episode: 17 Total reward: 26.0 Training loss: 11.2651 Explore P: 0.9915 RunMean : 23.6111\n",
      "Episode: 18 Total reward: 21.0 Training loss: 24.8415 Explore P: 0.9911 RunMean : 23.4737\n",
      "Episode: 19 Total reward: 12.0 Training loss: 9.1614 Explore P: 0.9909 RunMean : 22.9000\n",
      "Episode: 20 Total reward: 15.0 Training loss: 9.1509 Explore P: 0.9906 RunMean : 22.5238\n",
      "Episode: 21 Total reward: 10.0 Training loss: 16.3554 Explore P: 0.9904 RunMean : 21.9545\n",
      "Episode: 22 Total reward: 10.0 Training loss: 18.6006 Explore P: 0.9902 RunMean : 21.4348\n",
      "Episode: 23 Total reward: 41.0 Training loss: 12.0395 Explore P: 0.9894 RunMean : 22.2500\n",
      "Episode: 24 Total reward: 10.0 Training loss: 12.8364 Explore P: 0.9892 RunMean : 21.7600\n",
      "Episode: 25 Total reward: 41.0 Training loss: 14.7631 Explore P: 0.9884 RunMean : 22.5000\n",
      "Episode: 26 Total reward: 30.0 Training loss: 46.0448 Explore P: 0.9878 RunMean : 22.7778\n",
      "Episode: 27 Total reward: 74.0 Training loss: 21.1415 Explore P: 0.9863 RunMean : 24.6071\n",
      "Episode: 28 Total reward: 17.0 Training loss: 9.7505 Explore P: 0.9860 RunMean : 24.3448\n",
      "Episode: 29 Total reward: 23.0 Training loss: 6.6060 Explore P: 0.9855 RunMean : 24.3000\n",
      "Episode: 30 Total reward: 21.0 Training loss: 7.4892 Explore P: 0.9851 RunMean : 24.1935\n",
      "Episode: 31 Total reward: 17.0 Training loss: 16.9831 Explore P: 0.9848 RunMean : 23.9688\n",
      "Episode: 32 Total reward: 14.0 Training loss: 31.6762 Explore P: 0.9845 RunMean : 23.6667\n",
      "Episode: 33 Total reward: 12.0 Training loss: 27.9460 Explore P: 0.9843 RunMean : 23.3235\n",
      "Episode: 34 Total reward: 17.0 Training loss: 14.2116 Explore P: 0.9839 RunMean : 23.1429\n",
      "Episode: 35 Total reward: 28.0 Training loss: 24.1913 Explore P: 0.9834 RunMean : 23.2778\n",
      "Episode: 36 Total reward: 10.0 Training loss: 19.2155 Explore P: 0.9832 RunMean : 22.9189\n",
      "Episode: 37 Total reward: 10.0 Training loss: 62.6675 Explore P: 0.9830 RunMean : 22.5789\n",
      "Episode: 38 Total reward: 32.0 Training loss: 18.2114 Explore P: 0.9824 RunMean : 22.8205\n",
      "Episode: 39 Total reward: 10.0 Training loss: 7.4697 Explore P: 0.9822 RunMean : 22.5000\n",
      "Episode: 40 Total reward: 25.0 Training loss: 24.5470 Explore P: 0.9817 RunMean : 22.5610\n",
      "Episode: 41 Total reward: 17.0 Training loss: 7.6535 Explore P: 0.9813 RunMean : 22.4286\n",
      "Episode: 42 Total reward: 17.0 Training loss: 28.2176 Explore P: 0.9810 RunMean : 22.3023\n",
      "Episode: 43 Total reward: 36.0 Training loss: 5.8869 Explore P: 0.9803 RunMean : 22.6136\n",
      "Episode: 44 Total reward: 15.0 Training loss: 21.5618 Explore P: 0.9800 RunMean : 22.4444\n",
      "Episode: 45 Total reward: 17.0 Training loss: 22.1815 Explore P: 0.9797 RunMean : 22.3261\n",
      "Episode: 46 Total reward: 13.0 Training loss: 29.5247 Explore P: 0.9794 RunMean : 22.1277\n",
      "Episode: 47 Total reward: 26.0 Training loss: 11.9424 Explore P: 0.9789 RunMean : 22.2083\n",
      "Episode: 48 Total reward: 19.0 Training loss: 12.4713 Explore P: 0.9785 RunMean : 22.1429\n",
      "Episode: 49 Total reward: 20.0 Training loss: 28.8654 Explore P: 0.9781 RunMean : 22.1000\n",
      "Episode: 50 Total reward: 15.0 Training loss: 16.3238 Explore P: 0.9778 RunMean : 21.9608\n",
      "Episode: 51 Total reward: 40.0 Training loss: 24.3776 Explore P: 0.9771 RunMean : 22.3077\n",
      "Episode: 52 Total reward: 36.0 Training loss: 3.0555 Explore P: 0.9764 RunMean : 22.5660\n",
      "Episode: 53 Total reward: 23.0 Training loss: 14.6104 Explore P: 0.9759 RunMean : 22.5741\n",
      "Episode: 54 Total reward: 75.0 Training loss: 13.0764 Explore P: 0.9745 RunMean : 23.5273\n",
      "Episode: 55 Total reward: 27.0 Training loss: 8.0931 Explore P: 0.9739 RunMean : 23.5893\n",
      "Episode: 56 Total reward: 19.0 Training loss: 66.0316 Explore P: 0.9736 RunMean : 23.5088\n",
      "Episode: 57 Total reward: 24.0 Training loss: 96.0158 Explore P: 0.9731 RunMean : 23.5172\n",
      "Episode: 58 Total reward: 26.0 Training loss: 20.0276 Explore P: 0.9726 RunMean : 23.5593\n",
      "Episode: 59 Total reward: 14.0 Training loss: 17.4774 Explore P: 0.9723 RunMean : 23.4000\n",
      "Episode: 60 Total reward: 58.0 Training loss: 34.1643 Explore P: 0.9712 RunMean : 23.9672\n",
      "Episode: 61 Total reward: 22.0 Training loss: 21.1117 Explore P: 0.9708 RunMean : 23.9355\n",
      "Episode: 62 Total reward: 9.0 Training loss: 22.5490 Explore P: 0.9706 RunMean : 23.6984\n",
      "Episode: 63 Total reward: 21.0 Training loss: 81.6318 Explore P: 0.9702 RunMean : 23.6562\n",
      "Episode: 64 Total reward: 20.0 Training loss: 19.1401 Explore P: 0.9698 RunMean : 23.6000\n",
      "Episode: 65 Total reward: 44.0 Training loss: 37.5020 Explore P: 0.9689 RunMean : 23.9091\n",
      "Episode: 66 Total reward: 11.0 Training loss: 24.6112 Explore P: 0.9687 RunMean : 23.7164\n",
      "Episode: 67 Total reward: 18.0 Training loss: 35.2874 Explore P: 0.9684 RunMean : 23.6324\n",
      "Episode: 68 Total reward: 12.0 Training loss: 5.0415 Explore P: 0.9681 RunMean : 23.4638\n",
      "Episode: 69 Total reward: 21.0 Training loss: 18.8306 Explore P: 0.9677 RunMean : 23.4286\n",
      "Episode: 70 Total reward: 12.0 Training loss: 18.2271 Explore P: 0.9675 RunMean : 23.2676\n",
      "Episode: 71 Total reward: 24.0 Training loss: 52.6413 Explore P: 0.9670 RunMean : 23.2778\n",
      "Episode: 72 Total reward: 19.0 Training loss: 31.0983 Explore P: 0.9667 RunMean : 23.2192\n",
      "Episode: 73 Total reward: 32.0 Training loss: 60.7617 Explore P: 0.9660 RunMean : 23.3378\n",
      "Episode: 74 Total reward: 39.0 Training loss: 71.1984 Explore P: 0.9653 RunMean : 23.5467\n",
      "Episode: 75 Total reward: 26.0 Training loss: 70.7509 Explore P: 0.9648 RunMean : 23.5789\n",
      "Episode: 76 Total reward: 33.0 Training loss: 30.0379 Explore P: 0.9642 RunMean : 23.7013\n",
      "Episode: 77 Total reward: 16.0 Training loss: 49.1351 Explore P: 0.9638 RunMean : 23.6026\n",
      "Episode: 78 Total reward: 39.0 Training loss: 77.7881 Explore P: 0.9631 RunMean : 23.7975\n",
      "Episode: 79 Total reward: 20.0 Training loss: 26.4486 Explore P: 0.9627 RunMean : 23.7500\n",
      "Episode: 80 Total reward: 30.0 Training loss: 8.1680 Explore P: 0.9621 RunMean : 23.8272\n",
      "Episode: 81 Total reward: 29.0 Training loss: 78.6502 Explore P: 0.9616 RunMean : 23.8902\n",
      "Episode: 82 Total reward: 21.0 Training loss: 97.5038 Explore P: 0.9612 RunMean : 23.8554\n",
      "Episode: 83 Total reward: 12.0 Training loss: 41.7298 Explore P: 0.9609 RunMean : 23.7143\n",
      "Episode: 84 Total reward: 42.0 Training loss: 28.8246 Explore P: 0.9601 RunMean : 23.9294\n",
      "Episode: 85 Total reward: 15.0 Training loss: 63.5781 Explore P: 0.9598 RunMean : 23.8256\n",
      "Episode: 86 Total reward: 21.0 Training loss: 103.6328 Explore P: 0.9594 RunMean : 23.7931\n",
      "Episode: 87 Total reward: 44.0 Training loss: 39.1499 Explore P: 0.9586 RunMean : 24.0227\n",
      "Episode: 88 Total reward: 25.0 Training loss: 63.4166 Explore P: 0.9581 RunMean : 24.0337\n",
      "Episode: 89 Total reward: 41.0 Training loss: 95.0590 Explore P: 0.9573 RunMean : 24.2222\n",
      "Episode: 90 Total reward: 22.0 Training loss: 135.7745 Explore P: 0.9569 RunMean : 24.1978\n",
      "Episode: 91 Total reward: 14.0 Training loss: 143.2859 Explore P: 0.9566 RunMean : 24.0870\n",
      "Episode: 92 Total reward: 11.0 Training loss: 46.0329 Explore P: 0.9564 RunMean : 23.9462\n",
      "Episode: 93 Total reward: 63.0 Training loss: 78.1899 Explore P: 0.9552 RunMean : 24.3617\n",
      "Episode: 94 Total reward: 20.0 Training loss: 90.8581 Explore P: 0.9549 RunMean : 24.3158\n",
      "Episode: 95 Total reward: 20.0 Training loss: 11.7560 Explore P: 0.9545 RunMean : 24.2708\n",
      "Episode: 96 Total reward: 21.0 Training loss: 88.2380 Explore P: 0.9541 RunMean : 24.2371\n",
      "Episode: 97 Total reward: 66.0 Training loss: 41.8349 Explore P: 0.9528 RunMean : 24.6633\n",
      "Episode: 98 Total reward: 41.0 Training loss: 140.9594 Explore P: 0.9520 RunMean : 24.8283\n",
      "Episode: 99 Total reward: 13.0 Training loss: 116.9515 Explore P: 0.9518 RunMean : 24.7100\n",
      "Episode: 100 Total reward: 14.0 Training loss: 59.0135 Explore P: 0.9515 RunMean : 24.6800\n",
      "Episode: 101 Total reward: 56.0 Training loss: 41.6394 Explore P: 0.9504 RunMean : 25.1100\n",
      "Episode: 102 Total reward: 17.0 Training loss: 114.4426 Explore P: 0.9501 RunMean : 25.0700\n",
      "Episode: 103 Total reward: 34.0 Training loss: 13.2757 Explore P: 0.9495 RunMean : 25.2900\n",
      "Episode: 104 Total reward: 32.0 Training loss: 49.1476 Explore P: 0.9489 RunMean : 25.5000\n",
      "Episode: 105 Total reward: 15.0 Training loss: 102.3701 Explore P: 0.9486 RunMean : 25.0600\n",
      "Episode: 106 Total reward: 19.0 Training loss: 56.9884 Explore P: 0.9482 RunMean : 25.0400\n",
      "Episode: 107 Total reward: 44.0 Training loss: 83.8496 Explore P: 0.9474 RunMean : 25.3100\n",
      "Episode: 108 Total reward: 14.0 Training loss: 24.1513 Explore P: 0.9471 RunMean : 25.0200\n",
      "Episode: 109 Total reward: 29.0 Training loss: 83.8473 Explore P: 0.9466 RunMean : 25.1400\n",
      "Episode: 110 Total reward: 13.0 Training loss: 81.0411 Explore P: 0.9463 RunMean : 24.5400\n",
      "Episode: 111 Total reward: 16.0 Training loss: 27.9198 Explore P: 0.9460 RunMean : 24.5400\n",
      "Episode: 112 Total reward: 17.0 Training loss: 96.1663 Explore P: 0.9457 RunMean : 24.5900\n",
      "Episode: 113 Total reward: 13.0 Training loss: 64.8013 Explore P: 0.9455 RunMean : 24.5800\n",
      "Episode: 114 Total reward: 23.0 Training loss: 66.9520 Explore P: 0.9450 RunMean : 24.6300\n",
      "Episode: 115 Total reward: 15.0 Training loss: 50.5344 Explore P: 0.9447 RunMean : 24.6200\n",
      "Episode: 116 Total reward: 20.0 Training loss: 30.8566 Explore P: 0.9444 RunMean : 24.6300\n",
      "Episode: 117 Total reward: 18.0 Training loss: 157.0943 Explore P: 0.9440 RunMean : 24.5500\n",
      "Episode: 118 Total reward: 44.0 Training loss: 51.4343 Explore P: 0.9432 RunMean : 24.7800\n",
      "Episode: 119 Total reward: 14.0 Training loss: 84.4393 Explore P: 0.9429 RunMean : 24.8000\n",
      "Episode: 120 Total reward: 15.0 Training loss: 127.5017 Explore P: 0.9427 RunMean : 24.8000\n",
      "Episode: 121 Total reward: 16.0 Training loss: 27.9675 Explore P: 0.9423 RunMean : 24.8600\n",
      "Episode: 122 Total reward: 12.0 Training loss: 93.4124 Explore P: 0.9421 RunMean : 24.8800\n",
      "Episode: 123 Total reward: 14.0 Training loss: 83.1597 Explore P: 0.9419 RunMean : 24.6100\n",
      "Episode: 124 Total reward: 11.0 Training loss: 101.6295 Explore P: 0.9417 RunMean : 24.6200\n",
      "Episode: 125 Total reward: 16.0 Training loss: 175.2880 Explore P: 0.9414 RunMean : 24.3700\n",
      "Episode: 126 Total reward: 22.0 Training loss: 32.9655 Explore P: 0.9409 RunMean : 24.2900\n",
      "Episode: 127 Total reward: 15.0 Training loss: 22.7646 Explore P: 0.9407 RunMean : 23.7000\n",
      "Episode: 128 Total reward: 19.0 Training loss: 115.9381 Explore P: 0.9403 RunMean : 23.7200\n",
      "Episode: 129 Total reward: 33.0 Training loss: 85.5923 Explore P: 0.9397 RunMean : 23.8200\n",
      "Episode: 130 Total reward: 33.0 Training loss: 109.0901 Explore P: 0.9391 RunMean : 23.9400\n",
      "Episode: 131 Total reward: 13.0 Training loss: 19.0375 Explore P: 0.9388 RunMean : 23.9000\n",
      "Episode: 132 Total reward: 31.0 Training loss: 135.6039 Explore P: 0.9382 RunMean : 24.0700\n",
      "Episode: 133 Total reward: 22.0 Training loss: 82.8699 Explore P: 0.9378 RunMean : 24.1700\n",
      "Episode: 134 Total reward: 39.0 Training loss: 124.3636 Explore P: 0.9371 RunMean : 24.3900\n",
      "Episode: 135 Total reward: 35.0 Training loss: 79.8154 Explore P: 0.9364 RunMean : 24.4600\n",
      "Episode: 136 Total reward: 29.0 Training loss: 36.5054 Explore P: 0.9359 RunMean : 24.6500\n",
      "Episode: 137 Total reward: 18.0 Training loss: 88.6074 Explore P: 0.9356 RunMean : 24.7300\n",
      "Episode: 138 Total reward: 11.0 Training loss: 85.2581 Explore P: 0.9353 RunMean : 24.5200\n",
      "Episode: 139 Total reward: 41.0 Training loss: 192.0361 Explore P: 0.9346 RunMean : 24.8300\n",
      "Episode: 140 Total reward: 13.0 Training loss: 107.5896 Explore P: 0.9343 RunMean : 24.7100\n",
      "Episode: 141 Total reward: 19.0 Training loss: 122.6996 Explore P: 0.9340 RunMean : 24.7300\n",
      "Episode: 142 Total reward: 55.0 Training loss: 206.7387 Explore P: 0.9330 RunMean : 25.1100\n",
      "Episode: 143 Total reward: 27.0 Training loss: 35.9314 Explore P: 0.9324 RunMean : 25.0200\n",
      "Episode: 144 Total reward: 35.0 Training loss: 48.4697 Explore P: 0.9318 RunMean : 25.2200\n",
      "Episode: 145 Total reward: 9.0 Training loss: 13.6518 Explore P: 0.9316 RunMean : 25.1400\n",
      "Episode: 146 Total reward: 17.0 Training loss: 162.0551 Explore P: 0.9313 RunMean : 25.1800\n",
      "Episode: 147 Total reward: 18.0 Training loss: 118.3616 Explore P: 0.9310 RunMean : 25.1000\n",
      "Episode: 148 Total reward: 15.0 Training loss: 45.1864 Explore P: 0.9307 RunMean : 25.0600\n",
      "Episode: 149 Total reward: 44.0 Training loss: 16.6377 Explore P: 0.9299 RunMean : 25.3000\n",
      "Episode: 150 Total reward: 17.0 Training loss: 119.7445 Explore P: 0.9296 RunMean : 25.3200\n",
      "Episode: 151 Total reward: 25.0 Training loss: 74.7105 Explore P: 0.9291 RunMean : 25.1700\n",
      "Episode: 152 Total reward: 17.0 Training loss: 20.7756 Explore P: 0.9288 RunMean : 24.9800\n",
      "Episode: 153 Total reward: 17.0 Training loss: 88.2626 Explore P: 0.9285 RunMean : 24.9200\n",
      "Episode: 154 Total reward: 13.0 Training loss: 90.2290 Explore P: 0.9282 RunMean : 24.3000\n",
      "Episode: 155 Total reward: 31.0 Training loss: 220.2811 Explore P: 0.9277 RunMean : 24.3400\n",
      "Episode: 156 Total reward: 22.0 Training loss: 105.4856 Explore P: 0.9272 RunMean : 24.3700\n",
      "Episode: 157 Total reward: 15.0 Training loss: 114.5777 Explore P: 0.9270 RunMean : 24.2800\n",
      "Episode: 158 Total reward: 22.0 Training loss: 193.7681 Explore P: 0.9266 RunMean : 24.2400\n",
      "Episode: 159 Total reward: 24.0 Training loss: 149.7752 Explore P: 0.9261 RunMean : 24.3400\n",
      "Episode: 160 Total reward: 20.0 Training loss: 77.2901 Explore P: 0.9257 RunMean : 23.9600\n",
      "Episode: 161 Total reward: 25.0 Training loss: 312.8281 Explore P: 0.9253 RunMean : 23.9900\n",
      "Episode: 162 Total reward: 17.0 Training loss: 195.4706 Explore P: 0.9250 RunMean : 24.0700\n",
      "Episode: 163 Total reward: 32.0 Training loss: 56.6134 Explore P: 0.9244 RunMean : 24.1800\n",
      "Episode: 164 Total reward: 13.0 Training loss: 193.9928 Explore P: 0.9241 RunMean : 24.1100\n",
      "Episode: 165 Total reward: 14.0 Training loss: 47.6140 Explore P: 0.9239 RunMean : 23.8100\n",
      "Episode: 166 Total reward: 24.0 Training loss: 96.3819 Explore P: 0.9234 RunMean : 23.9400\n",
      "Episode: 167 Total reward: 38.0 Training loss: 81.0337 Explore P: 0.9227 RunMean : 24.1400\n",
      "Episode: 168 Total reward: 25.0 Training loss: 33.2407 Explore P: 0.9223 RunMean : 24.2700\n",
      "Episode: 169 Total reward: 22.0 Training loss: 94.6202 Explore P: 0.9219 RunMean : 24.2800\n",
      "Episode: 170 Total reward: 19.0 Training loss: 31.6684 Explore P: 0.9215 RunMean : 24.3500\n",
      "Episode: 171 Total reward: 17.0 Training loss: 126.4461 Explore P: 0.9212 RunMean : 24.2800\n",
      "Episode: 172 Total reward: 65.0 Training loss: 121.7669 Explore P: 0.9200 RunMean : 24.7400\n",
      "Episode: 173 Total reward: 16.0 Training loss: 18.9331 Explore P: 0.9197 RunMean : 24.5800\n",
      "Episode: 174 Total reward: 36.0 Training loss: 80.5996 Explore P: 0.9190 RunMean : 24.5500\n",
      "Episode: 175 Total reward: 19.0 Training loss: 137.2823 Explore P: 0.9187 RunMean : 24.4800\n",
      "Episode: 176 Total reward: 11.0 Training loss: 172.9449 Explore P: 0.9185 RunMean : 24.2600\n",
      "Episode: 177 Total reward: 20.0 Training loss: 112.5595 Explore P: 0.9181 RunMean : 24.3000\n",
      "Episode: 178 Total reward: 15.0 Training loss: 95.2467 Explore P: 0.9179 RunMean : 24.0600\n",
      "Episode: 179 Total reward: 29.0 Training loss: 211.7570 Explore P: 0.9173 RunMean : 24.1500\n",
      "Episode: 180 Total reward: 72.0 Training loss: 32.4999 Explore P: 0.9160 RunMean : 24.5700\n",
      "Episode: 181 Total reward: 18.0 Training loss: 47.4928 Explore P: 0.9157 RunMean : 24.4600\n",
      "Episode: 182 Total reward: 11.0 Training loss: 107.2894 Explore P: 0.9155 RunMean : 24.3600\n",
      "Episode: 183 Total reward: 70.0 Training loss: 168.5672 Explore P: 0.9142 RunMean : 24.9400\n",
      "Episode: 184 Total reward: 16.0 Training loss: 200.4568 Explore P: 0.9139 RunMean : 24.6800\n",
      "Episode: 185 Total reward: 16.0 Training loss: 27.8273 Explore P: 0.9136 RunMean : 24.6900\n",
      "Episode: 186 Total reward: 19.0 Training loss: 23.7237 Explore P: 0.9133 RunMean : 24.6700\n",
      "Episode: 187 Total reward: 17.0 Training loss: 84.3282 Explore P: 0.9129 RunMean : 24.4000\n",
      "Episode: 188 Total reward: 20.0 Training loss: 92.7456 Explore P: 0.9126 RunMean : 24.3500\n",
      "Episode: 189 Total reward: 14.0 Training loss: 25.0014 Explore P: 0.9123 RunMean : 24.0800\n",
      "Episode: 190 Total reward: 16.0 Training loss: 107.7568 Explore P: 0.9120 RunMean : 24.0200\n",
      "Episode: 191 Total reward: 11.0 Training loss: 16.6047 Explore P: 0.9118 RunMean : 23.9900\n",
      "Episode: 192 Total reward: 40.0 Training loss: 224.0645 Explore P: 0.9111 RunMean : 24.2800\n",
      "Episode: 193 Total reward: 19.0 Training loss: 64.3599 Explore P: 0.9108 RunMean : 23.8400\n",
      "Episode: 194 Total reward: 12.0 Training loss: 13.1501 Explore P: 0.9105 RunMean : 23.7600\n",
      "Episode: 195 Total reward: 15.0 Training loss: 143.1540 Explore P: 0.9103 RunMean : 23.7100\n",
      "Episode: 196 Total reward: 17.0 Training loss: 70.1461 Explore P: 0.9100 RunMean : 23.6700\n",
      "Episode: 197 Total reward: 18.0 Training loss: 126.5494 Explore P: 0.9096 RunMean : 23.1900\n",
      "Episode: 198 Total reward: 36.0 Training loss: 19.2377 Explore P: 0.9090 RunMean : 23.1400\n",
      "Episode: 199 Total reward: 17.0 Training loss: 140.5316 Explore P: 0.9087 RunMean : 23.1800\n",
      "Episode: 200 Total reward: 18.0 Training loss: 102.1609 Explore P: 0.9083 RunMean : 23.2200\n",
      "Episode: 201 Total reward: 12.0 Training loss: 149.9764 Explore P: 0.9081 RunMean : 22.7800\n",
      "Episode: 202 Total reward: 22.0 Training loss: 112.7277 Explore P: 0.9077 RunMean : 22.8300\n",
      "Episode: 203 Total reward: 12.0 Training loss: 41.2099 Explore P: 0.9075 RunMean : 22.6100\n",
      "Episode: 204 Total reward: 37.0 Training loss: 82.2716 Explore P: 0.9068 RunMean : 22.6600\n",
      "Episode: 205 Total reward: 18.0 Training loss: 138.2508 Explore P: 0.9065 RunMean : 22.6900\n",
      "Episode: 206 Total reward: 80.0 Training loss: 94.4056 Explore P: 0.9051 RunMean : 23.3000\n",
      "Episode: 207 Total reward: 12.0 Training loss: 76.6419 Explore P: 0.9048 RunMean : 22.9800\n",
      "Episode: 208 Total reward: 9.0 Training loss: 125.3177 Explore P: 0.9047 RunMean : 22.9300\n",
      "Episode: 209 Total reward: 20.0 Training loss: 93.1192 Explore P: 0.9043 RunMean : 22.8400\n",
      "Episode: 210 Total reward: 12.0 Training loss: 64.4576 Explore P: 0.9041 RunMean : 22.8300\n",
      "Episode: 211 Total reward: 53.0 Training loss: 145.9480 Explore P: 0.9031 RunMean : 23.2000\n",
      "Episode: 212 Total reward: 33.0 Training loss: 20.1558 Explore P: 0.9025 RunMean : 23.3600\n",
      "Episode: 213 Total reward: 21.0 Training loss: 133.0162 Explore P: 0.9022 RunMean : 23.4400\n",
      "Episode: 214 Total reward: 21.0 Training loss: 163.9800 Explore P: 0.9018 RunMean : 23.4200\n",
      "Episode: 215 Total reward: 44.0 Training loss: 84.5976 Explore P: 0.9010 RunMean : 23.7100\n",
      "Episode: 216 Total reward: 16.0 Training loss: 106.9781 Explore P: 0.9007 RunMean : 23.6700\n",
      "Episode: 217 Total reward: 18.0 Training loss: 132.6360 Explore P: 0.9004 RunMean : 23.6700\n",
      "Episode: 218 Total reward: 20.0 Training loss: 142.1452 Explore P: 0.9000 RunMean : 23.4300\n",
      "Episode: 219 Total reward: 53.0 Training loss: 82.3290 Explore P: 0.8991 RunMean : 23.8200\n",
      "Episode: 220 Total reward: 35.0 Training loss: 97.6266 Explore P: 0.8984 RunMean : 24.0200\n",
      "Episode: 221 Total reward: 12.0 Training loss: 123.0450 Explore P: 0.8982 RunMean : 23.9800\n",
      "Episode: 222 Total reward: 20.0 Training loss: 185.3528 Explore P: 0.8979 RunMean : 24.0600\n",
      "Episode: 223 Total reward: 24.0 Training loss: 249.1241 Explore P: 0.8974 RunMean : 24.1600\n",
      "Episode: 224 Total reward: 18.0 Training loss: 20.1509 Explore P: 0.8971 RunMean : 24.2300\n",
      "Episode: 225 Total reward: 33.0 Training loss: 175.3532 Explore P: 0.8965 RunMean : 24.4000\n",
      "Episode: 226 Total reward: 28.0 Training loss: 73.8539 Explore P: 0.8960 RunMean : 24.4600\n",
      "Episode: 227 Total reward: 16.0 Training loss: 14.5552 Explore P: 0.8957 RunMean : 24.4700\n",
      "Episode: 228 Total reward: 60.0 Training loss: 220.9644 Explore P: 0.8947 RunMean : 24.8800\n",
      "Episode: 229 Total reward: 17.0 Training loss: 73.0940 Explore P: 0.8943 RunMean : 24.7200\n",
      "Episode: 230 Total reward: 9.0 Training loss: 295.7286 Explore P: 0.8942 RunMean : 24.4800\n",
      "Episode: 231 Total reward: 25.0 Training loss: 129.9730 Explore P: 0.8937 RunMean : 24.6000\n",
      "Episode: 232 Total reward: 38.0 Training loss: 118.9467 Explore P: 0.8931 RunMean : 24.6700\n",
      "Episode: 233 Total reward: 21.0 Training loss: 285.5303 Explore P: 0.8927 RunMean : 24.6600\n",
      "Episode: 234 Total reward: 36.0 Training loss: 16.1128 Explore P: 0.8920 RunMean : 24.6300\n",
      "Episode: 235 Total reward: 15.0 Training loss: 78.9693 Explore P: 0.8918 RunMean : 24.4300\n",
      "Episode: 236 Total reward: 40.0 Training loss: 168.1378 Explore P: 0.8911 RunMean : 24.5400\n",
      "Episode: 237 Total reward: 70.0 Training loss: 89.5975 Explore P: 0.8898 RunMean : 25.0600\n",
      "Episode: 238 Total reward: 32.0 Training loss: 93.1696 Explore P: 0.8892 RunMean : 25.2700\n",
      "Episode: 239 Total reward: 52.0 Training loss: 123.3093 Explore P: 0.8883 RunMean : 25.3800\n",
      "Episode: 240 Total reward: 37.0 Training loss: 298.9714 Explore P: 0.8877 RunMean : 25.6200\n",
      "Episode: 241 Total reward: 66.0 Training loss: 154.9689 Explore P: 0.8865 RunMean : 26.0900\n",
      "Episode: 242 Total reward: 34.0 Training loss: 132.6678 Explore P: 0.8859 RunMean : 25.8800\n",
      "Episode: 243 Total reward: 11.0 Training loss: 58.4780 Explore P: 0.8857 RunMean : 25.7200\n",
      "Episode: 244 Total reward: 12.0 Training loss: 16.9050 Explore P: 0.8855 RunMean : 25.4900\n",
      "Episode: 245 Total reward: 25.0 Training loss: 86.4067 Explore P: 0.8850 RunMean : 25.6500\n",
      "Episode: 246 Total reward: 26.0 Training loss: 177.4487 Explore P: 0.8846 RunMean : 25.7400\n",
      "Episode: 247 Total reward: 35.0 Training loss: 117.2148 Explore P: 0.8840 RunMean : 25.9100\n",
      "Episode: 248 Total reward: 10.0 Training loss: 182.1439 Explore P: 0.8838 RunMean : 25.8600\n",
      "Episode: 249 Total reward: 31.0 Training loss: 174.6484 Explore P: 0.8832 RunMean : 25.7300\n",
      "Episode: 250 Total reward: 20.0 Training loss: 128.0020 Explore P: 0.8829 RunMean : 25.7600\n",
      "Episode: 251 Total reward: 34.0 Training loss: 72.6714 Explore P: 0.8823 RunMean : 25.8500\n",
      "Episode: 252 Total reward: 26.0 Training loss: 237.6183 Explore P: 0.8818 RunMean : 25.9400\n",
      "Episode: 253 Total reward: 31.0 Training loss: 66.5147 Explore P: 0.8813 RunMean : 26.0800\n",
      "Episode: 254 Total reward: 16.0 Training loss: 134.4581 Explore P: 0.8810 RunMean : 26.1100\n",
      "Episode: 255 Total reward: 37.0 Training loss: 95.5316 Explore P: 0.8803 RunMean : 26.1700\n",
      "Episode: 256 Total reward: 34.0 Training loss: 20.3844 Explore P: 0.8797 RunMean : 26.2900\n",
      "Episode: 257 Total reward: 32.0 Training loss: 188.7671 Explore P: 0.8792 RunMean : 26.4600\n",
      "Episode: 258 Total reward: 53.0 Training loss: 20.3255 Explore P: 0.8783 RunMean : 26.7700\n",
      "Episode: 259 Total reward: 30.0 Training loss: 105.9328 Explore P: 0.8777 RunMean : 26.8300\n",
      "Episode: 260 Total reward: 13.0 Training loss: 207.8138 Explore P: 0.8775 RunMean : 26.7600\n",
      "Episode: 261 Total reward: 15.0 Training loss: 115.1792 Explore P: 0.8772 RunMean : 26.6600\n",
      "Episode: 262 Total reward: 53.0 Training loss: 32.7771 Explore P: 0.8763 RunMean : 27.0200\n",
      "Episode: 263 Total reward: 18.0 Training loss: 133.2558 Explore P: 0.8760 RunMean : 26.8800\n",
      "Episode: 264 Total reward: 29.0 Training loss: 249.3378 Explore P: 0.8755 RunMean : 27.0400\n",
      "Episode: 265 Total reward: 28.0 Training loss: 134.8640 Explore P: 0.8750 RunMean : 27.1800\n",
      "Episode: 266 Total reward: 16.0 Training loss: 174.2843 Explore P: 0.8747 RunMean : 27.1000\n",
      "Episode: 267 Total reward: 43.0 Training loss: 194.6828 Explore P: 0.8740 RunMean : 27.1500\n",
      "Episode: 268 Total reward: 98.0 Training loss: 70.0088 Explore P: 0.8722 RunMean : 27.8800\n",
      "Episode: 269 Total reward: 22.0 Training loss: 99.1201 Explore P: 0.8719 RunMean : 27.8800\n",
      "Episode: 270 Total reward: 28.0 Training loss: 354.1528 Explore P: 0.8714 RunMean : 27.9700\n",
      "Episode: 271 Total reward: 25.0 Training loss: 398.7106 Explore P: 0.8709 RunMean : 28.0500\n",
      "Episode: 272 Total reward: 29.0 Training loss: 30.7924 Explore P: 0.8704 RunMean : 27.6900\n",
      "Episode: 273 Total reward: 29.0 Training loss: 99.2074 Explore P: 0.8699 RunMean : 27.8200\n",
      "Episode: 274 Total reward: 53.0 Training loss: 144.8717 Explore P: 0.8690 RunMean : 27.9900\n",
      "Episode: 275 Total reward: 46.0 Training loss: 64.9637 Explore P: 0.8682 RunMean : 28.2600\n",
      "Episode: 276 Total reward: 11.0 Training loss: 99.2693 Explore P: 0.8680 RunMean : 28.2600\n",
      "Episode: 277 Total reward: 34.0 Training loss: 229.0451 Explore P: 0.8674 RunMean : 28.4000\n",
      "Episode: 278 Total reward: 11.0 Training loss: 184.1963 Explore P: 0.8672 RunMean : 28.3600\n",
      "Episode: 279 Total reward: 20.0 Training loss: 166.1586 Explore P: 0.8669 RunMean : 28.2700\n",
      "Episode: 280 Total reward: 78.0 Training loss: 178.3463 Explore P: 0.8655 RunMean : 28.3300\n",
      "Episode: 281 Total reward: 22.0 Training loss: 41.9726 Explore P: 0.8652 RunMean : 28.3700\n",
      "Episode: 282 Total reward: 32.0 Training loss: 93.4403 Explore P: 0.8646 RunMean : 28.5800\n",
      "Episode: 283 Total reward: 28.0 Training loss: 192.1346 Explore P: 0.8641 RunMean : 28.1600\n",
      "Episode: 284 Total reward: 15.0 Training loss: 276.3983 Explore P: 0.8639 RunMean : 28.1500\n",
      "Episode: 285 Total reward: 27.0 Training loss: 183.0822 Explore P: 0.8634 RunMean : 28.2600\n",
      "Episode: 286 Total reward: 74.0 Training loss: 149.0130 Explore P: 0.8621 RunMean : 28.8100\n",
      "Episode: 287 Total reward: 15.0 Training loss: 442.2310 Explore P: 0.8619 RunMean : 28.7900\n",
      "Episode: 288 Total reward: 13.0 Training loss: 20.6186 Explore P: 0.8616 RunMean : 28.7200\n",
      "Episode: 289 Total reward: 11.0 Training loss: 118.3294 Explore P: 0.8614 RunMean : 28.6900\n",
      "Episode: 290 Total reward: 54.0 Training loss: 270.1999 Explore P: 0.8605 RunMean : 29.0700\n",
      "Episode: 291 Total reward: 43.0 Training loss: 376.0733 Explore P: 0.8598 RunMean : 29.3900\n",
      "Episode: 292 Total reward: 59.0 Training loss: 244.1227 Explore P: 0.8588 RunMean : 29.5800\n",
      "Episode: 293 Total reward: 46.0 Training loss: 541.9722 Explore P: 0.8580 RunMean : 29.8500\n",
      "Episode: 294 Total reward: 21.0 Training loss: 28.3375 Explore P: 0.8576 RunMean : 29.9400\n",
      "Episode: 295 Total reward: 37.0 Training loss: 120.5026 Explore P: 0.8570 RunMean : 30.1600\n",
      "Episode: 296 Total reward: 59.0 Training loss: 150.4201 Explore P: 0.8560 RunMean : 30.5800\n",
      "Episode: 297 Total reward: 38.0 Training loss: 114.6372 Explore P: 0.8553 RunMean : 30.7800\n",
      "Episode: 298 Total reward: 23.0 Training loss: 20.9039 Explore P: 0.8549 RunMean : 30.6500\n",
      "Episode: 299 Total reward: 15.0 Training loss: 116.0944 Explore P: 0.8547 RunMean : 30.6300\n",
      "Episode: 300 Total reward: 16.0 Training loss: 324.2987 Explore P: 0.8544 RunMean : 30.6100\n",
      "Episode: 301 Total reward: 19.0 Training loss: 411.7443 Explore P: 0.8541 RunMean : 30.6800\n",
      "Episode: 302 Total reward: 35.0 Training loss: 188.3374 Explore P: 0.8535 RunMean : 30.8100\n",
      "Episode: 303 Total reward: 47.0 Training loss: 101.6326 Explore P: 0.8527 RunMean : 31.1600\n",
      "Episode: 304 Total reward: 28.0 Training loss: 150.8865 Explore P: 0.8522 RunMean : 31.0700\n",
      "Episode: 305 Total reward: 28.0 Training loss: 45.2599 Explore P: 0.8517 RunMean : 31.1700\n",
      "Episode: 306 Total reward: 37.0 Training loss: 212.6143 Explore P: 0.8511 RunMean : 30.7400\n",
      "Episode: 307 Total reward: 26.0 Training loss: 179.2021 Explore P: 0.8506 RunMean : 30.8800\n",
      "Episode: 308 Total reward: 15.0 Training loss: 402.7444 Explore P: 0.8504 RunMean : 30.9400\n",
      "Episode: 309 Total reward: 14.0 Training loss: 24.5618 Explore P: 0.8502 RunMean : 30.8800\n",
      "Episode: 310 Total reward: 29.0 Training loss: 153.6459 Explore P: 0.8497 RunMean : 31.0500\n",
      "Episode: 311 Total reward: 28.0 Training loss: 103.9765 Explore P: 0.8492 RunMean : 30.8000\n",
      "Episode: 312 Total reward: 54.0 Training loss: 367.3305 Explore P: 0.8483 RunMean : 31.0100\n",
      "Episode: 313 Total reward: 65.0 Training loss: 379.6005 Explore P: 0.8472 RunMean : 31.4500\n",
      "Episode: 314 Total reward: 16.0 Training loss: 41.7177 Explore P: 0.8469 RunMean : 31.4000\n",
      "Episode: 315 Total reward: 25.0 Training loss: 120.9002 Explore P: 0.8465 RunMean : 31.2100\n",
      "Episode: 316 Total reward: 13.0 Training loss: 257.4013 Explore P: 0.8463 RunMean : 31.1800\n",
      "Episode: 317 Total reward: 25.0 Training loss: 412.1755 Explore P: 0.8458 RunMean : 31.2500\n",
      "Episode: 318 Total reward: 11.0 Training loss: 142.1869 Explore P: 0.8456 RunMean : 31.1600\n",
      "Episode: 319 Total reward: 23.0 Training loss: 289.8732 Explore P: 0.8453 RunMean : 30.8600\n",
      "Episode: 320 Total reward: 18.0 Training loss: 260.8398 Explore P: 0.8449 RunMean : 30.6900\n",
      "Episode: 321 Total reward: 18.0 Training loss: 324.5741 Explore P: 0.8446 RunMean : 30.7500\n",
      "Episode: 322 Total reward: 33.0 Training loss: 828.7430 Explore P: 0.8441 RunMean : 30.8800\n",
      "Episode: 323 Total reward: 70.0 Training loss: 184.3914 Explore P: 0.8429 RunMean : 31.3400\n",
      "Episode: 324 Total reward: 78.0 Training loss: 322.4012 Explore P: 0.8416 RunMean : 31.9400\n",
      "Episode: 325 Total reward: 33.0 Training loss: 28.2323 Explore P: 0.8410 RunMean : 31.9400\n",
      "Episode: 326 Total reward: 12.0 Training loss: 34.5035 Explore P: 0.8408 RunMean : 31.7800\n",
      "Episode: 327 Total reward: 48.0 Training loss: 43.7572 Explore P: 0.8400 RunMean : 32.1000\n",
      "Episode: 328 Total reward: 27.0 Training loss: 35.6412 Explore P: 0.8396 RunMean : 31.7700\n",
      "Episode: 329 Total reward: 41.0 Training loss: 418.6916 Explore P: 0.8389 RunMean : 32.0100\n",
      "Episode: 330 Total reward: 36.0 Training loss: 361.5101 Explore P: 0.8383 RunMean : 32.2800\n",
      "Episode: 331 Total reward: 18.0 Training loss: 40.3723 Explore P: 0.8380 RunMean : 32.2100\n",
      "Episode: 332 Total reward: 20.0 Training loss: 34.6132 Explore P: 0.8376 RunMean : 32.0300\n",
      "Episode: 333 Total reward: 18.0 Training loss: 144.1471 Explore P: 0.8373 RunMean : 32.0000\n",
      "Episode: 334 Total reward: 15.0 Training loss: 245.0061 Explore P: 0.8371 RunMean : 31.7900\n",
      "Episode: 335 Total reward: 19.0 Training loss: 88.9734 Explore P: 0.8368 RunMean : 31.8300\n",
      "Episode: 336 Total reward: 31.0 Training loss: 457.9503 Explore P: 0.8363 RunMean : 31.7400\n",
      "Episode: 337 Total reward: 41.0 Training loss: 348.9373 Explore P: 0.8356 RunMean : 31.4500\n",
      "Episode: 338 Total reward: 54.0 Training loss: 335.6392 Explore P: 0.8347 RunMean : 31.6700\n",
      "Episode: 339 Total reward: 14.0 Training loss: 226.4177 Explore P: 0.8344 RunMean : 31.2900\n",
      "Episode: 340 Total reward: 18.0 Training loss: 565.7655 Explore P: 0.8341 RunMean : 31.1000\n",
      "Episode: 341 Total reward: 11.0 Training loss: 42.0089 Explore P: 0.8340 RunMean : 30.5500\n",
      "Episode: 342 Total reward: 27.0 Training loss: 223.8116 Explore P: 0.8335 RunMean : 30.4800\n",
      "Episode: 343 Total reward: 13.0 Training loss: 282.8461 Explore P: 0.8333 RunMean : 30.5000\n",
      "Episode: 344 Total reward: 27.0 Training loss: 200.1774 Explore P: 0.8328 RunMean : 30.6500\n",
      "Episode: 345 Total reward: 20.0 Training loss: 382.6174 Explore P: 0.8325 RunMean : 30.6000\n",
      "Episode: 346 Total reward: 21.0 Training loss: 179.1819 Explore P: 0.8322 RunMean : 30.5500\n",
      "Episode: 347 Total reward: 30.0 Training loss: 33.3938 Explore P: 0.8317 RunMean : 30.5000\n",
      "Episode: 348 Total reward: 35.0 Training loss: 469.4245 Explore P: 0.8311 RunMean : 30.7500\n",
      "Episode: 349 Total reward: 27.0 Training loss: 331.2292 Explore P: 0.8306 RunMean : 30.7100\n",
      "Episode: 350 Total reward: 53.0 Training loss: 163.2943 Explore P: 0.8297 RunMean : 31.0400\n",
      "Episode: 351 Total reward: 22.0 Training loss: 218.3674 Explore P: 0.8294 RunMean : 30.9200\n",
      "Episode: 352 Total reward: 110.0 Training loss: 553.9531 Explore P: 0.8276 RunMean : 31.7600\n",
      "Episode: 353 Total reward: 28.0 Training loss: 173.3902 Explore P: 0.8271 RunMean : 31.7300\n",
      "Episode: 354 Total reward: 22.0 Training loss: 178.5198 Explore P: 0.8267 RunMean : 31.7900\n",
      "Episode: 355 Total reward: 34.0 Training loss: 42.7903 Explore P: 0.8262 RunMean : 31.7600\n",
      "Episode: 356 Total reward: 25.0 Training loss: 276.4302 Explore P: 0.8258 RunMean : 31.6700\n",
      "Episode: 357 Total reward: 26.0 Training loss: 265.8350 Explore P: 0.8253 RunMean : 31.6100\n",
      "Episode: 358 Total reward: 22.0 Training loss: 680.5073 Explore P: 0.8250 RunMean : 31.3000\n",
      "Episode: 359 Total reward: 46.0 Training loss: 122.5116 Explore P: 0.8242 RunMean : 31.4600\n",
      "Episode: 360 Total reward: 43.0 Training loss: 384.8596 Explore P: 0.8235 RunMean : 31.7600\n",
      "Episode: 361 Total reward: 32.0 Training loss: 230.8220 Explore P: 0.8230 RunMean : 31.9300\n",
      "Episode: 362 Total reward: 25.0 Training loss: 491.7935 Explore P: 0.8226 RunMean : 31.6500\n",
      "Episode: 363 Total reward: 91.0 Training loss: 156.9548 Explore P: 0.8211 RunMean : 32.3800\n",
      "Episode: 364 Total reward: 28.0 Training loss: 40.3023 Explore P: 0.8206 RunMean : 32.3700\n",
      "Episode: 365 Total reward: 17.0 Training loss: 252.4118 Explore P: 0.8203 RunMean : 32.2600\n",
      "Episode: 366 Total reward: 87.0 Training loss: 880.5630 Explore P: 0.8189 RunMean : 32.9700\n",
      "Episode: 367 Total reward: 19.0 Training loss: 243.2866 Explore P: 0.8186 RunMean : 32.7300\n",
      "Episode: 368 Total reward: 33.0 Training loss: 151.5079 Explore P: 0.8180 RunMean : 32.0800\n",
      "Episode: 369 Total reward: 13.0 Training loss: 204.2729 Explore P: 0.8178 RunMean : 31.9900\n",
      "Episode: 370 Total reward: 22.0 Training loss: 375.9681 Explore P: 0.8175 RunMean : 31.9300\n",
      "Episode: 371 Total reward: 28.0 Training loss: 237.4130 Explore P: 0.8170 RunMean : 31.9600\n",
      "Episode: 372 Total reward: 16.0 Training loss: 80.8085 Explore P: 0.8168 RunMean : 31.8300\n",
      "Episode: 373 Total reward: 94.0 Training loss: 568.3343 Explore P: 0.8152 RunMean : 32.4800\n",
      "Episode: 374 Total reward: 80.0 Training loss: 535.9055 Explore P: 0.8139 RunMean : 32.7500\n",
      "Episode: 375 Total reward: 32.0 Training loss: 40.6086 Explore P: 0.8134 RunMean : 32.6100\n",
      "Episode: 376 Total reward: 48.0 Training loss: 288.8875 Explore P: 0.8126 RunMean : 32.9800\n",
      "Episode: 377 Total reward: 18.0 Training loss: 383.5699 Explore P: 0.8123 RunMean : 32.8200\n",
      "Episode: 378 Total reward: 33.0 Training loss: 265.7330 Explore P: 0.8118 RunMean : 33.0400\n",
      "Episode: 379 Total reward: 40.0 Training loss: 130.1112 Explore P: 0.8111 RunMean : 33.2400\n",
      "Episode: 380 Total reward: 23.0 Training loss: 343.0541 Explore P: 0.8108 RunMean : 32.6900\n",
      "Episode: 381 Total reward: 22.0 Training loss: 275.2760 Explore P: 0.8104 RunMean : 32.6900\n",
      "Episode: 382 Total reward: 23.0 Training loss: 376.0316 Explore P: 0.8100 RunMean : 32.6000\n",
      "Episode: 383 Total reward: 23.0 Training loss: 223.5729 Explore P: 0.8097 RunMean : 32.5500\n",
      "Episode: 384 Total reward: 18.0 Training loss: 491.1066 Explore P: 0.8094 RunMean : 32.5800\n",
      "Episode: 385 Total reward: 19.0 Training loss: 704.7206 Explore P: 0.8091 RunMean : 32.5000\n",
      "Episode: 386 Total reward: 14.0 Training loss: 712.3558 Explore P: 0.8088 RunMean : 31.9000\n",
      "Episode: 387 Total reward: 29.0 Training loss: 188.7359 Explore P: 0.8084 RunMean : 32.0400\n",
      "Episode: 388 Total reward: 55.0 Training loss: 685.8025 Explore P: 0.8075 RunMean : 32.4600\n",
      "Episode: 389 Total reward: 22.0 Training loss: 822.8644 Explore P: 0.8071 RunMean : 32.5700\n",
      "Episode: 390 Total reward: 22.0 Training loss: 778.1589 Explore P: 0.8068 RunMean : 32.2500\n",
      "Episode: 391 Total reward: 21.0 Training loss: 562.5607 Explore P: 0.8064 RunMean : 32.0300\n",
      "Episode: 392 Total reward: 96.0 Training loss: 352.0296 Explore P: 0.8049 RunMean : 32.4000\n",
      "Episode: 393 Total reward: 44.0 Training loss: 470.5098 Explore P: 0.8042 RunMean : 32.3800\n",
      "Episode: 394 Total reward: 30.0 Training loss: 51.4842 Explore P: 0.8037 RunMean : 32.4700\n",
      "Episode: 395 Total reward: 21.0 Training loss: 58.0106 Explore P: 0.8034 RunMean : 32.3100\n",
      "Episode: 396 Total reward: 19.0 Training loss: 359.6736 Explore P: 0.8030 RunMean : 31.9100\n",
      "Episode: 397 Total reward: 14.0 Training loss: 184.1162 Explore P: 0.8028 RunMean : 31.6700\n",
      "Episode: 398 Total reward: 142.0 Training loss: 887.4337 Explore P: 0.8005 RunMean : 32.8600\n",
      "Episode: 399 Total reward: 36.0 Training loss: 638.1575 Explore P: 0.8000 RunMean : 33.0700\n",
      "Episode: 400 Total reward: 14.0 Training loss: 52.4952 Explore P: 0.7997 RunMean : 33.0500\n",
      "Episode: 401 Total reward: 15.0 Training loss: 1083.1620 Explore P: 0.7995 RunMean : 33.0100\n",
      "Episode: 402 Total reward: 36.0 Training loss: 595.2642 Explore P: 0.7989 RunMean : 33.0200\n",
      "Episode: 403 Total reward: 20.0 Training loss: 47.9054 Explore P: 0.7986 RunMean : 32.7500\n",
      "Episode: 404 Total reward: 30.0 Training loss: 407.2055 Explore P: 0.7981 RunMean : 32.7700\n",
      "Episode: 405 Total reward: 24.0 Training loss: 604.3216 Explore P: 0.7978 RunMean : 32.7300\n",
      "Episode: 406 Total reward: 129.0 Training loss: 445.7142 Explore P: 0.7957 RunMean : 33.6500\n",
      "Episode: 407 Total reward: 102.0 Training loss: 637.6218 Explore P: 0.7941 RunMean : 34.4100\n",
      "Episode: 408 Total reward: 38.0 Training loss: 476.3418 Explore P: 0.7935 RunMean : 34.6400\n",
      "Episode: 409 Total reward: 37.0 Training loss: 360.8085 Explore P: 0.7929 RunMean : 34.8700\n",
      "Episode: 410 Total reward: 14.0 Training loss: 232.3315 Explore P: 0.7927 RunMean : 34.7200\n",
      "Episode: 411 Total reward: 38.0 Training loss: 617.6332 Explore P: 0.7921 RunMean : 34.8200\n",
      "Episode: 412 Total reward: 64.0 Training loss: 505.7341 Explore P: 0.7910 RunMean : 34.9200\n",
      "Episode: 413 Total reward: 22.0 Training loss: 604.7310 Explore P: 0.7907 RunMean : 34.4900\n",
      "Episode: 414 Total reward: 44.0 Training loss: 920.5857 Explore P: 0.7900 RunMean : 34.7700\n",
      "Episode: 415 Total reward: 57.0 Training loss: 78.3729 Explore P: 0.7891 RunMean : 35.0900\n",
      "Episode: 416 Total reward: 23.0 Training loss: 629.9489 Explore P: 0.7887 RunMean : 35.1900\n",
      "Episode: 417 Total reward: 30.0 Training loss: 81.9290 Explore P: 0.7883 RunMean : 35.2400\n",
      "Episode: 418 Total reward: 58.0 Training loss: 57.6494 Explore P: 0.7874 RunMean : 35.7100\n",
      "Episode: 419 Total reward: 13.0 Training loss: 462.2305 Explore P: 0.7871 RunMean : 35.6100\n",
      "Episode: 420 Total reward: 79.0 Training loss: 1056.2192 Explore P: 0.7859 RunMean : 36.2200\n",
      "Episode: 421 Total reward: 19.0 Training loss: 336.0733 Explore P: 0.7856 RunMean : 36.2300\n",
      "Episode: 422 Total reward: 17.0 Training loss: 1006.8411 Explore P: 0.7853 RunMean : 36.0700\n",
      "Episode: 423 Total reward: 34.0 Training loss: 72.7678 Explore P: 0.7848 RunMean : 35.7100\n",
      "Episode: 424 Total reward: 23.0 Training loss: 566.1194 Explore P: 0.7844 RunMean : 35.1600\n",
      "Episode: 425 Total reward: 58.0 Training loss: 1397.9774 Explore P: 0.7835 RunMean : 35.4100\n",
      "Episode: 426 Total reward: 68.0 Training loss: 230.6816 Explore P: 0.7825 RunMean : 35.9700\n",
      "Episode: 427 Total reward: 16.0 Training loss: 818.6042 Explore P: 0.7822 RunMean : 35.6500\n",
      "Episode: 428 Total reward: 17.0 Training loss: 759.4417 Explore P: 0.7820 RunMean : 35.5500\n",
      "Episode: 429 Total reward: 10.0 Training loss: 1455.4692 Explore P: 0.7818 RunMean : 35.2400\n",
      "Episode: 430 Total reward: 21.0 Training loss: 121.5687 Explore P: 0.7815 RunMean : 35.0900\n",
      "Episode: 431 Total reward: 16.0 Training loss: 1079.3942 Explore P: 0.7812 RunMean : 35.0700\n",
      "Episode: 432 Total reward: 55.0 Training loss: 74.1079 Explore P: 0.7804 RunMean : 35.4200\n",
      "Episode: 433 Total reward: 27.0 Training loss: 64.8056 Explore P: 0.7799 RunMean : 35.5100\n",
      "Episode: 434 Total reward: 29.0 Training loss: 236.8794 Explore P: 0.7795 RunMean : 35.6500\n",
      "Episode: 435 Total reward: 40.0 Training loss: 1461.3198 Explore P: 0.7789 RunMean : 35.8600\n",
      "Episode: 436 Total reward: 16.0 Training loss: 361.7951 Explore P: 0.7786 RunMean : 35.7100\n",
      "Episode: 437 Total reward: 124.0 Training loss: 1116.4294 Explore P: 0.7767 RunMean : 36.5400\n",
      "Episode: 438 Total reward: 20.0 Training loss: 865.9596 Explore P: 0.7764 RunMean : 36.2000\n",
      "Episode: 439 Total reward: 37.0 Training loss: 381.6505 Explore P: 0.7758 RunMean : 36.4300\n",
      "Episode: 440 Total reward: 37.0 Training loss: 980.4623 Explore P: 0.7752 RunMean : 36.6200\n",
      "Episode: 441 Total reward: 169.0 Training loss: 2389.0056 Explore P: 0.7726 RunMean : 38.2000\n",
      "Episode: 442 Total reward: 42.0 Training loss: 1036.4098 Explore P: 0.7720 RunMean : 38.3500\n",
      "Episode: 443 Total reward: 85.0 Training loss: 206.8243 Explore P: 0.7707 RunMean : 39.0700\n",
      "Episode: 444 Total reward: 30.0 Training loss: 1191.7885 Explore P: 0.7702 RunMean : 39.1000\n",
      "Episode: 445 Total reward: 24.0 Training loss: 854.3271 Explore P: 0.7698 RunMean : 39.1400\n",
      "Episode: 446 Total reward: 50.0 Training loss: 2083.4050 Explore P: 0.7690 RunMean : 39.4300\n",
      "Episode: 447 Total reward: 26.0 Training loss: 1235.7723 Explore P: 0.7686 RunMean : 39.3900\n",
      "Episode: 448 Total reward: 39.0 Training loss: 1859.4999 Explore P: 0.7681 RunMean : 39.4300\n",
      "Episode: 449 Total reward: 104.0 Training loss: 334.6611 Explore P: 0.7665 RunMean : 40.2000\n",
      "Episode: 450 Total reward: 16.0 Training loss: 169.3765 Explore P: 0.7662 RunMean : 39.8300\n",
      "Episode: 451 Total reward: 15.0 Training loss: 656.3914 Explore P: 0.7660 RunMean : 39.7600\n",
      "Episode: 452 Total reward: 35.0 Training loss: 475.5118 Explore P: 0.7654 RunMean : 39.0100\n",
      "Episode: 453 Total reward: 19.0 Training loss: 604.9578 Explore P: 0.7652 RunMean : 38.9200\n",
      "Episode: 454 Total reward: 22.0 Training loss: 796.6943 Explore P: 0.7648 RunMean : 38.9200\n",
      "Episode: 455 Total reward: 20.0 Training loss: 421.7720 Explore P: 0.7645 RunMean : 38.7800\n",
      "Episode: 456 Total reward: 25.0 Training loss: 879.0942 Explore P: 0.7641 RunMean : 38.7800\n",
      "Episode: 457 Total reward: 42.0 Training loss: 2052.2856 Explore P: 0.7635 RunMean : 38.9400\n",
      "Episode: 458 Total reward: 13.0 Training loss: 653.8631 Explore P: 0.7633 RunMean : 38.8500\n",
      "Episode: 459 Total reward: 103.0 Training loss: 1119.8168 Explore P: 0.7617 RunMean : 39.4200\n",
      "Episode: 460 Total reward: 61.0 Training loss: 390.0334 Explore P: 0.7608 RunMean : 39.6000\n",
      "Episode: 461 Total reward: 21.0 Training loss: 720.6793 Explore P: 0.7605 RunMean : 39.4900\n",
      "Episode: 462 Total reward: 26.0 Training loss: 356.0959 Explore P: 0.7601 RunMean : 39.5000\n",
      "Episode: 463 Total reward: 15.0 Training loss: 662.4566 Explore P: 0.7598 RunMean : 38.7400\n",
      "Episode: 464 Total reward: 36.0 Training loss: 1095.5358 Explore P: 0.7593 RunMean : 38.8200\n",
      "Episode: 465 Total reward: 61.0 Training loss: 2429.9998 Explore P: 0.7584 RunMean : 39.2600\n",
      "Episode: 466 Total reward: 64.0 Training loss: 1834.3408 Explore P: 0.7574 RunMean : 39.0300\n",
      "Episode: 467 Total reward: 26.0 Training loss: 813.4962 Explore P: 0.7570 RunMean : 39.1000\n",
      "Episode: 468 Total reward: 11.0 Training loss: 832.5422 Explore P: 0.7568 RunMean : 38.8800\n",
      "Episode: 469 Total reward: 51.0 Training loss: 221.1366 Explore P: 0.7561 RunMean : 39.2600\n",
      "Episode: 470 Total reward: 50.0 Training loss: 602.5627 Explore P: 0.7553 RunMean : 39.5400\n",
      "Episode: 471 Total reward: 41.0 Training loss: 414.2193 Explore P: 0.7547 RunMean : 39.6700\n",
      "Episode: 472 Total reward: 14.0 Training loss: 1151.0052 Explore P: 0.7545 RunMean : 39.6500\n",
      "Episode: 473 Total reward: 62.0 Training loss: 1282.7114 Explore P: 0.7535 RunMean : 39.3300\n",
      "Episode: 474 Total reward: 14.0 Training loss: 1372.0818 Explore P: 0.7533 RunMean : 38.6700\n",
      "Episode: 475 Total reward: 15.0 Training loss: 101.7886 Explore P: 0.7531 RunMean : 38.5000\n",
      "Episode: 476 Total reward: 31.0 Training loss: 1852.4604 Explore P: 0.7526 RunMean : 38.3300\n",
      "Episode: 477 Total reward: 34.0 Training loss: 1790.6522 Explore P: 0.7521 RunMean : 38.4900\n",
      "Episode: 478 Total reward: 49.0 Training loss: 1017.8834 Explore P: 0.7514 RunMean : 38.6500\n",
      "Episode: 479 Total reward: 66.0 Training loss: 1580.6672 Explore P: 0.7504 RunMean : 38.9100\n",
      "Episode: 480 Total reward: 78.0 Training loss: 2560.1414 Explore P: 0.7492 RunMean : 39.4600\n",
      "Episode: 481 Total reward: 28.0 Training loss: 1790.2913 Explore P: 0.7488 RunMean : 39.5200\n",
      "Episode: 482 Total reward: 16.0 Training loss: 2177.9058 Explore P: 0.7486 RunMean : 39.4500\n",
      "Episode: 483 Total reward: 46.0 Training loss: 902.7173 Explore P: 0.7479 RunMean : 39.6800\n",
      "Episode: 484 Total reward: 22.0 Training loss: 336.2140 Explore P: 0.7476 RunMean : 39.7200\n",
      "Episode: 485 Total reward: 56.0 Training loss: 952.0493 Explore P: 0.7467 RunMean : 40.0900\n",
      "Episode: 486 Total reward: 28.0 Training loss: 350.3792 Explore P: 0.7463 RunMean : 40.2300\n",
      "Episode: 487 Total reward: 27.0 Training loss: 1114.1998 Explore P: 0.7459 RunMean : 40.2100\n",
      "Episode: 488 Total reward: 105.0 Training loss: 425.5065 Explore P: 0.7443 RunMean : 40.7100\n",
      "Episode: 489 Total reward: 14.0 Training loss: 427.6640 Explore P: 0.7441 RunMean : 40.6300\n",
      "Episode: 490 Total reward: 15.0 Training loss: 1231.0042 Explore P: 0.7439 RunMean : 40.5600\n",
      "Episode: 491 Total reward: 22.0 Training loss: 2756.2109 Explore P: 0.7436 RunMean : 40.5700\n",
      "Episode: 492 Total reward: 35.0 Training loss: 1187.8322 Explore P: 0.7431 RunMean : 39.9600\n",
      "Episode: 493 Total reward: 46.0 Training loss: 2685.7739 Explore P: 0.7424 RunMean : 39.9800\n",
      "Episode: 494 Total reward: 32.0 Training loss: 852.9197 Explore P: 0.7419 RunMean : 40.0000\n",
      "Episode: 495 Total reward: 110.0 Training loss: 546.1600 Explore P: 0.7403 RunMean : 40.8900\n",
      "Episode: 496 Total reward: 16.0 Training loss: 1167.2587 Explore P: 0.7400 RunMean : 40.8600\n",
      "Episode: 497 Total reward: 50.0 Training loss: 1761.6180 Explore P: 0.7393 RunMean : 41.2200\n",
      "Episode: 498 Total reward: 54.0 Training loss: 2119.4307 Explore P: 0.7385 RunMean : 40.3400\n",
      "Episode: 499 Total reward: 56.0 Training loss: 192.4792 Explore P: 0.7377 RunMean : 40.5400\n",
      "Episode: 500 Total reward: 112.0 Training loss: 980.5767 Explore P: 0.7360 RunMean : 41.5200\n",
      "Episode: 501 Total reward: 44.0 Training loss: 2020.2649 Explore P: 0.7354 RunMean : 41.8100\n",
      "Episode: 502 Total reward: 150.0 Training loss: 139.3766 Explore P: 0.7332 RunMean : 42.9500\n",
      "Episode: 503 Total reward: 28.0 Training loss: 2082.0781 Explore P: 0.7328 RunMean : 43.0300\n",
      "Episode: 504 Total reward: 77.0 Training loss: 4342.1172 Explore P: 0.7316 RunMean : 43.5000\n",
      "Episode: 505 Total reward: 25.0 Training loss: 461.1412 Explore P: 0.7313 RunMean : 43.5100\n",
      "Episode: 506 Total reward: 63.0 Training loss: 172.2436 Explore P: 0.7303 RunMean : 42.8500\n",
      "Episode: 507 Total reward: 27.0 Training loss: 676.3478 Explore P: 0.7299 RunMean : 42.1000\n",
      "Episode: 508 Total reward: 47.0 Training loss: 2906.2041 Explore P: 0.7293 RunMean : 42.1900\n",
      "Episode: 509 Total reward: 68.0 Training loss: 2090.3875 Explore P: 0.7283 RunMean : 42.5000\n",
      "Episode: 510 Total reward: 75.0 Training loss: 355.5062 Explore P: 0.7272 RunMean : 43.1100\n",
      "Episode: 511 Total reward: 19.0 Training loss: 1275.4147 Explore P: 0.7269 RunMean : 42.9200\n",
      "Episode: 512 Total reward: 32.0 Training loss: 105.4588 Explore P: 0.7264 RunMean : 42.6000\n",
      "Episode: 513 Total reward: 14.0 Training loss: 3099.3440 Explore P: 0.7262 RunMean : 42.5200\n",
      "Episode: 514 Total reward: 12.0 Training loss: 2688.1704 Explore P: 0.7261 RunMean : 42.2000\n",
      "Episode: 515 Total reward: 16.0 Training loss: 2356.5010 Explore P: 0.7258 RunMean : 41.7900\n",
      "Episode: 516 Total reward: 27.0 Training loss: 4334.1265 Explore P: 0.7254 RunMean : 41.8300\n",
      "Episode: 517 Total reward: 43.0 Training loss: 495.0286 Explore P: 0.7248 RunMean : 41.9600\n",
      "Episode: 518 Total reward: 27.0 Training loss: 1693.3752 Explore P: 0.7244 RunMean : 41.6500\n",
      "Episode: 519 Total reward: 72.0 Training loss: 132.4622 Explore P: 0.7234 RunMean : 42.2400\n",
      "Episode: 520 Total reward: 39.0 Training loss: 629.8784 Explore P: 0.7228 RunMean : 41.8400\n",
      "Episode: 521 Total reward: 80.0 Training loss: 1568.8618 Explore P: 0.7217 RunMean : 42.4500\n",
      "Episode: 522 Total reward: 84.0 Training loss: 769.3390 Explore P: 0.7204 RunMean : 43.1200\n",
      "Episode: 523 Total reward: 62.0 Training loss: 199.1646 Explore P: 0.7196 RunMean : 43.4000\n",
      "Episode: 524 Total reward: 32.0 Training loss: 2302.9016 Explore P: 0.7191 RunMean : 43.4900\n",
      "Episode: 525 Total reward: 103.0 Training loss: 2648.1526 Explore P: 0.7176 RunMean : 43.9400\n",
      "Episode: 526 Total reward: 13.0 Training loss: 1032.2245 Explore P: 0.7174 RunMean : 43.3900\n",
      "Episode: 527 Total reward: 16.0 Training loss: 2850.7068 Explore P: 0.7172 RunMean : 43.3900\n",
      "Episode: 528 Total reward: 96.0 Training loss: 1259.5620 Explore P: 0.7158 RunMean : 44.1800\n",
      "Episode: 529 Total reward: 13.0 Training loss: 3521.3560 Explore P: 0.7156 RunMean : 44.2100\n",
      "Episode: 530 Total reward: 105.0 Training loss: 1998.7059 Explore P: 0.7141 RunMean : 45.0500\n",
      "Episode: 531 Total reward: 22.0 Training loss: 3496.3303 Explore P: 0.7138 RunMean : 45.1100\n",
      "Episode: 532 Total reward: 34.0 Training loss: 1707.0680 Explore P: 0.7133 RunMean : 44.9000\n",
      "Episode: 533 Total reward: 58.0 Training loss: 161.4082 Explore P: 0.7125 RunMean : 45.2100\n",
      "Episode: 534 Total reward: 27.0 Training loss: 1636.6342 Explore P: 0.7121 RunMean : 45.1900\n",
      "Episode: 535 Total reward: 99.0 Training loss: 192.1257 Explore P: 0.7107 RunMean : 45.7800\n",
      "Episode: 536 Total reward: 41.0 Training loss: 1712.9246 Explore P: 0.7101 RunMean : 46.0300\n",
      "Episode: 537 Total reward: 36.0 Training loss: 189.4227 Explore P: 0.7096 RunMean : 45.1500\n",
      "Episode: 538 Total reward: 59.0 Training loss: 4644.3447 Explore P: 0.7088 RunMean : 45.5400\n",
      "Episode: 539 Total reward: 77.0 Training loss: 5094.9497 Explore P: 0.7077 RunMean : 45.9400\n",
      "Episode: 540 Total reward: 122.0 Training loss: 3987.5979 Explore P: 0.7060 RunMean : 46.7900\n",
      "Episode: 541 Total reward: 143.0 Training loss: 4278.8926 Explore P: 0.7040 RunMean : 46.5300\n",
      "Episode: 542 Total reward: 167.0 Training loss: 1894.3535 Explore P: 0.7016 RunMean : 47.7800\n",
      "Episode: 543 Total reward: 83.0 Training loss: 1071.6835 Explore P: 0.7004 RunMean : 47.7600\n",
      "Episode: 544 Total reward: 33.0 Training loss: 293.0034 Explore P: 0.7000 RunMean : 47.7900\n",
      "Episode: 545 Total reward: 21.0 Training loss: 131.1011 Explore P: 0.6997 RunMean : 47.7600\n",
      "Episode: 546 Total reward: 14.0 Training loss: 1622.7263 Explore P: 0.6995 RunMean : 47.4000\n",
      "Episode: 547 Total reward: 9.0 Training loss: 4502.2769 Explore P: 0.6994 RunMean : 47.2300\n",
      "Episode: 548 Total reward: 31.0 Training loss: 2987.0752 Explore P: 0.6989 RunMean : 47.1500\n",
      "Episode: 549 Total reward: 12.0 Training loss: 1645.1372 Explore P: 0.6988 RunMean : 46.2300\n",
      "Episode: 550 Total reward: 32.0 Training loss: 3292.3940 Explore P: 0.6983 RunMean : 46.3900\n",
      "Episode: 551 Total reward: 30.0 Training loss: 164.4582 Explore P: 0.6979 RunMean : 46.5400\n",
      "Episode: 552 Total reward: 20.0 Training loss: 3734.3838 Explore P: 0.6976 RunMean : 46.3900\n",
      "Episode: 553 Total reward: 20.0 Training loss: 4352.7554 Explore P: 0.6973 RunMean : 46.4000\n",
      "Episode: 554 Total reward: 59.0 Training loss: 1950.6156 Explore P: 0.6965 RunMean : 46.7700\n",
      "Episode: 555 Total reward: 137.0 Training loss: 3505.7671 Explore P: 0.6946 RunMean : 47.9400\n",
      "Episode: 556 Total reward: 112.0 Training loss: 171.4818 Explore P: 0.6931 RunMean : 48.8100\n",
      "Episode: 557 Total reward: 136.0 Training loss: 489.3474 Explore P: 0.6912 RunMean : 49.7500\n",
      "Episode: 558 Total reward: 9.0 Training loss: 197.7561 Explore P: 0.6911 RunMean : 49.7100\n",
      "Episode: 559 Total reward: 73.0 Training loss: 1033.3064 Explore P: 0.6900 RunMean : 49.4100\n",
      "Episode: 560 Total reward: 34.0 Training loss: 1327.1390 Explore P: 0.6896 RunMean : 49.1400\n",
      "Episode: 561 Total reward: 37.0 Training loss: 2710.3010 Explore P: 0.6891 RunMean : 49.3000\n",
      "Episode: 562 Total reward: 18.0 Training loss: 5653.4023 Explore P: 0.6888 RunMean : 49.2200\n",
      "Episode: 563 Total reward: 22.0 Training loss: 213.4427 Explore P: 0.6885 RunMean : 49.2900\n",
      "Episode: 564 Total reward: 16.0 Training loss: 2942.8618 Explore P: 0.6883 RunMean : 49.0900\n",
      "Episode: 565 Total reward: 27.0 Training loss: 3567.7720 Explore P: 0.6879 RunMean : 48.7500\n",
      "Episode: 566 Total reward: 26.0 Training loss: 2288.3728 Explore P: 0.6876 RunMean : 48.3700\n",
      "Episode: 567 Total reward: 68.0 Training loss: 1330.5282 Explore P: 0.6866 RunMean : 48.7900\n",
      "Episode: 568 Total reward: 64.0 Training loss: 6696.3418 Explore P: 0.6858 RunMean : 49.3200\n",
      "Episode: 569 Total reward: 52.0 Training loss: 180.9552 Explore P: 0.6850 RunMean : 49.3300\n",
      "Episode: 570 Total reward: 40.0 Training loss: 199.2569 Explore P: 0.6845 RunMean : 49.2300\n",
      "Episode: 571 Total reward: 47.0 Training loss: 2642.7642 Explore P: 0.6838 RunMean : 49.2900\n",
      "Episode: 572 Total reward: 85.0 Training loss: 3515.5647 Explore P: 0.6827 RunMean : 50.0000\n",
      "Episode: 573 Total reward: 115.0 Training loss: 5322.6035 Explore P: 0.6811 RunMean : 50.5300\n",
      "Episode: 574 Total reward: 130.0 Training loss: 311.0465 Explore P: 0.6793 RunMean : 51.6900\n",
      "Episode: 575 Total reward: 44.0 Training loss: 2315.6382 Explore P: 0.6788 RunMean : 51.9800\n",
      "Episode: 576 Total reward: 68.0 Training loss: 2970.1060 Explore P: 0.6778 RunMean : 52.3500\n",
      "Episode: 577 Total reward: 18.0 Training loss: 257.3268 Explore P: 0.6776 RunMean : 52.1900\n",
      "Episode: 578 Total reward: 188.0 Training loss: 161.9194 Explore P: 0.6750 RunMean : 53.5800\n",
      "Episode: 579 Total reward: 15.0 Training loss: 3235.6348 Explore P: 0.6748 RunMean : 53.0700\n",
      "Episode: 580 Total reward: 126.0 Training loss: 295.3263 Explore P: 0.6731 RunMean : 53.5500\n",
      "Episode: 581 Total reward: 149.0 Training loss: 191.2287 Explore P: 0.6711 RunMean : 54.7600\n",
      "Episode: 582 Total reward: 24.0 Training loss: 704.2246 Explore P: 0.6708 RunMean : 54.8400\n",
      "Episode: 583 Total reward: 151.0 Training loss: 5580.7383 Explore P: 0.6688 RunMean : 55.8900\n",
      "Episode: 584 Total reward: 66.0 Training loss: 2200.6167 Explore P: 0.6679 RunMean : 56.3300\n",
      "Episode: 585 Total reward: 79.0 Training loss: 223.9169 Explore P: 0.6669 RunMean : 56.5600\n",
      "Episode: 586 Total reward: 69.0 Training loss: 3322.2166 Explore P: 0.6659 RunMean : 56.9700\n",
      "Episode: 587 Total reward: 56.0 Training loss: 6916.6689 Explore P: 0.6652 RunMean : 57.2600\n",
      "Episode: 588 Total reward: 61.0 Training loss: 2904.4583 Explore P: 0.6644 RunMean : 56.8200\n",
      "Episode: 589 Total reward: 34.0 Training loss: 10393.0059 Explore P: 0.6639 RunMean : 57.0200\n",
      "Episode: 590 Total reward: 57.0 Training loss: 3379.5972 Explore P: 0.6632 RunMean : 57.4400\n",
      "Episode: 591 Total reward: 142.0 Training loss: 1377.0107 Explore P: 0.6613 RunMean : 58.6400\n",
      "Episode: 592 Total reward: 47.0 Training loss: 1564.4634 Explore P: 0.6607 RunMean : 58.7600\n",
      "Episode: 593 Total reward: 187.0 Training loss: 2997.6233 Explore P: 0.6582 RunMean : 60.1700\n",
      "Episode: 594 Total reward: 88.0 Training loss: 211.0029 Explore P: 0.6570 RunMean : 60.7300\n",
      "Episode: 595 Total reward: 21.0 Training loss: 9681.0156 Explore P: 0.6568 RunMean : 59.8400\n",
      "Episode: 596 Total reward: 35.0 Training loss: 1994.2097 Explore P: 0.6563 RunMean : 60.0300\n",
      "Episode: 597 Total reward: 134.0 Training loss: 2879.6768 Explore P: 0.6546 RunMean : 60.8700\n",
      "Episode: 598 Total reward: 134.0 Training loss: 6324.5815 Explore P: 0.6528 RunMean : 61.6700\n",
      "Episode: 599 Total reward: 55.0 Training loss: 4518.9883 Explore P: 0.6521 RunMean : 61.6600\n",
      "Episode: 600 Total reward: 198.0 Training loss: 276.4431 Explore P: 0.6495 RunMean : 62.5200\n",
      "Episode: 601 Total reward: 63.0 Training loss: 7826.9272 Explore P: 0.6487 RunMean : 62.7100\n",
      "Episode: 602 Total reward: 88.0 Training loss: 3088.8694 Explore P: 0.6475 RunMean : 62.0900\n",
      "Episode: 603 Total reward: 88.0 Training loss: 9319.0215 Explore P: 0.6464 RunMean : 62.6900\n",
      "Episode: 604 Total reward: 10.0 Training loss: 2390.7590 Explore P: 0.6463 RunMean : 62.0200\n",
      "Episode: 605 Total reward: 18.0 Training loss: 7032.6392 Explore P: 0.6460 RunMean : 61.9500\n",
      "Episode: 606 Total reward: 14.0 Training loss: 1334.6741 Explore P: 0.6459 RunMean : 61.4600\n",
      "Episode: 607 Total reward: 53.0 Training loss: 286.6241 Explore P: 0.6452 RunMean : 61.7200\n",
      "Episode: 608 Total reward: 54.0 Training loss: 7103.9248 Explore P: 0.6445 RunMean : 61.7900\n",
      "Episode: 609 Total reward: 157.0 Training loss: 7515.8984 Explore P: 0.6425 RunMean : 62.6800\n",
      "Episode: 610 Total reward: 112.0 Training loss: 4748.1265 Explore P: 0.6410 RunMean : 63.0500\n",
      "Episode: 611 Total reward: 96.0 Training loss: 4929.0410 Explore P: 0.6398 RunMean : 63.8200\n",
      "Episode: 612 Total reward: 114.0 Training loss: 18924.1777 Explore P: 0.6383 RunMean : 64.6400\n",
      "Episode: 613 Total reward: 12.0 Training loss: 231.4443 Explore P: 0.6382 RunMean : 64.6200\n",
      "Episode: 614 Total reward: 75.0 Training loss: 999.6309 Explore P: 0.6372 RunMean : 65.2500\n",
      "Episode: 615 Total reward: 44.0 Training loss: 267.7329 Explore P: 0.6367 RunMean : 65.5300\n",
      "Episode: 616 Total reward: 157.0 Training loss: 5504.2900 Explore P: 0.6347 RunMean : 66.8300\n",
      "Episode: 617 Total reward: 56.0 Training loss: 1954.7598 Explore P: 0.6340 RunMean : 66.9600\n",
      "Episode: 618 Total reward: 102.0 Training loss: 5029.7979 Explore P: 0.6327 RunMean : 67.7100\n",
      "Episode: 619 Total reward: 13.0 Training loss: 1163.3685 Explore P: 0.6325 RunMean : 67.1200\n",
      "Episode: 620 Total reward: 43.0 Training loss: 4343.1753 Explore P: 0.6320 RunMean : 67.1600\n",
      "Episode: 621 Total reward: 48.0 Training loss: 3574.3828 Explore P: 0.6314 RunMean : 66.8400\n",
      "Episode: 622 Total reward: 200.0 Training loss: 2939.7031 Explore P: 0.6288 RunMean : 68.0000\n",
      "Episode: 623 Total reward: 111.0 Training loss: 363.7228 Explore P: 0.6274 RunMean : 68.4900\n",
      "Episode: 624 Total reward: 137.0 Training loss: 255.1120 Explore P: 0.6257 RunMean : 69.5400\n",
      "Episode: 625 Total reward: 62.0 Training loss: 8590.6865 Explore P: 0.6250 RunMean : 69.1300\n",
      "Episode: 626 Total reward: 71.0 Training loss: 3509.3965 Explore P: 0.6241 RunMean : 69.7100\n",
      "Episode: 627 Total reward: 51.0 Training loss: 3436.1067 Explore P: 0.6234 RunMean : 70.0600\n",
      "Episode: 628 Total reward: 31.0 Training loss: 225.8002 Explore P: 0.6230 RunMean : 69.4100\n",
      "Episode: 629 Total reward: 15.0 Training loss: 312.5990 Explore P: 0.6229 RunMean : 69.4300\n",
      "Episode: 630 Total reward: 21.0 Training loss: 6039.8096 Explore P: 0.6226 RunMean : 68.5900\n",
      "Episode: 631 Total reward: 76.0 Training loss: 3957.3679 Explore P: 0.6216 RunMean : 69.1300\n",
      "Episode: 632 Total reward: 146.0 Training loss: 6230.6099 Explore P: 0.6198 RunMean : 70.2500\n",
      "Episode: 633 Total reward: 66.0 Training loss: 422.7186 Explore P: 0.6190 RunMean : 70.3300\n",
      "Episode: 634 Total reward: 25.0 Training loss: 3172.5801 Explore P: 0.6187 RunMean : 70.3100\n",
      "Episode: 635 Total reward: 205.0 Training loss: 6047.5952 Explore P: 0.6162 RunMean : 71.3700\n",
      "Episode: 636 Total reward: 146.0 Training loss: 455.4297 Explore P: 0.6144 RunMean : 72.4200\n",
      "Episode: 637 Total reward: 165.0 Training loss: 9492.3809 Explore P: 0.6124 RunMean : 73.7100\n",
      "Episode: 638 Total reward: 70.0 Training loss: 12714.0381 Explore P: 0.6115 RunMean : 73.8200\n",
      "Episode: 639 Total reward: 85.0 Training loss: 8118.5054 Explore P: 0.6105 RunMean : 73.9000\n",
      "Episode: 640 Total reward: 17.0 Training loss: 18551.5547 Explore P: 0.6103 RunMean : 72.8500\n",
      "Episode: 641 Total reward: 73.0 Training loss: 3590.3125 Explore P: 0.6094 RunMean : 72.1500\n",
      "Episode: 642 Total reward: 29.0 Training loss: 6569.5332 Explore P: 0.6090 RunMean : 70.7700\n",
      "Episode: 643 Total reward: 13.0 Training loss: 10690.5225 Explore P: 0.6089 RunMean : 70.0700\n",
      "Episode: 644 Total reward: 63.0 Training loss: 392.6444 Explore P: 0.6081 RunMean : 70.3700\n",
      "Episode: 645 Total reward: 125.0 Training loss: 273.4455 Explore P: 0.6066 RunMean : 71.4100\n",
      "Episode: 646 Total reward: 175.0 Training loss: 493.5878 Explore P: 0.6044 RunMean : 73.0200\n",
      "Episode: 647 Total reward: 45.0 Training loss: 5128.2900 Explore P: 0.6039 RunMean : 73.3800\n",
      "Episode: 648 Total reward: 32.0 Training loss: 17026.6094 Explore P: 0.6035 RunMean : 73.3900\n",
      "Episode: 649 Total reward: 86.0 Training loss: 4860.6582 Explore P: 0.6025 RunMean : 74.1300\n",
      "Episode: 650 Total reward: 150.0 Training loss: 392.4688 Explore P: 0.6007 RunMean : 75.3100\n",
      "Episode: 651 Total reward: 48.0 Training loss: 343.0405 Explore P: 0.6001 RunMean : 75.4900\n",
      "Episode: 652 Total reward: 132.0 Training loss: 4694.6885 Explore P: 0.5985 RunMean : 76.6100\n",
      "Episode: 653 Total reward: 176.0 Training loss: 5342.4004 Explore P: 0.5964 RunMean : 78.1700\n",
      "Episode: 654 Total reward: 103.0 Training loss: 427.5483 Explore P: 0.5952 RunMean : 78.6100\n",
      "Episode: 655 Total reward: 129.0 Training loss: 8235.5947 Explore P: 0.5937 RunMean : 78.5300\n",
      "Episode: 656 Total reward: 149.0 Training loss: 22168.9883 Explore P: 0.5919 RunMean : 78.9000\n",
      "Episode: 657 Total reward: 66.0 Training loss: 3704.5366 Explore P: 0.5911 RunMean : 78.2000\n",
      "Episode: 658 Total reward: 48.0 Training loss: 435.9729 Explore P: 0.5905 RunMean : 78.5900\n",
      "Episode: 659 Total reward: 38.0 Training loss: 226.8962 Explore P: 0.5901 RunMean : 78.2400\n",
      "Episode: 660 Total reward: 101.0 Training loss: 6534.3530 Explore P: 0.5889 RunMean : 78.9100\n",
      "Episode: 661 Total reward: 192.0 Training loss: 11988.5205 Explore P: 0.5866 RunMean : 80.4600\n",
      "Episode: 662 Total reward: 181.0 Training loss: 3954.3467 Explore P: 0.5845 RunMean : 82.0900\n",
      "Episode: 663 Total reward: 153.0 Training loss: 5552.7051 Explore P: 0.5827 RunMean : 83.4000\n",
      "Episode: 664 Total reward: 23.0 Training loss: 5268.7744 Explore P: 0.5825 RunMean : 83.4700\n",
      "Episode: 665 Total reward: 84.0 Training loss: 516.1276 Explore P: 0.5815 RunMean : 84.0400\n",
      "Episode: 666 Total reward: 122.0 Training loss: 4784.7695 Explore P: 0.5801 RunMean : 85.0000\n",
      "Episode: 667 Total reward: 78.0 Training loss: 253.2376 Explore P: 0.5792 RunMean : 85.1000\n",
      "Episode: 668 Total reward: 45.0 Training loss: 6977.7261 Explore P: 0.5786 RunMean : 84.9100\n",
      "Episode: 669 Total reward: 74.0 Training loss: 575.0853 Explore P: 0.5778 RunMean : 85.1300\n",
      "Episode: 670 Total reward: 19.0 Training loss: 311.6778 Explore P: 0.5776 RunMean : 84.9200\n",
      "Episode: 671 Total reward: 89.0 Training loss: 5120.6235 Explore P: 0.5765 RunMean : 85.3400\n",
      "Episode: 672 Total reward: 143.0 Training loss: 380.8262 Explore P: 0.5749 RunMean : 85.9200\n",
      "Episode: 673 Total reward: 158.0 Training loss: 453.2401 Explore P: 0.5731 RunMean : 86.3500\n",
      "Episode: 674 Total reward: 123.0 Training loss: 423.4803 Explore P: 0.5717 RunMean : 86.2800\n",
      "Episode: 675 Total reward: 81.0 Training loss: 10576.1045 Explore P: 0.5708 RunMean : 86.6500\n",
      "Episode: 676 Total reward: 14.0 Training loss: 488.3044 Explore P: 0.5706 RunMean : 86.1100\n",
      "Episode: 677 Total reward: 175.0 Training loss: 9686.1357 Explore P: 0.5686 RunMean : 87.6800\n",
      "Episode: 678 Total reward: 164.0 Training loss: 643.9609 Explore P: 0.5667 RunMean : 87.4400\n",
      "Episode: 679 Total reward: 116.0 Training loss: 517.4737 Explore P: 0.5654 RunMean : 88.4500\n",
      "Episode: 680 Total reward: 65.0 Training loss: 351.8174 Explore P: 0.5647 RunMean : 87.8400\n",
      "Episode: 681 Total reward: 56.0 Training loss: 317.3273 Explore P: 0.5641 RunMean : 86.9100\n",
      "Episode: 682 Total reward: 160.0 Training loss: 350.7668 Explore P: 0.5623 RunMean : 88.2700\n",
      "Episode: 683 Total reward: 255.0 Training loss: 341.4752 Explore P: 0.5594 RunMean : 89.3100\n",
      "Episode: 684 Total reward: 221.0 Training loss: 2803.3174 Explore P: 0.5569 RunMean : 90.8600\n",
      "Episode: 685 Total reward: 70.0 Training loss: 411.9817 Explore P: 0.5561 RunMean : 90.7700\n",
      "Episode: 686 Total reward: 141.0 Training loss: 7118.4478 Explore P: 0.5546 RunMean : 91.4900\n",
      "Episode: 687 Total reward: 46.0 Training loss: 495.0687 Explore P: 0.5541 RunMean : 91.3900\n",
      "Episode: 688 Total reward: 131.0 Training loss: 546.6940 Explore P: 0.5526 RunMean : 92.0900\n",
      "Episode: 689 Total reward: 80.0 Training loss: 409.7448 Explore P: 0.5517 RunMean : 92.5500\n",
      "Episode: 690 Total reward: 258.0 Training loss: 14916.9756 Explore P: 0.5489 RunMean : 94.5600\n",
      "Episode: 691 Total reward: 54.0 Training loss: 6903.7783 Explore P: 0.5483 RunMean : 93.6800\n",
      "Episode: 692 Total reward: 43.0 Training loss: 21660.1250 Explore P: 0.5478 RunMean : 93.6400\n",
      "Episode: 693 Total reward: 29.0 Training loss: 486.9900 Explore P: 0.5475 RunMean : 92.0600\n",
      "Episode: 694 Total reward: 157.0 Training loss: 41089.4688 Explore P: 0.5458 RunMean : 92.7500\n",
      "Episode: 695 Total reward: 72.0 Training loss: 6286.0439 Explore P: 0.5450 RunMean : 93.2600\n",
      "Episode: 696 Total reward: 186.0 Training loss: 652.5293 Explore P: 0.5430 RunMean : 94.7700\n",
      "Episode: 697 Total reward: 216.0 Training loss: 3987.9097 Explore P: 0.5407 RunMean : 95.5900\n",
      "Episode: 698 Total reward: 21.0 Training loss: 402.2307 Explore P: 0.5404 RunMean : 94.4600\n",
      "Episode: 699 Total reward: 157.0 Training loss: 7746.7163 Explore P: 0.5387 RunMean : 95.4800\n",
      "Episode: 700 Total reward: 25.0 Training loss: 17874.8477 Explore P: 0.5385 RunMean : 93.7500\n",
      "Episode: 701 Total reward: 197.0 Training loss: 31395.1250 Explore P: 0.5363 RunMean : 95.0900\n",
      "Episode: 702 Total reward: 160.0 Training loss: 14566.1289 Explore P: 0.5346 RunMean : 95.8100\n",
      "Episode: 703 Total reward: 187.0 Training loss: 20584.0117 Explore P: 0.5326 RunMean : 96.8000\n",
      "Episode: 704 Total reward: 101.0 Training loss: 503.0134 Explore P: 0.5316 RunMean : 97.7100\n",
      "Episode: 705 Total reward: 500.0 Training loss: 15123.4287 Explore P: 0.5263 RunMean : 102.5300\n",
      "Episode: 706 Total reward: 48.0 Training loss: 12344.1025 Explore P: 0.5258 RunMean : 102.8700\n",
      "Episode: 707 Total reward: 265.0 Training loss: 10758.5371 Explore P: 0.5230 RunMean : 104.9900\n",
      "Episode: 708 Total reward: 121.0 Training loss: 16370.4492 Explore P: 0.5217 RunMean : 105.6600\n",
      "Episode: 709 Total reward: 172.0 Training loss: 430.7067 Explore P: 0.5199 RunMean : 105.8100\n",
      "Episode: 710 Total reward: 24.0 Training loss: 14696.0068 Explore P: 0.5197 RunMean : 104.9300\n",
      "Episode: 711 Total reward: 169.0 Training loss: 8575.4824 Explore P: 0.5179 RunMean : 105.6600\n",
      "Episode: 712 Total reward: 301.0 Training loss: 635.0621 Explore P: 0.5148 RunMean : 107.5300\n",
      "Episode: 713 Total reward: 180.0 Training loss: 13336.6621 Explore P: 0.5130 RunMean : 109.2100\n",
      "Episode: 714 Total reward: 122.0 Training loss: 480.6241 Explore P: 0.5117 RunMean : 109.6800\n",
      "Episode: 715 Total reward: 103.0 Training loss: 46982.4453 Explore P: 0.5107 RunMean : 110.2700\n",
      "Episode: 716 Total reward: 63.0 Training loss: 371.5463 Explore P: 0.5100 RunMean : 109.3300\n",
      "Episode: 717 Total reward: 169.0 Training loss: 472.9754 Explore P: 0.5083 RunMean : 110.4600\n",
      "Episode: 718 Total reward: 124.0 Training loss: 19011.3340 Explore P: 0.5070 RunMean : 110.6800\n",
      "Episode: 719 Total reward: 176.0 Training loss: 18168.1152 Explore P: 0.5053 RunMean : 112.3100\n",
      "Episode: 720 Total reward: 168.0 Training loss: 322.9540 Explore P: 0.5036 RunMean : 113.5600\n",
      "Episode: 721 Total reward: 172.0 Training loss: 8865.5127 Explore P: 0.5018 RunMean : 114.8000\n",
      "Episode: 722 Total reward: 34.0 Training loss: 16547.8770 Explore P: 0.5015 RunMean : 113.1400\n",
      "Episode: 723 Total reward: 485.0 Training loss: 551.1204 Explore P: 0.4967 RunMean : 116.8800\n",
      "Episode: 724 Total reward: 38.0 Training loss: 41804.8672 Explore P: 0.4963 RunMean : 115.8900\n",
      "Episode: 725 Total reward: 154.0 Training loss: 15744.2490 Explore P: 0.4948 RunMean : 116.8100\n",
      "Episode: 726 Total reward: 220.0 Training loss: 312.3685 Explore P: 0.4926 RunMean : 118.3000\n",
      "Episode: 727 Total reward: 192.0 Training loss: 526.1876 Explore P: 0.4907 RunMean : 119.7100\n",
      "Episode: 728 Total reward: 225.0 Training loss: 560.4623 Explore P: 0.4885 RunMean : 121.6500\n",
      "Episode: 729 Total reward: 172.0 Training loss: 491.9014 Explore P: 0.4868 RunMean : 123.2200\n",
      "Episode: 730 Total reward: 38.0 Training loss: 316.8405 Explore P: 0.4864 RunMean : 123.3900\n",
      "Episode: 731 Total reward: 242.0 Training loss: 405.0280 Explore P: 0.4841 RunMean : 125.0500\n",
      "Episode: 732 Total reward: 180.0 Training loss: 331.5982 Explore P: 0.4824 RunMean : 125.3900\n",
      "Episode: 733 Total reward: 40.0 Training loss: 592.7314 Explore P: 0.4820 RunMean : 125.1300\n",
      "Episode: 734 Total reward: 319.0 Training loss: 754.9821 Explore P: 0.4789 RunMean : 128.0700\n",
      "Episode: 735 Total reward: 186.0 Training loss: 27730.0898 Explore P: 0.4771 RunMean : 127.8800\n",
      "Episode: 736 Total reward: 63.0 Training loss: 10363.5479 Explore P: 0.4765 RunMean : 127.0500\n",
      "Episode: 737 Total reward: 243.0 Training loss: 264.9283 Explore P: 0.4742 RunMean : 127.8300\n",
      "Episode: 738 Total reward: 197.0 Training loss: 515.6577 Explore P: 0.4723 RunMean : 129.1000\n",
      "Episode: 739 Total reward: 151.0 Training loss: 70046.6484 Explore P: 0.4709 RunMean : 129.7600\n",
      "Episode: 740 Total reward: 204.0 Training loss: 378.4393 Explore P: 0.4690 RunMean : 131.6300\n",
      "Episode: 741 Total reward: 213.0 Training loss: 71097.2578 Explore P: 0.4670 RunMean : 133.0300\n",
      "Episode: 742 Total reward: 273.0 Training loss: 401.9485 Explore P: 0.4645 RunMean : 135.4700\n",
      "Episode: 743 Total reward: 302.0 Training loss: 421.0185 Explore P: 0.4617 RunMean : 138.3600\n",
      "Episode: 744 Total reward: 191.0 Training loss: 509.6223 Explore P: 0.4599 RunMean : 139.6400\n",
      "Episode: 745 Total reward: 44.0 Training loss: 20907.4707 Explore P: 0.4595 RunMean : 138.8300\n",
      "Episode: 746 Total reward: 185.0 Training loss: 4615.4111 Explore P: 0.4578 RunMean : 138.9300\n",
      "Episode: 747 Total reward: 236.0 Training loss: 121345.1641 Explore P: 0.4557 RunMean : 140.8400\n",
      "Episode: 748 Total reward: 139.0 Training loss: 445.8239 Explore P: 0.4544 RunMean : 141.9100\n",
      "Episode: 749 Total reward: 270.0 Training loss: 446.8178 Explore P: 0.4519 RunMean : 143.7500\n",
      "Episode: 750 Total reward: 376.0 Training loss: 2405.4429 Explore P: 0.4486 RunMean : 146.0100\n",
      "Episode: 751 Total reward: 37.0 Training loss: 667.1532 Explore P: 0.4482 RunMean : 145.9000\n",
      "Episode: 752 Total reward: 318.0 Training loss: 244.3235 Explore P: 0.4454 RunMean : 147.7600\n",
      "Episode: 753 Total reward: 201.0 Training loss: 2879.2263 Explore P: 0.4436 RunMean : 148.0100\n",
      "Episode: 754 Total reward: 100.0 Training loss: 5060.2275 Explore P: 0.4427 RunMean : 147.9800\n",
      "Episode: 755 Total reward: 204.0 Training loss: 7241.8057 Explore P: 0.4409 RunMean : 148.7300\n",
      "Episode: 756 Total reward: 281.0 Training loss: 575.9996 Explore P: 0.4384 RunMean : 150.0500\n",
      "Episode: 757 Total reward: 285.0 Training loss: 338.1815 Explore P: 0.4359 RunMean : 152.2400\n",
      "Episode: 758 Total reward: 300.0 Training loss: 353.7735 Explore P: 0.4333 RunMean : 154.7600\n",
      "Episode: 759 Total reward: 254.0 Training loss: 4152.5283 Explore P: 0.4311 RunMean : 156.9200\n",
      "Episode: 760 Total reward: 169.0 Training loss: 328.0398 Explore P: 0.4297 RunMean : 157.6000\n",
      "Episode: 761 Total reward: 260.0 Training loss: 498.6396 Explore P: 0.4275 RunMean : 158.2800\n",
      "Episode: 762 Total reward: 405.0 Training loss: 281.3975 Explore P: 0.4240 RunMean : 160.5200\n",
      "Episode: 763 Total reward: 294.0 Training loss: 359.9561 Explore P: 0.4215 RunMean : 161.9300\n",
      "Episode: 764 Total reward: 101.0 Training loss: 263.9489 Explore P: 0.4207 RunMean : 162.7100\n",
      "Episode: 765 Total reward: 357.0 Training loss: 380.8476 Explore P: 0.4177 RunMean : 165.4400\n",
      "Episode: 766 Total reward: 215.0 Training loss: 263.0158 Explore P: 0.4159 RunMean : 166.3700\n",
      "Episode: 767 Total reward: 286.0 Training loss: 278.8635 Explore P: 0.4135 RunMean : 168.4500\n",
      "Episode: 768 Total reward: 369.0 Training loss: 359.4016 Explore P: 0.4105 RunMean : 171.6900\n",
      "Episode: 769 Total reward: 500.0 Training loss: 1752.5208 Explore P: 0.4064 RunMean : 175.9500\n",
      "Episode: 770 Total reward: 287.0 Training loss: 387.5225 Explore P: 0.4041 RunMean : 178.6300\n",
      "Episode: 771 Total reward: 340.0 Training loss: 347.2417 Explore P: 0.4013 RunMean : 181.1400\n",
      "Episode: 772 Total reward: 270.0 Training loss: 1628.4996 Explore P: 0.3992 RunMean : 182.4100\n",
      "Episode: 773 Total reward: 75.0 Training loss: 286.1414 Explore P: 0.3986 RunMean : 181.5800\n",
      "Episode: 774 Total reward: 321.0 Training loss: 22303.0879 Explore P: 0.3960 RunMean : 183.5600\n",
      "Episode: 775 Total reward: 20.0 Training loss: 450.4030 Explore P: 0.3959 RunMean : 182.9500\n",
      "Episode: 776 Total reward: 176.0 Training loss: 486.1095 Explore P: 0.3945 RunMean : 184.5700\n",
      "Episode: 777 Total reward: 26.0 Training loss: 1475.8979 Explore P: 0.3943 RunMean : 183.0800\n",
      "Episode: 778 Total reward: 197.0 Training loss: 555.2354 Explore P: 0.3927 RunMean : 183.4100\n",
      "Episode: 779 Total reward: 125.0 Training loss: 4210.4248 Explore P: 0.3917 RunMean : 183.5000\n",
      "Episode: 780 Total reward: 130.0 Training loss: 339.7869 Explore P: 0.3907 RunMean : 184.1500\n",
      "Episode: 781 Total reward: 411.0 Training loss: 294.1770 Explore P: 0.3875 RunMean : 187.7000\n",
      "Episode: 782 Total reward: 397.0 Training loss: 329.4250 Explore P: 0.3845 RunMean : 190.0700\n",
      "Episode: 783 Total reward: 394.0 Training loss: 423.9573 Explore P: 0.3814 RunMean : 191.4600\n",
      "Episode: 784 Total reward: 500.0 Training loss: 90175.3047 Explore P: 0.3776 RunMean : 194.2500\n",
      "Episode: 785 Total reward: 339.0 Training loss: 533.6581 Explore P: 0.3751 RunMean : 196.9400\n",
      "Episode: 786 Total reward: 275.0 Training loss: 258.2036 Explore P: 0.3730 RunMean : 198.2800\n",
      "Episode: 787 Total reward: 330.0 Training loss: 461.9298 Explore P: 0.3706 RunMean : 201.1200\n",
      "Episode: 788 Total reward: 474.0 Training loss: 405.1732 Explore P: 0.3671 RunMean : 204.5500\n",
      "Episode: 789 Total reward: 395.0 Training loss: 383.7903 Explore P: 0.3642 RunMean : 207.7000\n",
      "Episode: 790 Total reward: 352.0 Training loss: 179.5084 Explore P: 0.3616 RunMean : 208.6400\n",
      "Episode: 791 Total reward: 469.0 Training loss: 236.7010 Explore P: 0.3583 RunMean : 212.7900\n",
      "Episode: 792 Total reward: 317.0 Training loss: 358.7320 Explore P: 0.3560 RunMean : 215.5300\n",
      "Episode: 793 Total reward: 289.0 Training loss: 267.4758 Explore P: 0.3539 RunMean : 218.1300\n",
      "Episode: 794 Total reward: 185.0 Training loss: 6397.8135 Explore P: 0.3526 RunMean : 218.4100\n",
      "Episode: 795 Total reward: 371.0 Training loss: 315.6790 Explore P: 0.3500 RunMean : 221.4000\n",
      "Episode: 796 Total reward: 381.0 Training loss: 195.4288 Explore P: 0.3474 RunMean : 223.3500\n",
      "Episode: 797 Total reward: 500.0 Training loss: 208.2234 Explore P: 0.3439 RunMean : 226.1900\n",
      "Episode: 798 Total reward: 367.0 Training loss: 2772.9741 Explore P: 0.3414 RunMean : 229.6500\n",
      "Episode: 799 Total reward: 477.0 Training loss: 49163.2773 Explore P: 0.3382 RunMean : 232.8500\n",
      "Episode: 800 Total reward: 360.0 Training loss: 247.2257 Explore P: 0.3357 RunMean : 236.2000\n",
      "Episode: 801 Total reward: 315.0 Training loss: 184.1133 Explore P: 0.3336 RunMean : 237.3800\n",
      "Episode: 802 Total reward: 292.0 Training loss: 273.9033 Explore P: 0.3317 RunMean : 238.7000\n",
      "Episode: 803 Total reward: 476.0 Training loss: 253.6061 Explore P: 0.3285 RunMean : 241.5900\n",
      "Episode: 804 Total reward: 395.0 Training loss: 253.2893 Explore P: 0.3260 RunMean : 244.5300\n",
      "Episode: 805 Total reward: 350.0 Training loss: 555.6541 Explore P: 0.3237 RunMean : 243.0300\n",
      "Episode: 806 Total reward: 409.0 Training loss: 305.9293 Explore P: 0.3210 RunMean : 246.6400\n",
      "Episode: 807 Total reward: 208.0 Training loss: 203.0592 Explore P: 0.3197 RunMean : 246.0700\n",
      "Episode: 808 Total reward: 246.0 Training loss: 149.9857 Explore P: 0.3181 RunMean : 247.3200\n",
      "Episode: 809 Total reward: 193.0 Training loss: 145.1019 Explore P: 0.3169 RunMean : 247.5300\n",
      "Episode: 810 Total reward: 16.0 Training loss: 539.4089 Explore P: 0.3168 RunMean : 247.4500\n",
      "Episode: 811 Total reward: 341.0 Training loss: 198.0964 Explore P: 0.3147 RunMean : 249.1700\n",
      "Episode: 812 Total reward: 446.0 Training loss: 116.9358 Explore P: 0.3119 RunMean : 250.6200\n",
      "Episode: 813 Total reward: 500.0 Training loss: 193.1676 Explore P: 0.3088 RunMean : 253.8200\n",
      "Episode: 814 Total reward: 500.0 Training loss: 107.8605 Explore P: 0.3057 RunMean : 257.6000\n",
      "Episode: 815 Total reward: 357.0 Training loss: 93.7340 Explore P: 0.3035 RunMean : 260.1400\n",
      "Episode: 816 Total reward: 423.0 Training loss: 89.3919 Explore P: 0.3010 RunMean : 263.7400\n",
      "Episode: 817 Total reward: 500.0 Training loss: 122.9284 Explore P: 0.2980 RunMean : 267.0500\n",
      "Episode: 818 Total reward: 500.0 Training loss: 155.0013 Explore P: 0.2950 RunMean : 270.8100\n",
      "Episode: 819 Total reward: 495.0 Training loss: 135.4264 Explore P: 0.2921 RunMean : 274.0000\n",
      "Episode: 820 Total reward: 500.0 Training loss: 139.5670 Explore P: 0.2892 RunMean : 277.3200\n",
      "Episode: 821 Total reward: 349.0 Training loss: 112.9676 Explore P: 0.2872 RunMean : 279.0900\n",
      "Episode: 822 Total reward: 330.0 Training loss: 103.9518 Explore P: 0.2853 RunMean : 282.0500\n",
      "Episode: 823 Total reward: 500.0 Training loss: 48.3575 Explore P: 0.2824 RunMean : 282.2000\n",
      "Episode: 824 Total reward: 500.0 Training loss: 45.4476 Explore P: 0.2796 RunMean : 286.8200\n",
      "Episode: 825 Total reward: 500.0 Training loss: 179.3857 Explore P: 0.2769 RunMean : 290.2800\n",
      "Episode: 826 Total reward: 500.0 Training loss: 49.1409 Explore P: 0.2741 RunMean : 293.0800\n",
      "Episode: 827 Total reward: 500.0 Training loss: 167.4285 Explore P: 0.2714 RunMean : 296.1600\n",
      "Episode: 828 Total reward: 500.0 Training loss: 121.2405 Explore P: 0.2687 RunMean : 298.9100\n",
      "Episode: 829 Total reward: 488.0 Training loss: 85.9106 Explore P: 0.2661 RunMean : 302.0700\n",
      "Episode: 830 Total reward: 500.0 Training loss: 83.8763 Explore P: 0.2634 RunMean : 306.6900\n",
      "Episode: 831 Total reward: 500.0 Training loss: 87.1576 Explore P: 0.2608 RunMean : 309.2700\n",
      "Episode: 832 Total reward: 500.0 Training loss: 102.6114 Explore P: 0.2582 RunMean : 312.4700\n",
      "Episode: 833 Total reward: 500.0 Training loss: 66.1856 Explore P: 0.2556 RunMean : 317.0700\n",
      "Episode: 834 Total reward: 500.0 Training loss: 76.0015 Explore P: 0.2531 RunMean : 318.8800\n",
      "Episode: 835 Total reward: 500.0 Training loss: 78.4931 Explore P: 0.2506 RunMean : 322.0200\n",
      "Episode: 836 Total reward: 493.0 Training loss: 78.8297 Explore P: 0.2481 RunMean : 326.3200\n",
      "Episode: 837 Total reward: 481.0 Training loss: 69.0843 Explore P: 0.2457 RunMean : 328.7000\n",
      "Episode: 838 Total reward: 500.0 Training loss: 45.6753 Explore P: 0.2433 RunMean : 331.7300\n",
      "Episode: 839 Total reward: 481.0 Training loss: 29418.7734 Explore P: 0.2410 RunMean : 335.0300\n",
      "Episode: 840 Total reward: 475.0 Training loss: 37.5439 Explore P: 0.2387 RunMean : 337.7400\n",
      "Episode: 841 Total reward: 420.0 Training loss: 53.4651 Explore P: 0.2367 RunMean : 339.8100\n",
      "Episode: 842 Total reward: 500.0 Training loss: 41.2299 Explore P: 0.2343 RunMean : 342.0800\n",
      "Episode: 843 Total reward: 443.0 Training loss: 52.8039 Explore P: 0.2323 RunMean : 343.4900\n",
      "Episode: 844 Total reward: 453.0 Training loss: 35.1147 Explore P: 0.2302 RunMean : 346.1100\n",
      "Episode: 845 Total reward: 500.0 Training loss: 58.3931 Explore P: 0.2279 RunMean : 350.6700\n",
      "Episode: 846 Total reward: 500.0 Training loss: 23180.0332 Explore P: 0.2256 RunMean : 353.8200\n",
      "Episode: 847 Total reward: 322.0 Training loss: 39.4031 Explore P: 0.2242 RunMean : 354.6800\n",
      "Episode: 848 Total reward: 500.0 Training loss: 25.5759 Explore P: 0.2219 RunMean : 358.2900\n",
      "Episode: 849 Total reward: 449.0 Training loss: 28.0440 Explore P: 0.2199 RunMean : 360.0800\n",
      "Episode: 850 Total reward: 500.0 Training loss: 43.5163 Explore P: 0.2178 RunMean : 361.3200\n",
      "Episode: 851 Total reward: 500.0 Training loss: 30.4177 Explore P: 0.2156 RunMean : 365.9500\n",
      "Episode: 852 Total reward: 362.0 Training loss: 13077.8076 Explore P: 0.2140 RunMean : 366.3900\n",
      "Episode: 853 Total reward: 329.0 Training loss: 40.2014 Explore P: 0.2126 RunMean : 367.6700\n",
      "Episode: 854 Total reward: 352.0 Training loss: 34.8917 Explore P: 0.2111 RunMean : 370.1900\n",
      "Episode: 855 Total reward: 367.0 Training loss: 10690.5137 Explore P: 0.2096 RunMean : 371.8200\n",
      "Episode: 856 Total reward: 273.0 Training loss: 1416.2489 Explore P: 0.2085 RunMean : 371.7400\n",
      "Episode: 857 Total reward: 500.0 Training loss: 31.0769 Explore P: 0.2064 RunMean : 373.8900\n",
      "Episode: 858 Total reward: 321.0 Training loss: 41.3256 Explore P: 0.2051 RunMean : 374.1000\n",
      "Episode: 859 Total reward: 393.0 Training loss: 56.6624 Explore P: 0.2035 RunMean : 375.4900\n",
      "Episode: 860 Total reward: 500.0 Training loss: 39.1866 Explore P: 0.2014 RunMean : 378.8000\n",
      "Episode: 861 Total reward: 500.0 Training loss: 32.6709 Explore P: 0.1994 RunMean : 381.2000\n",
      "Episode: 862 Total reward: 242.0 Training loss: 47.3897 Explore P: 0.1985 RunMean : 379.5700\n",
      "Episode: 863 Total reward: 500.0 Training loss: 21.9501 Explore P: 0.1965 RunMean : 381.6300\n",
      "Episode: 864 Total reward: 500.0 Training loss: 25.7035 Explore P: 0.1945 RunMean : 385.6200\n",
      "Episode: 865 Total reward: 500.0 Training loss: 23.8728 Explore P: 0.1926 RunMean : 387.0500\n",
      "Episode: 866 Total reward: 500.0 Training loss: 22.5865 Explore P: 0.1907 RunMean : 389.9000\n",
      "Episode: 867 Total reward: 500.0 Training loss: 25.2763 Explore P: 0.1888 RunMean : 392.0400\n",
      "Episode: 868 Total reward: 500.0 Training loss: 31.4738 Explore P: 0.1869 RunMean : 393.3500\n",
      "Episode: 869 Total reward: 500.0 Training loss: 20.5085 Explore P: 0.1850 RunMean : 393.3500\n",
      "Episode: 870 Total reward: 433.0 Training loss: 68.9968 Explore P: 0.1835 RunMean : 394.8100\n",
      "Episode: 871 Total reward: 500.0 Training loss: 25.9310 Explore P: 0.1816 RunMean : 396.4100\n",
      "Episode: 872 Total reward: 369.0 Training loss: 23.4090 Explore P: 0.1803 RunMean : 397.4000\n",
      "Episode: 873 Total reward: 308.0 Training loss: 26.5706 Explore P: 0.1792 RunMean : 399.7300\n",
      "Episode: 874 Total reward: 426.0 Training loss: 1694.4658 Explore P: 0.1777 RunMean : 400.7800\n",
      "Episode: 875 Total reward: 445.0 Training loss: 36.3301 Explore P: 0.1761 RunMean : 405.0300\n",
      "Episode: 876 Total reward: 373.0 Training loss: 20.2068 Explore P: 0.1748 RunMean : 407.0000\n",
      "Episode: 877 Total reward: 500.0 Training loss: 18.1465 Explore P: 0.1730 RunMean : 411.7400\n",
      "Episode: 878 Total reward: 500.0 Training loss: 27.2588 Explore P: 0.1713 RunMean : 414.7700\n",
      "Episode: 879 Total reward: 500.0 Training loss: 28.5456 Explore P: 0.1696 RunMean : 418.5200\n",
      "Episode: 880 Total reward: 500.0 Training loss: 18.9434 Explore P: 0.1679 RunMean : 422.2200\n",
      "Episode: 881 Total reward: 461.0 Training loss: 23.8900 Explore P: 0.1664 RunMean : 422.7200\n",
      "Episode: 882 Total reward: 500.0 Training loss: 28.2730 Explore P: 0.1647 RunMean : 423.7500\n",
      "Episode: 883 Total reward: 500.0 Training loss: 33.4819 Explore P: 0.1631 RunMean : 424.8100\n",
      "Episode: 884 Total reward: 500.0 Training loss: 30.9015 Explore P: 0.1615 RunMean : 424.8100\n",
      "Episode: 885 Total reward: 491.0 Training loss: 26.8398 Explore P: 0.1599 RunMean : 426.3300\n",
      "Episode: 886 Total reward: 500.0 Training loss: 22.6839 Explore P: 0.1583 RunMean : 428.5800\n",
      "Episode: 887 Total reward: 500.0 Training loss: 121.0985 Explore P: 0.1567 RunMean : 430.2800\n",
      "Episode: 888 Total reward: 500.0 Training loss: 13.6115 Explore P: 0.1552 RunMean : 430.5400\n",
      "Episode: 889 Total reward: 500.0 Training loss: 13.5419 Explore P: 0.1536 RunMean : 431.5900\n",
      "Episode: 890 Total reward: 500.0 Training loss: 12.0019 Explore P: 0.1521 RunMean : 433.0700\n",
      "Episode: 891 Total reward: 500.0 Training loss: 30.3796 Explore P: 0.1506 RunMean : 433.3800\n",
      "Episode: 892 Total reward: 500.0 Training loss: 18.6437 Explore P: 0.1491 RunMean : 435.2100\n",
      "Episode: 893 Total reward: 500.0 Training loss: 21.0875 Explore P: 0.1476 RunMean : 437.3200\n",
      "Episode: 894 Total reward: 500.0 Training loss: 13743.8809 Explore P: 0.1461 RunMean : 440.4700\n",
      "Episode: 895 Total reward: 500.0 Training loss: 14.0302 Explore P: 0.1447 RunMean : 441.7600\n",
      "Episode: 896 Total reward: 500.0 Training loss: 9.8842 Explore P: 0.1432 RunMean : 442.9500\n",
      "Episode: 897 Total reward: 500.0 Training loss: 18.7277 Explore P: 0.1418 RunMean : 442.9500\n",
      "Episode: 898 Total reward: 500.0 Training loss: 11.9635 Explore P: 0.1404 RunMean : 444.2800\n",
      "Episode: 899 Total reward: 500.0 Training loss: 8.5853 Explore P: 0.1390 RunMean : 444.5100\n",
      "Episode: 900 Total reward: 500.0 Training loss: 10.0672 Explore P: 0.1376 RunMean : 445.9100\n",
      "Episode: 901 Total reward: 500.0 Training loss: 7.9557 Explore P: 0.1363 RunMean : 447.7600\n",
      "Episode: 902 Total reward: 323.0 Training loss: 21663.5000 Explore P: 0.1354 RunMean : 448.0700\n",
      "Episode: 903 Total reward: 500.0 Training loss: 9694.4609 Explore P: 0.1340 RunMean : 448.3100\n",
      "Episode: 904 Total reward: 500.0 Training loss: 13.8722 Explore P: 0.1327 RunMean : 449.3600\n",
      "Episode: 905 Total reward: 500.0 Training loss: 9777.8633 Explore P: 0.1314 RunMean : 450.8600\n",
      "Episode: 906 Total reward: 500.0 Training loss: 4.0889 Explore P: 0.1301 RunMean : 451.7700\n",
      "Episode: 907 Total reward: 500.0 Training loss: 8332.6318 Explore P: 0.1288 RunMean : 454.6900\n",
      "Episode: 908 Total reward: 500.0 Training loss: 5.0310 Explore P: 0.1275 RunMean : 457.2300\n",
      "Episode: 909 Total reward: 500.0 Training loss: 15433.6621 Explore P: 0.1262 RunMean : 460.3000\n",
      "Episode: 910 Total reward: 500.0 Training loss: 2.9869 Explore P: 0.1250 RunMean : 465.1400\n",
      "Episode: 911 Total reward: 500.0 Training loss: 6735.2144 Explore P: 0.1237 RunMean : 466.7300\n",
      "Episode: 912 Total reward: 500.0 Training loss: 24.6128 Explore P: 0.1225 RunMean : 467.2700\n",
      "Episode: 913 Total reward: 500.0 Training loss: 6264.0972 Explore P: 0.1213 RunMean : 467.2700\n",
      "Episode: 914 Total reward: 500.0 Training loss: 10.7936 Explore P: 0.1201 RunMean : 467.2700\n",
      "Episode: 915 Total reward: 500.0 Training loss: 6.5593 Explore P: 0.1189 RunMean : 468.7000\n",
      "Episode: 916 Total reward: 500.0 Training loss: 10.2554 Explore P: 0.1177 RunMean : 469.4700\n",
      "Episode: 917 Total reward: 500.0 Training loss: 6.9978 Explore P: 0.1165 RunMean : 469.4700\n",
      "Episode: 918 Total reward: 500.0 Training loss: 9.0094 Explore P: 0.1154 RunMean : 469.4700\n",
      "Episode: 919 Total reward: 500.0 Training loss: 9.9225 Explore P: 0.1142 RunMean : 469.5200\n",
      "Episode: 920 Total reward: 500.0 Training loss: 8.0980 Explore P: 0.1131 RunMean : 469.5200\n",
      "Episode: 921 Total reward: 462.0 Training loss: 4469.6006 Explore P: 0.1120 RunMean : 470.6500\n",
      "Episode: 922 Total reward: 500.0 Training loss: 11.1872 Explore P: 0.1109 RunMean : 472.3500\n",
      "Episode: 923 Total reward: 500.0 Training loss: 4572.3408 Explore P: 0.1098 RunMean : 472.3500\n",
      "Episode: 924 Total reward: 500.0 Training loss: 9.1435 Explore P: 0.1087 RunMean : 472.3500\n",
      "Episode: 925 Total reward: 500.0 Training loss: 6.4619 Explore P: 0.1076 RunMean : 472.3500\n",
      "Episode: 926 Total reward: 500.0 Training loss: 6840.6841 Explore P: 0.1066 RunMean : 472.3500\n",
      "Episode: 927 Total reward: 500.0 Training loss: 9.9927 Explore P: 0.1055 RunMean : 472.3500\n",
      "Episode: 928 Total reward: 95.0 Training loss: 6.5358 Explore P: 0.1053 RunMean : 468.3000\n",
      "Episode: 929 Total reward: 500.0 Training loss: 350.8738 Explore P: 0.1043 RunMean : 468.4200\n",
      "Episode: 930 Total reward: 500.0 Training loss: 6377.9409 Explore P: 0.1032 RunMean : 468.4200\n",
      "Episode: 931 Total reward: 489.0 Training loss: 7.1215 Explore P: 0.1022 RunMean : 468.3100\n",
      "Episode: 932 Total reward: 500.0 Training loss: 17.1602 Explore P: 0.1012 RunMean : 468.3100\n",
      "Episode: 933 Total reward: 500.0 Training loss: 29.8809 Explore P: 0.1002 RunMean : 468.3100\n",
      "Episode: 934 Total reward: 500.0 Training loss: 62.7283 Explore P: 0.0992 RunMean : 468.3100\n",
      "Episode: 935 Total reward: 198.0 Training loss: 146.1781 Explore P: 0.0988 RunMean : 465.2900\n",
      "Episode: 936 Total reward: 138.0 Training loss: 225.6694 Explore P: 0.0985 RunMean : 461.7400\n",
      "Episode: 937 Total reward: 107.0 Training loss: 415.3438 Explore P: 0.0983 RunMean : 458.0000\n",
      "Episode: 938 Total reward: 107.0 Training loss: 432.4462 Explore P: 0.0981 RunMean : 454.0700\n",
      "Episode: 939 Total reward: 92.0 Training loss: 577.6641 Explore P: 0.0979 RunMean : 450.1800\n",
      "Episode: 940 Total reward: 96.0 Training loss: 11023.6416 Explore P: 0.0977 RunMean : 446.3900\n",
      "Episode: 941 Total reward: 15.0 Training loss: 642.3060 Explore P: 0.0977 RunMean : 442.3400\n",
      "Episode: 942 Total reward: 84.0 Training loss: 892.3158 Explore P: 0.0976 RunMean : 438.1800\n",
      "Episode: 943 Total reward: 13.0 Training loss: 718.4109 Explore P: 0.0975 RunMean : 433.8800\n",
      "Episode: 944 Total reward: 13.0 Training loss: 984.6996 Explore P: 0.0975 RunMean : 429.4800\n",
      "Episode: 945 Total reward: 9.0 Training loss: 52057.0664 Explore P: 0.0975 RunMean : 424.5700\n",
      "Episode: 946 Total reward: 10.0 Training loss: 831.3071 Explore P: 0.0975 RunMean : 419.6700\n",
      "Episode: 947 Total reward: 11.0 Training loss: 1001.6387 Explore P: 0.0974 RunMean : 416.5600\n",
      "Episode: 948 Total reward: 11.0 Training loss: 828.4213 Explore P: 0.0974 RunMean : 411.6700\n",
      "Episode: 949 Total reward: 9.0 Training loss: 980.8236 Explore P: 0.0974 RunMean : 407.2700\n",
      "Episode: 950 Total reward: 15.0 Training loss: 53231.3086 Explore P: 0.0974 RunMean : 402.4200\n",
      "Episode: 951 Total reward: 13.0 Training loss: 610.9263 Explore P: 0.0973 RunMean : 397.5500\n",
      "Episode: 952 Total reward: 12.0 Training loss: 959.3634 Explore P: 0.0973 RunMean : 394.0500\n",
      "Episode: 953 Total reward: 11.0 Training loss: 761.4685 Explore P: 0.0973 RunMean : 390.8700\n",
      "Episode: 954 Total reward: 87.0 Training loss: 988.1312 Explore P: 0.0971 RunMean : 388.2200\n",
      "Episode: 955 Total reward: 90.0 Training loss: 864.4000 Explore P: 0.0970 RunMean : 385.4500\n",
      "Episode: 956 Total reward: 90.0 Training loss: 73146.1172 Explore P: 0.0968 RunMean : 383.6200\n",
      "Episode: 957 Total reward: 109.0 Training loss: 13028.2217 Explore P: 0.0966 RunMean : 379.7100\n",
      "Episode: 958 Total reward: 115.0 Training loss: 491.2636 Explore P: 0.0964 RunMean : 377.6500\n",
      "Episode: 959 Total reward: 126.0 Training loss: 445.8252 Explore P: 0.0961 RunMean : 374.9800\n",
      "Episode: 960 Total reward: 143.0 Training loss: 329.0327 Explore P: 0.0958 RunMean : 371.4100\n",
      "Episode: 961 Total reward: 234.0 Training loss: 320.5156 Explore P: 0.0954 RunMean : 368.7500\n",
      "Episode: 962 Total reward: 500.0 Training loss: 279.3481 Explore P: 0.0944 RunMean : 371.3300\n",
      "Episode: 963 Total reward: 365.0 Training loss: 152.0020 Explore P: 0.0938 RunMean : 369.9800\n",
      "Episode: 964 Total reward: 246.0 Training loss: 176.5657 Explore P: 0.0933 RunMean : 367.4400\n",
      "Episode: 965 Total reward: 194.0 Training loss: 489.5676 Explore P: 0.0929 RunMean : 364.3800\n",
      "Episode: 966 Total reward: 156.0 Training loss: 170.3805 Explore P: 0.0926 RunMean : 360.9400\n",
      "Episode: 967 Total reward: 148.0 Training loss: 190.3795 Explore P: 0.0924 RunMean : 357.4200\n",
      "Episode: 968 Total reward: 119.0 Training loss: 274.7590 Explore P: 0.0921 RunMean : 353.6100\n",
      "Episode: 969 Total reward: 121.0 Training loss: 380.9852 Explore P: 0.0919 RunMean : 349.8200\n",
      "Episode: 970 Total reward: 111.0 Training loss: 338.3985 Explore P: 0.0917 RunMean : 346.6000\n",
      "Episode: 971 Total reward: 36.0 Training loss: 400.5019 Explore P: 0.0917 RunMean : 341.9600\n",
      "Episode: 972 Total reward: 14.0 Training loss: 361.8903 Explore P: 0.0916 RunMean : 338.4100\n",
      "Episode: 973 Total reward: 10.0 Training loss: 22129.3086 Explore P: 0.0916 RunMean : 335.4300\n",
      "Episode: 974 Total reward: 104.0 Training loss: 342.5943 Explore P: 0.0914 RunMean : 332.2100\n",
      "Episode: 975 Total reward: 95.0 Training loss: 48313.3555 Explore P: 0.0912 RunMean : 328.7100\n",
      "Episode: 976 Total reward: 12.0 Training loss: 54442.0039 Explore P: 0.0912 RunMean : 325.1000\n",
      "Episode: 977 Total reward: 98.0 Training loss: 336.8083 Explore P: 0.0910 RunMean : 321.0800\n",
      "Episode: 978 Total reward: 99.0 Training loss: 641.9440 Explore P: 0.0909 RunMean : 317.0700\n",
      "Episode: 979 Total reward: 17.0 Training loss: 667.3403 Explore P: 0.0908 RunMean : 312.2400\n",
      "Episode: 980 Total reward: 9.0 Training loss: 21119.5566 Explore P: 0.0908 RunMean : 307.3300\n",
      "Episode: 981 Total reward: 11.0 Training loss: 490.0320 Explore P: 0.0908 RunMean : 302.8300\n",
      "Episode: 982 Total reward: 10.0 Training loss: 530.4960 Explore P: 0.0908 RunMean : 297.9300\n",
      "Episode: 983 Total reward: 9.0 Training loss: 44304.1250 Explore P: 0.0908 RunMean : 293.0200\n",
      "Episode: 984 Total reward: 9.0 Training loss: 1146.2080 Explore P: 0.0907 RunMean : 288.1100\n",
      "Episode: 985 Total reward: 10.0 Training loss: 608.8430 Explore P: 0.0907 RunMean : 283.3000\n",
      "Episode: 986 Total reward: 8.0 Training loss: 930.5112 Explore P: 0.0907 RunMean : 278.3800\n",
      "Episode: 987 Total reward: 10.0 Training loss: 607.9709 Explore P: 0.0907 RunMean : 273.4800\n",
      "Episode: 988 Total reward: 10.0 Training loss: 1027.9556 Explore P: 0.0907 RunMean : 268.5800\n",
      "Episode: 989 Total reward: 8.0 Training loss: 644.3625 Explore P: 0.0907 RunMean : 263.6600\n",
      "Episode: 990 Total reward: 10.0 Training loss: 952.9373 Explore P: 0.0906 RunMean : 258.7600\n",
      "Episode: 991 Total reward: 11.0 Training loss: 23062.6562 Explore P: 0.0906 RunMean : 253.8700\n",
      "Episode: 992 Total reward: 9.0 Training loss: 28715.3438 Explore P: 0.0906 RunMean : 248.9600\n",
      "Episode: 993 Total reward: 12.0 Training loss: 49875.9141 Explore P: 0.0906 RunMean : 244.0800\n",
      "Episode: 994 Total reward: 10.0 Training loss: 68059.0078 Explore P: 0.0906 RunMean : 239.1800\n",
      "Episode: 995 Total reward: 10.0 Training loss: 43707.0898 Explore P: 0.0906 RunMean : 234.2800\n",
      "Episode: 996 Total reward: 10.0 Training loss: 975.1256 Explore P: 0.0905 RunMean : 229.3800\n",
      "Episode: 997 Total reward: 9.0 Training loss: 986.9359 Explore P: 0.0905 RunMean : 224.4700\n",
      "Episode: 998 Total reward: 117.0 Training loss: 86558.5938 Explore P: 0.0903 RunMean : 220.6400\n",
      "Episode: 999 Total reward: 211.0 Training loss: 51619.5625 Explore P: 0.0899 RunMean : 217.7500\n",
      "Episode: 1000 Total reward: 500.0 Training loss: 3271.4973 Explore P: 0.0890 RunMean : 217.7500\n",
      "Episode: 1001 Total reward: 199.0 Training loss: 24167.6523 Explore P: 0.0887 RunMean : 214.7400\n",
      "Episode: 1002 Total reward: 165.0 Training loss: 18418.8926 Explore P: 0.0884 RunMean : 213.1600\n",
      "Episode: 1003 Total reward: 199.0 Training loss: 868.5342 Explore P: 0.0880 RunMean : 210.1500\n",
      "Episode: 1004 Total reward: 170.0 Training loss: 25104.0781 Explore P: 0.0877 RunMean : 206.8500\n",
      "Episode: 1005 Total reward: 199.0 Training loss: 16138.1748 Explore P: 0.0874 RunMean : 203.8400\n",
      "Episode: 1006 Total reward: 272.0 Training loss: 22637.7207 Explore P: 0.0869 RunMean : 201.5600\n",
      "Episode: 1007 Total reward: 200.0 Training loss: 26144.7031 Explore P: 0.0866 RunMean : 198.5600\n",
      "Episode: 1008 Total reward: 500.0 Training loss: 365.1210 Explore P: 0.0857 RunMean : 198.5600\n",
      "Episode: 1009 Total reward: 268.0 Training loss: 8950.4502 Explore P: 0.0852 RunMean : 196.2400\n",
      "Episode: 1010 Total reward: 233.0 Training loss: 618.6809 Explore P: 0.0849 RunMean : 193.5700\n",
      "Episode: 1011 Total reward: 216.0 Training loss: 355.0129 Explore P: 0.0845 RunMean : 190.7300\n",
      "Episode: 1012 Total reward: 228.0 Training loss: 340.3591 Explore P: 0.0841 RunMean : 188.0100\n",
      "Episode: 1013 Total reward: 186.0 Training loss: 601.6702 Explore P: 0.0838 RunMean : 184.8700\n",
      "Episode: 1014 Total reward: 183.0 Training loss: 22449.0723 Explore P: 0.0835 RunMean : 181.7000\n",
      "Episode: 1015 Total reward: 147.0 Training loss: 388.7097 Explore P: 0.0832 RunMean : 178.1700\n",
      "Episode: 1016 Total reward: 169.0 Training loss: 430.7647 Explore P: 0.0830 RunMean : 174.8600\n",
      "Episode: 1017 Total reward: 175.0 Training loss: 426.6786 Explore P: 0.0827 RunMean : 171.6100\n",
      "Episode: 1018 Total reward: 165.0 Training loss: 538.4442 Explore P: 0.0824 RunMean : 168.2600\n",
      "Episode: 1019 Total reward: 134.0 Training loss: 451.5880 Explore P: 0.0822 RunMean : 164.6000\n",
      "Episode: 1020 Total reward: 144.0 Training loss: 4133.6514 Explore P: 0.0819 RunMean : 161.0400\n",
      "Episode: 1021 Total reward: 131.0 Training loss: 9024.2109 Explore P: 0.0817 RunMean : 157.7300\n",
      "Episode: 1022 Total reward: 152.0 Training loss: 7735.6914 Explore P: 0.0815 RunMean : 154.2500\n",
      "Episode: 1023 Total reward: 139.0 Training loss: 12940.6162 Explore P: 0.0812 RunMean : 150.6400\n",
      "Episode: 1024 Total reward: 133.0 Training loss: 604.4568 Explore P: 0.0810 RunMean : 146.9700\n",
      "Episode: 1025 Total reward: 138.0 Training loss: 14397.2607 Explore P: 0.0808 RunMean : 143.3500\n",
      "Episode: 1026 Total reward: 127.0 Training loss: 508.7368 Explore P: 0.0806 RunMean : 139.6200\n",
      "Episode: 1027 Total reward: 128.0 Training loss: 721.9573 Explore P: 0.0804 RunMean : 135.9000\n",
      "Episode: 1028 Total reward: 161.0 Training loss: 24403.8672 Explore P: 0.0801 RunMean : 136.5600\n",
      "Episode: 1029 Total reward: 139.0 Training loss: 441.8113 Explore P: 0.0799 RunMean : 132.9500\n",
      "Episode: 1030 Total reward: 116.0 Training loss: 17969.6445 Explore P: 0.0797 RunMean : 129.1100\n",
      "Episode: 1031 Total reward: 122.0 Training loss: 1473.6223 Explore P: 0.0795 RunMean : 125.4400\n",
      "Episode: 1032 Total reward: 129.0 Training loss: 731.6409 Explore P: 0.0793 RunMean : 121.7300\n",
      "Episode: 1033 Total reward: 133.0 Training loss: 606.8485 Explore P: 0.0791 RunMean : 118.0600\n",
      "Episode: 1034 Total reward: 123.0 Training loss: 481.9460 Explore P: 0.0789 RunMean : 114.2900\n",
      "Episode: 1035 Total reward: 145.0 Training loss: 578.8406 Explore P: 0.0787 RunMean : 113.7600\n",
      "Episode: 1036 Total reward: 160.0 Training loss: 596.3364 Explore P: 0.0784 RunMean : 113.9800\n",
      "Episode: 1037 Total reward: 130.0 Training loss: 647.7010 Explore P: 0.0782 RunMean : 114.2100\n",
      "Episode: 1038 Total reward: 141.0 Training loss: 19010.8750 Explore P: 0.0780 RunMean : 114.5500\n",
      "Episode: 1039 Total reward: 123.0 Training loss: 22876.7168 Explore P: 0.0778 RunMean : 114.8600\n",
      "Episode: 1040 Total reward: 126.0 Training loss: 16692.5176 Explore P: 0.0776 RunMean : 115.1600\n",
      "Episode: 1041 Total reward: 136.0 Training loss: 8802.4580 Explore P: 0.0774 RunMean : 116.3700\n",
      "Episode: 1042 Total reward: 182.0 Training loss: 433.1342 Explore P: 0.0771 RunMean : 117.3500\n",
      "Episode: 1043 Total reward: 183.0 Training loss: 668.7861 Explore P: 0.0769 RunMean : 119.0500\n",
      "Episode: 1044 Total reward: 158.0 Training loss: 364.7557 Explore P: 0.0766 RunMean : 120.5000\n",
      "Episode: 1045 Total reward: 221.0 Training loss: 578.8748 Explore P: 0.0763 RunMean : 122.6200\n",
      "Episode: 1046 Total reward: 123.0 Training loss: 540.9409 Explore P: 0.0761 RunMean : 123.7500\n",
      "Episode: 1047 Total reward: 147.0 Training loss: 23978.7676 Explore P: 0.0759 RunMean : 125.1100\n",
      "Episode: 1048 Total reward: 165.0 Training loss: 16375.4336 Explore P: 0.0756 RunMean : 126.6500\n",
      "Episode: 1049 Total reward: 159.0 Training loss: 13858.1895 Explore P: 0.0754 RunMean : 128.1500\n",
      "Episode: 1050 Total reward: 120.0 Training loss: 563.8181 Explore P: 0.0752 RunMean : 129.2000\n",
      "Episode: 1051 Total reward: 126.0 Training loss: 497.4686 Explore P: 0.0750 RunMean : 130.3300\n",
      "Episode: 1052 Total reward: 170.0 Training loss: 330.8086 Explore P: 0.0748 RunMean : 131.9100\n",
      "Episode: 1053 Total reward: 130.0 Training loss: 459.8315 Explore P: 0.0746 RunMean : 133.1000\n",
      "Episode: 1054 Total reward: 133.0 Training loss: 273.7304 Explore P: 0.0744 RunMean : 133.5600\n",
      "Episode: 1055 Total reward: 177.0 Training loss: 292.9857 Explore P: 0.0741 RunMean : 134.4300\n",
      "Episode: 1056 Total reward: 227.0 Training loss: 408.8471 Explore P: 0.0738 RunMean : 135.8000\n",
      "Episode: 1057 Total reward: 165.0 Training loss: 501.8867 Explore P: 0.0735 RunMean : 136.3600\n",
      "Episode: 1058 Total reward: 164.0 Training loss: 23144.4668 Explore P: 0.0733 RunMean : 136.8500\n",
      "Episode: 1059 Total reward: 135.0 Training loss: 21595.6855 Explore P: 0.0731 RunMean : 136.9400\n",
      "Episode: 1060 Total reward: 135.0 Training loss: 432.3002 Explore P: 0.0729 RunMean : 136.8600\n",
      "Episode: 1061 Total reward: 214.0 Training loss: 423.0868 Explore P: 0.0726 RunMean : 136.6600\n",
      "Episode: 1062 Total reward: 167.0 Training loss: 404.7791 Explore P: 0.0723 RunMean : 133.3300\n",
      "Episode: 1063 Total reward: 213.0 Training loss: 9307.6396 Explore P: 0.0720 RunMean : 131.8100\n",
      "Episode: 1064 Total reward: 355.0 Training loss: 302.6126 Explore P: 0.0715 RunMean : 132.9000\n",
      "Episode: 1065 Total reward: 343.0 Training loss: 310.1136 Explore P: 0.0710 RunMean : 134.3900\n",
      "Episode: 1066 Total reward: 158.0 Training loss: 180.3607 Explore P: 0.0708 RunMean : 134.4100\n",
      "Episode: 1067 Total reward: 307.0 Training loss: 338.9521 Explore P: 0.0704 RunMean : 136.0000\n",
      "Episode: 1068 Total reward: 370.0 Training loss: 292.2325 Explore P: 0.0699 RunMean : 138.5100\n",
      "Episode: 1069 Total reward: 261.0 Training loss: 315.0302 Explore P: 0.0695 RunMean : 139.9100\n",
      "Episode: 1070 Total reward: 500.0 Training loss: 306.4421 Explore P: 0.0688 RunMean : 143.8000\n",
      "Episode: 1071 Total reward: 500.0 Training loss: 239.1775 Explore P: 0.0681 RunMean : 148.4400\n",
      "Episode: 1072 Total reward: 155.0 Training loss: 219.1469 Explore P: 0.0679 RunMean : 149.8500\n",
      "Episode: 1073 Total reward: 170.0 Training loss: 262.7741 Explore P: 0.0677 RunMean : 151.4500\n",
      "Episode: 1074 Total reward: 245.0 Training loss: 172.7011 Explore P: 0.0673 RunMean : 152.8600\n",
      "Episode: 1075 Total reward: 172.0 Training loss: 14868.6934 Explore P: 0.0671 RunMean : 153.6300\n",
      "Episode: 1076 Total reward: 184.0 Training loss: 10713.5361 Explore P: 0.0669 RunMean : 155.3500\n",
      "Episode: 1077 Total reward: 432.0 Training loss: 4150.7778 Explore P: 0.0663 RunMean : 158.6900\n",
      "Episode: 1078 Total reward: 194.0 Training loss: 183.5193 Explore P: 0.0660 RunMean : 159.6400\n",
      "Episode: 1079 Total reward: 168.0 Training loss: 17401.3184 Explore P: 0.0658 RunMean : 161.1500\n",
      "Episode: 1080 Total reward: 153.0 Training loss: 140.1334 Explore P: 0.0656 RunMean : 162.5900\n",
      "Episode: 1081 Total reward: 272.0 Training loss: 140.8940 Explore P: 0.0653 RunMean : 165.2000\n",
      "Episode: 1082 Total reward: 316.0 Training loss: 7825.1978 Explore P: 0.0648 RunMean : 168.2600\n",
      "Episode: 1083 Total reward: 500.0 Training loss: 69.0229 Explore P: 0.0642 RunMean : 173.1700\n",
      "Episode: 1084 Total reward: 334.0 Training loss: 142.7620 Explore P: 0.0638 RunMean : 176.4200\n",
      "Episode: 1085 Total reward: 173.0 Training loss: 94.2209 Explore P: 0.0635 RunMean : 178.0500\n",
      "Episode: 1086 Total reward: 231.0 Training loss: 89.8077 Explore P: 0.0633 RunMean : 180.2800\n",
      "Episode: 1087 Total reward: 500.0 Training loss: 81.8128 Explore P: 0.0626 RunMean : 185.1800\n",
      "Episode: 1088 Total reward: 482.0 Training loss: 105.5539 Explore P: 0.0620 RunMean : 189.9000\n",
      "Episode: 1089 Total reward: 218.0 Training loss: 4861.8560 Explore P: 0.0618 RunMean : 192.0000\n",
      "Episode: 1090 Total reward: 260.0 Training loss: 7452.1074 Explore P: 0.0614 RunMean : 194.5000\n",
      "Episode: 1091 Total reward: 459.0 Training loss: 87.0786 Explore P: 0.0609 RunMean : 198.9800\n",
      "Episode: 1092 Total reward: 204.0 Training loss: 100.9434 Explore P: 0.0606 RunMean : 200.9300\n",
      "Episode: 1093 Total reward: 194.0 Training loss: 5110.1982 Explore P: 0.0604 RunMean : 202.7500\n",
      "Episode: 1094 Total reward: 366.0 Training loss: 6301.2993 Explore P: 0.0600 RunMean : 206.3100\n",
      "Episode: 1095 Total reward: 359.0 Training loss: 78.3480 Explore P: 0.0595 RunMean : 209.8000\n",
      "Episode: 1096 Total reward: 406.0 Training loss: 3301.8994 Explore P: 0.0590 RunMean : 213.7600\n",
      "Episode: 1097 Total reward: 472.0 Training loss: 50.6359 Explore P: 0.0585 RunMean : 218.3900\n",
      "Episode: 1098 Total reward: 500.0 Training loss: 63.0066 Explore P: 0.0579 RunMean : 222.2200\n",
      "Episode: 1099 Total reward: 500.0 Training loss: 48.1489 Explore P: 0.0573 RunMean : 225.1100\n",
      "Episode: 1100 Total reward: 500.0 Training loss: 29.5287 Explore P: 0.0568 RunMean : 225.1100\n",
      "Episode: 1101 Total reward: 477.0 Training loss: 52.7846 Explore P: 0.0562 RunMean : 227.8900\n",
      "Episode: 1102 Total reward: 500.0 Training loss: 18.8883 Explore P: 0.0557 RunMean : 231.2400\n",
      "Episode: 1103 Total reward: 500.0 Training loss: 21.9039 Explore P: 0.0551 RunMean : 234.2500\n",
      "Episode: 1104 Total reward: 500.0 Training loss: 2092.3828 Explore P: 0.0546 RunMean : 237.5500\n",
      "Episode: 1105 Total reward: 424.0 Training loss: 62.5439 Explore P: 0.0541 RunMean : 239.8000\n",
      "Episode: 1106 Total reward: 500.0 Training loss: 2991.8081 Explore P: 0.0536 RunMean : 242.0800\n",
      "Episode: 1107 Total reward: 426.0 Training loss: 65.1157 Explore P: 0.0531 RunMean : 244.3400\n",
      "Episode: 1108 Total reward: 378.0 Training loss: 23.8337 Explore P: 0.0527 RunMean : 243.1200\n",
      "Episode: 1109 Total reward: 500.0 Training loss: 49.9336 Explore P: 0.0522 RunMean : 245.4400\n",
      "Episode: 1110 Total reward: 500.0 Training loss: 16.0764 Explore P: 0.0517 RunMean : 248.1100\n",
      "Episode: 1111 Total reward: 500.0 Training loss: 58.6607 Explore P: 0.0511 RunMean : 250.9500\n",
      "Episode: 1112 Total reward: 500.0 Training loss: 27.7882 Explore P: 0.0506 RunMean : 253.6700\n",
      "Episode: 1113 Total reward: 500.0 Training loss: 23.9521 Explore P: 0.0501 RunMean : 256.8100\n",
      "Episode: 1114 Total reward: 428.0 Training loss: 15.7460 Explore P: 0.0497 RunMean : 259.2600\n",
      "Episode: 1115 Total reward: 500.0 Training loss: 19.1346 Explore P: 0.0492 RunMean : 262.7900\n",
      "Episode: 1116 Total reward: 500.0 Training loss: 20.1460 Explore P: 0.0487 RunMean : 266.1000\n",
      "Episode: 1117 Total reward: 500.0 Training loss: 12.3651 Explore P: 0.0482 RunMean : 269.3500\n",
      "Episode: 1118 Total reward: 494.0 Training loss: 26.8756 Explore P: 0.0478 RunMean : 272.6400\n",
      "Episode: 1119 Total reward: 500.0 Training loss: 23.5543 Explore P: 0.0473 RunMean : 276.3000\n",
      "Episode: 1120 Total reward: 500.0 Training loss: 15.9245 Explore P: 0.0468 RunMean : 279.8600\n",
      "Episode: 1121 Total reward: 500.0 Training loss: 17.3846 Explore P: 0.0464 RunMean : 283.5500\n",
      "Episode: 1122 Total reward: 500.0 Training loss: 855.4840 Explore P: 0.0459 RunMean : 287.0300\n",
      "Episode: 1123 Total reward: 500.0 Training loss: 24.6003 Explore P: 0.0454 RunMean : 290.6400\n",
      "Episode: 1124 Total reward: 500.0 Training loss: 10.9013 Explore P: 0.0450 RunMean : 294.3100\n",
      "Episode: 1125 Total reward: 500.0 Training loss: 15.7143 Explore P: 0.0445 RunMean : 297.9300\n",
      "Episode: 1126 Total reward: 500.0 Training loss: 22.6950 Explore P: 0.0441 RunMean : 301.6600\n",
      "Episode: 1127 Total reward: 500.0 Training loss: 19.1606 Explore P: 0.0437 RunMean : 305.3800\n",
      "Episode: 1128 Total reward: 500.0 Training loss: 11.9067 Explore P: 0.0432 RunMean : 308.7700\n",
      "Episode: 1129 Total reward: 500.0 Training loss: 14.9852 Explore P: 0.0428 RunMean : 312.3800\n",
      "Episode: 1130 Total reward: 500.0 Training loss: 15.0415 Explore P: 0.0424 RunMean : 316.2200\n",
      "Episode: 1131 Total reward: 500.0 Training loss: 13.3505 Explore P: 0.0419 RunMean : 320.0000\n",
      "Episode: 1132 Total reward: 500.0 Training loss: 13.1100 Explore P: 0.0415 RunMean : 323.7100\n",
      "Episode: 1133 Total reward: 500.0 Training loss: 10.7460 Explore P: 0.0411 RunMean : 327.3800\n",
      "Episode: 1134 Total reward: 500.0 Training loss: 5107.3647 Explore P: 0.0407 RunMean : 331.1500\n",
      "Episode: 1135 Total reward: 500.0 Training loss: 11.8727 Explore P: 0.0403 RunMean : 334.7000\n",
      "Episode: 1136 Total reward: 500.0 Training loss: 10.3314 Explore P: 0.0399 RunMean : 338.1000\n",
      "Episode: 1137 Total reward: 500.0 Training loss: 9.8719 Explore P: 0.0395 RunMean : 341.8000\n",
      "Episode: 1138 Total reward: 500.0 Training loss: 10.7597 Explore P: 0.0391 RunMean : 345.3900\n",
      "Episode: 1139 Total reward: 500.0 Training loss: 7.6209 Explore P: 0.0387 RunMean : 349.1600\n",
      "Episode: 1140 Total reward: 500.0 Training loss: 3527.7615 Explore P: 0.0383 RunMean : 352.9000\n",
      "Episode: 1141 Total reward: 500.0 Training loss: 6.6908 Explore P: 0.0379 RunMean : 356.5400\n",
      "Episode: 1142 Total reward: 500.0 Training loss: 6.4895 Explore P: 0.0376 RunMean : 359.7200\n",
      "Episode: 1143 Total reward: 500.0 Training loss: 6.0571 Explore P: 0.0372 RunMean : 362.8900\n",
      "Episode: 1144 Total reward: 500.0 Training loss: 3.2595 Explore P: 0.0368 RunMean : 366.3100\n",
      "Episode: 1145 Total reward: 500.0 Training loss: 1761.2198 Explore P: 0.0365 RunMean : 369.1000\n",
      "Episode: 1146 Total reward: 500.0 Training loss: 4.3457 Explore P: 0.0361 RunMean : 372.8700\n",
      "Episode: 1147 Total reward: 500.0 Training loss: 3.1867 Explore P: 0.0357 RunMean : 376.4000\n",
      "Episode: 1148 Total reward: 500.0 Training loss: 3.9926 Explore P: 0.0354 RunMean : 379.7500\n",
      "Episode: 1149 Total reward: 500.0 Training loss: 2289.3242 Explore P: 0.0350 RunMean : 383.1600\n",
      "Episode: 1150 Total reward: 500.0 Training loss: 1.7961 Explore P: 0.0347 RunMean : 386.9600\n",
      "Episode: 1151 Total reward: 500.0 Training loss: 346.3125 Explore P: 0.0343 RunMean : 390.7000\n",
      "Episode: 1152 Total reward: 500.0 Training loss: 3.9556 Explore P: 0.0340 RunMean : 394.0000\n",
      "Episode: 1153 Total reward: 500.0 Training loss: 4.3371 Explore P: 0.0337 RunMean : 397.7000\n",
      "Episode: 1154 Total reward: 396.0 Training loss: 2.6345 Explore P: 0.0334 RunMean : 400.3300\n",
      "Episode: 1155 Total reward: 500.0 Training loss: 6.7436 Explore P: 0.0331 RunMean : 403.5600\n",
      "Episode: 1156 Total reward: 500.0 Training loss: 3.2957 Explore P: 0.0327 RunMean : 406.2900\n",
      "Episode: 1157 Total reward: 500.0 Training loss: 3.7272 Explore P: 0.0324 RunMean : 409.6400\n",
      "Episode: 1158 Total reward: 304.0 Training loss: 47.7170 Explore P: 0.0322 RunMean : 411.0400\n",
      "Episode: 1159 Total reward: 500.0 Training loss: 3.9804 Explore P: 0.0319 RunMean : 414.6900\n",
      "Episode: 1160 Total reward: 500.0 Training loss: 3.3907 Explore P: 0.0316 RunMean : 418.3400\n",
      "Episode: 1161 Total reward: 500.0 Training loss: 73.8503 Explore P: 0.0313 RunMean : 421.2000\n",
      "Episode: 1162 Total reward: 500.0 Training loss: 16.2689 Explore P: 0.0309 RunMean : 424.5300\n",
      "Episode: 1163 Total reward: 500.0 Training loss: 9.5107 Explore P: 0.0306 RunMean : 427.4000\n",
      "Episode: 1164 Total reward: 500.0 Training loss: 520.0219 Explore P: 0.0303 RunMean : 428.8500\n",
      "Episode: 1165 Total reward: 500.0 Training loss: 295.5256 Explore P: 0.0300 RunMean : 430.4200\n",
      "Episode: 1166 Total reward: 500.0 Training loss: 4.6269 Explore P: 0.0297 RunMean : 433.8400\n",
      "Episode: 1167 Total reward: 500.0 Training loss: 6.8201 Explore P: 0.0294 RunMean : 435.7700\n",
      "Episode: 1168 Total reward: 444.0 Training loss: 10.5484 Explore P: 0.0292 RunMean : 436.5100\n",
      "Episode: 1169 Total reward: 500.0 Training loss: 10.1030 Explore P: 0.0289 RunMean : 438.9000\n",
      "Episode: 1170 Total reward: 443.0 Training loss: 7.8204 Explore P: 0.0286 RunMean : 438.3300\n",
      "Episode: 1171 Total reward: 500.0 Training loss: 8.1313 Explore P: 0.0283 RunMean : 438.3300\n",
      "Episode: 1172 Total reward: 151.0 Training loss: 4511.9478 Explore P: 0.0283 RunMean : 438.2900\n",
      "Episode: 1173 Total reward: 222.0 Training loss: 14.5032 Explore P: 0.0281 RunMean : 438.8100\n",
      "Episode: 1174 Total reward: 269.0 Training loss: 15.0809 Explore P: 0.0280 RunMean : 439.0500\n",
      "Episode: 1175 Total reward: 500.0 Training loss: 7.0495 Explore P: 0.0277 RunMean : 442.3300\n",
      "Episode: 1176 Total reward: 500.0 Training loss: 29.5183 Explore P: 0.0274 RunMean : 445.4900\n",
      "Episode: 1177 Total reward: 500.0 Training loss: 9.9568 Explore P: 0.0272 RunMean : 446.1700\n",
      "Episode: 1178 Total reward: 500.0 Training loss: 5.1264 Explore P: 0.0269 RunMean : 449.2300\n",
      "Episode: 1179 Total reward: 341.0 Training loss: 3.6448 Explore P: 0.0267 RunMean : 450.9600\n",
      "Episode: 1180 Total reward: 500.0 Training loss: 10.4107 Explore P: 0.0264 RunMean : 454.4300\n",
      "Episode: 1181 Total reward: 365.0 Training loss: 9.0139 Explore P: 0.0262 RunMean : 455.3600\n",
      "Episode: 1182 Total reward: 500.0 Training loss: 5.8671 Explore P: 0.0260 RunMean : 457.2000\n",
      "Episode: 1183 Total reward: 470.0 Training loss: 8.9330 Explore P: 0.0257 RunMean : 456.9000\n",
      "Episode: 1184 Total reward: 193.0 Training loss: 25.6756 Explore P: 0.0256 RunMean : 455.4900\n",
      "Episode: 1185 Total reward: 500.0 Training loss: 12.5445 Explore P: 0.0254 RunMean : 458.7600\n",
      "Episode: 1186 Total reward: 500.0 Training loss: 553.2048 Explore P: 0.0251 RunMean : 461.4500\n",
      "Episode: 1187 Total reward: 500.0 Training loss: 25.5221 Explore P: 0.0249 RunMean : 461.4500\n",
      "Episode: 1188 Total reward: 500.0 Training loss: 8.2976 Explore P: 0.0246 RunMean : 461.6300\n",
      "Episode: 1189 Total reward: 500.0 Training loss: 13.6986 Explore P: 0.0244 RunMean : 464.4500\n",
      "Episode: 1190 Total reward: 500.0 Training loss: 16.3942 Explore P: 0.0241 RunMean : 466.8500\n",
      "Episode: 1191 Total reward: 500.0 Training loss: 10.2473 Explore P: 0.0239 RunMean : 467.2600\n",
      "Episode: 1192 Total reward: 500.0 Training loss: 10.3293 Explore P: 0.0237 RunMean : 470.2200\n",
      "Episode: 1193 Total reward: 500.0 Training loss: 7.8827 Explore P: 0.0234 RunMean : 473.2800\n",
      "Episode: 1194 Total reward: 500.0 Training loss: 4705.4727 Explore P: 0.0232 RunMean : 474.6200\n",
      "Episode: 1195 Total reward: 500.0 Training loss: 13.5264 Explore P: 0.0230 RunMean : 476.0300\n",
      "Episode: 1196 Total reward: 34.0 Training loss: 15.9388 Explore P: 0.0230 RunMean : 472.3100\n",
      "Episode: 1197 Total reward: 500.0 Training loss: 9.2298 Explore P: 0.0227 RunMean : 472.5900\n",
      "Episode: 1198 Total reward: 155.0 Training loss: 20.9224 Explore P: 0.0227 RunMean : 469.1400\n",
      "Episode: 1199 Total reward: 200.0 Training loss: 30.0157 Explore P: 0.0226 RunMean : 466.1400\n",
      "Episode: 1200 Total reward: 168.0 Training loss: 35.7747 Explore P: 0.0225 RunMean : 462.8200\n",
      "Episode: 1201 Total reward: 198.0 Training loss: 5588.7441 Explore P: 0.0224 RunMean : 460.0300\n",
      "Episode: 1202 Total reward: 500.0 Training loss: 608.8953 Explore P: 0.0222 RunMean : 460.0300\n",
      "Episode: 1203 Total reward: 500.0 Training loss: 8.3314 Explore P: 0.0220 RunMean : 460.0300\n",
      "Episode: 1204 Total reward: 500.0 Training loss: 6.7431 Explore P: 0.0217 RunMean : 460.0300\n",
      "Episode: 1205 Total reward: 500.0 Training loss: 7.6513 Explore P: 0.0215 RunMean : 460.7900\n",
      "Episode: 1206 Total reward: 500.0 Training loss: 8.5812 Explore P: 0.0213 RunMean : 460.7900\n",
      "Episode: 1207 Total reward: 500.0 Training loss: 7.3992 Explore P: 0.0211 RunMean : 461.5300\n",
      "Episode: 1208 Total reward: 500.0 Training loss: 340.3524 Explore P: 0.0209 RunMean : 462.7500\n",
      "Episode: 1209 Total reward: 500.0 Training loss: 10.9189 Explore P: 0.0207 RunMean : 462.7500\n",
      "Episode: 1210 Total reward: 500.0 Training loss: 7.3912 Explore P: 0.0205 RunMean : 462.7500\n",
      "Episode: 1211 Total reward: 483.0 Training loss: 10.0110 Explore P: 0.0203 RunMean : 462.5800\n",
      "Episode: 1212 Total reward: 500.0 Training loss: 10.1310 Explore P: 0.0201 RunMean : 462.5800\n",
      "Episode: 1213 Total reward: 500.0 Training loss: 13.1714 Explore P: 0.0199 RunMean : 462.5800\n",
      "Episode: 1214 Total reward: 500.0 Training loss: 29.6920 Explore P: 0.0197 RunMean : 463.3000\n",
      "Episode: 1215 Total reward: 391.0 Training loss: 13.2807 Explore P: 0.0195 RunMean : 462.2100\n",
      "Episode: 1216 Total reward: 500.0 Training loss: 11.8066 Explore P: 0.0193 RunMean : 462.2100\n",
      "Episode: 1217 Total reward: 500.0 Training loss: 12.1894 Explore P: 0.0191 RunMean : 462.2100\n",
      "Episode: 1218 Total reward: 485.0 Training loss: 16.0579 Explore P: 0.0190 RunMean : 462.1200\n",
      "Episode: 1219 Total reward: 500.0 Training loss: 21.5808 Explore P: 0.0188 RunMean : 462.1200\n",
      "Episode: 1220 Total reward: 500.0 Training loss: 5.4275 Explore P: 0.0186 RunMean : 462.1200\n",
      "Episode: 1221 Total reward: 500.0 Training loss: 12.5550 Explore P: 0.0184 RunMean : 462.1200\n",
      "Episode: 1222 Total reward: 500.0 Training loss: 8.9973 Explore P: 0.0182 RunMean : 462.1200\n",
      "Episode: 1223 Total reward: 500.0 Training loss: 9.7828 Explore P: 0.0180 RunMean : 462.1200\n",
      "Episode: 1224 Total reward: 500.0 Training loss: 6.8750 Explore P: 0.0178 RunMean : 462.1200\n",
      "Episode: 1225 Total reward: 500.0 Training loss: 6.9898 Explore P: 0.0177 RunMean : 462.1200\n",
      "Episode: 1226 Total reward: 500.0 Training loss: 3.4908 Explore P: 0.0175 RunMean : 462.1200\n",
      "Episode: 1227 Total reward: 500.0 Training loss: 3.1449 Explore P: 0.0173 RunMean : 462.1200\n",
      "Episode: 1228 Total reward: 500.0 Training loss: 6.2782 Explore P: 0.0171 RunMean : 462.1200\n",
      "Episode: 1229 Total reward: 500.0 Training loss: 4.7510 Explore P: 0.0170 RunMean : 462.1200\n",
      "Episode: 1230 Total reward: 500.0 Training loss: 4842.1226 Explore P: 0.0168 RunMean : 462.1200\n",
      "Episode: 1231 Total reward: 500.0 Training loss: 5726.2896 Explore P: 0.0166 RunMean : 462.1200\n",
      "Episode: 1232 Total reward: 500.0 Training loss: 6.2184 Explore P: 0.0165 RunMean : 462.1200\n",
      "Episode: 1233 Total reward: 500.0 Training loss: 3.6293 Explore P: 0.0163 RunMean : 462.1200\n",
      "Episode: 1234 Total reward: 500.0 Training loss: 4261.2236 Explore P: 0.0162 RunMean : 462.1200\n",
      "Episode: 1235 Total reward: 500.0 Training loss: 4.3990 Explore P: 0.0160 RunMean : 462.1200\n",
      "Episode: 1236 Total reward: 500.0 Training loss: 5.6884 Explore P: 0.0158 RunMean : 462.1200\n",
      "Episode: 1237 Total reward: 500.0 Training loss: 4.3193 Explore P: 0.0157 RunMean : 462.1200\n",
      "Episode: 1238 Total reward: 500.0 Training loss: 5.8030 Explore P: 0.0155 RunMean : 462.1200\n",
      "Episode: 1239 Total reward: 500.0 Training loss: 4.5010 Explore P: 0.0154 RunMean : 462.1200\n",
      "Episode: 1240 Total reward: 500.0 Training loss: 3.3859 Explore P: 0.0152 RunMean : 462.1200\n",
      "Episode: 1241 Total reward: 500.0 Training loss: 2.8790 Explore P: 0.0151 RunMean : 462.1200\n",
      "Episode: 1242 Total reward: 500.0 Training loss: 3.5204 Explore P: 0.0149 RunMean : 462.1200\n",
      "Episode: 1243 Total reward: 500.0 Training loss: 3.2274 Explore P: 0.0148 RunMean : 462.1200\n",
      "Episode: 1244 Total reward: 500.0 Training loss: 4.3605 Explore P: 0.0146 RunMean : 462.1200\n",
      "Episode: 1245 Total reward: 500.0 Training loss: 3.5075 Explore P: 0.0145 RunMean : 462.1200\n",
      "Episode: 1246 Total reward: 500.0 Training loss: 3.6125 Explore P: 0.0143 RunMean : 462.1200\n",
      "Episode: 1247 Total reward: 500.0 Training loss: 2.6113 Explore P: 0.0142 RunMean : 462.1200\n",
      "Episode: 1248 Total reward: 500.0 Training loss: 3.2972 Explore P: 0.0140 RunMean : 462.1200\n",
      "Episode: 1249 Total reward: 500.0 Training loss: 3.7786 Explore P: 0.0139 RunMean : 462.1200\n",
      "Episode: 1250 Total reward: 500.0 Training loss: 1.8021 Explore P: 0.0138 RunMean : 462.1200\n",
      "Episode: 1251 Total reward: 500.0 Training loss: 1.7062 Explore P: 0.0136 RunMean : 462.1200\n",
      "Episode: 1252 Total reward: 500.0 Training loss: 3.8330 Explore P: 0.0135 RunMean : 462.1200\n",
      "Episode: 1253 Total reward: 500.0 Training loss: 2.0415 Explore P: 0.0134 RunMean : 462.1200\n",
      "Episode: 1254 Total reward: 500.0 Training loss: 2.9250 Explore P: 0.0132 RunMean : 463.1600\n",
      "Episode: 1255 Total reward: 500.0 Training loss: 5154.9375 Explore P: 0.0131 RunMean : 463.1600\n",
      "Episode: 1256 Total reward: 500.0 Training loss: 1.8346 Explore P: 0.0130 RunMean : 463.1600\n",
      "Episode: 1257 Total reward: 500.0 Training loss: 2647.6577 Explore P: 0.0128 RunMean : 463.1600\n",
      "Episode: 1258 Total reward: 500.0 Training loss: 3.0464 Explore P: 0.0127 RunMean : 465.1200\n",
      "Episode: 1259 Total reward: 500.0 Training loss: 1.9205 Explore P: 0.0126 RunMean : 465.1200\n",
      "Episode: 1260 Total reward: 500.0 Training loss: 3.7347 Explore P: 0.0125 RunMean : 465.1200\n",
      "Episode: 1261 Total reward: 500.0 Training loss: 1.9957 Explore P: 0.0123 RunMean : 465.1200\n",
      "Episode: 1262 Total reward: 500.0 Training loss: 2.3961 Explore P: 0.0122 RunMean : 465.1200\n",
      "Episode: 1263 Total reward: 500.0 Training loss: 2349.3696 Explore P: 0.0121 RunMean : 465.1200\n",
      "Episode: 1264 Total reward: 500.0 Training loss: 1.3399 Explore P: 0.0120 RunMean : 465.1200\n",
      "Episode: 1265 Total reward: 500.0 Training loss: 7.1046 Explore P: 0.0118 RunMean : 465.1200\n",
      "Episode: 1266 Total reward: 500.0 Training loss: 2.7225 Explore P: 0.0117 RunMean : 465.1200\n",
      "Episode: 1267 Total reward: 500.0 Training loss: 2.4335 Explore P: 0.0116 RunMean : 465.1200\n",
      "Episode: 1268 Total reward: 500.0 Training loss: 1.9405 Explore P: 0.0115 RunMean : 465.6800\n",
      "Episode: 1269 Total reward: 500.0 Training loss: 1.6077 Explore P: 0.0114 RunMean : 465.6800\n",
      "Episode: 1270 Total reward: 500.0 Training loss: 3.6529 Explore P: 0.0113 RunMean : 466.2500\n",
      "Episode: 1271 Total reward: 500.0 Training loss: 6.1804 Explore P: 0.0112 RunMean : 466.2500\n",
      "Episode: 1272 Total reward: 500.0 Training loss: 2.5011 Explore P: 0.0110 RunMean : 469.7400\n",
      "Episode: 1273 Total reward: 500.0 Training loss: 2.1266 Explore P: 0.0109 RunMean : 472.5200\n",
      "Episode: 1274 Total reward: 500.0 Training loss: 2.9668 Explore P: 0.0108 RunMean : 474.8300\n",
      "Episode: 1275 Total reward: 500.0 Training loss: 2.0203 Explore P: 0.0107 RunMean : 474.8300\n",
      "Episode: 1276 Total reward: 500.0 Training loss: 1.8871 Explore P: 0.0106 RunMean : 474.8300\n",
      "Episode: 1277 Total reward: 500.0 Training loss: 1.9066 Explore P: 0.0105 RunMean : 474.8300\n",
      "Episode: 1278 Total reward: 500.0 Training loss: 2762.7888 Explore P: 0.0104 RunMean : 474.8300\n",
      "Episode: 1279 Total reward: 500.0 Training loss: 1.8935 Explore P: 0.0103 RunMean : 476.4200\n",
      "Episode: 1280 Total reward: 500.0 Training loss: 3.6544 Explore P: 0.0102 RunMean : 476.4200\n",
      "Episode: 1281 Total reward: 500.0 Training loss: 6.5073 Explore P: 0.0101 RunMean : 477.7700\n",
      "Episode: 1282 Total reward: 500.0 Training loss: 2.6560 Explore P: 0.0100 RunMean : 477.7700\n",
      "Episode: 1283 Total reward: 500.0 Training loss: 2.1077 Explore P: 0.0099 RunMean : 478.0700\n",
      "Episode: 1284 Total reward: 500.0 Training loss: 1.6063 Explore P: 0.0098 RunMean : 481.1400\n",
      "Episode: 1285 Total reward: 500.0 Training loss: 1.6792 Explore P: 0.0097 RunMean : 481.1400\n",
      "Episode: 1286 Total reward: 500.0 Training loss: 1.7711 Explore P: 0.0096 RunMean : 481.1400\n",
      "Episode: 1287 Total reward: 500.0 Training loss: 3.7865 Explore P: 0.0095 RunMean : 481.1400\n",
      "Episode: 1288 Total reward: 500.0 Training loss: 2.3066 Explore P: 0.0094 RunMean : 481.1400\n",
      "Episode: 1289 Total reward: 500.0 Training loss: 1.8047 Explore P: 0.0093 RunMean : 481.1400\n",
      "Episode: 1290 Total reward: 500.0 Training loss: 4.0448 Explore P: 0.0092 RunMean : 481.1400\n",
      "Episode: 1291 Total reward: 500.0 Training loss: 1.4714 Explore P: 0.0091 RunMean : 481.1400\n",
      "Episode: 1292 Total reward: 500.0 Training loss: 2.4251 Explore P: 0.0090 RunMean : 481.1400\n",
      "Episode: 1293 Total reward: 500.0 Training loss: 3.8276 Explore P: 0.0090 RunMean : 481.1400\n",
      "Episode: 1294 Total reward: 500.0 Training loss: 2.1279 Explore P: 0.0089 RunMean : 481.1400\n",
      "Episode: 1295 Total reward: 500.0 Training loss: 2.8712 Explore P: 0.0088 RunMean : 481.1400\n",
      "Episode: 1296 Total reward: 500.0 Training loss: 1.5609 Explore P: 0.0087 RunMean : 485.8000\n",
      "Episode: 1297 Total reward: 500.0 Training loss: 1.4464 Explore P: 0.0086 RunMean : 485.8000\n",
      "Episode: 1298 Total reward: 500.0 Training loss: 1.4813 Explore P: 0.0085 RunMean : 489.2500\n",
      "Episode: 1299 Total reward: 500.0 Training loss: 5.0250 Explore P: 0.0084 RunMean : 492.2500\n",
      "Episode: 1300 Total reward: 500.0 Training loss: 2.2195 Explore P: 0.0083 RunMean : 495.5700\n",
      "average training reward =  183.926210607\n",
      "INFO:tensorflow:Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-23 00:28:11,926] Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average test reward =  500.0000000000452\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 5, got 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e1576820b7cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmainQN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_episodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_and_train_qnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m                                     \u001b[0mtrain_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4000\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.999\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mexplore_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mexplore_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00002\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mhidden_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mhidden_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m                                           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test='\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 5, got 4)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAisAAAF5CAYAAABeAGpJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzsvXmYHFd19/853bPPSCPNaBnLkrAcO/JGnMjGYPzabC87\nAQIvxALCmkBY/SgbS0gwNiFssR22QAIBAj9EeO2XGEwSQ9jxHmTAYZFtWYu1r6NZe6aX+/vj9p2q\nrqnuruq9e87neebp7urqqjvVI91vnfM954oxBkVRFEVRlFYl0ewBKIqiKIqilELFiqIoiqIoLY2K\nFUVRFEVRWhoVK4qiKIqitDQqVhRFURRFaWlUrCiKoiiK0tKoWFEURVEUpaVRsaIoiqIoSkujYkVR\nFEVRlJZGxYqiKIqiKC1N08WKiLxHRHKBn18G9rlORA6KyIyIfFtEzgm83ysinxCR4yIyKSI3i8ia\nxv4miqIoiqLUg6aLlTz/A6wFxvI//8u9ISJvB94CvB64DJgGbheRHt/nbwKeC7wYuApYB9zSkJEr\niqIoilJXupo9gDwZY8yxIu9dA1xvjLkNQEReCRwBXgh8VUSWA68FrjbG/CC/z2uAX4nIZcaYe+s/\nfEVRFEVR6kWrRFbOFZEDIrJLRL4kIhsARGQTNtLyHbejMWYCuAe4PL/pUqzo8u+zE9jn20dRFEVR\nlDalFcTK3cCrgWcCfwxsAn4oIoNYoWKwkRQ/R/LvgU0fzedFTLF9FEVRFEVpU5qeBjLG3O57+T8i\nci+wF3gp8Ot6nVdERrECaQ+Qqtd5FEVRFKUD6QPOAm43xpyo98maLlaCGGNOi8iDwDnA9wHBRk/8\n0ZW1wP3554eBHhFZHoiurM2/V4xnAv9frcatKIqiKEuQlwNfrvdJWk6siMgQVqh8wRizW0QOA08D\nfp5/fznweOAT+Y/8BMjk9/lafp/NwEbgrhKn2gPwpS99ifPPP7/2v0ibsW3bNm688cZmD6Pp6HWw\ntMp1OHjwIPPz85x11lk1O+bMzAxHjx5l5cqVDA8PAzA1NcXx48cZGRlh+fLlAOzZsweAv//7v1+4\nFocOHWJubq7geIODg+zYMc0HP7iC888f5+BB+Ku/gpERb59ly5YxOTm58HrlypWcOnUKgOHhYU6f\nPg2AMXDoEHzgA2dx5ZXw538Od901w4c+dJRrr+3h4ovX8Za3QH8/fPjD8I537GHvXujr6+fKK2d5\n6lPt8Tdu3EgiEZ7lz2Qy7N+/n4GBAdasidbh4cCBA1x33XV8+tOfXrgutfpO5ufnOXjwIH19fYyN\n2cy9O4f/PP5tYfzsZ6u57rpB7roLenqK7/fJTx7nvvumeM97oKuri/Xr15c89ujoKL29y/jd3z3G\nwMA0N94If/u3f8s//MM/8G//dpwvfnEGgOuvh1Wr+nj3u8dIJuFTnwKRKFegPfnVr37FK17xCsjP\npfWm6WJFRD4MfAOb+jkTeC+QBr6S3+Um4N0i8jD2olwP7AduBWu4FZHPAjeIyClgEvgocEeZSqAU\nwPnnn8+WLVtq/Wu1HcPDw3od0OvgaJXrMDIywtzcHJs3b67ZMaempjhw4ACrV69mJK8oJiYmOHTo\nEGvWrGHlypWAFSFQeC327dvH7OxswfGGh4c5evQ0xozxtrcd5v3vh4cegte+1ttnxYoVjI+PL7xe\nvXo1x47ZAsjR0VFOnLBR9AcegI99DA4c2MxTnwpbtsDExBR9fQfYtKmXLVvOoqcHxsbse2984yB3\n3w0//OEQx49PceGF9vjnnntuSbEyPDzM0NAQZ555ZqRrtnLlSpYtW8aWLVsWrkutvpO5uTlWrlzJ\nwMAAGzZsALxr7z+Pf1sYu3efyeDgEE94QunznXPOEXbsGOfCC6G7u5uzzz6bBx4Y5M474ZprIJks\n3H/t2rV0da2gu/sgfX2TXHghC9fivvsO0dc3BcBjHgNnnz2AyAYuuQQuuSTmhWhfGmKjaLpYAdZj\nQ0ijwDHgx8ATXA7MGPMhERkAPg2sAH4EPNsYM+87xjYgC9wM9AL/Cby5Yb+BoihLmrk5MCbBeefB\n4x5nxUol5AMs3HefFSMAvb3eOQBSKejrs88vuMD+HDkCMzOVj7+dyeXgnnvgzjv7GB0tv//gIMzO\n2iiW4/Ofh4MH4eqrYd26xZ/JZMKP5d/uNOzUFAwNRR6+EpGmixVjzNYI+1wLXFvi/TngrfkfRVGU\nhpJO28mvt9dGPXbtKr2/FMkPpPL3qL/92+ACI06YzOdvz+bmvG2OZBKy2QoH3+IYY4peL4AHH4Q/\n+qOzyWS6eO5zyx9vcNAKnPl5L13kDj8+Hi5W0unwY4WJlclJWLas/DiUeLRC6bKiKEpbYPy34z7m\n5624SCTsXfXUVOH7pSZbP3NzMD6+mi7fbaSLrLgJ0x9ZcSSTdgJuR4pd06jvu2u9axd8/evlz+ey\nSR/5iHdNBwbs44EDi/cXkaKRFb9AdEJzakrFSj1QsaIAsHVr2QDXkkCvg0Wvg0e5ayEizM9DX58g\nYieq6enCNENUUqlu0umRgm29vVbouMhKKuUJGEcjIivPjRK2qAPGmALBYkxh5MpGNIRVq7xoVCl+\n+7dtqu6eeyBvFVoQh9/8ZvhngpEVdy0yGS8qc8cdcOutommgOqFiRQF0cnLodbDodfAody1WrFhB\nOj1KLmdv2YeG7IRaiYcklfLu/B1OmJRKAyUSNrIyVMdZ8nnPe17djl2KYGTlvvtg2zZrRgbPy1PG\nf7vAypXCi15knzsR4q5td3f4Z4KRFXctMhn7fff1wbe/DR/8IKxfD7/zO9HGokRHxYqiKG3H5OQk\nu3fvruiz5dIKcRER5uZW0ddnb7FdCuCOO+Ifa26uvFgJSwM5seKo9e/YTIKRlYl8Ny2Xspmdtdcj\nWMVTCidKnFhxgqdYKq1UGqi7G770JdiwATZuTLJzp43cKLWl6QZbRVGUuBw7dox0MddjHSkmAmZn\nbe8TgPPOs4/79nnvR/WspFKef8LhxMrevXD33TZiExQrXV3R00BRx9IqBMWKExrT0/bRRqPi/U7F\nxEqxa1jKYNvVZY26n/gEnHPOmliiSYmORlYURVHyVDqRu7t7sBPhb/0WnDwZ/zhTU5DvSbdAMmmj\nNV/8Ilx+uZ1YV60q3CcYWekkgmLFVd24NFsqFd8j4hcrmYxnji0mVopFVubn1wD2YAMDAyRVqdQN\njawoiqJUSSplIysjIyOcPHmS0VE4XGqxjzx/+IfwmtfAFVfY18eO2XRCkE9+0k7Oq1fbO/nf/M3C\n99u5GqgcwWiWEykuGjI7G92v4nCG2nTa9qkRsdGRYqKkWGQlne5mamottk+pUk80sqIoilIFIrIQ\nWVm9ejV9fX2MjESLrBw9CjfcUPh648bF+w0Pw1lnwYUXwubNi9u4V1IN1E6+Fv9Yg2JlagryTYcj\n4yIrc3O2gd9zngNPf3o8z4orae7SW/6GoGJFURSlBDMzM+Tys1ixCd5FVgCSyeSCWCmlB5y4cJkD\nY2wpbcQO+AV0choICq+766viUjcTEzAyUplnxS3XdOGFNpUU17OSTqtYaRQqVhRFWfKUijI8+uij\n7PO7ZUPwG2yTySSjo3Yi80dNguSXBloQK7OzdrKM0jI+SCd3sAXv+1m9evXCkgT+JmwjI0U+WAQn\nVtyxBgbsNYzSVt9POl283FmpLSpWFEVZkoSZaY8cOcKhQ4cWbQ+utBzEX06cSCTYtMk+/8EPin/m\n9a+3j11ddiJ2EYPgxBvF9BvHs9Jq6Z844xkYGFgoXT56FL73PdtuP67AC4qV/v7Sgk8jK81HxYqi\nKIqPCTcbxsAfWQE44wx4yUtgzZrw/f3zs4usuJREpZGVXK79ypKj4gSNiCwIjN274cYb7fMLL4z3\ne7trHhQrcfusaGSlcahYURRFqZKwRm3d3cXvyF35LSwWK3HNomA9K0shDQSL110CeP7z4x1PxH4/\nP/2pfe3EStw0kDXYdqZAbDVUrCiKogQ45gwlAaI0hXPRjZ4er+tskJkZb4JzaSCXaaqkY36nG2z9\nzM3BM58Jf/AH3rZgb5ooPOlJtn/Ns55lo1ml0kCuAV0QTQM1DhUriqIoAU5G7Oh25AisWSP8+teL\nIyu9vVas3HknHDhQKHL80YGeHvvoojDBRQqjEKeDbTtjlzaATZtsms3bHv9Yb3ub7Tr7H/9hoyyl\nxMqtt9pH9105tHS5cahYURRFqZCDB63wGBvzGrs5enqsAPnABzwzrcO/yKFL+1QjVpZKZMV1nA1e\no1p4dZxYCQbPjIF//Vf7PHiNVaw0Dr3MiqIoFeJ8Jg89tDh9478LD3p2XWTlMY+B+Xk7OzqxErx7\nj0Ind7AFL/3mvD4uivUP/wDHj9fmHP5+N37tMz9vX1x0ETz6aOFnVKw0Dr3MiqIsKaop3Q1+dnLS\nTlZh7d79oiNYMeIm3aEhz6viKksqCRJ0slgpXBfIXhwXWTnzzMqa6IXhxEo2ayNV3jnt4/Lli69x\nOg3JpBpsG4GKFUVRWh5jTEuW5bqGZGFD84uVYLTEGW+HhrzojI2sLM4Blfq9x8bGMMaQSEyTy5Xu\nmNsJuPRZJamycvjFil9cOrHiVsP2R14yGS1dbhTqWVEURamQqSm7bk8Y/r4rwQnNRVNGRuD0aasw\nMpnHMD5+RqzzDw8Ps2LFioWJ9t/+TbjvvmjRo0oiTM1oKHfgwAGyeeerEw71Fit+nEByYsUfXclk\nvM8p9UUjK4qiKBXwox/Bnj3FS403b/aeB0trnVgZHYVTp+zz+fm+ivwq4KUt/uZvbDnuC15gHzuB\nbDbLVN7k40q+GylWnEByqb5czttXPSuNQy+zoihKRFxk4dAh+PCH7ba1a8P3TSbte0eOQG9vYURi\nft4KjJERG53JZKyAqXQSDk6Yxfq7tCvuujsTcj0EgjtmMbHiImXByIqKlcagaSBFUZSYuDbt4KUH\nHH6PyUc+YqtI/B1rwQqT7m6XQjJMTFQnVi6+GJ78ZHjGM+zrduq5Eie15DrJ1iP14qJTwW61wciK\ni4qJSL4pXOt5qToRFSuKoigx8d9d9/cXn6yGh+Hsswv7qoCd8Hp6PL/LxISQSlUuVtauhT/5E3jO\nc+zrYu3h251Mxl7reoiVYmmg//t/7ePGjfbxnnv849HISqNQsaIoihKTQrFSet/eXrt2kJ+5OVmI\nrIjYSE01kRWH30tRjFZbdTkKwTRQPcSKEx3B8uRUyvqSnvIU+9p/bVWsNA4VK4qiKBFxk6Z/Qgum\ngYL09pZLA1mxMjtb/ljliCJW2hn3e9VDIBRLA6VS8PSn2+c9PSpWmoWKFUVRljxxow1xIit9feFi\npafHCpmeHutZmZ4Oby4Xh6UiVhJ1mLmKGWxTKe87Djbfs03haj8WZTEqVhRFWZJU02TOr23KRUP6\n+iCVMgWfueMOOzmKWIEyO2t9LWHHijNOZ/Z06ZJ2IsrvmU7bfeoRzXCiI5gGmpvz2vsHFzu0kRU1\n2DYCFSuKoigx8U9omzaV3tf5UPzlxA8+6B1jZGSSVMpoZKUELvLVyGqg//ovuPnmxZGVYBpIO9g2\nBs22KYqixMTdXX/mM/DEJ5bet6/PRlD8BtrubnjWs7z3Uym47z649NLqxuUiDp0mVhz1MtiOjIxw\n4MBJwPtuP/pR+9jfXxhZ0T4rzUEjK4qiKDFxE5abxPwE0xluH79vZX7em+T6+uC22+wkuX9/deOK\nE1lpx6qgTEYQqb1nZfXq1XR32y+knGdlcRqotmNRwlGxoiiKEhMnVhKJ4l6LgbwBxYoVs1C+nMvZ\nHzfJ9fZ6HpijR6sb11KIrNTL0Losvz5BFLHivnM12DYOFSuKoigx8YuVYrjIhYusuM6nwfJbf2+V\nYusMRWUpeFbqJQ6KVQPNzEhBGshdW2M0stJIVKwoirKkqEX6wx0iysTpPCsuDeQmO2fM9KeSvvCF\n6sZVbMJtZeK125e6iZViHWxTKa8fjt+z4h67u7UaqBGoWFEURYlIsClclKpil0JwaaDgYnxudeQn\nPxnGxqobn5tw61W63Cyfi7+Dbb3EihOPTqycf76tzvrc5+BlL7Pb/J6VejaoUxajl1lRFCUmUdJA\nDpfmcWIlOMm96lVw5ZVwxRXhn4/TZ8VLA7WfebYcIlLXNFBYZOXxj7eLQ/b3w6lThWkgFSuNRS+z\noihKTNyEFkWs9PSAiFkUWRkeXgscYWDArsxcbVQFvAZl7bo20IMPPsiwy7mEYFc5rs+5g2Ilm10s\njPxpoGCETKkvmgZSFEWJSZw0kIjtTFsYWREGB6t004bQ7tVAxhjGx8eLvp/J1KfVPiz2+2Szi4WI\npoGah4oVRVGUmORyrmw52v79/YsNtj09tR9XJ1cDiUhDIivu2hWLrCwWK2qwbQSqCRVFUWJijHeH\nH/SUhHlMBgbMotJlFSvxCXpWxsbGmA2uElkhrtmci5oVEyvqWWkOepkVRVnyVLLqcrmoiv+YjYqs\nuImzHRcyjEKwGmh4eLikxyUuXV2FYiQsDeTEjIqVxqJpIEVRWp5WM4W6NFBU/J4VJyT8zeBqRadG\nVvxpIKiDysvT1VXoWQl+x/40kBpsG4uKFUVRlJjEFSv9/YtLl3t6au91cD6aKE3hWk0ARiGTgYmJ\njXU7fleXJ0KKGWyDaSBddbkxqFhRFEWJSdhddyn8YmVuznpe8ksH1Rz/hNppWINt/RbjCaaBSpUu\nq8G2sahYURRlSRKn2VqQUpGV4eFhBgYGFhYyBGuwdZ4VJ1oGB2s/ThEhkehcsVLvtXj8YiWXi1oN\nVL/xKB4qVhRFUWLirwYK0tXVxYYNG0j4dujt9RYynJuzqZp6eFbs+dtLrERJR/k9K/VMu3R3LzbY\n+sWielaah4oVRVHalmb5LuJ6Vnp6vElwbs6mhaoI7JSkk9NAjYyslDLYutb/7jNK/VGxoiiKEhO/\nWImSpunuhn37YGbGipV6+VXAjquTS5frGVmJYrANpoHUYNsYVKwoiqLEJG5kpavLRoD+5m+sZ8VG\nVuoTWrETan0iTs1cdbkRaSAXWTEmTgfb+o1H8VCxoijKkiadTnP06NFYn4krVtwEu3u3lwaqF+XS\nQO1YsuyoZxpIRBbEiqv4idbBVquBGoGKFUVRljRzzvlahqmpqYXn8SMr/vNBX1/9JrhO9qw0IrIy\nOws//rH32o+uutw8Wk6siMg7RCQnIjcEtl8nIgdFZEZEvi0i5wTe7xWRT4jIcRGZFJGbRWRNY0ev\nKEqrE4wsRE3HHDhwYOGzcfusuFOIwPw89PVF/2xcOlWsOFNrvQ22d98Nf/d39nWpDraaBmosLSVW\nRORxwOuBnwW2vx14S/69y4Bp4HYR8fddvgl4LvBi4CpgHXBLA4atKEobkMvlSIc4TxNxVMfCsRan\nCErhRI4x9RcrUfustFM6yI21EZGVUq/VYNs8WkasiMgQ8CXgD4HxwNvXANcbY24zxvwP8EqsGHlh\n/rPLgdcC24wxPzDG3A+8BrhCRC5r1O+gKErrcvDgQR555JFF2ysxusa5wxeRhdQBxBcrcZvC+Sta\nakWrCJtGRFb8qMG2dWgZsQJ8AviGMea7/o0isgkYA77jthljJoB7gMvzmy7FriDt32cnsM+3j6Io\nS5hZ10I2QCViJaxSJAq5nCdW6lsNVJdDN5VGVAMFG/VFESvd3WqwbQQtoQlF5Grgt7GiI8gYYIAj\nge1H8u8BrAXm8yKm2D6Koig1Ie4dvn89mfl5WL68PuOCzvSsuMhOvSMrV18NQ0Pw9a/b16XSQGqw\nbSxNj6yIyHqs3+TlxpgObWWkKEonEddg659s5+fr12ofontW2o1GRFbGxuB5z/NeRyldriTCpsSn\nFTThJcBqYId4cdEkcJWIvAU4DxBs9MQfXVkL3J9/fhjoEZHlgejK2vx7Rdm2bRvDw8MF27Zu3crW\nrVsr/HUURel0wrqbFsPvWfGngepFPSIr9UpZQfS1gcCWfdfb0OoXkuVWXbZrB9V3PK3A9u3b2b59\ne8G206dPN3QMrSBW/gt4bGDb54FfAR8wxjwiIoeBpwE/hwVD7eOxPheAnwCZ/D5fy++zGdgI3FXq\n5DfeeCNbtmypyS+iKEr7UI1pNJOJWw3kPa93ZKUT00AAJ04I+/fD+efX9zw9vhrTcp6VpZICCruB\n37FjB5dccknDxtD0NJAxZtoY80v/D7Y0+YQx5lf53W4C3i0ivysijwX+BdgP3Jo/xgTwWeAGEXmy\niFwC/DNwhzHm3ob/UoqitCxxRYoxtvfGwYPetjiRFYDHPc4+LlvWmMhKpxlsjTEczsfIL764umON\njo6yvIRpKJpYqX/PF6WQpouVIhT8b2KM+RDwMeDT2CqgfuDZxph5327bgNuAm4HvAwexPVcURWlz\nGlk6+9//DQcOeK//6Z/g/e+H977X2xY3svLYxxpe9jL7mXqKFRHp2IUMXbTILyYqIZlMsnr16qLv\n+wVIsVLmXM5eYxUrjaMlL7Ux5qkh264Fri3xmTngrfkfRVGUSASF0HXX2Qnx5pvt629/2z76u/LH\njawArFwJExPW49DXJ5F9IHH9Ip2aBspk7HXo7i78LmqN/3Ink4XX34mVbNZeY20I1zhaNbKiKIrS\ncJxumffFbK+6yj66VA7Ej6yAFSu5nJ3oNA0UD2NMQzvGuu86LA0Enljp6rIdkJctW8aaNbq6Sz1p\nyciKoihKM5ieLv6ev1Q5TlM4d2d+0UXetnqXLmezxdNm1aTUmtnJ1h9ZqTcualYsDZTJFBps161b\nV/9BLXE0sqIoipJnPL/Qh3+Scv4Pf7QibhrIGMPAADzrWfZ1u0VWWqHdfq08K8Xwp3uKCSL1rDQP\nFSuKoih5nBfCv5aPEyt+H0il7fbdfKgLGS6mnDenUZEVEaG/3z4Pir6wNJDSGPRSK4qypCg1STth\n4hcrbuL3T1yVTlRusmu3yEor0EjPyqteZbvZrl1buF0Nts1DxYqiKC1LPe/+w44dFpEolgaqJLLi\nfC/1SmW4c7RTNVDU77iRYmVoCF4c0viimGdFqT+aBlIUZUkQpQQ4qlipdKJyYqWeGZjOjaxIzdrb\nV7p8gN+zomKlsahYURSlZSk3qdQ68uIXK06k1MKz4sZZb7HimsJ1plhpftrFnwZSg21jUbGiKErL\nUo0YyeVyzPsbpkTAL0hmZuxjschK3NJlgMc/3j5u2hR9TJU0hetEsZJOy4JYGRsbK9kyvxpKXW9N\nAzUPFSuKonQkBw8eZPfu3Yu2RzHYgtdzJcxgW6ln5fzz4etfh3r2D2s3z0pUMhnP6zM8PMwZZ5zR\n8DGowbZ5qFhRFKVlqdRbAJBKpWJ/xj/Jf/ObsGtX8TRQ3D4rjSKZLKxm6hQyGWm6ONDS5eahYkVR\nlJal0b1A/JGVb3wDtm3zVluuNA0UhYGBgZodq5MjK60kVr7yleaOZamhYkVRlCWNXxCVmuSr6WAb\nJBgx2rBhQ+UHC9BuBtvJyclI+6XTjRErUTwrTtSed179x6NYVKwoitKyVJMGKhaVKRWtiSJWjKnc\ns9IIyq263Gqda6empiLtl8lIXfvTRMF95/Pz9u/SGaaV+qNiRVGUlqXRE2upSd695/wgccRKpoF5\nmXaLrESlldJALrLSqoK1E1GxoijKkqKSyEpfnycA3D5R00DVRIcqIapYabUISzmy2bmmiBX/96di\npXmoWFEUZUkSNlmn0155bDrdQy5nZ6OBgcX9VlpxohKRju2zksulaiZWqu1g69r3tOLfQKeiYkVR\nlCVFuchKb+/i7YOD3orMTgg0qmw17sRqq4HqEzVpZjQmkzEN8azEMdiqWGkcKlYURVHyZLPhYmXZ\nMnBtW1waqFUnqk7ts5LNqmdlKaNiRVGUJUWp6EBwQnTPly2zkRVXCQSt7VnRPiv1QcVK81CxoijK\nkqJUqWwwDeSeL1tmH+fm4kdWGi1WOtWzMjGxrq5iJcr3pJ6V5qFiRVGUlqeWXolSZcTZrGewNQb6\n+uwENjRkt6VSYEySw4fHWnaiSiTs2NshFTTnjEARSKV6mt5nRcReX42sNB4VK4qidCSVCJxgG/2z\nz7aP7qY7lYLly89kYmK4ZSMrifz/6vv2NfS0sZmdnWXPnj2R9/evulxPyn1ffrGS0Bm0YeilVhRF\nyRNso//Sl8LICFxwgX2dSrV+n5VTp+zjP/1TQ08bm2zMXFWj2u2XI5nUyEozULGiKIqSZ3FkRfj8\n52H1au/9Vq4GEhGe9SwbCdq0qdmjKU0iZljC3wOnWqoRkF1dKlaagYoVRVGWJGFpolwORNyMKPT3\n22f+1XbdRNWoyErczzt/TaubbOP+Xq0SWVHPSnNQsaIoSttSC+NtcNVl/wTkbv6TSZib682LFVnY\nVin1Tg2Vqghyv2+z2+1HiazkcvCtb9nHVhEryaRWAzWDBvVgVBRFaX1sNZAnJJyocFGUbLb1PSvQ\nHuXLUcTSj34EH/849PdbgdAKYkXTQM1BIyuKoih5MplwEZJMWh+IPw3UyhNVV1fri5UouAjGF78I\nDz1UO89KNSQSMD9ffXRNiYeKFUVRlDzZrDcB+W/8XcbCH1lp5YkqmeyMLrZOOB4+bB/7+up/zmAk\nLPhaq4Gag6aBFEVR8rjIyjOfCeedF0wDmYoMts3whiSTpi6RlUb/LkEx8IxnNPT0oahnpTmoWFEU\npSMpN7EeP36c0dHRgm02siK8+c2FbffdpGQNuK2fAmgHz0oU/B7cCy4QLr+8Meddvnw5qVSKeadK\nfKhnpTloGkhRlCVBFKNrsCmcI5HwPCtxDbaNxP2OiURniBV/KmvNmsad94wzzqCvSM5JS5ebg4oV\nRVGUPMHS5WA1kCuhhdaeqNrBYBslpeSuNRRGupqJpoGaQwveGyiKojQHG1lZHIHxp4HcAoFRK5Kr\n9XlUUvrcKQZbfxamlmJFO9i2HypWFEVR8vhLl/0TmvVOWNNqNmv7fTShfUpkOsWz4hdcjagEioKm\ngZqDihVFUZQ8Qc+KEywidpLK5exPKzQnK0WniBVNAykOFSuKoih5/H1WgrjUiousRKUZpcvt4FkJ\nEnad6pWIBbXhAAAgAElEQVQGqgZNAzUHFSuKoixp/JNkMc8KeAIgk7Fi5ayzzgotbQ3S19dHKpWq\n2XijkEgU96y0ytpAUWhkZCWqj0XTQM1BxYqiKEqeYLt9/wTmUituQb3e3l56I8ygQ0NDpNNppqen\n6zHkUDolDTQ35z3v62sNk5BfoKhYaRxauqwoipKnWGRFRBYEgIusxKGrQU1ZnLjqFLEyM+M9bxWD\nrV+ftrp3qZPQyIqiKEqeUpGVri6v3X4rNoTz0w5iJUoaanbWe96oRQzLpYNe8Qr4nd8RNm2CwcHG\njElRsaIoyhIm65vRjbGVPsU8K04A/OIXMDZW/theJVH16YtEIsHIyEjk/dvRYBuGX6y0SmRlbAw2\nboRNm5o9kqWFpoEURVmyPPzwwwvPXbM350MIW213zx741rfgda8rf+yVK1eydu1aBgYGqh7nueee\ny/LlyyPvX8pg2074fcmtUg2kNIdIkRURuQuIZB03xjyxqhEpiqIEKJcy2Lt3L729vYyFhDwymUwk\nz4i35o8nUgrTQHD8uH3+pCeVH7OIsGLFioJt/f39zPrDBXWiHdJAUWiFyEotImNK9USNrHwf+EH+\n5y7gQqAf+Gn+py+/7c7aD1FRFKU0qVSK06dPh763e/fuSMdwk3spg+3UlH29bFlFwySRaEwwu15i\npV7lzu9+N9xww+Lt/gIqjawsbSJFVowx73TPReRTwKeMMW/37yMiHwCiJ1UVRVEaQM7ld3z8+tew\nYwe87GXetnKrKXd1wfg4gFQsVhqFMwO3Cz//Odx9N7zhDd62XA5OnvReq1hZ2lQi868GPhOy/bPA\nS6sbjqIoSv15xzvgK18p3OYm9+7u8DRQMmmYnrZ+kLgpiUanEtphIcOwKI1/zKdPez4iaJ0+K0pz\nqESszAOXhWy/LP+eoihKSxMSbCnrWXHG22XLWncRQzfeRKIdPStmwRMEXlTFRVQ0srK0qaR0+ePA\np0XkYuDe/LbHA38MfLhWA1MURSlHtR4K/8c9z8riezjnWQEYGqrqlA3Bv9heO3HqlFcW7lrad3XZ\nTratUrqsNIfYYsUYc52I7AGuAd6c3/xr4M3GmH+p4dgURVHqin9CL5cGcl6W9esbMbLqaMdqIJHC\nUmU3fvcVqFhZ2sRKA4lIUkQuA/7NGHOJMWYw/3NJpUJFRP5YRH4mIqfzP3eKyLMC+1wnIgdFZEZE\nvi0i5wTe7xWRT4jIcRGZFJGbRWRNJeNRFGXp4F97xqWBiokVV8hzySW1O393nfq1R2kK14oLGfpL\nld34Xcv9GD3xlA4kllgxxmSBHwGrajiGR4G3A1uAS4DvAreKyPkAIvJ24C3A67G+mGngdhHxN1++\nCXgu8GLgKmAdcEsNx6goSgfiFytRIyu1nDTPOusszjnnnPI7xiTKqsuthEuxhUVWnL9o48bGjklp\nLSrxrPwS2AA8UosBGGO+Gdj0bhF5I/AE4FfYdNP1xpjbAETklcAR4IXAV0VkOfBa4GpjzA/y+7wG\n+JWIXGaMuRdFUZQQ5ua8yTsssuInmbT79ffX7vz16rvSbmkgpwn9kRX3fVxzDTz6qBfZqt8Yarc8\nglJ7Kvn6/wL4iIj8bxFZKSI9/p9qBiMiCRG5GhgA7hSRTcAY8B23jzFmArgHuDy/6VKs6PLvsxPY\n59tHUZQlwtzcHGnnzizDT3/qPQ9GVowxCxOXMWbh7r8dvBPtIFb8ER47VhOaBnrc4+DVr679+UdH\nRznzzDNrf2ClLlQiVm7HpmtuB44Ds4Gf2IjIRSIyCcwBnwR+Ly84xrBt/o8EPnIk/x7AWmA+L2KK\n7aMoShtjjGHfvn3MRyhx2bNnD488Uhj4zeVyoemPf/xH73lYB1v/XXY1Rs9G362300KGxnhVWWFi\nxYnEWrNq1Sp6tR66bagkDfTsmo/CVhNdDAwD/wf4FxG5qg7nURSlDZmfn2d2dpaTJ0+Grv9Tjoce\nemjheViPFSgfWcnl7PNq0kCN8ou0Q1M4h19U3XsvPP3ptnw52FFY0zNLm0pKl2+v9SCMMRk8D8z9\n+Yqja4APAYKNnvijK2uB+/PPDwM9IrI8EF1Zm3+vJNu2bWN4eLhg29atW9m6dWslv4qiKC1OsXUE\n3eTY05Mgl1ssVjIZ+7yV00Dt2BTOP869e+Ftb4OvfrX+kZVqWGrCafv27Wzfvr1gW7G1uOpFJZEV\nAESkC1gPFPhUjDEPVjsobHqq1xizW0QOA08Dfp4/73JsE7pP5Pf9CZDJ7/O1/D6bgY3YRRdLcuON\nN7Jly5YaDFlRlHbAlcIG8UdW/FVCwfdrabCtF+3gWXEE+6m4iiAnHpstVpaaMAkj7AZ+x44dXFLL\nOv4yxBYrIjIKfBp4AeGel1h/WiLyfuA/sIbYZcDLgScBz8jvchO2QuhhYA9wPbAfuBWs4VZEPgvc\nICKngEngo8AdWgmkKEqQMCEC/siKLFQJ+SeqbLb21UD1Iplsn4UMi40zl7MRItUKClQWWbkBW7r8\nFOA/sQsbjmF7pfxpBcdbA3wBOAM4jY2gPMMY810AY8yHRGQAK5BWYPu8PNsY43fabQOywM1Ab35c\nb0ZRFCVAsUKhcn1W3PutnAZytJPBttg4M5nmR1WU1qESsfJ04EXGmLtFJAfsNMbcJiIngT8Bvh7n\nYMaYP4ywz7XAtSXenwPemv9RFEUpStB46jyvnlhx281CtUhXVxcnTtgd1q5txCiro1RTuGqopUHY\nHcsTK4XHzmZVrCgelZQuLwMO5Z+fAlbnn+8gfDVmRVGUliF4J++qg4JN4Ywx9Pf3c+6559Lf38/y\n5fb99evj5yUa7XtoJ8+Ku/7BS5TJeJVAilLJn8KDwLnAXuAB4LUishPbRTbYD0VRFKWlCKaBnEjJ\nZu2E6e+zAl6X2b/+azh5sjoPRSNLl9tlbSB3/d11dY/NiqyoobY1qUSsfBw4K//8eqw59jXYipyy\nKR1FUZRmEpzE3etyHokVKyDQ5aBlaWfPimurHxQrKiKWNpX0Wfmc7/k9+Zb4FwJ7jDEHazk4RVGU\nWpPJQC6XJJHILrwGOzmWSju0SiSiFP4+K+3WFM5d3hUr7KOmgRQ/sT0rIrLO/9oYc9oYc6cKFUVR\n2oFMBjKZZMFr99gphs5SaaBWE13Os3LGGfZx2TL7mE57ZmdFqcRgu19EHhSRfxKRl4vI+pqPSlEU\npQKiTMRWnIjvtf1MLmcn+U5IN7SDwTZYDfRXf2V46lM9T9HEBAumZkWpRKycC3wA28/k/cA+EXlY\nRD4rIq+o6egURVFiEFWs+HfzR1b8aYdWi0DEoV5ipR7XxF3/gQFbFu6WQ1CxoviJLVaMMbuMMf9s\njHmlMeYxwAXAj4FXYpu7KYqi1JVqoh9ucnzmMwtfp9PFPRLtFm1ph8iKw6WBurqsYHHLIUxOqlhR\nPCrxrPSIyFUi8tci8l3s2jyPBz4DvKzWA1QURQlS7A7fbS8lLlwa6Mor7Ws3qc/O2smyHjSjz0q7\nGWyTSXv9UykrYMbHVawoHpV4rU8DE8AtwKeArcYY7a+iKErTiZKmcFU/LoqSyUBPj72jr5dYiTO+\nWtBOkRW/WBkctM9nZuDECRgdbdw42i16ttSoRKz8AHgi8CygD+gTke8bY/bVdGSKoihlKDb5i0jR\n96w3RRYqf1wE4tixDUCRVQ7bjESi/cRKIuGJxf377feyalXzxlUKFTaNpxLPyrOAldgFDH8FvBT4\nmYg8kl/9WFEUpSlENdh2dbFIrJw+3Utf38q6TETL8vW4bq2hetPVZU3Ezg9SK6anp2t7QBangQC+\n+lX7uM7XKEMFwtKmkmogjDFZY8y9wDexHWy/h12J+dW1G5qiKEo8ynlWbrsNvvCFwsiKmywnJmSh\nx0et6e3tZfPmzSTr3MjF/d7B361WnDhxorYHxBtjV5dNx4H1q6xZAxs31vx0sVGR1BpUYrB9k4h8\nVUQOY9cGeiNwGHg5sK7khxVFUZrIl79sH5cv99q6u8jK1BQMDTVnXLUmkQiuaLyYZpdmB/usJBJm\nQWRNTDRvdWsVJ61JJZGVNwJHgbcAY8aYi4wxbzLGfFWNtoqitDJ9ffaxu9tLOZw+bR/Tae/Ovt2p\nV2QF4N574d3vrt3x/Gkgv1hxZltFgcrWBnpsPQaiKIpSjLm52hhfnVgxRhgdtamHvXvhvPO8Pivl\n7qzb4c67lFipNqJy441QS+uKX6y4aFcqVf/KLKW9qMizIiKXichnROR7bq0gEblaRJ5Q2+EpiqLA\n8ePHI+1XbiLu77ePK1bYiXHNGnj0Ubstk+mctWhcWXY9Iiu19tiGRVageZGVdhCjS5FKPCvPx5Yv\n9wKXY8uXAdYANQwOKoqi1JaxMfv4539uH/v6IJWyAqdUu/12m8CCfpx6UKtKo2zWjlekUKw0qHBK\naRMqiay8B3iLMeYPgLRv+4+BS2oyKkVRlCooJi7m5+HSS2HDBvs6mfQWzivVbr/dqKdnxTE/XxuD\nbjbrjdcvVpq1Ana7CdOlQiVi5TzgOyHbx7H9VxRFUSoiV+Xterk00Px8oYm2q6v4QobtTCPESjpd\nfp8o5HJgjL3wrSBWlNakErFyFNgUsv1yYHd1w1EUZaly4sQJHnroobqew4kVfz8SN+l2kmelHSIr\nTlhmMpDN9mKMWUhfQfOEo0ZWWpNKxMrngJtE5GLAAKMi8mLgI8A/1nJwiqJ0PplMhmw2y9TUVNXH\nKhVZMQYeeqjQC9HVtTgN1M6TVbApXD09K/VOAyUqKv9QOpVKtOv7gG7gLqy59m4gA3zUGHNjDcem\nKMoSYNeuXQD0ubriOnHwoI2sDA972/xiRdNA8ahlGshdd79AUc+K4qeSPis54K9E5APAZmAIeMAY\nc6rWg1MURamEsAlnctI+Xnmlty2ZtCv8GmN/OiUN5Cb9+oqVWkZWCiNCweethgqaxlPxfYQxZhrY\n4d8mIs8zxtxW9agURVmyGGMqngxKpYFmZuyjv3+Hi6z416fpBBrjWandcdx193/tjRYrKkBam1hZ\nQbGcIyIbA9ufKSL3Al+r6egURVFqhGtmNji42GBrJ3XpGLFSz6ZwjjvvNAtLFVTD3JzXrE/Eiwpp\nGkjxE1msiMh5wIPATmC3iHxZREZF5Hbgq8Cd2LSQoihKyzE9bSdCvzXGlS67Sb27uzMmq0Y0hXvj\nGw1XXFH5510ULJWy34m3YrZ9v5XTQErjiXMf8UHgIPAOYCvw+8DFwHbg/xhjJms/PEVRlOiUSwP1\n9xemGqKmgZq9QnFcGpEGEoEjNVi61h9Z8aORFcVPHLHyBODZxpgdIvId4EXA3xlj/rk+Q1MURamM\nsAlnenrxejMuDeQiEMXa7U9MTNRjmDXH/d6JhB17ObFSjT8IDGvXVvhRH6mUFSuZQBhIIyuKnzie\nldXAAQBjzDgwDfyoHoNSFEWJgjGGrG9GPnnyZNF9Z2Y8seImaJcGco1zl4JnpVZRIhFbDl4tc3PQ\n17dYMGlkRfETR6wYoFtEekSkN/86kX+98FOfYSqKovh9Dd6E8vDDDy88n3ElPyFMT8PAQOG2YBqo\n3p6V/ny+o7vONdJRm8JVJ1yswbZa7eMiK0G0KZziJ86fgwB7gVlgBttf5Zf51/4fRVGUulLJJBuW\nBqqkdLkaMTM0NMS5555bd7HSiD4rz32uIZeD2Sr/13cGW4f7ajUNpPiJE/R8dt1GoSiKUkdOnYIT\nJ2DjxsLtySRkMqahfVYSDQgZRDXYViL6urvh1a+G3/gN+H//DyYmFkes4pBOFy6B4NA0kOIn8j9N\nY8zt9RyIoihKrcgGZulXvco+nnde4X49PbYpWSbTWR1s61kNlM3a6zQ0ZIXO5CSMjcU/jhNK6TT0\n9LSOZ0VpTTQrqChKxxEUK46evKvO3T13d1uDp+vGWufliRpGvZrCGWPNyIkEDA3ZbZNVNq1IpwtF\nojaFU8JQsaIoSktRz54mwTRPT48VK25Rvk4RK1GbwsW91m53K1bsi2qrujOZQrGiTeGUMFSsKIqy\nZAiKle5uO1mmUvZ1X19n3FnXy2DrjpdMwtq1hkQCfMVYFWHTQN5rFStKGCpWFEVZMoRFVsBb5DDM\n6NlO+Nc8gtobbF0/mkQC+vsN558P998fd5SFtFpkpRPEaieiYkVRlCWDizi4Camnx06ObpHDTkkD\n1aspnDteIgGnT59mxQpP6FV6vFyu0GDrhtfKZmcVNI0nUjWQiHw56gGNMS+rfDiKoii1xUUDYHED\nMzchWrEiHSNW6uVZcdcymYTp6emFDsBx2Lt3L4ODgyQSiYXP+oWJO0ePthhVfESNrEiMH0VRlIYQ\nZc0eZ54Nw02ILrLSKRNkvUqX/WIFvKZ6cUilUpw4cQJjzMJnW0msaNSkNYkUWTHGbK33QBRFUeJy\n4sSJou9NT8OhQ7BmjbetVGSlt7dwReZ2JopYSafhH//R8KIXwbp10Y7rTwMBFUVWgmOAQmHSbLGi\ntCbqWVEUpSN53/vgT/4k/M7f71kBK1Y6JQUEIFJ81WWX+vnBD+DP/gz+9E+jHze4OnUUsRJcbDLs\neGHCpNFixf1NaGSlNamoubSIPA94KbARKPiTMsY8sQbjUhRFKUqUCWXfPvtYau0aG1kxzMy0fyWQ\nHxEbXSkVWXn0UfsYp5rHCb84YuXQoUNMTk6yefPmoscLM9O2ssFWaTyxIysi8kbgX4E54HJgJ5AF\nLgDuqOnoFEVZckQxfUbbxz76M0XBj7l0SSrVGWLFL+LsukfF9z18GMDw8MPRV04OiouuLlNWrExN\nTZU9Xli7fQ1wKH4qSQO9DfhjY8wfAfPA9caYK4FPAaqFFUWpmlp2sT1ypPh7znsRbPneCZSLrJw8\naSMj2Wx0k2yweqdaz4pb5qAThKJSXyoRK48Bfph/ngKW5Z9/Fnh5LQalKMrSwwmUXC7Hgw8+GKnS\nJ4z774fdu73XpcRKMmnv4NPpxqy43EjKiZWJCTjzTHvN5+aiHdOJC+cniRJZKYU7b39/+PsjIyOV\nH7xC1LPSmlQiVo4CK/PP9wGX5p9voEIPjKIoiiOTn/2mXT1xTN7zHrjmGu/1+Lhnnn384+3j8uXL\nAS+yMjcnHSdWXNQkiBOFp0/DGWfYbVHFipe2SSyco1Kxcvz48dAFJLdsAe2CoQSp5J/n94DnAT8F\nvgj8vYi8EOtf+UYNx6YoyhKmVne44+Owbp1w001eaqk7n8dwYmV+PnpkpV3uvEt5VjIZ23n2/PPj\nRVa8BR+7gPmqIyv33uuOJwsly3/5l14ER1EclYiVN7jPGWNuEpFx4InAB4GP1XBsiqIsQWrlV3GH\nOXgQVq4M38cabM2S86y4oJXrQRM/smIfq/Ws/Pu/28e+Pq9tf3e3PX4dF98OpZ6rfSvVU4lYWWGM\nOepeGGM+D3weQETWYH0siqIoFeEmjVpFMA4cgDPPFGDxZOSqgYIr/3YCpcSKK+ceGakssuKEXXd3\ndZEVR09P+BpDzYhitUvkbKlRiWflUF6UFCAio8ChuAcTkXeKyL0iMiEiR0TkayLymyH7XSciB0Vk\nRkS+LSLnBN7vFZFPiMhxEZkUkZvDxqkoSntQy0ljYCD82FHTQAPBA7QBxcSKMWZBrIyO2sdqIivl\nKomiRSwK91HBoASpRKwU+ysaoLKoypXY9NHjgf+NLX/+logs+MNF5O3AW4DXA5cB08DtIuK/F7oJ\neC7wYuAqYB1wSwXjURQlBtlsdsEUWwtqFY73N4Pr7w//b8tfDVQqDXTmmWfWZEyNpJjBFqqPrHR1\nSf6xNpGVdkPFVOOJnAYSkffnnxrgL0XEb9VPYg22D8QdgDHmOYHzvBpbcXQJ8OP85muw/Vxuy+/z\nSuAI8ELgqyKyHHgtcLUx5gf5fV4D/EpELjPG3Bt3XIqiROPhhx8GCO1QGgcnUqKkgaJMFiMjcPy4\nfV4sxePSQMaUjqwkEu2xMknUpnAzMzYtVklkpbvba9hWrWellVDPSmsTx7PylPyjAFcA/uDfPLAb\n+EANxrQCK4hOAojIJmAM+I7bwRgzISL3YAXSV7Hl012BfXaKyL78PipWFKWDiDKxOCECxZuO+TVI\np5UuR/GsrFxpr2O56ht3vYMRqFpEVl73uuo+rywNIv/zNMZcDiAi24E3GGMq69hUArG3BTcBPzbG\n/DK/eQwrXoKtnY7k3wNYC8yHjMm/j6IoNSCbzZJIJOoWCq+VwdbfDK5YZMV/iqUiVowxpFI2srJi\nhd0WP7Li0kDxIit+kenGNjRUXHyqwVZxxI5tGmO2OlEgIqtEZFUNx/NJ7BpDV9fwmIqi1JCHH36Y\n4y6/UgdqlQYCmwqC0pU+TqR0WulyKc/K3JzQ0wO9vfE9K93d0Jfv4pZMVh5ZCbbubyeKrSKt1I/Y\n9xL56MefA38GjOa3nQA+DHzEVJj4E5GPA88BrjTG+KuKDmNTT2spjK6sBe737dMjIssD0ZW1+feK\nsm3bNoaHhwu2bd26la1bt1byayhK2zM7O8u+ffs455xzSPpzKT6mp6dZvXp1XceRyWSKGneL/TcT\n3LxihV0DJ2yhPMfgoK0L6KTIijGmpGclnRa6u73fOargSKchmx1ieHiY8fHxqjwrpVZcbgZxpq6c\n62C3RNi+fTvbt28v2Hb69OmGjqGSf57vBd4MvA9vleX/BfwlMAhcG/eAeaHyAuBJxph9/veMMbtF\n5DDwNODn+f2XY6uHPpHf7SdAJr/P1/L7bAY2AneVOveNN97IFtvfWVEUYHJyEoB0Ol1UrNQTN2mM\nj4/H/mzwhtd5UkrNQ8uXT5BKdZZYgdKelbk56+NxX285weEiWek0JJPeheruNrG6zfoFQauJlTgs\ntVRR2A38jh07uOSSSxo2hkr+eb4O+ENjzNd82+4Vkb3A3xNTrIjIJ4GtwPOBaRFZm3/rtDHGlULf\nBLxbRB4G9gDXA/uBW2HBcPtZ4AYROQVMAh8F7tBKIEVpD4LVQFG57z649VZ43/sWT85uEg5OxsGq\nGWjPSTNI8PcqJlbm521kJZGw1zpqViPoWenvt83cjCn0/0Q9FoRf91o3BozDUhMi7UIlYmUU+EXI\n9gfy78Xlj7EG2u8Htr8G+BcAY8yHRGQA+DS2WuhHwLONMX5Nvw3IAjcDvcB/YiNAiqI0mUwmQzKZ\nrMtE8LGP2fV/7HkK39uyBfbsKR05cGJlqURWjDHMz1vPios8xRErvb3ed9jfb8jlbDVRsYqr4Ln9\nxwIrVkoJ1NWrVzM1NRVtgDWkGVFFpTiVNA/4H2xztiBvyL8XC2NMwhiTDPn5l8B+1xpj1hljBowx\nzzTGPBx4f84Y81ZjzCpjzDJjzEv8ywIoilI74kQ/jDHs2rWLEydOVHVsY8JLbP1CxD/p/t7vwUUX\nuX2KiyQ3YXeKWBERjDFlDLbWxxM1suJPA/kjK66xb1ir/CDB79VrMFf6cyMjI2zcuLH8CWrMqlWr\nGBsboyfEna3Rl8ZTyT/PdwDfEJGnAXfmtz0R2IxdjVlRFGURM1FmNIqLlQ9+EG6/3S5M6McvVvzP\nRWDTJvu8VGo9bhqoXSaqUgbb+XlbISVixVocg61/7u7vt9/VzEzxxSL9tLJnJfh3l0gkFhVfKM0j\ntlgxxvyXiJwHvBU4P7/5O8ALjTF7azk4RVHqw+TkJOl0mhFX20v9Oni640atoAgbx/Q03Hmn99ov\nGPxr0/gjL319du2br3/dTojF1rDpxDSQqwYqHVkpv18QJ1b8nhXwVnGOQxSxop4VxRGn3f5fY0uT\nZ/Ki5M/qNyxFUerJwXx4wi9W9u3bRyqVYmWJW+RqBE01nw1Ohu5Y//7v3kRrjNeZ9clPhhe9KNqx\nnVjplFWX3WRbyrPi0kCl9gsjnbYi0DEw4EVWotDKkRWltYnjWXkPMFSvgSiK0lxSqUrWIY1OuchK\nqWogf9My/2E+9anC7U7UXH11ofgodbfsPCuDg8Ht7bEeUDFKeVbSaaGriwVvS7w0kFm4Nn199gRR\nxYoff1M4XZdHKUecwKfGxhRFqZhqGmn5xUo2Gy4+cjl45BH73Bk/oxAmVjZs2EB3G9/yl2sKl8tB\nMhk/suK8Lslkkq6uLpJJ+8UUSwP5v3NjTIEocSm7VrnMKpham7hZWv02FUWJRVzPShh+L0omEz6x\n3HILfPnL9nkcseIiMH6xMhDnAC2GPw1UrGFbNmtFWlzPSibjpY+6u7sZGLAfLNbMtFQFWJQ+K4ri\niCtWHhSRkn9FxpiRUu8riqLEJRhZCcMJFYh3t14sDdTuJBLFPSvZbGWRlWA10OCgQcTrcxOk1Bo6\narBV4hBXrLwHaOyCAIqiLCnC7qofeMB7nsnYCaX4PCiUuacqmJDc6do4mLKIchGTXE4WIitRPCvu\nO/GLFRF7jOXL4dSp8M8FJ/6gwdaVTmskRSlHXLHyFW20pihKFNwihNXeqT76KNx8s3tlmJuzCxy6\nyh8/y5bBc58b7/guO9UpkZVy1UDg0kDVRVZc87mVK4tHVvyENYWzDeainbveqGBqbeLY3fWbVBQF\nKP0f+/Hjx0mn0+zatYtdu3YV3XdycrJsG/WDB+Fd7yrctmfPLnK5HEeOLN5/ejp+CXKniRVH6ciK\nl/6qxGDrmJycZM2a6YojK61irlVaH60GUhQlMuXuPo0xnDhxIlK32oPBVrQhfOhDheZNEU9cPPTQ\n4v1zufhixXknOqFZqRMHpdJAfs9KuaqhIMHICsDGjfsZH98ce6yZTHmx0qqeFfW1NJ7IkZX8Gj6a\nAlIUpSyV/GceJoRcw7aREXjvewHMwgQ8NeVFB/zEFSvOvDtayTKsLYi79olEYU8aP9msFKyJVC6y\n4r4bWw1U+N7gYLQ0kP844HXRDcOtx9POVVlKbWnvrkeKonQc/gnN3XknEp4wcRPw/Lxdj+a66wo/\nHze10GlixVE+DSSxSpez2fDI1eBgcYOtH2MMJ0+eXHg9NQVDQ9574ImTrq4uNm/e3NBeN+pZaW1U\nrNOxGPIAACAASURBVChKFWSzWXbu3MlsmNtzCVLr//DdXJVM2p+hoakFseJSEsHoStjdetKFaEJw\njXvdOjftjjO+ljfY2udRxYpLFQ0O2uUYXN+coaFokZXp6ekCj9L0tCdWHMuWLQNUOCiLUbGiKFWQ\nzhseJiYmmjqO6enpgrvWVqKaiccvVtzk6iZWl0YIipWwibe/v5/169eHnuP3fq/i4bU05cRKMlm+\n060f12Cuv99+Ke57LRVZ8X/3wb+DqSnP1OyEjxOVrS5WdDXmxqNiRVE6gP3793Ps2LGmjiGbzS5M\nMtUYEMPSQC6yAoVpoDCxUmxJn8Ei5T6veIVdmbnTKGWw9bfbj+JZAc+I3NvrHQfiRVa8McCOHYuP\n5dYcaqZYifK3q2Kl8ahYURQlMqUmkcOHD9f8fE6sDA0tjqwExUp/v60euuqqmg+jrfCngcoZbKN6\nVowxpNNw8uTogsBwDA7aKFfYOpj+vxd/CmjvXvvoVnB2+7VLZEVpPCpWFEWpCaVaq0chbILqyjdX\nGBoqjKzMzsIvfmHvzN32K66A886rf5OxdilbLdZuHxYvZBglDdTfv5rjx1ctCAyHC1hFMdk6Jift\n4wtfaB9bQayoQGptVKwoilIT3B19kLiTQFga6Ld+qzCyctNNcOyYfd9tdxqiXcREvSkVMclkKGi3\nH0VnOs9KWBoI4MSJzILZPJvNkkqlFvYxBv77vz1R5NrwBD0rrZAGUloTFSuKosQmbDKJIxKirsDs\n0j/Pf35hZMVlnNzaMlDcq7LUiFINFIysRBErrsQ7LA0EcPy4VTNTU1McOHCAvS7XA+zZY0vMb7rJ\nvnb2FddGpd08K0rj0X/eiqIUJZfLcTrfQnZycrJkqsf/n3yp//BzuRwPhbWfzeOvrMpm4YwzCkXJ\nz34Gu3fb5/70hc4xhZTuYCuxS5eDBlvH8uUAhuPHvW1z/mWygf377eMPfwg/+YknWlassErHiVf3\ndxNVzCpLBxUriqIU5cSJExw+fJi5uTkOHjxYskV+sTRQkDgTkX8NG/d4333e+729nolUxYpHOYOt\ni6xELV02xhRNAw0P23TcoUNSsL97/N734MMf9o51/fXe8zPPPJNzzjln0d+NelaUICpWFEUpihMW\n7j/yWpho40wKwQX3wPNOgK0mcYfTNJDF326/dJ+VBLlcLoZnxR43aLAVgQ0bDE7HBr/fz3zGfu7C\nC+1rJ6A2bLBjTSaTWgqslEX/eStKFXRyftsYU3LV3CBRDbaVihX3uG+f9/5FF2lkpRjlm8IlyGaz\nkdNAwciKn7PPnuLAgcXbjTH09dkvZt06b7HIpz+9MNoyNjbG5s3eYoi9YSdpEOX+TW/atKlBI1H8\nqFhRlBYjl8s1LCR94MCBgmZdtaLY+EtFVsK223SFfR5cGwjgqU/1IitujkloiKXsqsv2uibJ5XIV\nG2z939dZZx3ilK922Z8GWr/efjGveAWsXm3f37jRM9cG2bRpExs2bCg/oBrTyTcenYD+q1aUFuOh\nhx7i0Ucfbci5pqamatbMzf+fvV8ABddNiuNZ8a9hk182JnBOWLXKPn/sY+0EPDIyEn3QHYj7HoqL\nFcjlpCCyEqfdfljQY/VqOH48HXIu63W56iq76ORv/IbdXmodpp6enpJrOdWLVatWsWbNmqZGdZTi\nqFhRlBakkQsjRoniRI30hO135MiRio4FhWmg7m54ylMW7zM6CrfcAk94AqxcuVIjK3mKiRW3rasr\nGdmz4kSHf9kD//d49tlw+LBhz57F6wGNj0u+YgjWrrWPQd9LK5BIJFi5cmWzh6EUQf9VK4pSMf4W\n6lHD6JWKFSieOnDN4xRLqWqgXM5GV7xqIBPZYOsXGStWrFh4ftllIGIWSsodmYw13p5xhn3tGsgF\nKpsVpSwqVhRFKUo5AXLA56rs7u6ua+kyFBcrike5aqBs1jVgi9duf26uMAU0OjrKxo0bAbt9xYoc\nwbU0jxwxzM8LbsHrxzzGPmrxjxKXrmYPQFFaAdsoK0tXl/6TCMNvmKzVsfzs328nzVWrCqMkfoMt\nlPY6KIUUSwM5rdjV5cSKbRJXjvn5cL+KY+1aw7Fjhd/v0aMGkAVj7fnnw8c+Zg22ihIHjawoCrb5\n2a5du5ZsYyh/11hHqWtR6RpAxaqB3vQmeMMbDC9+Mfz61952v8EW7EKF55xT9jRLnlLVQJmMwZjE\nggjs6oqWBgpGVqAw8rZmjeHo0cL3jx2bxxjwe54f8xgtM1fio2JFUWisobUVSaVSodvdZFSNwTYu\nhw55z4NpoIsughtuqPoUHU25aqBs1mCM+NYGKi9WrMFWQhrCFYqV++8H35JAnDgBvb2iETGlalSs\nKEoVtHIkpp5jq+bY5T7rdJMxcPfd3qJ3Sjy8qp3C7Tay4hcr0UuXS6WBLrjAnsjfTv/kSVi1SjSS\nolSNihVF6UBmZmZ48MEHGR8fr8nxggIjl8tV3Xq/GC7I5RbG86eFouDu9geWqBvXdRJ2Eang15TN\nGnI5wdmzolcDlRYrT3yi/Tl40JBOwz33wLFjVqx0Eto8rjmom1BR2pywSIVL6xw5cqSgxDQKUVNi\nYWKlFtEcV9ZaJy20JHCeFbDX0e8bD0ZWynlW3Hca5lkJft+/+7tw++1w7bXwwAN225VXVvObKIpF\nxYqi+AhbD6fVCRMI1fwOfv9K0LPiP1ecdYPi7Oe0UiW9OFo5Ldco/J4VCIus5PIG2+pKl4FF1XMX\nXABr1swtCBWAc89d3I12/fr1+l0psdA0kKK0OfX6T7+S45b7TNj7wcnUaSVtHFYZLg1UXKzYyEph\n6XL5487PL+4829XVVdAxWARe8ILCL+75z188zQwODjLkOsQpSgQ0sqIoAXK5HCLSNhGWuJGVStYC\nqnX0xs9ttxW+dmLFrUVz442LP3P55V5X1Ci0y3dZK6KJFfs6Tgfb8HWBVnP06NGFv5GXvMRGYJ78\nZCteVq4UTp+u/HdRFFCxoiiLePjhh0kmk/yGW3WtDSk1OZ+u0cxRaUQn+LmgRcaJFBdZCbPcvPOd\nFZ16SeDvYAuLW+5nMia/kGE0z4pjfj58MckVK1awYsUKdu7cCdimfi9+sfd+cK2mx7g2tooSA00D\nKYoP17QsEyWJ3yJUmwYq9fm4EYnKUkeFr92ld2Il7iK4Sy2KEqRUGsgYQy5XaLBNJEp7Vtx3mkrF\n/y7cePz0teIqhkrLo2JFUdqcOCmaWkVDannsmRm7crKjWrGiFE8DWbFCQQfbWpUub9y4kf6Q7m+6\nCrZSC/SvSFEq5OTJk+z1t+tsEn6RUInBNe45qt0vuM/MjF0TyJHJwPi4FSsihWW39WLdunX1P0mD\nKFUNZPvjQC6XoLu7eoOtn/7+fnpD1Ey3Lomt1AD1rChKhdTK+1EtcSIrcVY8LneuSoTP3r17F/V9\nmZkpXKDw5El45Sutgba3tzHryHRSA7lSaaBcLkcuR4FnJZnMRSxdDjfY+vH/fY2MjDA1NdVR11Zp\nHhpZUZQ2J45oiLtv3LWBypHJZBYJptlZGBiAL3/ZNhCbnLTbDx0KTzuE3b0rhfjFiv9ye2LF67MC\nByM1hSuXBgKvUeDGjRtZvXo1mzZtoquri82bN1f4myiKRSMritKBNMuzUmy/X//aGmnPPz88DTQy\nAkNDMDzsVQOB+lUqIVgNFB5ZSSz0WUkkonULjmKwdWIl2CwOYHR0lJ6envInUpQQVKwoio927KoZ\nTM2UqoapNg1UKX/xF/bx619f/N7MjI2sgPWn+EuZw+wO5b4jrQYqnQZynpWengTGdNHV1VUTz4o7\nPoSLlVV+Y5KixETTQIrSgRSb0GsZWankWJlMeGTFeVaCc1xYIUktzb6dSjnPiqsGWrZsGYmEqZln\nxZUlL3XBqNQeFSuK0ubUy7Pi57hbArmC4/s3TU0V7pPNWo+KP7LiJ7l4WZklLUKiUK4aKJeTvMHW\nlhV3d+cwpjD9FsQYSKfLp4HWrl3L2WefXeVvoCiLUbGiKC3EXJ0XxGnGRO+fBINi5fWvtyXKKlZq\nR6k0UCaTwZgk4ImVvj6bupmZKX5MF3kpJ1as+NFSZaX2qFhROoZ0Os18qdvDFmdmZqaivi1h5cS1\nmNDj9mwpZrD166+gWDl2zD66Ne2iiBWlPMaY0Hb72Ww2L1bstU4kEvT22h2mp4sfK5220RU1PCvN\nQsWK0jE88sgj7N69u6pjNOuufWZmhkcffbTm508GZvu43pPqW/nDLbd4r/1ixX/oCy+0j8Gb8kZF\nVjrJY+FVA9nr5I+sWLFiFWEyafft7bX7lYqspNP2UTvlK82iJcSKiFwpIl8XkQMikhOR54fsc52I\nHBSRGRH5toicE3i/V0Q+ISLHRWRSRG4WkTWN+y0UpXKyUcoxakAjxdixY/D7vw9f+5q3bWLCG4Pr\np/Lyl3uLFdbCYNtJwqMS3O8vYv+mFntW7EV1QtBGS0zRyAo4sVLeYKso9aIlxAowCPwUeBOw6H8i\nEXk78Bbg9cBlwDRwu4j4i/ZvAp4LvBi4ClgH3IKitDC5XI60u22t8HOt5OHwj+Xee21vDj+PPgrf\n/7597lJAl1zivR9sdqqelfi4XiaZjFUfYQZb8K6ti5aUFyuaBlKaR0uIFWPMfxpj/toYcysQdlt0\nDXC9MeY2Y8z/AK/EipEXAojIcuC1wDZjzA+MMfcDrwGuEJHLGvNbKEud+fl5Tp48GeszBw4c4JFH\nHol9rn379oV+rpxnJcpEPz4OH/946eqQsGMFXx8+XLh/d7dNCb3rXYa5OThyxG5f44t/Ll9e+Jly\nnpWlHkUJo6+vDxEJTQMZY8hm7TXr6rLXr68PVq8+ztRU8fpl9awozaYlxEopRGQTMAZ8x20zxkwA\n9wCX5zddim1w599nJ7DPt4+i1JX9+/dzLB8uyGQy7Ny5k5lSRgBg1t8BLQJzc3Ps3LmzoGqo1pGG\nm2+Gb30Lfvaz+J8NmmcvvhiWLbOvN260jyKGyUmbEkokvPfBSwc51GBbGSKCiDXO+g22dtXlwshK\nby+sXHmSEyeOhh7LGWzdvorSDFperGCFigGOBLYfyb8HsBaYz4uYYvsoSllqNfG7FM3U1FRNjudI\nBfMqMYny+zmT6y9/Wbx9fpC5OetN8WuvVAr6+5MMD9vXLoLixMrsrE1B+IMjbl+HipXKSCQSiIRH\nVsLECsDMTHHflBpslWbTDmJFUepOWDohrnBphJcieI7JyclYvVmijNEt3/Kud0U/1t13w3XXFX5m\nfh66u3sXIicvfSlceimAYWLCihX/assAK1fCy14G73ynfZ1I1CbN4zqrnnnmmZx11lk1OWYrUyoN\nlE4n8mXLdltPjxWMs7MzRSN9arBVmk07rA10GOtjWUthdGUtcL9vnx4RWR6IrqzNv1eUbdu2MRy4\nndu6dStbt26tdtxLnuPHjzM1NbUkJodmcfDgwdDt1QinSnp6TeT/1R065J03nYaeHuENb4AvfhHO\nPhv+9E/hzjsNU1PhYkUErr4aji5kJAawfvpohP3ew8PDDOUbubjHTsdGVmz+Z7FYkQVBatNFNrqS\nStlU5rnnnrvoeJoGWtps376d7du3F2w7ffp0Q8fQ8mLFGLNbRA4DTwN+DguG2scDn8jv9hMgk9/n\na/l9NgMbgbtKHf/GG29ky5Yt9Rn8EufEiRPNHkJZ0uk04+PjNY+KNMv4GbeRWxiVDN2KFVPQq2N+\n3t61n302vOc9dtvAACSTNg2UShVPKzifRch6eIGxyqLfKXjtwxbVCztOJ5HJZJiePgWsWSRW5uc9\nseJwYqVYHx4VK0ubsBv4HTt2cIm/lK/OtIRYEZFB4By8SqCzReRi4KQx5lFsWfK7ReRhYA9wPbAf\nuBWs4VZEPgvcICKngEngo8Adxph7G/rLKC2JS5X0Bv63PXz4MDMzM/QHb/Epv4JxFFq5zPb0adsI\nbN26wu2uCijOr+4iK0Gx0ttbeBARWL7ccOKEPX+wVNmxdi285CU2daSUp7e3l6mpqYW/12w2SyIB\nIl5fFVgcWfE+X9hpOMj8vFYDKc2lVTwrl2JTOj/Bmmn/DtgBvBfAGPMh4GPAp7FVQP3As40x/uLK\nbcBtwM3A94GD2J4risKePXvYs2dP2f1aWVzUAv/v96Y3wRveYFMuO3d6+/hLlufmvP1TKbj9djtp\n3XQT/Oxn3nvj41aIzMyYguMEJ0Ww5cn/+q/W51Js8hOBP/gDGBmJ/zsuRUZHR9m0aVNBx2LnSQlL\nA7nr7sRNX19pseLWBlKDrdIsWiKyYoz5AWWEkzHmWuDaEu/PAW/N/ygKp06dYtmyZZHSAJ1CnD4r\nroPs615nxcYPf2hf+ycttw/A5z4H//Eftrz4u9+FEyfg+uvte65nir9YKSyyAjaycuiQfd5h2Zem\nISILzeAcNrLiiRW3dlOpNFAxnMFW1yhUmkWrRFYUpeYcPXqUQ25WrIBqoiyt4oGo5HfwUjmmQKw4\nQeLWWly/3nvv8GFYv94wM2MW1vyxYmXx8Zcv7+zoVStwxhln5CMrZkGsTOdb1KbTiUVipVxkxZql\nVVwqzUPFitKRuEk65++IFWH/Wp47znEblX4KP0/htp07YfNmGBs7zOSk997+/fbRNel1qYFMxgoc\nJ15cGqlYZGVoSMVKvbGly/a5EyuuLDmVGowVWbFdb8ubnRWlnqhYUTqaVCpVsgV+q0RAasGPfwxx\nFp0O8RRjDBw6BBddZF+fPu0ZHlw5sbucTsi4Sc4ZdW+4wU6Q2Wz1kRVdtLBygmJlfn6ewcFB5ucT\nBaXLUD6yksuFLyqpKI1C//yUjidKF9liJZtRGR8fjzWmSpkvsmDPrl3woQ/ZH4jmWfGLFTd5zc7a\niWks3/fZCRK/SdNVpB8/7n0GYMOGSURy3HWXJ2AGBhaLCX97faU+iAjJJHR1ZRfKjo0xJBKJ0PRc\nuWqgXE67CSvNRcWK0pFUmlapVTqmnNG1Eqanpzl16lToe7/4xcKZI40LbOrmqU+FK674/9s78/i4\nynr/v7+TPWkySZM2abo3tBUQWVqgInBBRH4gKv3BRRYvV7gXvQJ6L4qIFzdw30D5gRcUFzZxuSqi\nIot49QqiLPVSL4WWQkrbtOmSJs2+TZ7fH9955pw5c2YySSeZNHner1deM3POc7ZnTub5nO/2qMtm\nZMQLqLWl8a01xT+QWcvKH/+oQsVvWSkoUFVjBUxFReo5uIySyaGgAJqamgkWpQ3L0iotzRxgq5YV\nZ8Vy5A8nVhyOHDNR8SeZJj20wa89gWKv6c5lZEQHp8MPhxNO0GX33w+XX67vo1GYPx9+8xvdPihW\nioogFjO0t3vCZM4csKWSNm/WZRUVqQPcMcfAySfr++OPT3tJk8p0dScVF5MiVgYGxitWcn9+Dke2\nuNvPAWgg6rZt2xgeTj9N/HQgG/dIGLFY+kneJotM340daKzhZbTr9Fs+1Etm+NGPvHaVlbB2Lbz0\nklpg/N4nY9SKIqLF4Oyxy8rgH/5B93/zzd7+gyxYANdcoxMfvuUtma7YcaAUF3vfj/3u/ZYVK9Iy\nuYF08kPnBnLkFydWHAD09vbS29s7ofM9DAwMJNInx0pnZ+eYhNR4RUlY21gsxubNm0ftm7Fk/rS3\nt+d0okQ70LS3Z+cGuuUW/VxWBsceC0VFQ0ntZs2CefO0fUdH6kA2bx6AobnZs+aUlUFhYbIYmjUr\nvcWioMClwk4UVoQELSsiQn//+GJWnGXFkU/c7eeYNLZs2cJ2m/86Rnbu3Jl20r6xMJ65c6xVpddf\nSz7L44Ttr7e3l927d48alJsumDYM+/S8ZYs3r04mnorPmFVRAXV1cOyxyUKwtFStKyJqeQkOZA0N\nuu4//gO+/W1dVl4Ol16a3C7MspJLpqv7JleEuYF6elK/F+sGSvfvoZYV19eO/OHEygHS09NDZ2fn\n6A0d48bWSpnIWiQTVWcljGyvp7u7m927d2dVK6a/X60hXV2GV18d+7kFg15FdH9g2Lw52Q0EWsXW\nBvPu3atP5kVFUFpqkuYaikbdAJdPwtxAvb2eWLFiLxrVjC9/EUA/xjg3kCO/OLGC/hN3hfyXbt++\nnU2bNmXcdvv27QdUJXUm0tLSwkb/ZDSjYC0bkTHYobMVH5mezCdKHNn9hs0Y7Kezs5P29vbEvZnp\nXPv7Ixx2mIqMdeuSLTth7rOVK/W1qUlf585NPY9Zs3R/t9/uFYSzWUKzZsFDD3ltbTrywMBAQvic\neebUdvNUzoAc6jA3UJhlpbZWX9NNlO7cQI58424/YP/+/ezYsSMl26Knp2faTGy3a9eutGmvk002\ndU/8WMvCWMRKOibbOpNpmV98ZHI/RSIRhoeHM8bM9PcLc+dCY6Nh3brkddu2bUs6zsiIVqk99VTv\nafmKK0b4zGc0fqW+XpdpXIMBhNtuU+FhB7VZs+DQQ2O86U3eZ9AgYCtWSkqmtpsmGo3m+xQmDH/g\nbJgbKDjbtf1ebe0cP7aCrRMrjnziCijjDQrZlmY/GLHxEWVlZZQeYKGLrq4uiouLKZmk+eLt91Mw\ngXboXIiYsZbWTzeQG6PWkdWr9X4sKCgYNTC5ry9CaWmMI4+E555LXjc05AXPGmN4+GF97w8fKigw\nHHkkHHmkt0xE/4zR16Ii74m8ogL27NlDXZ1+9hsp/GLFkV+KirKLWamt1dmwX3wxfD8uG8iRb5xW\nnmG8ZmehOwB27NjBli1bDvxkssSKyFw8pY8nG8hPX19fVvvI1GY0sbJuHdxwAzzxRPbiua9PKC2F\n5cu9GiepbXTUam3Vzz4Nk0Goe9dRVUVi1l1rSbFixS9M7FN7JstKriwuU9lyMxXwu4EyxayIqEsw\nXfy7EyuOfOPESh452F1MU/n8J6KC7dDQEFu3bh3VnZZtxlE6N9Dtt+trpiJdQXp7hZISqKsz7NmT\nOpliV1cXW7dupbe3NyFS/MlNmc/ZG9CsWLGl+mfP1tehIc9aZ91IYzHgTZaVbqYRjFkZHhaGh8Oz\ntMrLU60wFrWuOWHoyB9OrOSJjo4ONm3aNKGup+Hh4XHXNcmG0YKPD4TBwcGEJWAyMnWyOYZ1R6Wr\n9zLWmJV02Gq03/iGtyxzILC6gVSsqJk/mGrsn4XamvpPOSXjacSP66WzRiIa5wI2G8gb9GIx7/xs\nNlBp6YEPcLmsRTOT8NdZ8YteK1DHKlacZcWRb5xYYfJ/4GKxWCLdeSKP3dLSMu66JvmmubmZrVu3\njnv7XPRra2sre/bsSXwerztq586dSTVVxnJuH/zg6O2Hh1UslJZCba22tfP3tLbCV78K997rjTQ7\ndsBll8G7353NGWiALagQWrUKHnzQc/VY64m/wO+JJ8JVV2kZ/2z7yj21Twz+AFtjTEKs2Bgjf7+X\nlSVb2yyugq1jKuACbPPAZl9QwUSKlelSOn8yxGTYMfr7++nv709kjWTKSmpv1wybNWtS99fZ2Uln\nZyfl5eX09vaGFozzv/fP07Jliw42wblcks8TjIlQWgo1Nbqso0PdMZ/+tIqTBx+E005TK0l/f2o2\nSDp+8AMtCrdzJxx6aOp66w4aGUmezfmtb9X3EyFCSkpKGEhTbrU82wubIQQDbK2hNSxru6zMWVYc\nUxdnWXFkxcDAwLQQP+OpYGtJJ1b6++Ef/xE+/3mt5urfh+2zgoICtm3bxq5du0YJvk2NVXn55dT2\nzz0Hv/2td/yREY1Zseb9nh6DMWpZWbAA+vo0/dQORlZkjMb8+YZDDhHe+EbP9ePHEyvh26dLNx+v\niFmxYgWLFy8O3U9NTQ2zbOSvAwhzA2l/jVWsuNRlR76Z8bdfW1vbmMqop8MYMy4LwMHiY9+yZUtO\nMon8dHV1sWvXLlpaWjLG7kxkH2UzaAbPLbjNo49673/5S/B7r/wCJ1MJfos1GFx+Odx1l75/6aXk\nNhs2aLaQnd9nYEAtKyUlUFnpZXw8+aSKiCOOUBHU1uYNRgdqgKiJm3CsGyjd15dry4qITHiG0XQg\nXZ2VoBvIT3m5rg+7PY2BSMT1ryN/zHix0tXVlVIMbjxs2bJlXAGnB4tYgdy7lXbs2EFHRwfd3d05\n+Q78jDWQNtP3EBRpwUHRxodYXngh834zuYFsNzQ0qEtnzhx4+WX/tnDvvd7nWMwOMBqzYi0r3d3w\n5S/rezvpYHf32C0r6frFWkxGs6w4YZFf/G4gY0zCDWQNUMGYFQ3WTt6Hi1lxTAVmvFjJFWOZdM5P\nc3PzmDN2jDFjOt5YBNFog0g+rEcTJeiGh4cTGT7JxwsPNPRj+98Y+NnPktdpDImXfZO6f13nr0hr\nl1mTvbVYVFZCZ6dJfC8vvgj/+7/evvbv12VFRcL8+VBWZhBRN5Atjd/UpFk9vb3edWUrViD8nvBn\nmwAcdVT2204WB9ODwERRUpI8QeFoMSsAYVOdObHiyDdOrEwB9gUfzUdh165dNDc3T9DZZCYfA0CY\nJSIWi7F3794DSm195ZVXQl2AP/4xXHCB/sB//OPJKcSg9Vaam5sZHBxMsaqAxocEjxdWUyXMmmQn\nlrbF1kpLk4VTMK60vR2am6GpSd1AkYg+NXd3G5YuhdWrYeFCAM0ECbOsVIcFowTONYi/mNhdd8F7\n3xu+/WhTJFRVVTF//nxnackxfjE5MuJNRNnTIxQXhwds23sibDJDJ1Yc+caJlYOQ/vjj90QIhz17\n9iQmGdy0aVPKJI3BYwY/b9y4MfFnaW1tzXlNlj179tDW1pYoJR+ciPJARMwzz+hrfz+sXw+PP57c\n1m8tseLBzpEDyWb0sPPIFJ/z8staKbahQT+XlnpPw5D8HjQu5Xe/g717JXG8qioVOP39OgCVl6uo\n6OsLj1kpDhm5li5dCqgwCyvYlhzYmn4gG02ERCKRvAXFzgTLi/2e7b9Hb2+4VSWsrR+dyNAJSkf+\ncGJlBnAg1Vw7w2zCY9x3Z2fnAQ0MYZaVYM2TsU6OONqxIHxStyD2ifXMMz3XTVjl2cHBwYTLVYjT\nCAAAIABJREFUKVMcS3c3RKPebMWlpWqpseutWPnc59SKYoN79+zx/pUrK9WyYsVKUREUFqa3rIwm\nKMLESraTSrpy+/nFCpCODi9mxS9WgjErkN4N5LKBHPnE3X4HIfYHJp8umXSfc7XfXLcfy3a2yW23\n6Wvwwd+/DytWolF1H1VWpk//tGSyrPT1JVs9wiwrs2Zphk91tTewVFd7g461rPT12Sqyuo2NWSks\n9MrmQ+aYlGzWZ8KJifxiA65teFRPj6S1rLiYFcdUxomVg5ixzvI7WfsaDzZoeGRkJK0g6uzsTASl\njiaa0p3nDhsUkvFc9HXDBn3NNMeNdQNZT4qta5HNRIagMSd/+1vyJHN+sVJWlixWOjo88XTppfra\n0AD3368pvcYYKis1wNZaVkBTmq2ACQbXjkdQZLtNthaYAz0OzAy3zlixYsUWUA5aVvxEoxqg7Q/g\nBpcN5JgaOLHiw/3YeWSb4ptNn2Uz4BhjaG5uZufOnRmP0dbWBnjWibDjDw8Ps3v37tDjhGX/ZOLw\nw1PjRMIsK36x4g+wDcNvWfnUp+D660lMjtjTk2pZ6e723EAbNsCKFbru7/5Og1tvuw0OOSS9ZQU8\ni894xErY+sLC0Ytf19fXZ9UuE0VFRSxYsOCA9jETsd+Z37IymhsoEoHDDtP78dlnk/fnxIoj3zix\nkmN6enrSDogDAwNpy4R3d3cnBrGRkZGsYjDsbLoTIbJGi1Xxn0PYez/ZihXQ4OEDtQTt27cvEYSc\nLcPDWmRt3brkolhHH60DfDrPjRUrNqzDpor6eeqp5MJufrGybZvdj2HdOvif/0kWK01NsH27V2iu\npQWWLfPW19SoS8fvGrSWFb9YmTUrvWXFks71M143UEXYbHmB7e33OG/ePOpsCtQY9uPIjL2XPDdQ\nessK6FxUQGKyS4sLsHXkGydWcsz27dtTMmhAB6gtW7awZcuW0HUtLS0Ja0BraystLS2jDtqDg4Ps\n2LGDvaNEgo5n8G9tbc2qXa5cTNlWsA0G24btu8gXkBGLwauv6vs//UkDWMNYt07L1599tsEaAy6+\nWEvVA9x0E9g5DTNZVkpKVFj4BesXvgDXXutN9mevtaXFW/byyzqPDyTPiGutKBs2tNLXp4NNbW3q\n+fsru1ZVadzB8LDfDaTbdnXBrFmRlG39r2H7Hm1Z2PcwFhdOUVERtWEXNg5sQHBVVVVO9ncwU1Cg\n95PnBpKUGCw/NTV6L/tKAAG2gu3EnafDMRru9vORHEvQPu79hFV69U9emO64djv7ms7FYa0GdtAb\nzbWRS8uL3VdHh8Za5Oo49hps3EU6hoeHGW1qAxsnMTICa9fCJZeo++SLX9TZgCMRuPnm5G2s18gY\nFSVnnw3vepcnHP77v3X2Ym3jHdsayqw+OuYYTSVubd2VOAfLl74EF16ok/61tsIjj3jrbHwMQHm5\n92+pcyga9u/Xcvng1WDx4xcG5eXQ3q7n6Les9PXpIFRSMifttpkYzdqSDQcawxIk7DwKCgpYuXJl\naBbTTCQazd6yAhq47ZskHFBR7dxAjnzixEoa0sU8+ElnfbA/oP39/QwODjI0NJQTwdDX10dLS8uY\ntws7dnNzc9rzz2Zf992nvu3HHhvdDTQyYmhuDp9zBNQS8eUvj2A1XjrrjTEan/GVrwykjVkxBjo7\nR9i8WS0Xlkcf1e9k3z5obNzORz+afA628JqItrHmc79LZvt2eN/74NlnvWN2d6s1xY6ZCxaoS8dm\nBFmBAfDnP+tg8dxzWkTtgQe8ddb6A8mDQkmJCo7OTm9fmSwrxhjKyryMDmtZmTVLj93ZCbNnjy2O\nJEwQ5Fp0pGMs/zcHGh8znfB/Z9FodqnL/vZ+y4oNsHXd68gn7vY7APYHbaU+jDFZT/wXVuXUvxzU\n8rDVP0Me6X/IjTG0trZmtNAMDg4yODhIQ7z6WLaDgnU57VLDAeeeq1aC6ur0rpznn4dPflItFRdf\nnLyus1OtHZ2dMU4+GQ49NL3VpKVFrREtLTHOPNOkVOE0Bj77WXjoIcOcZONBUsBgVVVPygzC3d3J\nZm4rUvwuma4u/fvKVwx33qnL/vpXDcL19u1dV3m5znoc5LHHvPcnnqjuqeef1+OffLLWbPFTV6d9\nbPcdVnA2aFmBZMtKdbVh06YCdu5sZPXqktBtcx2zkmm7XNdZKS0tTUyu6EimutoTH93do1tWgmIF\nYGjIi8tyOPKBs6z4yDb+IpNIsYwl6ySbzJtMhcSCDAwMJAXIpgvqBejt7WVwcDCjlcV/HFue3lot\nRAzf/76+f9VvHoizbRt897v6/k9/Sl4Xi8G7363vCwpG2LkzPJPHHv/pp23bGHv2pMauPPywVp8V\nSe6X2lr98a2ogI98BM45x4s/AXXVPPaYuleqqrTfrFgJ8+8PDJjE+b/wArz+9d46W9Bt/3699rvv\n9qwulqeegtmzVahcdJEev6tLXUgf+pA3c7LllFPgiSfU4lNaGp5K7S84V1aWXFQOoLJyCGOE3t5y\nTjllfEJhvG6gBQsWME9nUxxX5lEm5s+fT11dHQsXLkzZ1lpawir0ziSsZQUy11nxtw8XKy7A1pE/\nnFjJgmDqbGtrKwMDA0k/jrt3q5vAkilgNIgtGZ/tOXjHHN1VBYQG/Fq2bds25nmGBgZ0sL/8cli8\nuJ0XXtgWOrFiaytceSXYmOKeHuumgZ071R1iKSiIJTJeghM72mtftw7mz9e2+/Yl90d3dzfr16t1\n4rHHhjnmGG/d9dfr6+rVcNJJUF+vLhXbpTfdpOe2ezcsW6YRuFasVFXBZZeRtL99+9Qs/vvfaxCr\nfxK/OXOgqek1fv1ruPFG2LgR5s6FG26AN7zBizc5+WQNul2wwLPeXHNNeH+vWmVob4fvfU9FThhl\nZWWJ+1FdP8b3HkZGVMy87W1w6qnh+ziQANtMVFRUpM3oCd7XYxUrBQUF1NbWhrqliouLWbZs2YwM\ntPX3o7WsDA3p32huoLCYFWdZceQb5wYKIZOFxf8E6w8GveoqTVl98EH9AcjWsvLoozqgnHRS+vPo\n6uoKTSUea82Q8RK0JH3zm/q6YgWcemoX27cTKni+/nXv/fLlmvHyznd6y848Uwf373wHbrghhm86\nIbq7kyft6+rSeXouuQSef94kAkiNMYl+6O7WOXoqKjoSrpLrroMjjujjO98RrJegqkqtIj09+vrH\nP+ryf/onXbdhAxx/vHfsc87xrDFPPw3f+Ibh2WfV0lFZCStWRBLitKJCg2jvvlu3nT0brr5a61cc\nfbQKmL17vSwj25+7diXHx/hZtMgTvmEZ2Y2NjRT4Al3sXEDgWVZGRgwgvO996QVBVVVV6KSaQdeN\nP/NorGQzV1A2Ql9Esgqg9WeGzVSiUdi0Sev1QLIbMV3Miv/ByxjD8HD45IcziYqKCrq6uiYtXsuR\njBMrPkZzA/kn5wtiB5G2Nh2IRhMSQ0Nw3nne0/3cubBqVfj5ZFN1taenh/Lycjo6OrK2uGQiFlOL\nyIsvwtln70pa91//pa/z58PSpeqiGB7WALwHH4TNm+GVV7Qvios1XmXv3mTxAvCb36iLA+Dww0e4\n+2741rc0+PT663U24Wee0X648UZtd8IJcPvtammw2Nic7m6IexsSwbo64zDMnet9t5pho0+br72m\n38H3v+9ZLdJZHubMgbPOgltuMXz2s3a/qQPsCSd4YuWSS1SoWOz4as8LNF00U7jFggVtXHUV3Hor\n7NpVDKRasUAHnqGhIYaGNiZEirWsrF07wq5dcPrp4cdYsWIFIpIQK7nI/AmeWy7bLV++/EBOZ0Zh\nLSWati8Z7zVI7waa6WIlGo1SVVXlppDIE04ixuns1NLnsViqaNGn0lREhP5+jYOw/OUvdpv0T4dP\nPw3f/nZydsxHPgL792fvOvIzNDTE9u3baWtrS5tyfd998I53wK9+lT4rx/KLX2jK79VXq3gwBn7+\ncw0CtRpsx45GZs2CQw/VWiOvvqrt7rxT3SPbtmmGzRlnqPsjXW0HO5Afc4zu+Fe/UrFjDTU332zo\n7zds2qQujMZGmDPH0NamQkqf+lSZ2HlzgESAbZh/Xr0CJpFhU1yc3r0SRCQ5Jmb37tQBtrFRY1Eq\nK+GQQ5K3P/98jdN53evSHyNMNL/1rfra07MobftIJML+/fuTBhX7vrLS8OEPS9qpA8byAzxa25qa\nGhYvXpxk7Qlue6ATHB6IdWemYcWHNc767/VssoHAuYEs7p7LH06sADt26ABy1FFaS8M/WGzfroPb\nvfemumFEhAce0LgEOyj84Q/66hcrP/85fPzj6tb45S81Y+Xhh7392OyPxx/vzSKoVi0el12mRcz8\n7cJiX155BX79a/jRj/Tzt76lcR2bNoX3xd696pbxs3+/xkt84hO6PcA11+io19Sk175hg/WLJ5vd\n7WBtRYM/vgO84NRlyww//rGm7d5yi4qCRYs01uPss0cwRt0oAHPmjPDAA/DRj6qw8buBrFi56CLt\n57DMGQ2C1dolXV2jZ0cECQbwhg3KF1ygAnFRQFssXaqCZTy/eZ/8JDzxRPpiF9Y87R9U7HH89+NY\nf3DHmsEjIpRmmlApA7MyVSxzZE0wZsVaVozJbMWz7XfuTI5bcQG2jnzj3EB4T/FgWL9+kJER/afc\ntEmDHvv7DZ/5zE5++lOv+NfAwADGGDZvVvfNpz4F99yjAsIfy7Jhgw70AH//98nHPftsHVwvvFBd\nIrfeqvEJdlAOipU//xk+/3nv8yOPaODn7t36pB6cBHD9ehVJYfzhD151VNAfso98xEuP9fOVr3jv\nf/MbfT3/fB0YCwpg5Uq9zvXrYWQkwhVXwJo1JPoGtM1HPqJpvtdeq2JizZrUeXBOOkktM0cdpS6U\nZ54xdHVphot131RXey62J57YTlGRWsV6erwf4qIiteiEUVmpbqHbb1dL0VgzXj/6US2N//vfE++D\n3FbLamxsDHX9rV6tsT9Bb6QVKXaA8sZ7wQbahgVAZ0tQpIwmWjK5U0fbtq6ujpqaGl555ZXsT9CR\nkWhU7/O9e/V7Ge1+P+MMfX30URXWgItZceQdZ1lBB7qiIjjtNHj22Wbuu08Hivvu0/VHHqn/5E8+\n6W3T2tpKLBajo8P759fKoTq42yfZH/5Q1wUfNM86S2MzLrpIn37nztXl69enrzNi92XZuFH38bGP\n9TE0pMf0V8+9667Ufaxdq5Ycf+ouqHWppUVdK4cemrwuWKn29NNh5Upv0DnsMBVSzz4LJ54Y4Ywz\n9Ols9WrvyT4SUSEye7a6it785tSA0kgkwhVXRFmzRmuyHHIIrF+/HRHtSytWFi3yxMott+g1feEL\n+tkfGJsOETjrLMO+fWoNGuvD/GmnGT70If/+xmepSEdlGlOPrYnjp6ysLGGNsKLF9tN46xAGXSxj\nvb6xFHILywaarOJuM2XiUns/7Nql1pF0c0NZVqzw0u8BYjFDLObcQI784sQKKjBqauDMM211Vo2W\nHRjQmW3/8IchlizRYE8/r72m1hdrbbGD3gMPwCc+sZc77tCJ6c47TwM4i4o0DuTQQ3Ww9nPrrRp0\neeed/QwM6FOw/8e0r0/dP1deCVdcoeXiKys1NiMWU+tKT09vov1vf6vZN5A8gJ9+OjQ0qLiwLh1I\nNvna+URE9Fre9S4VcqBF3T7wgeQBzMadFBbC5z4XSXFxZDv4iAjz5kX493/3Cq319fVx9dX9vPnN\nmnIciUS4/PIY112nQs/y8sv6HabLqAlSU+M55f11UsbC6aer+zDXYgV0xuJFAR9SecjF+YWNFSt2\nUfAw9fX1occKWoZGiycJrq+urk7UUYHMNYHG2ldzgtX9JoDJOEY+sa7QXbs84ZKJSEQtrPY3IThZ\np8ORD5wbCP3nXLQIzjknRlubFjHbs0fjNw4/HHbs2MphhyXP3xKLeXEndgw5/XSNSfjAB2I8/rjX\n1loRfvpT/RyWbVJaqpaIbdta2LZNs1qMMYmKsRs3avGwww7zMknuvVeF1nveA//6r/qjcsEFyRaY\nhQvV7bJrl5cua604v/qVWmbAe4o6/nh4+9s106eiQvvm4ou9Y9vsHf+gc8QR6nI59VQoLEwdjObM\nmZOx1oslEomEpgWeeaYX1xOJRBCJccIJ8MY36vl0dqq7LhjTXFJSkrYg3lln7WVwEN7//vA5TzJt\na2NkPvAB/SwiNDU1MTw8nFXV4mwG7OqQYJuwvvELDbtfu2jevGTRELb93LlzU1KAx+r2qaurS9p3\nmFjR702oqanJ6l6wWKHb1NTkghvHiWdZMVmJFUiueuvEimMq4MQKXgn44eFhVq1SsfLMM2qtaGrS\nddXVOiju26dujCee0OXG1HDhhZqBE4moCfXyywcSqatvfnNyTY1MXHghPPSQWk4Abr3VsHBhGyIa\nK9LQkLwvEXWr+KP3/ULl4x9Xa0RRUfJ2xx3Xxs9/ru/XrYOf/EQrsVZXewXUgkQi6dNeCwtJpPIG\nmTVrFpWVlVkNUCIyag0Df/aPiPZJfb2KlgsvnMecOcMUFxcTiUTSzkZdUVHBggU9XHVV5nMBFVqd\nnZ0J4VJcXJwS/2FdF+NxK8ybNy/rwTusb8IsK6CTJjY2jr59WK2SoBsqFzErIsKKFSuSJqwcDb9F\nzs37MzaCAbagDyzV1dkJPn/VW6vZXYCtI5+4XwAfvb29ifiT22/X1+OO09eqKhUq99/vCRWAK6+M\npQSeWWv7Oedo1o6foqKitBVrS0u13LqNv1i7Vi0WJ56oJdovvbQMkb6U7das0WDbD39YLUIlJTqI\nH3ts+HUefvhezjxTt/nqV239Bc/VcyCEuQiC8Q/+wWz58uV0dHSwZ8+etJYVP2H1a0Tg619fRFnA\nGZ9uQKyrq0tUyV2yZAkiklTUrra2NrE+Go0mFeQLO7/Z2eY9h5zXWGYGHq2SrH9AP/RQFWX+asDZ\nFLNavnx52rTgdP1ZUFAwahZbcB/2XNO1tecxkVRUVFBWVjbtK9xasdLZCYsXZ7+NfQCyk3K6RC1H\nPnFixcfQ0BDBquDBB7pHHtGnjg9+UN0fs2fHqKmZnzQb8po1Wjn1bW+rp709uaBacXExQ0ND1NfX\ns2tX8jpQ10ZNjQqI888f4cknte4JwDvfGT7YvPe9Kmz8T9KjVQJdu1ZrobS1qWXpjjtUFI0X6zbJ\nNBkjJIsVa0mxrozCwsK0A6rdrrS0lP6QMq5BoQLpB2f/XDEFBQUpT+2zZ89ODPLB6wnLqgmbeyZT\n//tnSPafR5gQmzt3btZF/vwuocbGRoaGhlKmLhiNsD7LxrKSrbCIRCIsXLiQoqIiuq1KzvI8ck0k\nEkmJC5qOVFQYVq9WsRKWyh+G37JivyYnVhz5xAXYEvT7eymvd97pmcRPOAGWLNF02ttuU6tFaanO\nuRIMfCwq0vbRqA6g/nlRsin/feed6s659todfO1rJI4fjYZ/XUVFnlCpra2NX4dQZyeiCaGhQdOg\n77hDi6397GeeyytImBAIYgdse312sAkGb2YaDIuKihLr/e0KCgoST79hGTHpqK+vT5qJd/bs2axc\nuZJIJJKwaIw28Prf19XVpQiQsJiR0QqWiUjKPWP3ExQ+Y6lXks5VYu9h/7na+ySXWAvTaO6w8vLy\ngzL+ZLy1Y6YCa9Z0AdkF2BpjAjM161QNY61H5HDkEmdZARYuXMiW+Gx7lZWV3HhjF21tmmkzb948\nurq6qK7WNFk/IpJ2EjW7ftmyZYA3I7EdJP0/6NXV1XT40nH8euaQQzQbxwaYhmGf4ktKSohGo7S1\ntSXOraCgIMmCE41Gk+b6KS8vp7e3N8WC1NTURF9fHzt27KC8vJzi4mL2799PeXl56GBUUVFBXV1d\nwsVVVVVFTU1NyuDrn3/G7qesrIySkhJqamoSYqCqqirRJ8GBra6ujuHh4aQ+C6OwsJC6ujra29sp\nKChIEm/FxcWhliB7PDvw+9fX1tZSWFhIa2srlZWVzJ07N8UNU1lZSXl5eSJeprKykqGhoSRrUElJ\nCQ0NDcRisUQflJaWsnDhwpR7aSwF2dLVe6msrKSuri7pu6iqqqK9vX1MbqggtbW1SanytbW17Nu3\nL6vYHS8YOLc1aiaShQsXjmmC0nziv19isRg1NRoXlU3MSiwWIxot9M3UrK9OrDjyibOskBpDEIl4\n5drDBgmbptnU1JSocRGWFioiFBUVJX6Qy8vLE4ODupwqEJGUNNWGhgafhQSuv34Js2cTOnPt0qVL\nE9aDJUuWJAY7+5Rrj2ctHsXFxUR9j1fpLD2FhYWJa/dbIqLRaFrTeXFxcWKQr6qqCnWPlJSUsMJf\njS5+DkuWLKGoqIiSkhIaGxupra1NepINioZ0abhB7HazZ89O2kd9fT3z5s1L9NfixYuTvoeGhgYa\n4+Yqf8CpvabCwkIKCwtTBtvGxkaqq6sTlqDGxsaESCovL2f27Nk0NDQQiUQoKiqiqKiI+vp66uvr\nQ91gYX1oCQbCZgpCDe6nuLiY5cuXZyUWgveIPW5dXV2Spcuee7oZlv0UFBQwb9485trUtIOASCRy\n0AT6igjz588HoKOjI1HsMRvLysjISMKyopOo9mCMEyuO/HJw/OdNMPYfe3BwkGg0mpJFEqwoWlVV\nxaxZs5IGlqqqqiQLRmlpaeKHLRKJEI1GqampSXpitz8moNYFOzlbJBLBGENbWxvgDSyRSITW1tZE\n+76+voTFwIqbgoKCRFu7L9CBcv/+/YlzsdaVuro6ioqK2LdvX+KpcUE8dai8vJyqqiqi0ShdXWpG\nHu2puaSkJOn4QfwiKB12MFy0aBGbNm2ipKSE2tpaRkZGkgbd2tpa2traEtarMGwWSvCYftcS6Pfl\nF0cFBQWJ86itrU2IP3tdo/XDnDlzEvU7rCCorKxMSUkWkdA0ZUskEqGuri7p3FasWJGY9Tt4TZaK\nioq0lqmxYPdZXV1NNBqlpKQk4/7C+jod0z2wNd/YB6m2trZENuDixamWocLCQoaHhxO/Ka+99hqV\nlXVEIr387W/d8arcLmbFkV9mvFipr69PPOFa7CBohUVlZWViWTAmw2I/FxYWsnDhwpQnWf8T6KJF\ni0J/9P37FBGWL1+ecFXYtkuXLkVEEqIlWGo9uJ+SkhIWLlxIWVkZ0WiU0tJSRCSxzLqLamtr2bRp\nE8aYxJNxJBJJWJHCxMfixYsxxrB169akuJawtkuWLGFoaCgRq9HU1DTqzNQiwuLFixOpyP7CY6Df\nU0VFxahxQLmIjwhmsaSrMht2TOviySb2J4xgfMlo2TqZApXHe+yxWrIcU4ujj4YnnpjP7NmphQXr\n6upobW2lsbGRV155hZGREZYs2U1xMVx6qbaprw+vR+RwTBYy3UpOi8iVwDVAA/A88AFjzDMh7Y4B\nnnvuuec45phjcnLsjo6OrAbPXGAzPTI9lY+F+++/n3PPPZe+vr4kN5HFGMO+fftS3CnTjfvvv58L\nL7ww36cxbjo7OykpKaGkpOSAvrODvR9yycHcFz09PQwNDTEyMpJVin1bWxv9/f10dXXz17/CwEAh\nxx3XyNy5/Tz22MMHbT/kmoP5nsgV69atY5VO/rbKGLNuoo83rWJWRORdwNeATwFHo2LlERFJnxaT\nQ6qrqydFqIDGEeRKqID+8wXjWfxYC8x0Fiqg/XAwU1VVlZTpNN7v7GDvh1xyMPdFRUUF1dXVWdcC\nqq2tZf78+TQ1LeO885bxnvc0cdhhZdTV1RzU/ZBrXF9MPtNKrABXA3cYY+42xrwE/AvQC1yWeTOH\nw+FwWIKucYcj30wbsSIiRcAqIDErj1Ef12+BN+brvBwOh8PhcBwY00asAHVAARAsC7sLjV9xOBwO\nh8NxEDKTs4FKAV588cV8n8eUYP/+/axbN+ExUlMe1w+K6wcP1xeK6wcP1xdJY+eklHaeNtlAcTdQ\nL3CuMeZB3/LvA1FjzNpA+4uA+yb1JB0Oh8PhmF5cbIz5wUQfZNpYVowxQyLyHHAa8CCAaBrEacAt\nIZs8AlwMbAFSZ8ZzOBwOh8ORjlJgCTqWTjjTxrICICLnA99Hs4CeRrODzgNeZ4zZk8dTczgcDofD\nMU6mjWUFwBjz43hNlRuBeuB/gDOcUHE4HA6H4+BlWllWHA6Hw+FwTD+mU+qyw+FwOByOaYgTKw6H\nw+FwOKY0M1asiMiVItIsIn0i8mcROTbf55QrRORjIvK0iHSKyC4R+bmIrAhpd6OI7BCRXhF5TEQO\nCawvEZHbRGSviHSJyH+KyNzJu5LcIiLXiciIiNwUWD4j+kFEGkXknvh19IrI8/EJPf1tpn1fiEhE\nRD4jIq/Gr3OziHw8pN206gsROUlEHhSRlvj/wTtC2hzwNYtIjYjcJyL7RaRdRO4UkYqJvr6xkKkv\nRKRQRL4kIutFpDve5i4RmRfYx0HfF9ncE762t8fbfDCwfFL6YUaKFcnzhIeTwEnA/wOOB94CFAGP\nikiZbSAiHwWuAt4LHAf0oH1Q7NvP14G3AecCJwONwE8n4wJyjagYfS/6XfuXz4h+EJFq4ElgADgD\nOBT4MNDuazMj+gK4DngfcAXwOuBa4FoRuco2mKZ9UYEmHVwBpAQr5vCaf4DeX6fF254M3JHLC8kB\nmfqiHDgKuAEdH9YCK4FfBNpNh77IeE9YRGQtOp60hKyenH4wxsy4P+DPwDd8nwXYDlyb73OboOut\nA0aAE33LdgBX+z5XAX3A+b7PA8BaX5uV8f0cl+9rGuP1zwI2Am8G/gu4aab1A/BF4A+jtJkpffFL\n4NuBZf8J3D1T+iJ+nu/I9fePDkgjwNG+NmcAw0BDvq87274IabMaiAELpmtfpOsHYD6wNX49zcAH\nA/fIpPTDjLOsyMyc8LAaVc37AERkKTpfkr8POoG/4PXBajS13d9mI3rTHmz9dBvwS2PM7/wLZ1g/\nvB14VkR+LOoaXCci/2xXzrC++BNwmogsBxCRI4E3AQ/FP8+kvgByes1rgHZjzF99u//vaPJ/AAAH\nmklEQVQt+vtz/ESd/yRgf0M74p9XMQP6QkQEuBv4sjEmbG6aSeuHaVVnJUsyTXi4cvJPZ2KJ32xf\nB54wxmyIL25Ab5RMkz7WA4PxH6x0baY8InIBatJdHbJ6xvQDsAx4P+r+/Bxq5r9FRAaMMfcws/ri\ni+gT4UsiEkPd4dcbY34YXz+T+sKSq2tuAHb7VxpjYiKyj4OzXxCREvSe+YExpju+uIGZ0RfXodd5\na5r1k9YPM1GszDS+CRyGPjnOKERkASrU3mKMGcr3+eSZCPC0MeYT8c/Pi8jr0WrP9+TvtPLCu4CL\ngAuADaiY/YaI7IgLN4cD0GBb4CeokLsiz6czqYjIKuCDaNxO3plxbiBgL+p7rA8srwdaJ/90Jg4R\nuRU4CzjFGLPTt6oVjdPJ1AetQLGIVGVoM9VZBcwB1onIkIgMAX8H/KuIDKLqfyb0A8BOIGjGfRFY\nFH8/U+4JgC8DXzTG/MQY84Ix5j7gZuBj8fUzqS8subrmViCYCVIAzOYg6xefUFkIvNVnVYGZ0Rcn\nor+f23y/n4uBm0Tk1XibSeuHGSdW4k/YdsJDIGnCwz/l67xyTVyovBM41Riz1b/OGNOM3iT+PqhC\n/Ye2D55DA6D8bVaig9tTE3ryueO3wBHok/OR8b9ngXuBI40xrzIz+gE0Eyjo5lwJvAYz6p4AzfaI\nBZaNEP89nGF9AeT0mp8CqkXE/zR+GiqE/jJR559rfEJlGXCaMaY90GQm9MXdwBvwfjuPRIOwv4wG\nyMJk9kO+I5Dz8QecD/QCl6Cpi3cAbcCcfJ9bjq7vm2hK6kmowrV/pb4218av+e3ogP4A8DJQHNhP\nM3AKaqV4Evhjvq/vAPsmmA00I/oBjdkZQK0HTagbpAu4YAb2xffQAMCz0CfFtahP/fPTuS/QNNUj\nUfE+Avxb/PPCXF4zGqj8LHAs6n7eCNyT7+vPti/Q8IhfoEL+CJJ/Q4umU1+Mdk+EtE/KBprMfsh7\nZ+XxS7oC2IKm5j0FrM73OeXw2kbQJ8fg3yWBdp9GlXIvOs33IYH1JWi9lr3owPYTYG6+r+8A++Z3\n+MTKTOoHdHBeH7/OF4DLQtpM+76I/0DfFP+B7UEH5BuAwuncF6gLNOy34bu5vGY0c+ZeYD/60PRt\noDzf159tX6ACNrjOfj55OvVFNvdEoP2rpIqVSekHN5Ghw+FwOByOKc2Mi1lxOBwOh8NxcOHEisPh\ncDgcjimNEysOh8PhcDimNE6sOBwOh8PhmNI4seJwOBwOh2NK48SKw+FwOByOKY0TKw6Hw+FwOKY0\nTqw4HA6Hw+GY0jix4nA4HA6HY0rjxIrD4Zh0RGSxiIyIyBsm8BjfE5GfTdT+HQ7H5OHEisPhGDNx\nITAiIrH4q33/UJa72Ao0AP87gafpcDimCYX5PgGHw3HQ8hvgPehU75aBbDY0OinZ7gk4J4fDMQ1x\nlhWHwzFeBowxe4wxu31/+wHilpZ/EZGHRKRXRF4RkXPthkE3kIhUi8h9IrI73n6jiPyjr/3rReTx\n+Lq9InKHiFT41kdE5CYRaReRPSLyJZJFFKJ8TEReje/nr/5zcjgcUxcnVhwOx0RxIzpd/BuA+4Af\nishK33r/lO+fBV4HnBF/fT865TwiUg48ArQBq4DzgLeg09JbrgEuQS09JwKzgbWB8/l34N3Ae4HD\ngJuBe0TkpAO7TIfDMdGIWmMdDocje0Tke+jA3+9bbIDPG2O+KCIjwDeNMVf5tnkKeM4Yc5WILAaa\ngaOMMetF5BfAHmPMP4cc63LgC8ACY0x/fNmZwC+BecaYPSLSAnzNGHNTfH1BfP/PGmP+r4gUA/uA\n04wxf/Ht+9tAmTHm3TnrHIfDkXNczIrD4RgvvwP+hWR3yz7f+z8H2j8FHJlmX/8B/FREVgGPAg8Y\nY56Kr3sd8LwVKnGeRC3DK0VkAJgHPG1XGmNiIvKsr/0hQDnwmIj4z7cI+Gv6S3Q4HFMBJ1YcDsd4\n6THGNOdiR8aYh0VkEXAWcDrwuIjcaoy5Nhf7B2bFX88CdgTWZRUU7HA48oeLWXE4HBPFmpDPL/o+\nJ/mgjTFtxph7jDGXAP+GxpYQ3+ZIESnzNT8RiAEvGWM6gZ3A8XZl3A20ytd+AypKFhtjXg38tYz/\nEh0Ox2TgLCsOh2O8lIhIfWDZsDGmLf7+70XkOeAJNL7lWOBSX9uEO0ZEbgCeA14ASoGzUYEBGpz7\naeCueLu5wC3A3caYvfE23wCuE5HNwEvAh4Bqu39jTLeIfBW4OS5kngCiwJuA/caYe8bdCw6HY8Jx\nYsXhcIyX/0OqS2UjmmkD8CngAuA21PJxgTFmo6+t37IyCHweWAL0AX8ELgQwxvSJyBmoIHka6AX+\nE/iwb/uvoUXmvg+MAN8FfoYKEuL7+YSI7AauA5YBHcC6+HEdDscUxmUDORyOnBPPBjrHGPNgvs/F\n4XAc/LiYFYfD4XA4HFMaJ1YcDsdE4Ey2DocjZzg3kMPhcDgcjimNs6w4HA6Hw+GY0jix4nA4HA6H\nY0rjxIrD4XA4HI4pjRMrDofD4XA4pjROrDgcDofD4ZjSOLHicDgcDodjSuPEisPhcDgcjimNEysO\nh8PhcDimNP8fbIvRLU9KcTUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22229823240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gym import wrappers\n",
    "    \n",
    "env = gym.make('CartPole-v1')\n",
    "#env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\n",
    "\n",
    "test,train, mainQN, saver, num_episodes = test_and_train_qnetwork(memory_size=10000,\\\n",
    "                                     train_episodes=4000,\\\n",
    "                                           gamma=0.999,\\\n",
    "                                           explore_start=1.,\\\n",
    "                                           explore_stop=0.0,\\\n",
    "                                           decay_rate=0.00002,\\\n",
    "                                           hidden_layers=1,\\\n",
    "                                           hidden_size=64,\\\n",
    "                                           learning_rate=0.001,\\\n",
    "                                           batch_size=64,\\\n",
    "                                           alpha=0.1,\\\n",
    "                                           verbose=True)\n",
    "print('test=',str(test))\n",
    "print(train)\n",
    "print('number of episodes=',str(num_episodes))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 23:50:18,379] Making new env: CartPole-v0\n",
      "[2017-05-22 23:50:18,382] Clearing 4 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints\\cartpole.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 23:50:18,392] Restoring parameters from checkpoints\\cartpole.ckpt\n",
      "[2017-05-22 23:50:18,484] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000000.mp4\n",
      "[2017-05-22 23:50:21,927] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000001.mp4\n",
      "[2017-05-22 23:50:25,823] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000008.mp4\n",
      "[2017-05-22 23:50:30,765] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000027.mp4\n",
      "[2017-05-22 23:50:37,157] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000064.mp4\n",
      "[2017-05-22 23:50:45,686] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-1\\openaigym.video.0.2564.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.9999999998906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Monitor.close of <Monitor<TimeLimit<CartPoleEnv<CartPole-v0>>>>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "env = wrappers.Monitor(env, '/tmp/cartpole-experiment-1',force=True)\n",
    "avg_test_rewards = test_q_network(mainQN, saver, test_episodes=200, render=False)\n",
    "print(avg_test_rewards)\n",
    "env.close\n",
    "#     if verbose:\n",
    "#         print('average test reward = ', avg_test_rewards)\n",
    "    \n",
    "#     return avg_test_rewards, avg_train_rewards, mainQN, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 23:52:13,462] Finished writing results. You can upload them to the scoreboard via gym.upload('D:\\\\tmp\\\\cartpole-experiment-1')\n",
      "[2017-05-22 23:52:13,463] [CartPole-v0] Uploading 200 episodes of training data\n",
      "[2017-05-22 23:52:14,715] [CartPole-v0] Uploading videos of 6 training episodes (79922 bytes)\n",
      "[2017-05-22 23:52:15,216] [CartPole-v0] Creating evaluation object from /tmp/cartpole-experiment-1 with learning curve and training video\n",
      "[2017-05-22 23:52:15,550] \n",
      "****************************************************\n",
      "You successfully uploaded your evaluation on CartPole-v0 to\n",
      "OpenAI Gym! You can find it at:\n",
      "\n",
      "    https://gym.openai.com/evaluations/eval_XidnJOdDQlK8HQV5xk1QRA\n",
      "\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "gym.upload('/tmp/cartpole-experiment-1', api_key='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 21:43:41,579] Making new env: CartPole-v0\n",
      "[2017-05-22 21:43:41,580] Clearing 3 monitor files from previous run (because force=True was provided)\n",
      "[2017-05-22 21:43:41,585] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-2\\openaigym.video.0.2340.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03158918  0.01501189 -0.04439814  0.02392597]\n",
      "[-0.03128894 -0.17944616 -0.04391962  0.30227684]\n",
      "[-0.03487786  0.01627333 -0.03787408 -0.00392752]\n",
      "[-0.0345524   0.21191741 -0.03795263 -0.3083155 ]\n",
      "[-0.03031405  0.0173562  -0.04411894 -0.02783925]\n",
      "[-0.02996692  0.21308217 -0.04467573 -0.33410928]\n",
      "[-0.02570528  0.40881056 -0.05135791 -0.64053921]\n",
      "[-0.01752907  0.60460946 -0.0641687  -0.9489429 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 21:43:43,488] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-2\\openaigym.video.0.2340.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00543688  0.80053387 -0.08314756 -1.26107733]\n",
      "[ 0.0105738   0.99661498 -0.1083691  -1.57860008]\n",
      "[ 0.0305061   1.19284804 -0.1399411  -1.90302116]\n",
      "[ 0.05436306  1.38917853 -0.17800153 -2.2356465 ]\n",
      "Episode finished after 12 timesteps\n",
      "[ 0.01721082 -0.01583853 -0.02459659  0.00499927]\n",
      "[ 0.01689405 -0.21059925 -0.02449661  0.28982131]\n",
      "[ 0.01268206 -0.01513671 -0.01870018 -0.01048581]\n",
      "[ 0.01237933 -0.20998555 -0.0189099   0.27623882]\n",
      "[ 0.00817962 -0.40483268 -0.01338512  0.56289808]\n",
      "[  8.29628614e-05  -5.99764277e-01  -2.12716057e-03   8.51334169e-01]\n",
      "[-0.01191232 -0.79485716  0.01489952  1.14334745]\n",
      "[-0.02780947 -0.99017059  0.03776647  1.44066537]\n",
      "[-0.04761288 -0.7955336   0.06657978  1.16001877]\n",
      "[-0.06352355 -0.99145678  0.08978015  1.47281241]\n",
      "[-0.08335269 -0.79753982  0.1192364   1.2094684 ]\n",
      "[-0.09930348 -0.60414221  0.14342577  0.95640423]\n",
      "[-0.11138633 -0.80087136  0.16255386  1.29049072]\n",
      "[-0.12740375 -0.99764366  0.18836367  1.6293388 ]\n",
      "Episode finished after 14 timesteps\n",
      "[ 0.00567666 -0.00429267 -0.02422598 -0.0220614 ]\n",
      "[ 0.0055908   0.19116817 -0.02466721 -0.32228838]\n",
      "[ 0.00941417  0.38663254 -0.03111298 -0.62264717]\n",
      "[ 0.01714682  0.5821748  -0.04356592 -0.92496434]\n",
      "[ 0.02879031  0.3876675  -0.06206521 -0.64628455]\n",
      "[ 0.03654366  0.58359685 -0.0749909  -0.95784816]\n",
      "[ 0.0482156   0.38955898 -0.09414786 -0.68963604]\n",
      "[ 0.05600678  0.58585263 -0.10794058 -1.01041114]\n",
      "[ 0.06772383  0.39232375 -0.12814881 -0.75348026]\n",
      "[ 0.07557031  0.58895772 -0.14321841 -1.08358537]\n",
      "[ 0.08734946  0.78564897 -0.16489012 -1.41756401]\n",
      "[ 0.10306244  0.59290733 -0.1932414  -1.18063128]\n",
      "Episode finished after 12 timesteps\n",
      "[ 0.046459   -0.00798891 -0.0432039  -0.03734576]\n",
      "[ 0.04629922  0.1877251  -0.04395081 -0.34334084]\n",
      "[ 0.05005372 -0.00674493 -0.05081763 -0.06483487]\n",
      "[ 0.04991882 -0.20110285 -0.05211433  0.2113917 ]\n",
      "[ 0.04589677 -0.005276   -0.04788649 -0.09726445]\n",
      "[ 0.04579125 -0.19968009 -0.04983178  0.17993415]\n",
      "[ 0.04179764 -0.00388178 -0.0462331  -0.12804321]\n",
      "[ 0.04172001  0.19187094 -0.04879396 -0.43494623]\n",
      "[ 0.04555743  0.38764848 -0.05749289 -0.74260275]\n",
      "[ 0.0533104   0.58351491 -0.07234494 -1.05281056]\n",
      "[ 0.06498069  0.77951769 -0.09340115 -1.36729654]\n",
      "[ 0.08057105  0.58568073 -0.12074709 -1.10522846]\n",
      "[ 0.09228466  0.78216544 -0.14285165 -1.43322304]\n",
      "[ 0.10792797  0.5890655  -0.17151612 -1.18837919]\n",
      "[ 0.11970928  0.78594449 -0.1952837  -1.52954336]\n",
      "Episode finished after 15 timesteps\n",
      "[ 0.01739391 -0.02319332 -0.02043269 -0.02869286]\n",
      "[ 0.01693004  0.1722156  -0.02100654 -0.32775184]\n",
      "[ 0.02037435  0.36763022 -0.02756158 -0.62698457]\n",
      "[ 0.02772696  0.17290359 -0.04010127 -0.34310764]\n",
      "[ 0.03118503  0.36857242 -0.04696343 -0.64816154]\n",
      "[ 0.03855648  0.17413512 -0.05992666 -0.37062933]\n",
      "[ 0.04203918 -0.02008651 -0.06733924 -0.09742775]\n",
      "[ 0.04163745  0.17593271 -0.0692878  -0.41057295]\n",
      "[ 0.0451561   0.37196503 -0.07749926 -0.72427021]\n",
      "[ 0.05259541  0.17799554 -0.09198466 -0.45695127]\n",
      "[ 0.05615532  0.37428936 -0.10112369 -0.77715259]\n",
      "[ 0.0636411   0.18069269 -0.11666674 -0.51792082]\n",
      "[ 0.06725496  0.37724734 -0.12702516 -0.84497083]\n",
      "[ 0.0747999   0.18406619 -0.14392457 -0.59477881]\n",
      "[ 0.07848123 -0.00877928 -0.15582015 -0.35066932]\n",
      "[ 0.07830564 -0.20138175 -0.16283353 -0.11089178]\n",
      "[ 0.07427801 -0.39384133 -0.16505137  0.126317  ]\n",
      "[ 0.06640118 -0.58626143 -0.16252503  0.36271956]\n",
      "[ 0.05467595 -0.38924767 -0.15527064  0.02352106]\n",
      "[ 0.046891   -0.1922793  -0.15480022 -0.31384349]\n",
      "[ 0.04304541 -0.38489626 -0.16107709 -0.07370263]\n",
      "[ 0.03534749 -0.57738644 -0.16255114  0.16414285]\n",
      "[ 0.02379976 -0.76985343 -0.15926828  0.40145772]\n",
      "[ 0.00840269 -0.57287323 -0.15123913  0.06309986]\n",
      "[-0.00305478 -0.37594289 -0.14997713 -0.27321875]\n",
      "[-0.01057363 -0.56864216 -0.15544151 -0.03134273]\n",
      "[-0.02194648 -0.37167227 -0.15606836 -0.36875134]\n",
      "[-0.02937992 -0.56427228 -0.16344339 -0.12906066]\n",
      "[-0.04066537 -0.75672154 -0.1660246   0.10792733]\n",
      "[-0.0557998  -0.55965776 -0.16386605 -0.23219106]\n",
      "[-0.06699295 -0.75210532 -0.16850988  0.00465192]\n",
      "[-0.08203506 -0.55501781 -0.16841684 -0.33609973]\n",
      "[-0.09313542 -0.35794955 -0.17513883 -0.67680055]\n",
      "[-0.10029441 -0.16088257 -0.18867484 -1.01910703]\n",
      "[-0.10351206  0.03618421 -0.20905698 -1.36460325]\n",
      "Episode finished after 35 timesteps\n",
      "[ 0.02298201 -0.00600255 -0.0044421  -0.04751785]\n",
      "[ 0.02286196  0.18918281 -0.00539245 -0.34159898]\n",
      "[ 0.02664562 -0.005862   -0.01222443 -0.05062139]\n",
      "[ 0.02652838  0.18943308 -0.01323686 -0.34713602]\n",
      "[ 0.03031704  0.38474078 -0.02017958 -0.64396343]\n",
      "[ 0.03801186  0.1899058  -0.03305885 -0.35770285]\n",
      "[ 0.04180997 -0.00473095 -0.04021291 -0.07562478]\n",
      "[ 0.04171535  0.19094373 -0.0417254  -0.38071892]\n",
      "[ 0.04553423 -0.00356165 -0.04933978 -0.10147851]\n",
      "[ 0.04546299 -0.19794304 -0.05136935  0.17523874]\n",
      "[ 0.04150413 -0.00212499 -0.04786458 -0.13319683]\n",
      "[ 0.04146163  0.19364874 -0.05052851 -0.44058791]\n",
      "[ 0.04533461 -0.00072308 -0.05934027 -0.16425136]\n",
      "[ 0.04532015  0.19519592 -0.0626253  -0.4750484 ]\n",
      "[ 0.04922407  0.00101164 -0.07212627 -0.20274278]\n",
      "[ 0.0492443  -0.19300867 -0.07618112  0.06634427]\n",
      "[ 0.04538413  0.00311816 -0.07485424 -0.2493683 ]\n",
      "[ 0.04544649 -0.19085943 -0.0798416   0.01879671]\n",
      "[ 0.0416293  -0.38475098 -0.07946567  0.28525902]\n",
      "[ 0.03393428 -0.57865496 -0.07376049  0.55185881]\n",
      "[ 0.02236118 -0.38257882 -0.06272331  0.23687839]\n",
      "[ 0.0147096  -0.18661945 -0.05798574 -0.07491121]\n",
      "[ 0.01097722 -0.38086425 -0.05948397  0.19892802]\n",
      "[ 0.00335993 -0.18494418 -0.05550541 -0.11191028]\n",
      "[ -3.38953218e-04  -3.79228664e-01  -5.77436144e-02   1.62757421e-01]\n",
      "[-0.00792353 -0.57347848 -0.05448847  0.43667932]\n",
      "[-0.0193931  -0.76778849 -0.04575488  0.71170008]\n",
      "[-0.03474887 -0.962248   -0.03152088  0.98963683]\n",
      "[-0.05399383 -1.15693416 -0.01172814  1.27225541]\n",
      "[-0.07713251 -0.96166451  0.01371697  0.97592308]\n",
      "[-0.0963658  -1.15696773  0.03323543  1.27288301]\n",
      "[-0.11950515 -0.96228527  0.05869309  0.99079001]\n",
      "[-0.13875086 -1.15814155  0.07850889  1.3013144 ]\n",
      "[-0.16191369 -0.96409867  0.10453518  1.03420454]\n",
      "[-0.18119566 -0.77051035  0.12521927  0.77608461]\n",
      "[-0.19660587 -0.57731262  0.14074096  0.52527537]\n",
      "[-0.20815212 -0.38442252  0.15124647  0.28004245]\n",
      "[-0.21584057 -0.19174526  0.15684732  0.03862308]\n",
      "[-0.21967548 -0.38872801  0.15761978  0.37639442]\n",
      "[-0.22745004 -0.19615479  0.16514767  0.13726396]\n",
      "[-0.23137313 -0.00373597  0.16789295 -0.09910422]\n",
      "[-0.23144785  0.1886317   0.16591086 -0.33446945]\n",
      "[-0.22767522  0.38105168  0.15922147 -0.57058173]\n",
      "[-0.22005419  0.18409729  0.14780984 -0.23227348]\n",
      "[-0.21637224  0.37683205  0.14316437 -0.47492522]\n",
      "[-0.2088356   0.56967292  0.13366586 -0.71928053]\n",
      "[-0.19744214  0.37297963  0.11928025 -0.38769151]\n",
      "[-0.18998255  0.17638435  0.11152642 -0.05990865]\n",
      "[-0.18645486  0.36974522  0.11032825 -0.31542719]\n",
      "[-0.17905996  0.17323881  0.10401971  0.00991103]\n",
      "[-0.17559518 -0.02320922  0.10421793  0.33351699]\n",
      "[-0.17605937 -0.21964817  0.11088827  0.6571613 ]\n",
      "[-0.18045233 -0.41612474  0.12403149  0.98260046]\n",
      "[-0.18877482 -0.22286329  0.1436835   0.73130709]\n",
      "[-0.19323209 -0.02998838  0.15830964  0.48707374]\n",
      "[-0.19383186 -0.22694831  0.16805112  0.82516809]\n",
      "[-0.19837082 -0.42392091  0.18455448  1.16563956]\n",
      "[-0.20684924 -0.23161665  0.20786727  0.93603322]\n",
      "Episode finished after 58 timesteps\n",
      "[-0.03783027 -0.01103463  0.01544723 -0.04519796]\n",
      "[-0.03805097  0.18386244  0.01454327 -0.3329674 ]\n",
      "[-0.03437372  0.37877441  0.00788392 -0.62102886]\n",
      "[-0.02679823  0.57378538 -0.00453665 -0.91121837]\n",
      "[-0.01532252  0.76896842 -0.02276102 -1.2053237 ]\n",
      "[  5.68478771e-05   5.74147910e-01  -4.68674957e-02  -9.19859785e-01]\n",
      "[ 0.01153981  0.37968968 -0.06526469 -0.64226673]\n",
      "[ 0.0191336   0.18553524 -0.07811003 -0.37082931]\n",
      "[ 0.0228443   0.381675   -0.08552661 -0.68708289]\n",
      "[ 0.0304778   0.18783781 -0.09926827 -0.42250404]\n",
      "[ 0.03423456  0.38421569 -0.10771835 -0.74475766]\n",
      "[ 0.04191887  0.58064625 -0.1226135  -1.06930371]\n",
      "[ 0.0535318   0.77715756 -0.14399958 -1.39781579]\n",
      "[ 0.06907495  0.5840897  -0.17195589 -1.15340112]\n",
      "[ 0.08075674  0.78098553 -0.19502392 -1.49469538]\n",
      "Episode finished after 15 timesteps\n",
      "[-0.04240573 -0.01728493  0.0278611  -0.00057409]\n",
      "[-0.04275143 -0.21279514  0.02784961  0.30076751]\n",
      "[-0.04700734 -0.01808098  0.03386497  0.01699625]\n",
      "[-0.04736895 -0.21367181  0.03420489  0.32016869]\n",
      "[-0.05164239 -0.01905326  0.04060826  0.0384659 ]\n",
      "[-0.05202346  0.17546355  0.04137758 -0.24113323]\n",
      "[-0.04851419 -0.02022429  0.03655492  0.06430883]\n",
      "[-0.04891867 -0.21585076  0.03784109  0.36829725]\n",
      "[-0.05323569 -0.02128636  0.04520704  0.0877822 ]\n",
      "[-0.05366141 -0.21702617  0.04696268  0.39437829]\n",
      "[-0.05800194 -0.02260098  0.05485025  0.11686399]\n",
      "[-0.05845396 -0.21846418  0.05718753  0.42633485]\n",
      "[-0.06282324 -0.02419689  0.06571423  0.15221427]\n",
      "[-0.06330718 -0.22019525  0.06875851  0.46488331]\n",
      "[-0.06771108 -0.02610884  0.07805618  0.19464069]\n",
      "[-0.06823326 -0.22225554  0.08194899  0.51089011]\n",
      "[-0.07267837 -0.02837781  0.09216679  0.24511553]\n",
      "[-0.07324593 -0.22468703  0.0970691   0.56538824]\n",
      "[-0.07773967 -0.4210272   0.10837687  0.8870056 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-22 21:43:46,601] Starting new video recorder writing to D:\\tmp\\cartpole-experiment-2\\openaigym.video.0.2340.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08616021 -0.61744012  0.12611698  1.21169691]\n",
      "[-0.09850901 -0.42415134  0.15035092  0.96104664]\n",
      "[-0.10699204 -0.62093918  0.16957185  1.29693513]\n",
      "[-0.11941082 -0.42832723  0.19551055  1.06177668]\n",
      "Episode finished after 23 timesteps\n",
      "[ 0.01929627 -0.04759821  0.01128067 -0.03405203]\n",
      "[ 0.0183443   0.14736017  0.01059963 -0.32315455]\n",
      "[ 0.02129151 -0.0479111   0.00413654 -0.02714787]\n",
      "[ 0.02033328 -0.24309212  0.00359359  0.26683731]\n",
      "[ 0.01547144 -0.43826518  0.00893033  0.56065151]\n",
      "[ 0.00670614 -0.63351132  0.02014336  0.85613453]\n",
      "[-0.00596409 -0.82890187  0.03726605  1.15508265]\n",
      "[-0.02254213 -0.63428515  0.06036771  0.87431393]\n",
      "[-0.03522783 -0.83017359  0.07785398  1.18534868]\n",
      "[-0.0518313  -1.0262142   0.10156096  1.50138481]\n",
      "[-0.07235558 -0.83246154  0.13158865  1.24206102]\n",
      "[-0.08900482 -1.02900389  0.15642987  1.57290131]\n",
      "[-0.10958489 -1.22560767  0.1878879   1.91000915]\n",
      "Episode finished after 13 timesteps\n",
      "[-0.02936307  0.04969574  0.03889237  0.02069656]\n",
      "[-0.02836916  0.24423898  0.0393063  -0.25946615]\n",
      "[-0.02348438  0.04857858  0.03411698  0.04535083]\n",
      "[-0.02251281 -0.14701555  0.03502399  0.34859975]\n",
      "[-0.02545312  0.0475912   0.04199599  0.06716358]\n",
      "[-0.02450129 -0.1481069   0.04333926  0.37279511]\n",
      "[-0.02746343  0.04637344  0.05079516  0.09408627]\n",
      "[-0.02653596 -0.14943836  0.05267689  0.40235249]\n",
      "[-0.02952473 -0.34526634  0.06072394  0.71116685]\n",
      "[-0.03643006 -0.15103551  0.07494727  0.43819947]\n",
      "[-0.03945077  0.04295005  0.08371126  0.17005185]\n",
      "[-0.03859177 -0.15326411  0.0871123   0.48792483]\n",
      "[-0.04165705 -0.34950017  0.0968708   0.8067414 ]\n",
      "[-0.04864705 -0.54580693  0.11300562  1.12825652]\n",
      "[-0.05956319 -0.35233186  0.13557076  0.87304797]\n",
      "[-0.06660983 -0.15928798  0.15303171  0.62587492]\n",
      "[-0.06979559 -0.35617751  0.16554921  0.96257371]\n",
      "[-0.07691914 -0.55309028  0.18480069  1.30235404]\n",
      "Episode finished after 18 timesteps\n",
      "[ 0.0288528  -0.01424239  0.03316189 -0.01845229]\n",
      "[ 0.02856796 -0.20982384  0.03279284  0.28450639]\n",
      "[ 0.02437148 -0.40539778  0.03848297  0.58734895]\n",
      "[ 0.01626352 -0.21083531  0.05022995  0.30703252]\n",
      "[ 0.01204682 -0.40663569  0.0563706   0.61512405]\n",
      "[ 0.0039141  -0.21234479  0.06867308  0.3407148 ]\n",
      "[ -3.32792617e-04  -4.08373210e-01   7.54873785e-02   6.54238373e-01]\n",
      "[-0.00850026 -0.60446056  0.08857215  0.96970398]\n",
      "[-0.02058947 -0.80065265  0.10796623  1.28884471]\n",
      "[-0.03660252 -0.60705694  0.13374312  1.03182245]\n",
      "[-0.04874366 -0.41394302  0.15437957  0.78394177]\n",
      "[-0.05702252 -0.22124128  0.1700584   0.54353435]\n",
      "[-0.06144735 -0.41829361  0.18092909  0.88460562]\n",
      "[-0.06981322 -0.61534984  0.1986212   1.22826854]\n",
      "Episode finished after 14 timesteps\n",
      "[ 0.02402884  0.03851564 -0.01227161 -0.01467831]\n",
      "[ 0.02479915  0.23381141 -0.01256518 -0.31120768]\n",
      "[ 0.02947538  0.4291101  -0.01878933 -0.60782666]\n",
      "[ 0.03805758  0.62448964 -0.03094587 -0.90636797]\n",
      "[ 0.05054737  0.42980005 -0.04907323 -0.62357004]\n",
      "[ 0.05914337  0.23539637 -0.06154463 -0.34673731]\n",
      "[ 0.0638513   0.04120137 -0.06847937 -0.07407901]\n",
      "[ 0.06467533  0.23723483 -0.06996095 -0.3875572 ]\n",
      "[ 0.06942002  0.43327651 -0.0777121  -0.70145211]\n",
      "[ 0.07808555  0.23931285 -0.09174114 -0.43420909]\n",
      "[ 0.08287181  0.43560574 -0.10042532 -0.7543443 ]\n",
      "[ 0.09158393  0.2420011  -0.11551221 -0.49487597]\n",
      "[ 0.09642395  0.04868144 -0.12540973 -0.24071404]\n",
      "[ 0.09739758  0.24535093 -0.13022401 -0.57017536]\n",
      "[ 0.10230459  0.05227259 -0.14162751 -0.32118782]\n",
      "[ 0.10335005  0.24909747 -0.14805127 -0.65496854]\n",
      "[ 0.108332    0.44593667 -0.16115064 -0.99036556]\n",
      "[ 0.11725073  0.64280555 -0.18095795 -1.32901621]\n",
      "[ 0.13010684  0.83968967 -0.20753828 -1.67243199]\n",
      "Episode finished after 19 timesteps\n",
      "[  4.65557646e-02  -8.98761061e-05   4.96372319e-02   4.58966789e-02]\n",
      "[ 0.04655397 -0.19588716  0.05055517  0.35381822]\n",
      "[ 0.04263622 -0.39169015  0.05763153  0.66200435]\n",
      "[ 0.03480242 -0.19741543  0.07087162  0.38801036]\n",
      "[ 0.03085411 -0.00336727  0.07863182  0.11848764]\n",
      "[ 0.03078677  0.19054515  0.08100158 -0.1483883 ]\n",
      "[ 0.03459767 -0.00563769  0.07803381  0.16870951]\n",
      "[ 0.03448492  0.18828562  0.081408   -0.09837159]\n",
      "[ 0.03825063  0.38215218  0.07944057 -0.36430083]\n",
      "[ 0.04589367  0.57606054  0.07215455 -0.63091511]\n",
      "[ 0.05741488  0.77010549  0.05953625 -0.90003013]\n",
      "[ 0.07281699  0.57422948  0.04153565 -0.58924336]\n",
      "[ 0.08430158  0.37855128  0.02975078 -0.28377126]\n",
      "[ 0.09187261  0.57323655  0.02407536 -0.56692449]\n",
      "[ 0.10333734  0.76801265  0.01273687 -0.85192649]\n",
      "[ 0.11869759  0.57271939 -0.00430166 -0.55526583]\n",
      "[ 0.13015198  0.3776581  -0.01540698 -0.26394128]\n",
      "[ 0.13770514  0.18275941 -0.02068581  0.02384258]\n",
      "[ 0.14136033  0.37817181 -0.02020895 -0.27529451]\n",
      "[ 0.14892377  0.57357618 -0.02571484 -0.57428223]\n",
      "[ 0.16039529  0.378824   -0.03720049 -0.28980988]\n",
      "[ 0.16797177  0.57445612 -0.04299669 -0.59398946]\n",
      "[ 0.17946089  0.77015269 -0.05487648 -0.89990015]\n",
      "[ 0.19486395  0.96597364 -0.07287448 -1.20931499]\n",
      "[ 0.21418342  1.16195711 -0.09706078 -1.52391608]\n",
      "[ 0.23742256  1.35810798 -0.1275391  -1.84524863]\n",
      "[ 0.26458472  1.1646019  -0.16444407 -1.59474194]\n",
      "[ 0.28787676  0.97176798 -0.19633891 -1.35752216]\n",
      "Episode finished after 28 timesteps\n",
      "[ 0.04812963  0.03402094 -0.04908267  0.04699764]\n",
      "[ 0.04881005  0.22981108 -0.04814272 -0.26075841]\n",
      "[ 0.05340627  0.03540825 -0.05335789  0.01635948]\n",
      "[ 0.05411444  0.23125321 -0.0530307  -0.29266964]\n",
      "[ 0.0587395   0.03692589 -0.05888409 -0.01717216]\n",
      "[ 0.05947802  0.23284071 -0.05922753 -0.32783698]\n",
      "[ 0.06413483  0.42875365 -0.06578427 -0.63859382]\n",
      "[ 0.07270991  0.23460766 -0.07855615 -0.36733137]\n",
      "[ 0.07740206  0.04068474 -0.08590278 -0.10041583]\n",
      "[ 0.07821575 -0.15310775 -0.08791109  0.16397667]\n",
      "[ 0.0751536   0.04315549 -0.08463156 -0.15509391]\n",
      "[ 0.07601671 -0.15065916 -0.08773344  0.10973555]\n",
      "[ 0.07300353 -0.34442152 -0.08553873  0.37350068]\n",
      "[ 0.0661151  -0.14819522 -0.07806871  0.05511967]\n",
      "[ 0.06315119  0.04795428 -0.07696632 -0.26113732]\n",
      "[ 0.06411028  0.24408573 -0.08218907 -0.5770693 ]\n",
      "[ 0.06899199  0.44025767 -0.09373045 -0.89447031]\n",
      "[ 0.07779715  0.24652322 -0.11161986 -0.63266063]\n",
      "[ 0.08272761  0.44301082 -0.12427307 -0.95830605]\n",
      "[ 0.09158783  0.24975903 -0.14343919 -0.70710621]\n",
      "[ 0.09658301  0.05688476 -0.15758132 -0.46279262]\n",
      "[ 0.0977207  -0.13570023 -0.16683717 -0.22363181]\n",
      "[ 0.0950067  -0.32809353 -0.1713098   0.01212814]\n",
      "[ 0.08844483 -0.13098169 -0.17106724 -0.32933081]\n",
      "[ 0.08582519  0.06611009 -0.17765386 -0.67070209]\n",
      "[ 0.08714739  0.26319865 -0.1910679  -1.0136379 ]\n",
      "Episode finished after 26 timesteps\n",
      "[ 0.03257094 -0.04544678 -0.03526248  0.02116087]\n",
      "[ 0.031662    0.15016266 -0.03483926 -0.28243591]\n",
      "[ 0.03466526 -0.04444548 -0.04048798 -0.00094151]\n",
      "[ 0.03377635 -0.23896409 -0.04050681  0.27869707]\n",
      "[ 0.02899707 -0.0432884  -0.03493287 -0.02648145]\n",
      "[ 0.0281313   0.15231665 -0.0354625  -0.3299782 ]\n",
      "[ 0.03117763  0.347925   -0.04206206 -0.63363004]\n",
      "[ 0.03813613  0.54360769 -0.05473467 -0.93925705]\n",
      "[ 0.04900829  0.73942308 -0.07351981 -1.24862422]\n",
      "[ 0.06379675  0.93540652 -0.09849229 -1.56340061]\n",
      "[ 0.08250488  0.74159062 -0.1297603  -1.30299567]\n",
      "[ 0.09733669  0.54833124 -0.15582022 -1.05358628]\n",
      "[ 0.10830331  0.74513699 -0.17689194 -1.39084432]\n",
      "[ 0.12320605  0.94196517 -0.20470883 -1.73321487]\n",
      "Episode finished after 14 timesteps\n",
      "[ 0.02952904 -0.04796749 -0.03110508 -0.0454169 ]\n",
      "[ 0.02856969  0.14758636 -0.03201342 -0.34774921]\n",
      "[ 0.03152141  0.34314868 -0.0389684  -0.65035272]\n",
      "[ 0.03838439  0.53879113 -0.05197546 -0.95504741]\n",
      "[ 0.04916021  0.73457225 -0.07107641 -1.26359642]\n",
      "[ 0.06385165  0.93052717 -0.09634834 -1.57766554]\n",
      "[ 0.0824622   1.12665595 -0.12790165 -1.89877687]\n",
      "[ 0.10499532  1.32290997 -0.16587718 -2.22825396]\n",
      "Episode finished after 8 timesteps\n",
      "[ 0.04305961  0.0322213   0.03516371 -0.04491327]\n",
      "[ 0.04370403 -0.16338678  0.03426544  0.25865346]\n",
      "[ 0.0404363  -0.35898073  0.03943851  0.56194423]\n",
      "[ 0.03325668 -0.5546333   0.0506774   0.86678679]\n",
      "[ 0.02216402 -0.36023626  0.06801313  0.59045837]\n",
      "[ 0.01495929 -0.16612919  0.0798223   0.31995138]\n",
      "[ 0.01163671  0.0277706   0.08622133  0.05347063]\n",
      "[ 0.01219212 -0.16847505  0.08729074  0.37206326]\n",
      "[ 0.00882262  0.02530539  0.094732    0.10813022]\n",
      "[ 0.00932873  0.21895116  0.09689461 -0.15322649]\n",
      "[ 0.01370775  0.41256181  0.09383008 -0.41383777]\n",
      "[ 0.02195899  0.60623724  0.08555332 -0.67552742]\n",
      "[ 0.03408373  0.80007269  0.07204278 -0.94009518]\n",
      "[ 0.05008519  0.9941535   0.05324087 -1.20929898]\n",
      "[ 0.06996826  1.18854898  0.02905489 -1.48483361]\n",
      "[  9.37392350e-02   9.93085136e-01  -6.41779686e-04  -1.18322064e+00]\n",
      "[ 0.11360094  0.79797152 -0.02430619 -0.89073896]\n",
      "[ 0.12956037  0.60318762 -0.04212097 -0.60579474]\n",
      "[ 0.14162412  0.40867919 -0.05423687 -0.32667078]\n",
      "[ 0.1497977   0.6045297  -0.06077028 -0.63595237]\n",
      "[ 0.1618883   0.8004442  -0.07348933 -0.94713712]\n",
      "[ 0.17789718  0.60638469 -0.09243207 -0.67841997]\n",
      "[ 0.19002488  0.80266092 -0.10600047 -0.99871386]\n",
      "[ 0.20607809  0.60910339 -0.12597475 -0.74111298]\n",
      "[ 0.21826016  0.41592486 -0.14079701 -0.49058008]\n",
      "[ 0.22657866  0.61272293 -0.15060861 -0.82411376]\n",
      "[ 0.23883312  0.41994654 -0.16709088 -0.58233426]\n",
      "[ 0.24723205  0.61696669 -0.17873757 -0.92264501]\n",
      "[ 0.25957138  0.42465098 -0.19719047 -0.69103664]\n",
      "Episode finished after 29 timesteps\n",
      "[ 0.00869642 -0.0317159   0.03414911 -0.00617802]\n",
      "[ 0.0080621  -0.22731054  0.03402555  0.29708076]\n",
      "[ 0.00351589 -0.4229006   0.03996717  0.60029762]\n",
      "[-0.00494212 -0.61855822  0.05197312  0.9052969 ]\n",
      "[-0.01731328 -0.814344    0.07007906  1.21385224]\n",
      "[-0.03360016 -0.6201928   0.0943561   0.94392664]\n",
      "[-0.04600402 -0.42645997  0.11323464  0.6823196 ]\n",
      "[-0.05453322 -0.23307745  0.12688103  0.42732341]\n",
      "[-0.05919477 -0.42974663  0.1354275   0.75715876]\n",
      "[-0.0677897  -0.23672518  0.15057067  0.50997173]\n",
      "[-0.0725242  -0.43361184  0.16077011  0.84606093]\n",
      "[-0.08119644 -0.24100538  0.17769133  0.60794001]\n",
      "[-0.08601655 -0.43810806  0.18985013  0.95090553]\n",
      "[-0.09477871 -0.63520771  0.20886824  1.29672419]\n",
      "Episode finished after 14 timesteps\n",
      "[-0.00869149  0.01991773  0.00031862 -0.0106579 ]\n",
      "[ -8.29313096e-03  -1.75208792e-01   1.05461338e-04   2.82125536e-01]\n",
      "[-0.01179731  0.01991165  0.00574797 -0.01052413]\n",
      "[-0.01139907  0.2149507   0.00553749 -0.30138797]\n",
      "[ -7.10005966e-03   4.09993293e-01  -4.90269881e-04  -5.92319357e-01]\n",
      "[ 0.00109981  0.21487821 -0.01233666 -0.2997909 ]\n",
      "[ 0.00539737  0.41017381 -0.01833248 -0.5963389 ]\n",
      "[ 0.01360085  0.21531315 -0.03025925 -0.30948647]\n",
      "[ 0.01790711  0.0206351  -0.03644898 -0.02649794]\n",
      "[ 0.01831981  0.21626029 -0.03697894 -0.33045445]\n",
      "[ 0.02264502  0.41188859 -0.04358803 -0.63456562]\n",
      "[ 0.03088279  0.60759056 -0.05627934 -0.94065058]\n",
      "[ 0.0430346   0.41327046 -0.07509235 -0.66616932]\n",
      "[ 0.05130001  0.60935207 -0.08841574 -0.98151927]\n",
      "[ 0.06348705  0.80554051 -0.10804613 -1.30061281]\n",
      "[ 0.07959786  0.61194283 -0.13405838 -1.04361347]\n",
      "[ 0.09183672  0.80856539 -0.15493065 -1.37519627]\n",
      "[ 0.10800803  0.61568135 -0.18243458 -1.13470329]\n",
      "[ 0.12032165  0.81265971 -0.20512864 -1.47860626]\n",
      "Episode finished after 19 timesteps\n",
      "[-0.0225129   0.04749441 -0.0175406   0.033015  ]\n",
      "[-0.02156301 -0.14737166 -0.0168803   0.32011248]\n",
      "[-0.02451044 -0.3422492  -0.01047805  0.60742456]\n",
      "[-0.03135542 -0.14698233  0.00167044  0.31145985]\n",
      "[-0.03429507  0.04811579  0.00789964  0.01930419]\n",
      "[-0.03333276 -0.14711856  0.00828572  0.31446904]\n",
      "[-0.03627513  0.04788439  0.0145751   0.02441064]\n",
      "[-0.03531744  0.24279432  0.01506332 -0.26363828]\n",
      "[-0.03046155  0.43769806  0.00979055 -0.55153227]\n",
      "[-0.02170759  0.63268115 -0.0012401  -0.84111451]\n",
      "[-0.00905397  0.82782001 -0.01806239 -1.13418716]\n",
      "[ 0.00750243  1.02317361 -0.04074613 -1.43247982]\n",
      "[ 0.0279659   0.82857745 -0.06939573 -1.1528039 ]\n",
      "[ 0.04453745  0.63442595 -0.0924518  -0.88266358]\n",
      "[ 0.05722597  0.83067369 -0.11010508 -1.20292017]\n",
      "[ 0.07383945  0.63713394 -0.13416348 -0.94667402]\n",
      "[ 0.08658213  0.83378258 -0.15309696 -1.27832208]\n",
      "[ 0.10325778  0.64090721 -0.1786634  -1.03722783]\n",
      "[ 0.11607592  0.44855136 -0.19940796 -0.80553495]\n",
      "Episode finished after 19 timesteps\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "env = gym.make('CartPole-v1')\n",
    "env = wrappers.Monitor(env, '/tmp/cartpolev1-experiment-1',force=True)\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
